200
training  [4.4793, -4.0765, 4.4558]  w:  [0.81782872 0.33990201 0.9494294 ]
6.508157170938431  -  87.3174  =  -80.80924282906157
training  [-4.1793, -4.9218, 1.7664]  w:  [0.81782872 0.33990201 0.9494294 ]
-3.413809181450213  -  1.5257  =  -4.939509181450213
training  [-3.9429, -0.7689, 4.883]  w:  [0.81782872 0.33990201 0.9494294 ]
1.1500962394186645  -  39.7859  =  -38.63580376058133
training  [-3.5796, 1.5557, 2.6683]  w:  [0.81782872 0.33990201 0.9494294 ]
0.1346483300371566  -  45.5674  =  -45.43275166996284
training  [-3.3354, 2.2292, -1.633]  w:  [0.81782872 0.33990201 0.9494294 ]
-3.5204945682694433  -  13.3589  =  -16.879394568269444
training  [1.2096, 0.3121, 1.6238]  w:  [0.81782872 0.33990201 0.9494294 ]
2.6370124949724714  -  74.5119  =  -71.87488750502753
training  [0.7371, -3.9118, -2.5583]  w:  [0.81782872 0.33990201 0.9494294 ]
-3.1557323539625446  -  3.3358  =  -6.491532353962544
training  [-4.4792, 1.3177, -2.0449]  w:  [0.81782872 0.33990201 0.9494294 ]
-5.1568177080270114  -  4.2974  =  -9.454217708027011
training  [4.312, -3.735, 1.8018]  w:  [0.81782872 0.33990201 0.9494294 ]
3.967625336609642  -  66.5833  =  -62.61567466339035
training  [2.2866, -3.657, 0.2785]  w:  [0.81782872 0.33990201 0.9494294 ]
0.8914415990739089  -  26.0005  =  -25.10905840092609
training  [2.3784, -4.0141, -0.8841]  w:  [0.81782872 0.33990201 0.9494294 ]
-0.2586673504706657  -  14.6809  =  -14.939567350470664
training  [-4.366, -3.5797, 1.0264]  w:  [0.81782872 0.33990201 0.9494294 ]
-3.812893074719412  -  1.8713  =  -5.684193074719412
training  [3.6044, -3.3175, 2.5052]  w:  [0.81782872 0.33990201 0.9494294 ]
4.198667461260635  -  71.0139  =  -66.81523253873937
training  [4.3441, -3.0375, 0.8353]  w:  [0.81782872 0.33990201 0.9494294 ]
3.313335774572953  -  63.8979  =  -60.584564225427044
training  [4.844, -1.8252, 0.5179]  w:  [0.81782872 0.33990201 0.9494294 ]
3.8328826642985923  -  78.0461  =  -74.2132173357014
training  [3.5894, -1.8357, 0.8357]  w:  [0.81782872 0.33990201 0.9494294 ]
3.104994443390712  -  68.8838  =  -65.77880555660929
training  [2.8556, -2.8244, 0.1182]  w:  [0.81782872 0.33990201 0.9494294 ]
1.4875950197679053  -  39.5252  =  -38.03760498023209
training  [0.1338, -2.4896, -4.1741]  w:  [0.81782872 0.33990201 0.9494294 ]
-4.699807809058338  -  2.2644  =  -6.964207809058339
training  [-3.224, 3.9292, 2.1957]  w:  [0.81782872 0.33990201 0.9494294 ]
0.7835253036350214  -  72.1211  =  -71.33757469636498
training  [-1.0141, 2.0322, 4.9616]  w:  [0.81782872 0.33990201 0.9494294 ]
4.572077659862435  -  92.3427  =  -87.77062234013756
training  [-3.6607, 0.5574, -1.4547]  w:  [0.81782872 0.33990201 0.9494294 ]
-4.185499165174233  -  5.8471  =  -10.032599165174233
training  [-4.6911, -3.1557, 4.7126]  w:  [0.81782872 0.33990201 0.9494294 ]
-0.43486409011859894  -  11.2337  =  -11.6685640901186
training  [4.3914, -2.8797, -1.5355]  w:  [0.81782872 0.33990201 0.9494294 ]
1.1547483907140308  -  37.475  =  -36.32025160928597
training  [-1.9869, -4.2265, 3.8654]  w:  [0.81782872 0.33990201 0.9494294 ]
0.6083846797235188  -  15.7889  =  -15.18051532027648
training  [-2.0447, 4.138, -0.4531]  w:  [0.81782872 0.33990201 0.9494294 ]
-0.6958863390794032  -  57.936  =  -58.6318863390794
training  [-1.6706, 2.0672, -0.8657]  w:  [0.81782872 0.33990201 0.9494294 ]
-1.4855402616217939  -  32.4185  =  -33.904040261621795
training  [-0.3293, 0.5779, -2.8227]  w:  [0.81782872 0.33990201 0.9494294 ]
-2.7528359921241763  -  14.3434  =  -17.09623599212418
training  [1.482, -1.8657, -3.7435]  w:  [0.81782872 0.33990201 0.9494294 ]
-2.976321966378522  -  7.1519  =  -10.128221966378522
training  [-4.7477, -3.338, -1.9109]  w:  [0.81782872 0.33990201 0.9494294 ]
-6.83166295580677  -  0.4077  =  -7.2393629558067705
training  [3.4221, 1.225, 2.261]  w:  [0.81782872 0.33990201 0.9494294 ]
5.361731494804003  -  95.0454  =  -89.683668505196
training  [0.5903, 4.8793, 2.8287]  w:  [0.81782872 0.33990201 0.9494294 ]
4.826899099274175  -  97.4647  =  -92.63780090072582
training  [3.541, -3.2957, 1.9379]  w:  [0.81782872 0.33990201 0.9494294 ]
3.6156156860948863  -  64.3732  =  -60.75758431390511
training  [-1.5212, -2.4221, -4.902]  w:  [0.81782872 0.33990201 0.9494294 ]
-6.7214606156221475  -  0.7227  =  -7.444160615622147
training  [-0.5397, -1.032, 3.4321]  w:  [0.81782872 0.33990201 0.9494294 ]
2.4663756081363584  -  60.5921  =  -58.12572439186364
training  [-4.4576, -4.2601, 4.2233]  w:  [0.81782872 0.33990201 0.9494294 ]
-1.0838446657406564  -  6.0247  =  -7.108544665740657
training  [-3.2289, 1.841, 2.7095]  w:  [0.81782872 0.33990201 0.9494294 ]
0.557551396285259  -  54.0111  =  -53.45354860371474
training  [1.6281, -0.9761, -4.5734]  w:  [0.81782872 0.33990201 0.9494294 ]
-3.3423918227511304  -  7.8658  =  -11.20819182275113
training  [-1.6917, 4.8284, -1.2181]  w:  [0.81782872 0.33990201 0.9494294 ]
-0.8988379450427573  -  61.2837  =  -62.18253794504276
training  [3.9849, -0.9782, 2.0434]  w:  [0.81782872 0.33990201 0.9494294 ]
4.866537558857217  -  88.3402  =  -83.47366244114278
training  [-3.8184, 1.2067, 2.2951]  w:  [0.81782872 0.33990201 0.9494294 ]
-0.53360202071151  -  34.1122  =  -34.645802020711514
training  [4.8842, -3.4563, -2.7572]  w:  [0.81782872 0.33990201 0.9494294 ]
0.20186899001766356  -  23.7819  =  -23.580031009982335
training  [0.3998, -1.1865, -2.3095]  w:  [0.81782872 0.33990201 0.9494294 ]
-2.269033006224658  -  11.4246  =  -13.693633006224658
training  [2.0692, -3.3887, 1.7303]  w:  [0.81782872 0.33990201 0.9494294 ]
2.183222945244986  -  42.6881  =  -40.50487705475501
training  [4.9949, 2.5811, -0.2251]  w:  [0.81782872 0.33990201 0.9494294 ]
4.748577189918049  -  95.9901  =  -91.24152281008195
training  [-2.1215, 3.7111, 1.2372]  w:  [0.81782872 0.33990201 0.9494294 ]
0.7010207613287622  -  71.3692  =  -70.66817923867124
training  [-0.8548, -1.4922, -2.6356]  w:  [0.81782872 0.33990201 0.9494294 ]
-3.70859788971642  -  4.7821  =  -8.490697889716419
training  [-0.3516, 1.8554, -3.2288]  w:  [0.81782872 0.33990201 0.9494294 ]
-2.722412037088472  -  20.3834  =  -23.105812037088473
training  [2.6396, -2.0585, 3.2964]  w:  [0.81782872 0.33990201 0.9494294 ]
4.588751479424017  -  80.826  =  -76.23724852057597
training  [3.182, 0.3063, 2.6692]  w:  [0.81782872 0.33990201 0.9494294 ]
5.240659925477458  -  92.9483  =  -87.70764007452254
training  [-3.9978, 3.3242, 4.3448]  w:  [0.81782872 0.33990201 0.9494294 ]
1.9854674465442184  -  79.1768  =  -77.19133255345578
training  [-3.2188, 0.9749, -3.9211]  w:  [0.81782872 0.33990201 0.9494294 ]
-6.023864235121782  -  2.7053  =  -8.729164235121782
training  [-1.4037, -1.6469, -3.1777]  w:  [0.81782872 0.33990201 0.9494294 ]
-4.72477259216746  -  2.6234  =  -7.34817259216746
training  [-4.433, -2.0077, -4.009]  w:  [0.81782872 0.33990201 0.9494294 ]
-8.114118439027003  -  0.3253  =  -8.439418439027003
training  [0.2189, -0.4741, -0.1024]  w:  [0.81782872 0.33990201 0.9494294 ]
-0.07934640522304737  -  33.6531  =  -33.73244640522305
training  [-1.6415, -0.7735, -3.0675]  w:  [0.81782872 0.33990201 0.9494294 ]
-4.517754728903317  -  3.7641  =  -8.281854728903317
training  [-3.2433, -1.4039, 3.9589]  w:  [0.81782872 0.33990201 0.9494294 ]
0.6290437300420795  -  30.0658  =  -29.436756269957918
training  [-2.9105, 0.5832, -4.0091]  w:  [0.81782872 0.33990201 0.9494294 ]
-5.988417043972234  -  2.4887  =  -8.477117043972234
training  [4.0515, 2.4255, -4.5583]  w:  [0.81782872 0.33990201 0.9494294 ]
-0.18991864908555733  -  61.2853  =  -61.475218649085555
training  [1.7539, -0.7567, 0.573]  w:  [0.81782872 0.33990201 0.9494294 ]
1.7212089896378628  -  57.0797  =  -55.35849101036214
training  [-0.3153, -0.7064, 2.725]  w:  [0.81782872 0.33990201 0.9494294 ]
2.0892269386156817  -  58.7004  =  -56.61117306138432
training  [4.1213, -3.7513, -1.8806]  w:  [0.81782872 0.33990201 0.9494294 ]
0.30994617806486935  -  22.1789  =  -21.86895382193513
training  [-3.9599, -4.7557, -3.2102]  w:  [0.81782872 0.33990201 0.9494294 ]
-7.902850183705417  -  0.1558  =  -8.058650183705417
training  [2.4555, -2.0981, -1.6104]  w:  [0.81782872 0.33990201 0.9494294 ]
-0.2339310824507188  -  24.4796  =  -24.71353108245072
training  [2.3627, -1.8248, -2.8985]  w:  [0.81782872 0.33990201 0.9494294 ]
-1.4398903779308543  -  15.7052  =  -17.145090377930853
training  [0.6186, 1.5369, 0.1015]  w:  [0.81782872 0.33990201 0.9494294 ]
1.1246713256872234  -  65.2154  =  -64.09072867431279
training  [-3.1581, 4.5694, 4.0636]  w:  [0.81782872 0.33990201 0.9494294 ]
2.828464655805513  -  90.3564  =  -87.52793534419447
training  [0.9721, 4.3573, 1.2892]  w:  [0.81782872 0.33990201 0.9494294 ]
3.50007069720112  -  94.3178  =  -90.81772930279888
training  [-2.0006, -0.4211, -3.9847]  w:  [0.81782872 0.33990201 0.9494294 ]
-5.562472199804773  -  2.4051  =  -7.967572199804773
training  [-3.6588, -2.5952, -1.0915]  w:  [0.81782872 0.33990201 0.9494294 ]
-4.910687601368684  -  1.5176  =  -6.428287601368684
training  [-2.874, 2.639, -4.4538]  w:  [0.81782872 0.33990201 0.9494294 ]
-5.682007002621992  -  5.497  =  -11.179007002621992
training  [3.9494, 2.5933, 0.0128]  w:  [0.81782872 0.33990201 0.9494294 ]
4.123553321070227  -  94.1462  =  -90.02264667892976
training  [-4.2855, 2.4065, -0.6828]  w:  [0.81782872 0.33990201 0.9494294 ]
-3.3351011948611005  -  14.4193  =  -17.7544011948611
training  [-2.5751, 2.4369, 4.9756]  w:  [0.81782872 0.33990201 0.9494294 ]
3.4462973810263815  -  87.1991  =  -83.75280261897362
training  [-4.4625, -3.9408, 3.116]  w:  [0.81782872 0.33990201 0.9494294 ]
-2.0306244890071463  -  4.1344  =  -6.165024489007147
training  [-0.5828, 1.8156, -0.1435]  w:  [0.81782872 0.33990201 0.9494294 ]
0.00425238750151638  -  51.1166  =  -51.11234761249848
training  [-4.8672, -0.3674, 3.9445]  w:  [0.81782872 0.33990201 0.9494294 ]
-0.3603916819846895  -  24.1396  =  -24.499991681984692
training  [3.9719, -2.8784, -3.6245]  w:  [0.81782872 0.33990201 0.9494294 ]
-1.171246899429065  -  14.6104  =  -15.781646899429065
training  [-3.0334, -4.0148, -1.1]  w:  [0.81782872 0.33990201 0.9494294 ]
-4.889812559095768  -  1.021  =  -5.910812559095768
training  [-4.0663, 3.2357, 4.2736]  w:  [0.81782872 0.33990201 0.9494294 ]
1.8317654783243142  -  77.2328  =  -75.40103452167568
training  [-1.9263, -3.2499, 4.1749]  w:  [0.81782872 0.33990201 0.9494294 ]
1.2837417995846963  -  26.8814  =  -25.597658200415303
training  [-0.4394, -3.3643, 2.1357]  w:  [0.81782872 0.33990201 0.9494294 ]
0.5248101041510469  -  20.85  =  -20.325189895848954
training  [-3.9833, 1.6599, 1.1834]  w:  [0.81782872 0.33990201 0.9494294 ]
-1.5698990498361831  -  25.5397  =  -27.109599049836184
training  [4.9539, 3.9439, -1.5671]  w:  [0.81782872 0.33990201 0.9494294 ]
3.9041304146014495  -  95.9509  =  -92.04676958539855
training  [-1.6791, 0.1656, 4.3603]  w:  [0.81782872 0.33990201 0.9494294 ]
2.822868576095521  -  71.5733  =  -68.75043142390449
training  [-2.0265, 2.027, -3.7523]  w:  [0.81782872 0.33990201 0.9494294 ]
-4.530892467071164  -  8.503  =  -13.033892467071164
training  [-4.3795, -3.4641, 2.3059]  w:  [0.81782872 0.33990201 0.9494294 ]
-2.5698461743960674  -  3.6654  =  -6.235246174396067
training  [-2.0176, 4.5346, 1.4648]  w:  [0.81782872 0.33990201 0.9494294 ]
1.281992599683727  -  81.6212  =  -80.33920740031627
training  [-4.5365, 0.4088, 3.3315]  w:  [0.81782872 0.33990201 0.9494294 ]
-0.4081040075380553  -  28.9449  =  -29.353004007538054
training  [0.0543, 1.7973, -1.0172]  w:  [0.81782872 0.33990201 0.9494294 ]
-0.310445607249239  -  47.9317  =  -48.24214560724924
training  [2.6143, -4.6344, 2.4982]  w:  [0.81782872 0.33990201 0.9494294 ]
2.9346722857096723  -  43.5132  =  -40.578527714290324
training  [1.3107, 3.092, 3.3522]  w:  [0.81782872 0.33990201 0.9494294 ]
5.305582342145195  -  96.6993  =  -91.3937176578548
training  [-4.1011, 2.4862, -1.7754]  w:  [0.81782872 0.33990201 0.9494294 ]
-4.1945499501275165  -  10.0187  =  -14.213249950127517
training  [-4.1914, -3.7981, 0.5226]  w:  [0.81782872 0.33990201 0.9494294 ]
-4.22265730972744  -  1.4295  =  -5.65215730972744
training  [2.7724, 0.2505, 4.7913]  w:  [0.81782872 0.33990201 0.9494294 ]
6.901494877100092  -  96.7925  =  -89.89100512289991
training  [4.0513, -1.7417, 0.4931]  w:  [0.81782872 0.33990201 0.9494294 ]
3.18942580602458  -  71.1234  =  -67.93397419397543
training  [0.3377, 0.4645, -1.6958]  w:  [0.81782872 0.33990201 0.9494294 ]
-1.1759771334283247  -  27.9534  =  -29.129377133428324
training  [-3.9085, -1.0112, 1.1947]  w:  [0.81782872 0.33990201 0.9494294 ]
-2.4059091612482666  -  8.608  =  -11.013909161248268
training  [3.2581, -0.8491, -1.3936]  w:  [0.81782872 0.33990201 0.9494294 ]
1.0528321495985875  -  50.1924  =  -49.13956785040141
training  [-1.619, -3.1926, 2.5651]  w:  [0.81782872 0.33990201 0.9494294 ]
0.02614550395738746  -  16.4754  =  -16.449254496042613
training  [-2.0603, -2.4461, -0.861]  w:  [0.81782872 0.33990201 0.9494294 ]
-3.333865525771744  -  3.9784  =  -7.312265525771744
training  [2.4631, -4.7946, -0.0765]  w:  [0.81782872 0.33990201 0.9494294 ]
0.31206840801757585  -  15.394  =  -15.081931591982425
training  [-4.8966, 4.2368, 1.9474]  w:  [0.81782872 0.33990201 0.9494294 ]
-0.7155644766864693  -  53.5883  =  -54.30386447668646
training  [-4.5155, 1.537, 4.7273]  w:  [0.81782872 0.33990201 0.9494294 ]
1.3177613954220146  -  59.2523  =  -57.93453860457798
training  [1.6792, 4.3261, -1.7225]  w:  [0.81782872 0.33990201 0.9494294 ]
1.2083559219712359  -  83.7729  =  -82.56454407802877
training  [1.0347, -3.3649, 3.378]  w:  [0.81782872 0.33990201 0.9494294 ]
2.9096436222940674  -  50.5979  =  -47.68825637770593
training  [0.261, 4.211, 2.3907]  w:  [0.81782872 0.33990201 0.9494294 ]
3.9145815133026893  -  94.9375  =  -91.02291848669731
training  [2.2971, 2.9466, 4.5417]  w:  [0.81782872 0.33990201 0.9494294 ]
7.192213110331086  -  98.7784  =  -91.58618688966892
training  [2.0725, 0.7739, -4.6808]  w:  [0.81782872 0.33990201 0.9494294 ]
-2.486088943861338  -  19.5109  =  -21.99698894386134
training  [2.8138, -0.5996, -1.4313]  w:  [0.81782872 0.33990201 0.9494294 ]
0.7384829115497109  -  47.2879  =  -46.54941708845029
training  [-2.1202, -2.4239, 1.6265]  w:  [0.81782872 0.33990201 0.9494294 ]
-1.0136020116019513  -  12.3599  =  -13.373502011601952
training  [1.9253, 2.5195, -2.185]  w:  [0.81782872 0.33990201 0.9494294 ]
0.3564455065371388  -  65.2467  =  -64.89025449346286
training  [0.5667, -2.7133, -2.6962]  w:  [0.81782872 0.33990201 0.9494294 ]
-3.0186441262194355  -  5.1106  =  -8.129244126219435
training  [-1.0348, -4.3581, 2.1113]  w:  [0.81782872 0.33990201 0.9494294 ]
-0.32308580834803813  -  10.5192  =  -10.842285808348038
training  [-4.3841, 2.6733, 1.2457]  w:  [0.81782872 0.33990201 0.9494294 ]
-1.4940786552026242  -  32.4639  =  -33.95797865520262
training  [2.8018, 1.712, 0.9061]  w:  [0.81782872 0.33990201 0.9494294 ]
3.7335827243489117  -  90.1138  =  -86.38021727565109
training  [-1.6242, 2.1521, 1.6044]  w:  [0.81782872 0.33990201 0.9494294 ]
0.9264502298651595  -  63.7879  =  -62.86144977013484
training  [1.0787, 1.4206, -4.5245]  w:  [0.81782872 0.33990201 0.9494294 ]
-2.9306366831284922  -  18.0555  =  -20.986136683128493
training  [2.4125, -0.8095, -1.5122]  w:  [0.81782872 0.33990201 0.9494294 ]
0.26213397625782076  -  38.8276  =  -38.565466023742175
training  [-3.9519, -1.0924, -0.4866]  w:  [0.81782872 0.33990201 0.9494294 ]
-4.065278619229096  -  3.6777  =  -7.7429786192290955
training  [-3.7211, 3.1614, -2.591]  w:  [0.81782872 0.33990201 0.9494294 ]
-4.428627818736195  -  11.1518  =  -15.580427818736194
training  [0.4954, -1.8257, 2.1505]  w:  [0.81782872 0.33990201 0.9494294 ]
1.826341175803244  -  47.7531  =  -45.92675882419676
training  [-0.1477, 3.1454, 3.5618]  w:  [0.81782872 0.33990201 0.9494294 ]
4.330012105287059  -  94.1572  =  -89.82718789471295
training  [3.9048, 2.8907, -2.1849]  w:  [0.81782872 0.33990201 0.9494294 ]
2.1016040269853318  -  85.8791  =  -83.77749597301467
training  [2.9896, 3.5226, 2.3105]  w:  [0.81782872 0.33990201 0.9494294 ]
5.835976180569043  -  98.038  =  -92.20202381943095
training  [2.3434, 0.0564, -3.6224]  w:  [0.81782872 0.33990201 0.9494294 ]
-1.503542757873188  -  24.7629  =  -26.266442757873186
training  [-4.4867, 1.3566, 3.3672]  w:  [0.81782872 0.33990201 0.9494294 ]
-0.011322385112952027  -  40.5785  =  -40.58982238511295
training  [-4.2711, 4.5089, -3.614]  w:  [0.81782872 0.33990201 0.9494294 ]
-5.391681935260482  -  10.0825  =  -15.474181935260482
training  [-4.1147, -0.5604, 0.8821]  w:  [0.81782872 0.33990201 0.9494294 ]
-2.718109248623575  -  8.344  =  -11.062109248623575
training  [2.9835, -4.3998, -1.3384]  w:  [0.81782872 0.33990201 0.9494294 ]
-0.3262251718588558  -  13.2692  =  -13.595425171858855
training  [4.4301, 3.6675, 3.0676]  w:  [0.81782872 0.33990201 0.9494294 ]
7.782123251388933  -  99.3834  =  -91.60127674861106
training  [1.8372, 1.3119, 0.0378]  w:  [0.81782872 0.33990201 0.9494294 ]
1.9843208001973853  -  74.9026  =  -72.91827919980263
training  [-3.6792, -1.4493, -0.1041]  w:  [0.81782872 0.33990201 0.9494294 ]
-3.6004110084538343  -  4.2442  =  -7.8446110084538345
training  [2.2272, 4.97, 3.7705]  w:  [0.81782872 0.33990201 0.9494294 ]
7.090604652005847  -  99.3199  =  -92.22929534799415
training  [-3.8965, -2.7583, -1.4686]  w:  [0.81782872 0.33990201 0.9494294 ]
-5.518553332008361  -  1.0337  =  -6.552253332008361
training  [-3.8251, 1.5245, -0.5056]  w:  [0.81782872 0.33990201 0.9494294 ]
-3.0901275329224287  -  12.9762  =  -16.06632753292243
training  [1.4072, 1.0499, 4.6353]  w:  [0.81782872 0.33990201 0.9494294 ]
5.9086017862384885  -  95.4618  =  -89.5531982137615
training  [-1.7119, -1.1275, -4.577]  w:  [0.81782872 0.33990201 0.9494294 ]
-6.128818859208328  -  1.4655  =  -7.594318859208329
training  [1.5381, -3.5781, 4.7296]  w:  [0.81782872 0.33990201 0.9494294 ]
4.532120267919215  -  69.9473  =  -65.41517973208079
training  [2.4913, -4.7487, -3.1079]  w:  [0.81782872 0.33990201 0.9494294 ]
-2.5273675999979144  -  3.9825  =  -6.509867599997914
training  [0.8319, -0.7889, 1.6712]  w:  [0.81782872 0.33990201 0.9494294 ]
1.9988894305969538  -  58.8336  =  -56.83471056940304
training  [2.4003, -3.159, 0.8644]  w:  [0.81782872 0.33990201 0.9494294 ]
1.7099706091427724  -  39.0041  =  -37.29412939085723
training  [-2.6517, 2.2578, 1.7511]  w:  [0.81782872 0.33990201 0.9494294 ]
0.2613401544906808  -  54.4525  =  -54.19115984550932
training  [2.3496, -1.2964, -1.3898]  w:  [0.81782872 0.33990201 0.9494294 ]
0.16140442077488792  -  33.888  =  -33.72659557922511
training  [4.706, 3.4156, 1.2028]  w:  [0.81782872 0.33990201 0.9494294 ]
6.151644936512643  -  98.4665  =  -92.31485506348736
training  [3.6693, 2.3423, 3.1115]  w:  [0.81782872 0.33990201 0.9494294 ]
6.751160971211543  -  98.3069  =  -91.55573902878845
training  [-4.1377, 0.7103, -4.8074]  w:  [0.81782872 0.33990201 0.9494294 ]
-7.706784393924627  -  0.9782  =  -8.684984393924626
training  [-1.3356, -3.2314, -4.1613]  w:  [0.81782872 0.33990201 0.9494294 ]
-6.1415119438329295  -  0.7659  =  -6.90741194383293
training  [-1.308, 4.5738, 4.748]  w:  [0.81782872 0.33990201 0.9494294 ]
4.9928146212275655  -  97.0884  =  -92.09558537877243
training  [1.8503, -2.3468, 1.5135]  w:  [0.81782872 0.33990201 0.9494294 ]
2.1525078461046823  -  50.2125  =  -48.059992153895315
training  [0.9794, 4.2458, -2.6876]  w:  [0.81782872 0.33990201 0.9494294 ]
-0.3075490608339746  -  68.3262  =  -68.63374906083398
training  [2.8936, -2.7623, -0.9651]  w:  [0.81782872 0.33990201 0.9494294 ]
0.5112635578906715  -  28.5596  =  -28.048336442109328
training  [-1.3235, -1.2644, -3.7798]  w:  [0.81782872 0.33990201 0.9494294 ]
-5.10082165208112  -  2.4511  =  -7.55192165208112
training  [-2.9397, -4.125, -2.3156]  w:  [0.81782872 0.33990201 0.9494294 ]
-6.004765586594592  -  0.554  =  -6.558765586594593
training  [-4.1333, 1.4012, -2.4215]  w:  [0.81782872 0.33990201 0.9494294 ]
-5.2031040476221495  -  4.4072  =  -9.610304047622149
training  [2.7193, -3.1938, -1.6833]  w:  [0.81782872 0.33990201 0.9494294 ]
-0.4598318986391261  -  17.0949  =  -17.554731898639126
training  [-2.9433, -4.5495, -3.4777]  w:  [0.81782872 0.33990201 0.9494294 ]
-7.25533007667961  -  0.2509  =  -7.50623007667961
training  [-1.1173, 2.2317, -1.5199]  w:  [0.81782872 0.33990201 0.9494294 ]
-1.598238463130215  -  33.1206  =  -34.71883846313022
training  [0.5178, -1.5256, -3.7834]  w:  [0.81782872 0.33990201 0.9494294 ]
-3.687153979060555  -  5.237  =  -8.924153979060556
training  [-2.7105, 1.6062, 3.8415]  w:  [0.81782872 0.33990201 0.9494294 ]
1.9764588933430192  -  70.4458  =  -68.46934110665698
training  [1.4194, -1.1613, -4.0572]  w:  [0.81782872 0.33990201 0.9494294 ]
-3.0859270727467023  -  8.3206  =  -11.406527072746703
training  [-0.1552, 1.2735, 4.3004]  w:  [0.81782872 0.33990201 0.9494294 ]
4.388864376351816  -  90.1085  =  -85.71963562364819
training  [-3.4815, -4.7835, -1.0098]  w:  [0.81782872 0.33990201 0.9494294 ]
-5.431925750069785  -  0.5839  =  -6.0158257500697845
training  [2.8193, 4.1057, -4.526]  w:  [0.81782872 0.33990201 0.9494294 ]
-0.5958772761805982  -  66.8081  =  -67.4039772761806
training  [-3.9939, 3.0056, -1.5763]  w:  [0.81782872 0.33990201 0.9494294 ]
-3.741302215310659  -  14.4018  =  -18.14310221531066
training  [-2.0593, 2.4585, 2.3597]  w:  [0.81782872 0.33990201 0.9494294 ]
1.3918629536584102  -  70.6698  =  -69.27793704634159
training  [-2.6263, 3.1311, 2.9468]  w:  [0.81782872 0.33990201 0.9494294 ]
1.7141821594031545  -  77.309  =  -75.59481784059685
training  [0.3087, -1.1669, 0.4491]  w:  [0.81782872 0.33990201 0.9494294 ]
0.28222081670821714  -  33.0798  =  -32.79757918329178
training  [-4.085, 1.1728, 1.8622]  w:  [0.81782872 0.33990201 0.9494294 ]
-1.174165822485047  -  26.4056  =  -27.579765822485047
training  [-0.9468, 0.7549, 3.9363]  w:  [0.81782872 0.33990201 0.9494294 ]
3.219510735950837  -  79.7738  =  -76.55428926404916
training  [-3.9515, 0.3005, -4.4521]  w:  [0.81782872 0.33990201 0.9494294 ]
-7.356464263321499  -  1.0441  =  -8.400564263321499
training  [-3.8772, -2.2493, -1.9634]  w:  [0.81782872 0.33990201 0.9494294 ]
-5.799536782560064  -  1.0509  =  -6.850436782560063
training  [2.8443, -2.5137, -4.5381]  w:  [0.81782872 0.33990201 0.9494294 ]
-2.83686700156128  -  6.8897  =  -9.72656700156128
training  [-2.0843, -0.4836, -3.0452]  w:  [0.81782872 0.33990201 0.9494294 ]
-4.760179418834162  -  3.5346  =  -8.294779418834162
training  [1.0353, -2.7229, 2.2017]  w:  [0.81782872 0.33990201 0.9494294 ]
2.011537606243255  -  43.9562  =  -41.94466239375675
training  [4.6442, 3.0445, 2.2175]  w:  [0.81782872 0.33990201 0.9494294 ]
6.938351497788972  -  98.8492  =  -91.91084850221102
training  [-0.6752, 4.861, 3.778]  w:  [0.81782872 0.33990201 0.9494294 ]
4.687009975111714  -  97.017  =  -92.32999002488828
training  [1.9475, -4.7001, 0.8243]  w:  [0.81782872 0.33990201 0.9494294 ]
0.7777626619925196  -  18.7839  =  -18.00613733800748
training  [2.581, 0.3566, -4.2932]  w:  [0.81782872 0.33990201 0.9494294 ]
-1.8440653120868054  -  23.5455  =  -25.389565312086805
training  [-0.6736, -4.1292, 4.2274]  w:  [0.81782872 0.33990201 0.9494294 ]
2.0592050461976887  -  31.2667  =  -29.20749495380231
training  [1.555, 3.0209, 3.0037]  w:  [0.81782872 0.33990201 0.9494294 ]
5.150334720310238  -  96.4078  =  -91.25746527968975
training  [-3.9024, 4.8914, -2.1405]  w:  [0.81782872 0.33990201 0.9494294 ]
-3.5611517487624536  -  25.4308  =  -28.991951748762453
training  [4.3376, -4.3305, 0.4366]  w:  [0.81782872 0.33990201 0.9494294 ]
2.4899890909695968  -  43.0907  =  -40.600710909030404
training  [-3.1254, 4.394, 4.8478]  w:  [0.81782872 0.33990201 0.9494294 ]
3.54013137755505  -  92.8121  =  -89.27196862244494
training  [-2.3382, -4.8182, 2.1568]  w:  [0.81782872 0.33990201 0.9494294 ]
-1.502233638681696  -  4.7434  =  -6.245633638681696
training  [2.9783, 1.8384, 3.3897]  w:  [0.81782872 0.33990201 0.9494294 ]
6.278895962574627  -  97.3486  =  -91.06970403742538
training  [-0.124, 2.8374, -0.6674]  w:  [0.81782872 0.33990201 0.9494294 ]
0.22937801351557463  -  62.785  =  -62.555621986484425
training  [2.6896, 0.3414, -0.2938]  w:  [0.81782872 0.33990201 0.9494294 ]
2.036732314743972  -  70.4455  =  -68.40876768525602
training  [-1.0399, 3.8536, 0.6071]  w:  [0.81782872 0.33990201 0.9494294 ]
1.0357848772504272  -  77.0369  =  -76.00111512274958
training  [-2.2706, 3.99, -2.3091]  w:  [0.81782872 0.33990201 0.9494294 ]
-2.693080308659546  -  31.1134  =  -33.806480308659545
training  [-4.6277, 1.2594, 2.4902]  w:  [0.81782872 0.33990201 0.9494294 ]
-0.9923242927381901  -  28.1093  =  -29.10162429273819
training  [1.7329, -3.6213, 0.0389]  w:  [0.81782872 0.33990201 0.9494294 ]
0.22326105416184094  -  19.3919  =  -19.168638945838158
training  [-0.7044, -2.822, 1.4681]  w:  [0.81782872 0.33990201 0.9494294 ]
-0.14142471495692832  -  17.8122  =  -17.95362471495693
training  [-0.4826, -3.1786, -1.9225]  w:  [0.81782872 0.33990201 0.9494294 ]
-3.30037468075591  -  3.5851  =  -6.885474680755911
training  [1.0986, -4.5818, -3.6128]  w:  [0.81782872 0.33990201 0.9494294 ]
-4.088994917649435  -  1.7158  =  -5.804794917649435
training  [-4.406, -3.9306, -0.2443]  w:  [0.81782872 0.33990201 0.9494294 ]
-5.171317775219284  -  0.8241  =  -5.995417775219284
training  [-1.8419, 1.1644, -1.3754]  w:  [0.81782872 0.33990201 0.9494294 ]
-2.416422018381447  -  17.8517  =  -20.268122018381447
training  [2.7272, 4.3966, 2.8811]  w:  [0.81782872 0.33990201 0.9494294 ]
6.460196693802965  -  98.904  =  -92.44380330619703
training  [1.9643, -1.4554, 2.803]  w:  [0.81782872 0.33990201 0.9494294 ]
3.773018179617786  -  76.0591  =  -72.28608182038221
training  [-3.7467, -0.8937, 1.6851]  w:  [0.81782872 0.33990201 0.9494294 ]
-1.7680458111318025  -  12.1571  =  -13.925145811131802
training  [-3.6985, 4.8435, -3.665]  w:  [0.81782872 0.33990201 0.9494294 ]
-4.858082897540137  -  14.6793  =  -19.537382897540137
260648.15954108024
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.03297133 0.13966324 1.06717152]
8.81275414475689  -  87.3174  =  -78.50464585524311
training  [-4.1793, -4.9218, 1.7664]  w:  [1.03297133 0.13966324 1.06717152]
-3.1194398082495  -  1.5257  =  -4.6451398082495
training  [-3.9429, -0.7689, 4.883]  w:  [1.03297133 0.13966324 1.06717152]
1.030708833595047  -  39.7859  =  -38.75519116640495
training  [-3.5796, 1.5557, 2.6683]  w:  [1.03297133 0.13966324 1.06717152]
-0.6328162922125462  -  45.5674  =  -46.200216292212545
training  [-3.3354, 2.2292, -1.633]  w:  [1.03297133 0.13966324 1.06717152]
-4.876726370254877  -  13.3589  =  -18.235626370254877
training  [1.2096, 0.3121, 1.6238]  w:  [1.03297133 0.13966324 1.06717152]
3.0259441296916507  -  74.5119  =  -71.48595587030835
training  [0.7371, -3.9118, -2.5583]  w:  [1.03297133 0.13966324 1.06717152]
-2.515076388469453  -  3.3358  =  -5.8508763884694535
training  [-4.4792, 1.3177, -2.0449]  w:  [1.03297133 0.13966324 1.06717152]
-6.625109963711804  -  4.2974  =  -10.922509963711803
training  [4.312, -3.735, 1.8018]  w:  [1.03297133 0.13966324 1.06717152]
5.855359818775491  -  66.5833  =  -60.727940181224504
training  [2.2866, -3.657, 0.2785]  w:  [1.03297133 0.13966324 1.06717152]
2.1484510474058194  -  26.0005  =  -23.85204895259418
training  [2.3784, -4.0141, -0.8841]  w:  [1.03297133 0.13966324 1.06717152]
0.9527104623032447  -  14.6809  =  -13.728189537696755
training  [-4.366, -3.5797, 1.0264]  w:  [1.03297133 0.13966324 1.06717152]
-3.9145604508778673  -  1.8713  =  -5.785860450877867
training  [3.6044, -3.3175, 2.5052]  w:  [1.03297133 0.13966324 1.06717152]
5.933387157712666  -  71.0139  =  -65.08051284228733
training  [4.3441, -3.0375, 0.8353]  w:  [1.03297133 0.13966324 1.06717152]
4.954512030349996  -  63.8979  =  -58.943387969650004
training  [4.844, -1.8252, 0.5179]  w:  [1.03297133 0.13966324 1.06717152]
5.301487897489581  -  78.0461  =  -72.74461210251042
training  [3.5894, -1.8357, 0.8357]  w:  [1.03297133 0.13966324 1.06717152]
4.34320271669157  -  68.8838  =  -64.54059728330843
training  [2.8556, -2.8244, 0.1182]  w:  [1.03297133 0.13966324 1.06717152]
2.6814277482649267  -  39.5252  =  -36.843772251735075
training  [0.1338, -2.4896, -4.1741]  w:  [1.03297133 0.13966324 1.06717152]
-4.663974679143872  -  2.2644  =  -6.9283746791438725
training  [-3.224, 3.9292, 2.1957]  w:  [1.03297133 0.13966324 1.06717152]
-0.4383462571363923  -  72.1211  =  -72.55944625713639
training  [-1.0141, 2.0322, 4.9616]  w:  [1.03297133 0.13966324 1.06717152]
4.531165629100903  -  92.3427  =  -87.8115343708991
training  [-3.6607, 0.5574, -1.4547]  w:  [1.03297133 0.13966324 1.06717152]
-5.255964259714385  -  5.8471  =  -11.103064259714385
training  [-4.6911, -3.1557, 4.7126]  w:  [1.03297133 0.13966324 1.06717152]
-0.2573545537673718  -  11.2337  =  -11.491054553767373
training  [4.3914, -2.8797, -1.5355]  w:  [1.03297133 0.13966324 1.06717152]
2.4953601893936805  -  37.475  =  -34.97963981060632
training  [-1.9869, -4.2265, 3.8654]  w:  [1.03297133 0.13966324 1.06717152]
1.4823474006513702  -  15.7889  =  -14.30655259934863
training  [-2.0447, 4.138, -0.4531]  w:  [1.03297133 0.13966324 1.06717152]
-2.0177254142895835  -  57.936  =  -59.953725414289586
training  [-1.6706, 2.0672, -0.8657]  w:  [1.03297133 0.13966324 1.06717152]
-2.3608204415018452  -  32.4185  =  -34.779320441501845
training  [-0.3293, 0.5779, -2.8227]  w:  [1.03297133 0.13966324 1.06717152]
-3.27175112742283  -  14.3434  =  -17.61515112742283
training  [1.482, -1.8657, -3.7435]  w:  [1.03297133 0.13966324 1.06717152]
-2.72466278596227  -  7.1519  =  -9.876562785962271
training  [-4.7477, -3.338, -1.9109]  w:  [1.03297133 0.13966324 1.06717152]
-7.409691912392386  -  0.4077  =  -7.817391912392386
training  [3.4221, 1.225, 2.261]  w:  [1.03297133 0.13966324 1.06717152]
6.118893452266445  -  95.0454  =  -88.92650654773355
training  [0.5903, 4.8793, 2.8287]  w:  [1.03297133 0.13966324 1.06717152]
4.3099298884435004  -  97.4647  =  -93.15477011155649
training  [3.541, -3.2957, 1.9379]  w:  [1.03297133 0.13966324 1.06717152]
5.265535029948649  -  64.3732  =  -59.107664970051346
training  [-1.5212, -2.4221, -4.902]  w:  [1.03297133 0.13966324 1.06717152]
-7.140909106817723  -  0.7227  =  -7.863609106817723
training  [-0.5397, -1.032, 3.4321]  w:  [1.03297133 0.13966324 1.06717152]
2.961012294050791  -  60.5921  =  -57.63108770594921
training  [-4.4576, -4.2601, 4.2233]  w:  [1.03297133 0.13966324 1.06717152]
-0.6925668532077376  -  6.0247  =  -6.717266853207738
training  [-3.2289, 1.841, 2.7095]  w:  [1.03297133 0.13966324 1.06717152]
-0.18673985982675756  -  54.0111  =  -54.19783985982676
training  [1.6281, -0.9761, -4.5734]  w:  [1.03297133 0.13966324 1.06717152]
-3.3351469055172114  -  7.8658  =  -11.200946905517212
training  [-1.6917, 4.8284, -1.2181]  w:  [1.03297133 0.13966324 1.06717152]
-2.3730492513747503  -  61.2837  =  -63.656749251374755
training  [3.9849, -0.9782, 2.0434]  w:  [1.03297133 0.13966324 1.06717152]
6.160327148558171  -  88.3402  =  -82.17987285144183
training  [-3.8184, 1.2067, 2.2951]  w:  [1.03297133 0.13966324 1.06717152]
-1.326500726509694  -  34.1122  =  -35.438700726509694
training  [4.8842, -3.4563, -2.7572]  w:  [1.03297133 0.13966324 1.06717152]
1.620115188871269  -  23.7819  =  -22.161784811128733
training  [0.3998, -1.1865, -2.3095]  w:  [1.03297133 0.13966324 1.06717152]
-2.217361123220571  -  11.4246  =  -13.641961123220572
training  [2.0692, -3.3887, 1.7303]  w:  [1.03297133 0.13966324 1.06717152]
3.510674342513716  -  42.6881  =  -39.17742565748628
training  [4.9949, 2.5811, -0.2251]  w:  [1.03297133 0.13966324 1.06717152]
5.279852950242265  -  95.9901  =  -90.71024704975773
training  [-2.1215, 3.7111, 1.2372]  w:  [1.03297133 0.13966324 1.06717152]
-0.3528398249457483  -  71.3692  =  -71.72203982494575
training  [-0.8548, -1.4922, -2.6356]  w:  [1.03297133 0.13966324 1.06717152]
-3.9040266342835857  -  4.7821  =  -8.686126634283585
training  [-0.3516, 1.8554, -3.2288]  w:  [1.03297133 0.13966324 1.06717152]
-3.54974495797836  -  20.3834  =  -23.933144957978364
training  [2.6396, -2.0585, 3.2964]  w:  [1.03297133 0.13966324 1.06717152]
5.956958544773169  -  80.826  =  -74.86904145522682
training  [3.182, 0.3063, 2.6692]  w:  [1.03297133 0.13966324 1.06717152]
6.178187836260056  -  92.9483  =  -86.77011216373995
training  [-3.9978, 3.3242, 4.3448]  w:  [1.03297133 0.13966324 1.06717152]
0.9713025892038916  -  79.1768  =  -78.20549741079611
training  [-3.2188, 0.9749, -3.9211]  w:  [1.03297133 0.13966324 1.06717152]
-7.373256670065259  -  2.7053  =  -10.07855667006526
training  [-1.4037, -1.6469, -3.1777]  w:  [1.03297133 0.13966324 1.06717152]
-5.071144180067263  -  2.6234  =  -7.694544180067263
training  [-4.433, -2.0077, -4.009]  w:  [1.03297133 0.13966324 1.06717152]
-9.137854401562173  -  0.3253  =  -9.463154401562173
training  [0.2189, -0.4741, -0.1024]  w:  [1.03297133 0.13966324 1.06717152]
0.05062471903650173  -  33.6531  =  -33.6024752809635
training  [-1.6415, -0.7735, -3.0675]  w:  [1.03297133 0.13966324 1.06717152]
-5.0772005888704115  -  3.7641  =  -8.84130058887041
training  [-3.2433, -1.4039, 3.9589]  w:  [1.03297133 0.13966324 1.06717152]
0.678516215227341  -  30.0658  =  -29.38728378477266
training  [-2.9105, 0.5832, -4.0091]  w:  [1.03297133 0.13966324 1.06717152]
-7.203408793808116  -  2.4887  =  -9.692108793808115
training  [4.0515, 2.4255, -4.5583]  w:  [1.03297133 0.13966324 1.06717152]
-0.3406514364370983  -  61.2853  =  -61.6259514364371
training  [1.7539, -0.7567, 0.573]  w:  [1.03297133 0.13966324 1.06717152]
2.3175345204031683  -  57.0797  =  -54.76216547959683
training  [-0.3153, -0.7064, 2.725]  w:  [1.03297133 0.13966324 1.06717152]
2.483688426693919  -  58.7004  =  -56.216711573306085
training  [4.1213, -3.7513, -1.8806]  w:  [1.03297133 0.13966324 1.06717152]
1.7263432648004935  -  22.1789  =  -20.452556735199504
training  [-3.9599, -4.7557, -3.2102]  w:  [1.03297133 0.13966324 1.06717152]
-8.180493630076418  -  0.1558  =  -8.336293630076417
training  [2.4555, -2.0981, -1.6104]  w:  [1.03297133 0.13966324 1.06717152]
0.524860637060935  -  24.4796  =  -23.954739362939065
training  [2.3627, -1.8248, -2.8985]  w:  [1.03297133 0.13966324 1.06717152]
-0.9074527764475646  -  15.7052  =  -16.612652776447565
training  [0.6186, 1.5369, 0.1015]  w:  [1.03297133 0.13966324 1.06717152]
0.9619624006703268  -  65.2154  =  -64.25343759932967
training  [-3.1581, 4.5694, 4.0636]  w:  [1.03297133 0.13966324 1.06717152]
1.7125086427029346  -  90.3564  =  -88.64389135729706
training  [0.9721, 4.3573, 1.2892]  w:  [1.03297133 0.13966324 1.06717152]
2.9885035738206005  -  94.3178  =  -91.32929642617941
training  [-2.0006, -0.4211, -3.9847]  w:  [1.03297133 0.13966324 1.06717152]
-6.377732987261242  -  2.4051  =  -8.78283298726124
training  [-3.6588, -2.5952, -1.0915]  w:  [1.03297133 0.13966324 1.06717152]
-5.306707237746655  -  1.5176  =  -6.8243072377466545
training  [-2.874, 2.639, -4.4538]  w:  [1.03297133 0.13966324 1.06717152]
-7.353156833923164  -  5.497  =  -12.850156833923164
training  [3.9494, 2.5933, 0.0128]  w:  [1.03297133 0.13966324 1.06717152]
4.455465424738285  -  94.1462  =  -89.69073457526171
training  [-4.2855, 2.4065, -0.6828]  w:  [1.03297133 0.13966324 1.06717152]
-4.8193637559570695  -  14.4193  =  -19.23866375595707
training  [-2.5751, 2.4369, 4.9756]  w:  [1.03297133 0.13966324 1.06717152]
2.990159501457877  -  87.1991  =  -84.20894049854212
training  [-4.4625, -3.9408, 3.116]  w:  [1.03297133 0.13966324 1.06717152]
-1.8347129671053248  -  4.1344  =  -5.969112967105325
training  [-0.5828, 1.8156, -0.1435]  w:  [1.03297133 0.13966324 1.06717152]
-0.5015822298504968  -  51.1166  =  -51.6181822298505
training  [-4.8672, -0.3674, 3.9445]  w:  [1.03297133 0.13966324 1.06717152]
-0.8695322470901488  -  24.1396  =  -25.00913224709015
training  [3.9719, -2.8784, -3.6245]  w:  [1.03297133 0.13966324 1.06717152]
-0.167111028590488  -  14.6104  =  -14.777511028590489
training  [-3.0334, -4.0148, -1.1]  w:  [1.03297133 0.13966324 1.06717152]
-4.868023858912172  -  1.021  =  -5.8890238589121715
training  [-4.0663, 3.2357, 4.2736]  w:  [1.03297133 0.13966324 1.06717152]
0.8122012445372433  -  77.2328  =  -76.42059875546275
training  [-1.9263, -3.2499, 4.1749]  w:  [1.03297133 0.13966324 1.06717152]
2.011630166006435  -  26.8814  =  -24.869769833993566
training  [-0.4394, -3.3643, 2.1357]  w:  [1.03297133 0.13966324 1.06717152]
1.3554015903846783  -  20.85  =  -19.494598409615325
training  [-3.9833, 1.6599, 1.1834]  w:  [1.03297133 0.13966324 1.06717152]
-2.6199168999604403  -  25.5397  =  -28.15961689996044
training  [4.9539, 3.9439, -1.5671]  w:  [1.03297133 0.13966324 1.06717152]
3.9956900028864517  -  95.9509  =  -91.95520999711356
training  [-1.6791, 0.1656, 4.3603]  w:  [1.03297133 0.13966324 1.06717152]
2.9418540632079915  -  71.5733  =  -68.631445936792
training  [-2.0265, 2.027, -3.7523]  w:  [1.03297133 0.13966324 1.06717152]
-5.81456671308548  -  8.503  =  -14.31756671308548
training  [-4.3795, -3.4641, 2.3059]  w:  [1.03297133 0.13966324 1.06717152]
-2.546914531699998  -  3.6654  =  -6.212314531699998
training  [-2.0176, 4.5346, 1.4648]  w:  [1.03297133 0.13966324 1.06717152]
0.11238680968336867  -  81.6212  =  -81.50881319031663
training  [-4.5365, 0.4088, 3.3315]  w:  [1.03297133 0.13966324 1.06717152]
-1.0736981677582786  -  28.9449  =  -30.018598167758277
training  [0.0543, 1.7973, -1.0172]  w:  [1.03297133 0.13966324 1.06717152]
-0.7784197933331046  -  47.9317  =  -48.71011979333311
training  [2.6143, -4.6344, 2.4982]  w:  [1.03297133 0.13966324 1.06717152]
4.719249530081495  -  43.5132  =  -38.7939504699185
training  [1.3107, 3.092, 3.3522]  w:  [1.03297133 0.13966324 1.06717152]
5.363126620655063  -  96.6993  =  -91.33617337934493
training  [-4.1011, 2.4862, -1.7754]  w:  [1.03297133 0.13966324 1.06717152]
-5.783744287884083  -  10.0187  =  -15.802444287884084
training  [-4.1914, -3.7981, 0.5226]  w:  [1.03297133 0.13966324 1.06717152]
-4.30234712075146  -  1.4295  =  -5.73184712075146
training  [2.7724, 0.2505, 4.7913]  w:  [1.03297133 0.13966324 1.06717152]
8.011934258301533  -  96.7925  =  -88.78056574169847
training  [4.0513, -1.7417, 0.4931]  w:  [1.03297133 0.13966324 1.06717152]
4.467847553406776  -  71.1234  =  -66.65555244659323
training  [0.3377, 0.4645, -1.6958]  w:  [1.03297133 0.13966324 1.06717152]
-1.3960014758940718  -  27.9534  =  -29.34940147589407
training  [-3.9085, -1.0112, 1.1947]  w:  [1.03297133 0.13966324 1.06717152]
-2.90364607824172  -  8.608  =  -11.511646078241721
training  [3.2581, -0.8491, -1.3936]  w:  [1.03297133 0.13966324 1.06717152]
1.759725592410636  -  50.1924  =  -48.43267440758936
training  [-1.619, -3.1926, 2.5651]  w:  [1.03297133 0.13966324 1.06717152]
0.619132242634318  -  16.4754  =  -15.856267757365682
training  [-2.0603, -2.4461, -0.861]  w:  [1.03297133 0.13966324 1.06717152]
-3.3886957478009148  -  3.9784  =  -7.367095747800915
training  [2.4631, -4.7946, -0.0765]  w:  [1.03297133 0.13966324 1.06717152]
1.793043698241517  -  15.394  =  -13.600956301758483
training  [-4.8966, 4.2368, 1.9474]  w:  [1.03297133 0.13966324 1.06717152]
-2.3881123752421014  -  53.5883  =  -55.9764123752421
training  [-4.5155, 1.537, 4.7273]  w:  [1.03297133 0.13966324 1.06717152]
0.595120303695297  -  59.2523  =  -58.6571796963047
training  [1.6792, 4.3261, -1.7225]  w:  [1.03297133 0.13966324 1.06717152]
0.5005596342153751  -  83.7729  =  -83.27234036578463
training  [1.0347, -3.3649, 3.378]  w:  [1.03297133 0.13966324 1.06717152]
4.2037680063345935  -  50.5979  =  -46.39413199366541
training  [0.261, 4.211, 2.3907]  w:  [1.03297133 0.13966324 1.06717152]
3.4090143629883425  -  94.9375  =  -91.52848563701166
training  [2.2971, 2.9466, 4.5417]  w:  [1.03297133 0.13966324 1.06717152]
7.63114302758533  -  98.7784  =  -91.14725697241468
training  [2.0725, 0.7739, -4.6808]  w:  [1.03297133 0.13966324 1.06717152]
-2.74629800505892  -  19.5109  =  -22.257198005058918
training  [2.8138, -0.5996, -1.4313]  w:  [1.03297133 0.13966324 1.06717152]
1.2953900431971606  -  47.2879  =  -45.99250995680284
training  [-2.1202, -2.4239, 1.6265]  w:  [1.03297133 0.13966324 1.06717152]
-0.7928810463699185  -  12.3599  =  -13.152781046369919
training  [1.9253, 2.5195, -2.185]  w:  [1.03297133 0.13966324 1.06717152]
0.008891445417779753  -  65.2467  =  -65.23780855458223
training  [0.5667, -2.7133, -2.6962]  w:  [1.03297133 0.13966324 1.06717152]
-2.6708712661025973  -  5.1106  =  -7.7814712661025975
training  [-1.0348, -4.3581, 2.1113]  w:  [1.03297133 0.13966324 1.06717152]
0.5755341526931352  -  10.5192  =  -9.943665847306864
training  [-4.3841, 2.6733, 1.2457]  w:  [1.03297133 0.13966324 1.06717152]
-2.8259122977430398  -  32.4639  =  -35.28981229774304
training  [2.8018, 1.712, 0.9061]  w:  [1.03297133 0.13966324 1.06717152]
4.100246640014006  -  90.1138  =  -86.01355335998599
training  [-1.6242, 2.1521, 1.6044]  w:  [1.03297133 0.13966324 1.06717152]
0.33498721241796203  -  63.7879  =  -63.45291278758204
training  [1.0787, 1.4206, -4.5245]  w:  [1.03297133 0.13966324 1.06717152]
-3.5157457854172485  -  18.0555  =  -21.571245785417247
training  [2.4125, -0.8095, -1.5122]  w:  [1.03297133 0.13966324 1.06717152]
0.7652091603272912  -  38.8276  =  -38.06239083967271
training  [-3.9519, -1.0924, -0.4866]  w:  [1.03297133 0.13966324 1.06717152]
-4.7540531679486  -  3.6777  =  -8.4317531679486
training  [-3.7211, 3.1614, -2.591]  w:  [1.03297133 0.13966324 1.06717152]
-6.167299659343282  -  11.1518  =  -17.31909965934328
training  [0.4954, -1.8257, 2.1505]  w:  [1.03297133 0.13966324 1.06717152]
2.551703181111626  -  47.7531  =  -45.20139681888838
training  [-0.1477, 3.1454, 3.5618]  w:  [1.03297133 0.13966324 1.06717152]
4.087778405679991  -  94.1572  =  -90.06942159432
training  [3.9048, 2.8907, -2.1849]  w:  [1.03297133 0.13966324 1.06717152]
2.1056078971097922  -  85.8791  =  -83.7734921028902
training  [2.9896, 3.5226, 2.3105]  w:  [1.03297133 0.13966324 1.06717152]
6.045848596599059  -  98.038  =  -91.99215140340094
training  [2.3434, 0.0564, -3.6224]  w:  [1.03297133 0.13966324 1.06717152]
-1.4371801065638756  -  24.7629  =  -26.200080106563874
training  [-4.4867, 1.3566, 3.3672]  w:  [1.03297133 0.13966324 1.06717152]
-0.8517853565700908  -  40.5785  =  -41.43028535657009
training  [-4.2711, 4.5089, -3.614]  w:  [1.03297133 0.13966324 1.06717152]
-7.638954144075742  -  10.0825  =  -17.721454144075743
training  [-4.1147, -0.5604, 0.8821]  w:  [1.03297133 0.13966324 1.06717152]
-3.3872823963205434  -  8.344  =  -11.731282396320543
training  [2.9835, -4.3998, -1.3384]  w:  [1.03297133 0.13966324 1.06717152]
1.0390772793524585  -  13.2692  =  -12.230122720647541
training  [4.4301, 3.6675, 3.0676]  w:  [1.03297133 0.13966324 1.06717152]
8.362036554630826  -  99.3834  =  -91.02136344536916
training  [1.8372, 1.3119, 0.0378]  w:  [1.03297133 0.13966324 1.06717152]
2.1213382050977283  -  74.9026  =  -72.78126179490228
training  [-3.6792, -1.4493, -0.1041]  w:  [1.03297133 0.13966324 1.06717152]
-4.114014589355991  -  4.2442  =  -8.358214589355992
training  [2.2272, 4.97, 3.7705]  w:  [1.03297133 0.13966324 1.06717152]
7.018530247636104  -  99.3199  =  -92.3013697523639
training  [-3.8965, -2.7583, -1.4686]  w:  [1.03297133 0.13966324 1.06717152]
-5.977453976805332  -  1.0337  =  -7.011153976805332
training  [-3.8251, 1.5245, -0.5056]  w:  [1.03297133 0.13966324 1.06717152]
-4.277863938368497  -  12.9762  =  -17.254063938368496
training  [1.4072, 1.0499, 4.6353]  w:  [1.03297133 0.13966324 1.06717152]
6.546889837284477  -  95.4618  =  -88.91491016271551
training  [-1.7119, -1.1275, -4.577]  w:  [1.03297133 0.13966324 1.06717152]
-6.8102579679690445  -  1.4655  =  -8.275757967969044
training  [1.5381, -3.5781, 4.7296]  w:  [1.03297133 0.13966324 1.06717152]
6.136378598707809  -  69.9473  =  -63.81092140129219
training  [2.4913, -4.7487, -3.1079]  w:  [1.03297133 0.13966324 1.06717152]
-1.4064397184315252  -  3.9825  =  -5.388939718431525
training  [0.8319, -0.7889, 1.6712]  w:  [1.03297133 0.13966324 1.06717152]
2.5326055660784776  -  58.8336  =  -56.30099443392152
training  [2.4003, -3.159, 0.8644]  w:  [1.03297133 0.13966324 1.06717152]
2.9607079736686748  -  39.0041  =  -36.043392026331325
training  [-2.6517, 2.2578, 1.7511]  w:  [1.03297133 0.13966324 1.06717152]
-0.5550743593418987  -  54.4525  =  -55.0075743593419
training  [2.3496, -1.2964, -1.3898]  w:  [1.03297133 0.13966324 1.06717152]
0.7628550281513384  -  33.888  =  -33.12514497184866
training  [4.706, 3.4156, 1.2028]  w:  [1.03297133 0.13966324 1.06717152]
6.6217907207826325  -  98.4665  =  -91.84470927921737
training  [3.6693, 2.3423, 3.1115]  w:  [1.03297133 0.13966324 1.06717152]
7.4379190777804105  -  98.3069  =  -90.86898092221959
training  [-4.1377, 0.7103, -4.8074]  w:  [1.03297133 0.13966324 1.06717152]
-9.305243034163134  -  0.9782  =  -10.283443034163133
training  [-1.3356, -3.2314, -4.1613]  w:  [1.03297133 0.13966324 1.06717152]
-6.271765140038263  -  0.7659  =  -7.037665140038263
training  [-1.308, 4.5738, 4.748]  w:  [1.03297133 0.13966324 1.06717152]
4.354595601733724  -  97.0884  =  -92.73380439826627
training  [1.8503, -2.3468, 1.5135]  w:  [1.03297133 0.13966324 1.06717152]
3.198709259606632  -  50.2125  =  -47.01379074039337
training  [0.9794, 4.2458, -2.6876]  w:  [1.03297133 0.13966324 1.06717152]
-1.2634558935881608  -  68.3262  =  -69.58965589358816
training  [2.8936, -2.7623, -0.9651]  w:  [1.03297133 0.13966324 1.06717152]
1.5732868363041062  -  28.5596  =  -26.986313163695893
training  [-1.3235, -1.2644, -3.7798]  w:  [1.03297133 0.13966324 1.06717152]
-5.577422664781393  -  2.4511  =  -8.028522664781393
training  [-2.9397, -4.125, -2.3156]  w:  [1.03297133 0.13966324 1.06717152]
-6.083879035984413  -  0.554  =  -6.6378790359844135
training  [-4.1333, 1.4012, -2.4215]  w:  [1.03297133 0.13966324 1.06717152]
-6.658040096606326  -  4.4072  =  -11.065240096606326
training  [2.7193, -3.1938, -1.6833]  w:  [1.03297133 0.13966324 1.06717152]
0.5665326605813739  -  17.0949  =  -16.528367339418626
training  [-2.9433, -4.5495, -3.4777]  w:  [1.03297133 0.13966324 1.06717152]
-7.387044802043797  -  0.2509  =  -7.637944802043797
training  [-1.1173, 2.2317, -1.5199]  w:  [1.03297133 0.13966324 1.06717152]
-2.4644464134796182  -  33.1206  =  -35.585046413479624
training  [0.5178, -1.5256, -3.7834]  w:  [1.03297133 0.13966324 1.06717152]
-3.715734415985462  -  5.237  =  -8.952734415985462
training  [-2.7105, 1.6062, 3.8415]  w:  [1.03297133 0.13966324 1.06717152]
1.5239977103832025  -  70.4458  =  -68.9218022896168
training  [1.4194, -1.1613, -4.0572]  w:  [1.03297133 0.13966324 1.06717152]
-3.0257197133693747  -  8.3206  =  -11.346319713369375
training  [-0.1552, 1.2735, 4.3004]  w:  [1.03297133 0.13966324 1.06717152]
4.606808393712475  -  90.1085  =  -85.50169160628754
training  [-3.4815, -4.7835, -1.0098]  w:  [1.03297133 0.13966324 1.06717152]
-5.341998569219214  -  0.5839  =  -5.925898569219214
training  [2.8193, 4.1057, -4.526]  w:  [1.03297133 0.13966324 1.06717152]
-1.3443468945537695  -  66.8081  =  -68.15244689455376
training  [-3.9939, 3.0056, -1.5763]  w:  [1.03297133 0.13966324 1.06717152]
-5.387994826541828  -  14.4018  =  -19.78979482654183
training  [-2.0593, 2.4585, 2.3597]  w:  [1.03297133 0.13966324 1.06717152]
0.734368854228898  -  70.6698  =  -69.93543114577109
training  [-2.6263, 3.1311, 2.9468]  w:  [1.03297133 0.13966324 1.06717152]
0.8691480054219647  -  77.309  =  -76.43985199457804
training  [0.3087, -1.1669, 0.4491]  w:  [1.03297133 0.13966324 1.06717152]
0.6351719479164185  -  33.0798  =  -32.44462805208358
training  [-4.085, 1.1728, 1.8622]  w:  [1.03297133 0.13966324 1.06717152]
-2.0686040176251916  -  26.4056  =  -28.47420401762519
training  [-0.9468, 0.7549, 3.9363]  w:  [1.03297133 0.13966324 1.06717152]
3.3281217859492735  -  79.7738  =  -76.44567821405072
training  [-3.9515, 0.3005, -4.4521]  w:  [1.03297133 0.13966324 1.06717152]
-8.790971725936348  -  1.0441  =  -9.835071725936348
training  [-3.8772, -2.2493, -1.9634]  w:  [1.03297133 0.13966324 1.06717152]
-6.414465511590663  -  1.0509  =  -7.465365511590663
training  [2.8443, -2.5137, -4.5381]  w:  [1.03297133 0.13966324 1.06717152]
-2.2559222162029133  -  6.8897  =  -9.145622216202913
training  [-2.0843, -0.4836, -3.0452]  w:  [1.03297133 0.13966324 1.06717152]
-5.470313995031438  -  3.5346  =  -9.004913995031437
training  [1.0353, -2.7229, 2.2017]  w:  [1.03297133 0.13966324 1.06717152]
3.038737726243546  -  43.9562  =  -40.917462273756456
training  [4.6442, 3.0445, 2.2175]  w:  [1.03297133 0.13966324 1.06717152]
7.588983008627801  -  98.8492  =  -91.26021699137219
training  [-0.6752, 4.861, 3.778]  w:  [1.03297133 0.13966324 1.06717152]
4.013214762844135  -  97.017  =  -93.00378523715587
training  [1.9475, -4.7001, 0.8243]  w:  [1.03297133 0.13966324 1.06717152]
2.2349499647861584  -  18.7839  =  -16.548950035213842
training  [2.581, 0.3566, -4.2932]  w:  [1.03297133 0.13966324 1.06717152]
-1.8656778723880216  -  23.5455  =  -25.411177872388024
training  [-0.6736, -4.1292, 4.2274]  w:  [1.03297133 0.13966324 1.06717152]
3.2388539676730006  -  31.2667  =  -28.027846032327
training  [1.555, 3.0209, 3.0037]  w:  [1.03297133 0.13966324 1.06717152]
5.233642184330085  -  96.4078  =  -91.17415781566991
training  [-3.9024, 4.8914, -2.1405]  w:  [1.03297133 0.13966324 1.06717152]
-5.6321991907756  -  25.4308  =  -31.0629991907756
training  [4.3376, -4.3305, 0.4366]  w:  [1.03297133 0.13966324 1.06717152]
4.3417318659259205  -  43.0907  =  -38.748968134074076
training  [-3.1254, 4.394, 4.8478]  w:  [1.03297133 0.13966324 1.06717152]
2.5586657806136133  -  92.8121  =  -90.25343421938639
training  [-2.3382, -4.8182, 2.1568]  w:  [1.03297133 0.13966324 1.06717152]
-0.786543425429306  -  4.7434  =  -5.529943425429306
training  [2.9783, 1.8384, 3.3897]  w:  [1.03297133 0.13966324 1.06717152]
6.950646703395197  -  97.3486  =  -90.39795329660481
training  [-0.124, 2.8374, -0.6674]  w:  [1.03297133 0.13966324 1.06717152]
-0.44403825005318387  -  62.785  =  -63.22903825005318
training  [2.6896, 0.3414, -0.2938]  w:  [1.03297133 0.13966324 1.06717152]
2.5124257160679444  -  70.4455  =  -67.93307428393206
training  [-1.0399, 3.8536, 0.6071]  w:  [1.03297133 0.13966324 1.06717152]
0.11189919739508924  -  77.0369  =  -76.92500080260491
training  [-2.2706, 3.99, -2.3091]  w:  [1.03297133 0.13966324 1.06717152]
-4.252414140148815  -  31.1134  =  -35.365814140148814
training  [-4.6277, 1.2594, 2.4902]  w:  [1.03297133 0.13966324 1.06717152]
-1.9469190047015328  -  28.1093  =  -30.056219004701532
training  [1.7329, -3.6213, 0.0389]  w:  [1.03297133 0.13966324 1.06717152]
1.3257865048245439  -  19.3919  =  -18.066113495175458
training  [-0.7044, -2.822, 1.4681]  w:  [1.03297133 0.13966324 1.06717152]
0.44495985428720597  -  17.8122  =  -17.367240145712795
training  [-0.4826, -3.1786, -1.9225]  w:  [1.03297133 0.13966324 1.06717152]
-2.9940827769140586  -  3.5851  =  -6.579182776914059
training  [1.0986, -4.5818, -3.6128]  w:  [1.03297133 0.13966324 1.06717152]
-3.360563992075533  -  1.7158  =  -5.076363992075533
training  [-4.406, -3.9306, -0.2443]  w:  [1.03297133 0.13966324 1.06717152]
-5.3609419862493155  -  0.8241  =  -6.185041986249315
training  [-1.8419, 1.1644, -1.3754]  w:  [1.03297133 0.13966324 1.06717152]
-3.2077937244706485  -  17.8517  =  -21.05949372447065
training  [2.7272, 4.3966, 2.8811]  w:  [1.03297133 0.13966324 1.06717152]
6.505790659658691  -  98.904  =  -92.39820934034131
training  [1.9643, -1.4554, 2.803]  w:  [1.03297133 0.13966324 1.06717152]
4.8170814772231765  -  76.0591  =  -71.24201852277682
training  [-3.7467, -0.8937, 1.6851]  w:  [1.03297133 0.13966324 1.06717152]
-2.196759973070116  -  12.1571  =  -14.353859973070115
training  [-3.6985, 4.8435, -3.665]  w:  [1.03297133 0.13966324 1.06717152]
-7.055169191033302  -  14.6793  =  -21.734469191033302
260146.44767214073
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.30799106 0.46371479 1.27971939]
9.670724674091897  -  87.3174  =  -77.6466753259081
training  [-4.1793, -4.9218, 1.7664]  w:  [1.30799106 0.46371479 1.27971939]
-5.488302171307093  -  1.5257  =  -7.014002171307093
training  [-3.9429, -0.7689, 4.883]  w:  [1.30799106 0.46371479 1.27971939]
0.7350415072128662  -  39.7859  =  -39.05085849278713
training  [-3.5796, 1.5557, 2.6683]  w:  [1.30799106 0.46371479 1.27971939]
-0.5460084679721442  -  45.5674  =  -46.11340846797214
training  [-3.3354, 2.2292, -1.633]  w:  [1.30799106 0.46371479 1.27971939]
-5.418742141133089  -  13.3589  =  -18.77764214113309
training  [1.2096, 0.3121, 1.6238]  w:  [1.30799106 0.46371479 1.27971939]
3.8048797162186947  -  74.5119  =  -70.7070202837813
training  [0.7371, -3.9118, -2.5583]  w:  [1.30799106 0.46371479 1.27971939]
-4.123745409507101  -  3.3358  =  -7.4595454095071005
training  [-4.4792, 1.3177, -2.0449]  w:  [1.30799106 0.46371479 1.27971939]
-7.864614764503429  -  4.2974  =  -12.162014764503429
training  [4.312, -3.735, 1.8018]  w:  [1.30799106 0.46371479 1.27971939]
6.213881115615635  -  66.5833  =  -60.36941888438436
training  [2.2866, -3.657, 0.2785]  w:  [1.30799106 0.46371479 1.27971939]
1.6514492283822602  -  26.0005  =  -24.34905077161774
training  [2.3784, -4.0141, -0.8841]  w:  [1.30799106 0.46371479 1.27971939]
0.1181284968201457  -  14.6809  =  -14.562771503179853
training  [-4.366, -3.5797, 1.0264]  w:  [1.30799106 0.46371479 1.27971939]
-6.057144830665588  -  1.8713  =  -7.928444830665588
training  [3.6044, -3.3175, 2.5052]  w:  [1.30799106 0.46371479 1.27971939]
6.382102181474391  -  71.0139  =  -64.63179781852561
training  [4.3441, -3.0375, 0.8353]  w:  [1.30799106 0.46371479 1.27971939]
5.342459906289992  -  63.8979  =  -58.555440093710004
training  [4.844, -1.8252, 0.5179]  w:  [1.30799106 0.46371479 1.27971939]
6.152303143899813  -  78.0461  =  -71.89379685610018
training  [3.5894, -1.8357, 0.8357]  w:  [1.30799106 0.46371479 1.27971939]
4.913123372977665  -  68.8838  =  -63.97067662702233
training  [2.8556, -2.8244, 0.1182]  w:  [1.30799106 0.46371479 1.27971939]
2.5766460586807662  -  39.5252  =  -36.94855394131923
training  [0.1338, -2.4896, -4.1741]  w:  [1.30799106 0.46371479 1.27971939]
-6.321131830385838  -  2.2644  =  -8.585531830385838
training  [-3.224, 3.9292, 2.1957]  w:  [1.30799106 0.46371479 1.27971939]
0.4149448237203215  -  72.1211  =  -71.70615517627968
training  [-1.0141, 2.0322, 4.9616]  w:  [1.30799106 0.46371479 1.27971939]
5.965383171089233  -  92.3427  =  -86.37731682891076
training  [-3.6607, 0.5574, -1.4547]  w:  [1.30799106 0.46371479 1.27971939]
-6.391296051710354  -  5.8471  =  -12.238396051710353
training  [-4.6911, -3.1557, 4.7126]  w:  [1.30799106 0.46371479 1.27971939]
-1.568456048424312  -  11.2337  =  -12.802156048424312
training  [4.3914, -2.8797, -1.5355]  w:  [1.30799106 0.46371479 1.27971939]
2.4435433535482414  -  37.475  =  -35.03145664645176
training  [-1.9869, -4.2265, 3.8654]  w:  [1.30799106 0.46371479 1.27971939]
0.38788932126744413  -  15.7889  =  -15.401010678732556
training  [-2.0447, 4.138, -0.4531]  w:  [1.30799106 0.46371479 1.27971939]
-1.335438381770465  -  57.936  =  -59.271438381770466
training  [-1.6706, 2.0672, -0.8657]  w:  [1.30799106 0.46371479 1.27971939]
-2.334391730229572  -  32.4185  =  -34.75289173022957
training  [-0.3293, 0.5779, -2.8227]  w:  [1.30799106 0.46371479 1.27971939]
-3.7750045950675375  -  14.3434  =  -18.11840459506754
training  [1.482, -1.8657, -3.7435]  w:  [1.30799106 0.46371479 1.27971939]
-3.717339454703903  -  7.1519  =  -10.869239454703903
training  [-4.7477, -3.338, -1.9109]  w:  [1.30799106 0.46371479 1.27971939]
-10.203244911367097  -  0.4077  =  -10.610944911367097
training  [3.4221, 1.225, 2.261]  w:  [1.30799106 0.46371479 1.27971939]
7.93757236673666  -  95.0454  =  -87.10782763326334
training  [0.5903, 4.8793, 2.8287]  w:  [1.30799106 0.46371479 1.27971939]
6.654652926822679  -  97.4647  =  -90.81004707317732
training  [3.541, -3.2957, 1.9379]  w:  [1.30799106 0.46371479 1.27971939]
5.583299722025329  -  64.3732  =  -58.78990027797467
training  [-1.5212, -2.4221, -4.902]  w:  [1.30799106 0.46371479 1.27971939]
-9.3860640326002  -  0.7227  =  -10.108764032600199
training  [-0.5397, -1.032, 3.4321]  w:  [1.30799106 0.46371479 1.27971939]
3.207648470678058  -  60.5921  =  -57.38445152932194
training  [-4.4576, -4.2601, 4.2233]  w:  [1.30799106 0.46371479 1.27971939]
-2.4013334449097243  -  6.0247  =  -8.426033444909724
training  [-3.2289, 1.841, 2.7095]  w:  [1.30799106 0.46371479 1.27971939]
0.09772626578071675  -  54.0111  =  -53.913373734219284
training  [1.6281, -0.9761, -4.5734]  w:  [1.30799106 0.46371479 1.27971939]
-4.175760403561345  -  7.8658  =  -12.041560403561345
training  [-1.6917, 4.8284, -1.2181]  w:  [1.30799106 0.46371479 1.27971939]
-1.532554177586883  -  61.2837  =  -62.816254177586885
training  [3.9849, -0.9782, 2.0434]  w:  [1.30799106 0.46371479 1.27971939]
7.373586374212692  -  88.3402  =  -80.9666136257873
training  [-3.8184, 1.2067, 2.2951]  w:  [1.30799106 0.46371479 1.27971939]
-1.4977844705441812  -  34.1122  =  -35.609984470544184
training  [4.8842, -3.4563, -2.7572]  w:  [1.30799106 0.46371479 1.27971939]
1.25731022598542  -  23.7819  =  -22.52458977401458
training  [0.3998, -1.1865, -2.3095]  w:  [1.30799106 0.46371479 1.27971939]
-2.982774696020285  -  11.4246  =  -14.407374696020284
training  [2.0692, -3.3887, 1.7303]  w:  [1.30799106 0.46371479 1.27971939]
3.349403256058197  -  42.6881  =  -39.3386967439418
training  [4.9949, 2.5811, -0.2251]  w:  [1.30799106 0.46371479 1.27971939]
7.442113966416536  -  95.9901  =  -88.54798603358346
training  [-2.1215, 3.7111, 1.2372]  w:  [1.30799106 0.46371479 1.27971939]
0.5292577416760107  -  71.3692  =  -70.839942258324
training  [-0.8548, -1.4922, -2.6356]  w:  [1.30799106 0.46371479 1.27971939]
-5.182854386315286  -  4.7821  =  -9.964954386315286
training  [-0.3516, 1.8554, -3.2288]  w:  [1.30799106 0.46371479 1.27971939]
-3.731471195679012  -  20.3834  =  -24.114871195679015
training  [2.6396, -2.0585, 3.2964]  w:  [1.30799106 0.46371479 1.27971939]
6.716483303475378  -  80.826  =  -74.10951669652462
training  [3.182, 0.3063, 2.6692]  w:  [1.30799106 0.46371479 1.27971939]
7.719890389670232  -  92.9483  =  -85.22840961032978
training  [-3.9978, 3.3242, 4.3448]  w:  [1.30799106 0.46371479 1.27971939]
1.8725188276166862  -  79.1768  =  -77.30428117238331
training  [-3.2188, 0.9749, -3.9211]  w:  [1.30799106 0.46371479 1.27971939]
-8.775993773865112  -  2.7053  =  -11.481293773865112
training  [-1.4037, -1.6469, -3.1777]  w:  [1.30799106 0.46371479 1.27971939]
-6.666283238335778  -  2.6234  =  -9.289683238335778
training  [-4.433, -2.0077, -4.009]  w:  [1.30799106 0.46371479 1.27971939]
-11.85971958660576  -  0.3253  =  -12.18501958660576
training  [0.2189, -0.4741, -0.1024]  w:  [1.30799106 0.46371479 1.27971939]
-0.06457120330499108  -  33.6531  =  -33.717671203304995
training  [-1.6415, -0.7735, -3.0675]  w:  [1.30799106 0.46371479 1.27971939]
-6.4312899395246745  -  3.7641  =  -10.195389939524674
training  [-3.2433, -1.4039, 3.9589]  w:  [1.30799106 0.46371479 1.27971939]
0.17306447737489528  -  30.0658  =  -29.892735522625102
training  [-2.9105, 0.5832, -4.0091]  w:  [1.30799106 0.46371479 1.27971939]
-8.666992518369215  -  2.4887  =  -11.155692518369214
training  [4.0515, 2.4255, -4.5583]  w:  [1.30799106 0.46371479 1.27971939]
0.5907211272149864  -  61.2853  =  -60.694578872785016
training  [1.7539, -0.7567, 0.573]  w:  [1.30799106 0.46371479 1.27971939]
2.6764717523965103  -  57.0797  =  -54.403228247603494
training  [-0.3153, -0.7064, 2.725]  w:  [1.30799106 0.46371479 1.27971939]
2.747257621628048  -  58.7004  =  -55.95314237837195
training  [4.1213, -3.7513, -1.8806]  w:  [1.30799106 0.46371479 1.27971939]
1.244449996623914  -  22.1789  =  -20.934450003376085
training  [-3.9599, -4.7557, -3.2102]  w:  [1.30799106 0.46371479 1.27971939]
-11.492957409243504  -  0.1558  =  -11.648757409243503
training  [2.4555, -2.0981, -1.6104]  w:  [1.30799106 0.46371479 1.27971939]
0.1779919529218854  -  24.4796  =  -24.301608047078116
training  [2.3627, -1.8248, -2.8985]  w:  [1.30799106 0.46371479 1.27971939]
-1.4650629087243168  -  15.7052  =  -17.170262908724318
training  [0.6186, 1.5369, 0.1015]  w:  [1.30799106 0.46371479 1.27971939]
1.6516980487276367  -  65.2154  =  -63.563701951272364
training  [-3.1581, 4.5694, 4.0636]  w:  [1.30799106 0.46371479 1.27971939]
3.188399486643856  -  90.3564  =  -87.16800051335613
training  [0.9721, 4.3573, 1.2892]  w:  [1.30799106 0.46371479 1.27971939]
4.941856797493133  -  94.3178  =  -89.37594320250687
training  [-2.0006, -0.4211, -3.9847]  w:  [1.30799106 0.46371479 1.27971939]
-7.911335060469088  -  2.4051  =  -10.316435060469088
training  [-3.6588, -2.5952, -1.0915]  w:  [1.30799106 0.46371479 1.27971939]
-7.3859240318970905  -  1.5176  =  -8.90352403189709
training  [-2.874, 2.639, -4.4538]  w:  [1.30799106 0.46371479 1.27971939]
-8.235037192356714  -  5.497  =  -13.732037192356714
training  [3.9494, 2.5933, 0.0128]  w:  [1.30799106 0.46371479 1.27971939]
6.384711873315335  -  94.1462  =  -87.76148812668465
training  [-4.2855, 2.4065, -0.6828]  w:  [1.30799106 0.46371479 1.27971939]
-5.363258455488636  -  14.4193  =  -19.782558455488637
training  [-2.5751, 2.4369, 4.9756]  w:  [1.30799106 0.46371479 1.27971939]
4.129190569238625  -  87.1991  =  -83.06990943076137
training  [-4.4625, -3.9408, 3.116]  w:  [1.30799106 0.46371479 1.27971939]
-3.6767117466087034  -  4.1344  =  -7.811111746608704
training  [-0.5828, 1.8156, -0.1435]  w:  [1.30799106 0.46371479 1.27971939]
-0.10401635186026764  -  51.1166  =  -51.220616351860265
training  [-4.8672, -0.3674, 3.9445]  w:  [1.30799106 0.46371479 1.27971939]
-1.4887697890327134  -  24.1396  =  -25.628369789032714
training  [3.9719, -2.8784, -3.6245]  w:  [1.30799106 0.46371479 1.27971939]
-0.7778898682935491  -  14.6104  =  -15.38828986829355
training  [-3.0334, -4.0148, -1.1]  w:  [1.30799106 0.46371479 1.27971939]
-7.237073551107196  -  1.021  =  -8.258073551107195
training  [-4.0663, 3.2357, 4.2736]  w:  [1.30799106 0.46371479 1.27971939]
1.6507666605998637  -  77.2328  =  -75.58203333940014
training  [-1.9263, -3.2499, 4.1749]  w:  [1.30799106 0.46371479 1.27971939]
1.3160905932890143  -  26.8814  =  -25.565309406710984
training  [-0.4394, -3.3643, 2.1357]  w:  [1.30799106 0.46371479 1.27971939]
0.5982897572962123  -  20.85  =  -20.25171024270379
training  [-3.9833, 1.6599, 1.1834]  w:  [1.30799106 0.46371479 1.27971939]
-2.9259806972553606  -  25.5397  =  -28.46568069725536
training  [4.9539, 3.9439, -1.5671]  w:  [1.30799106 0.46371479 1.27971939]
6.303053429757117  -  95.9509  =  -89.64784657024289
training  [-1.6791, 0.1656, 4.3603]  w:  [1.30799106 0.46371479 1.27971939]
3.4605038211902888  -  71.5733  =  -68.11279617880972
training  [-2.0265, 2.027, -3.7523]  w:  [1.30799106 0.46371479 1.27971939]
-6.512585067677913  -  8.503  =  -15.015585067677913
training  [-4.3795, -3.4641, 2.3059]  w:  [1.30799106 0.46371479 1.27971939]
-4.383796324135048  -  3.6654  =  -8.049196324135048
training  [-2.0176, 4.5346, 1.4648]  w:  [1.30799106 0.46371479 1.27971939]
1.33829127462996  -  81.6212  =  -80.28290872537004
training  [-4.5365, 0.4088, 3.3315]  w:  [1.30799106 0.46371479 1.27971939]
-1.4807497097295732  -  28.9449  =  -30.425649709729573
training  [0.0543, 1.7973, -1.0172]  w:  [1.30799106 0.46371479 1.27971939]
-0.39727205541817556  -  47.9317  =  -48.32897205541818
training  [2.6143, -4.6344, 2.4982]  w:  [1.30799106 0.46371479 1.27971939]
4.4674361888001375  -  43.5132  =  -39.04576381119986
training  [1.3107, 3.092, 3.3522]  w:  [1.30799106 0.46371479 1.27971939]
7.438065344642364  -  96.6993  =  -89.26123465535763
training  [-4.1011, 2.4862, -1.7754]  w:  [1.30799106 0.46371479 1.27971939]
-6.4833282375828984  -  10.0187  =  -16.5020282375829
training  [-4.1914, -3.7981, 0.5226]  w:  [1.30799106 0.46371479 1.27971939]
-6.574767528534512  -  1.4295  =  -8.004267528534513
training  [2.7724, 0.2505, 4.7913]  w:  [1.30799106 0.46371479 1.27971939]
9.873954477333509  -  96.7925  =  -86.91854552266649
training  [4.0513, -1.7417, 0.4931]  w:  [1.30799106 0.46371479 1.27971939]
5.122441772784404  -  71.1234  =  -66.0009582272156
training  [0.3377, 0.4645, -1.6958]  w:  [1.30799106 0.46371479 1.27971939]
-1.5130440358039352  -  27.9534  =  -29.466444035803935
training  [-3.9085, -1.0112, 1.1947]  w:  [1.30799106 0.46371479 1.27971939]
-4.052310710384953  -  8.608  =  -12.660310710384953
training  [3.2581, -0.8491, -1.3936]  w:  [1.30799106 0.46371479 1.27971939]
2.0844085146769835  -  50.1924  =  -48.10799148532301
training  [-1.619, -3.1926, 2.5651]  w:  [1.30799106 0.46371479 1.27971939]
-0.3154851656937483  -  16.4754  =  -16.790885165693748
training  [-2.0603, -2.4461, -0.861]  w:  [1.30799106 0.46371479 1.27971939]
-4.9309851246644225  -  3.9784  =  -8.909385124664423
training  [2.4631, -4.7946, -0.0765]  w:  [1.30799106 0.46371479 1.27971939]
0.900487324065463  -  15.394  =  -14.493512675934538
training  [-4.8966, 4.2368, 1.9474]  w:  [1.30799106 0.46371479 1.27971939]
-1.947916682067183  -  53.5883  =  -55.53621668206718
training  [-4.5155, 1.537, 4.7273]  w:  [1.30799106 0.46371479 1.27971939]
0.8561134488531268  -  59.2523  =  -58.39618655114687
training  [1.6792, 4.3261, -1.7225]  w:  [1.30799106 0.46371479 1.27971939]
1.9981384971754776  -  83.7729  =  -81.77476150282453
training  [1.0347, -3.3649, 3.378]  w:  [1.30799106 0.46371479 1.27971939]
4.115916548615029  -  50.5979  =  -46.48198345138498
training  [0.261, 4.211, 2.3907]  w:  [1.30799106 0.46371479 1.27971939]
5.353513784570547  -  94.9375  =  -89.58398621542945
training  [2.2971, 2.9466, 4.5417]  w:  [1.30799106 0.46371479 1.27971939]
10.183069809652473  -  98.7784  =  -88.59533019034754
training  [2.0725, 0.7739, -4.6808]  w:  [1.30799106 0.46371479 1.27971939]
-2.9204301563526798  -  19.5109  =  -22.43133015635268
training  [2.8138, -0.5996, -1.4313]  w:  [1.30799106 0.46371479 1.27971939]
1.5707195046475644  -  47.2879  =  -45.71718049535244
training  [-2.1202, -2.4239, 1.6265]  w:  [1.30799106 0.46371479 1.27971939]
-1.8157373447225575  -  12.3599  =  -14.175637344722556
training  [1.9253, 2.5195, -2.185]  w:  [1.30799106 0.46371479 1.27971939]
0.8904177426191668  -  65.2467  =  -64.35628225738084
training  [0.5667, -2.7133, -2.6962]  w:  [1.30799106 0.46371479 1.27971939]
-3.96733821511133  -  5.1106  =  -9.07793821511133
training  [-1.0348, -4.3581, 2.1113]  w:  [1.30799106 0.46371479 1.27971939]
-0.6725530319457111  -  10.5192  =  -11.19175303194571
training  [-4.3841, 2.6733, 1.2457]  w:  [1.30799106 0.46371479 1.27971939]
-2.9005684297828678  -  32.4639  =  -35.36446842978287
training  [2.8018, 1.712, 0.9061]  w:  [1.30799106 0.46371479 1.27971939]
5.618162815033058  -  90.1138  =  -84.49563718496694
training  [-1.6242, 2.1521, 1.6044]  w:  [1.30799106 0.46371479 1.27971939]
0.9267032995990625  -  63.7879  =  -62.86119670040094
training  [1.0787, 1.4206, -4.5245]  w:  [1.30799106 0.46371479 1.27971939]
-3.720407179733658  -  18.0555  =  -21.775907179733657
training  [2.4125, -0.8095, -1.5122]  w:  [1.30799106 0.46371479 1.27971939]
0.8449596585654173  -  38.8276  =  -37.98264034143458
training  [-3.9519, -1.0924, -0.4866]  w:  [1.30799106 0.46371479 1.27971939]
-6.298323369491888  -  3.6777  =  -9.976023369491887
training  [-3.7211, 3.1614, -2.591]  w:  [1.30799106 0.46371479 1.27971939]
-6.7169305405146655  -  11.1518  =  -17.868730540514665
training  [0.4954, -1.8257, 2.1505]  w:  [1.30799106 0.46371479 1.27971939]
2.5534112242246136  -  47.7531  =  -45.19968877577539
training  [-0.1477, 3.1454, 3.5618]  w:  [1.30799106 0.46371479 1.27971939]
5.8234827325052985  -  94.1572  =  -88.3337172674947
training  [3.9048, 2.8907, -2.1849]  w:  [1.30799106 0.46371479 1.27971939]
3.6518449524848253  -  85.8791  =  -82.22725504751517
training  [2.9896, 3.5226, 2.3105]  w:  [1.30799106 0.46371479 1.27971939]
8.50064344177959  -  98.038  =  -89.53735655822041
training  [2.3434, 0.0564, -3.6224]  w:  [1.30799106 0.46371479 1.27971939]
-1.5443557391813392  -  24.7629  =  -26.307255739181336
training  [-4.4867, 1.3566, 3.3672]  w:  [1.30799106 0.46371479 1.27971939]
-0.9304168953957204  -  40.5785  =  -41.50891689539572
training  [-4.2711, 4.5089, -3.614]  w:  [1.30799106 0.46371479 1.27971939]
-8.12062287964902  -  10.0825  =  -18.20312287964902
training  [-4.1147, -0.5604, 0.8821]  w:  [1.30799106 0.46371479 1.27971939]
-4.51301612096549  -  8.344  =  -12.85701612096549
training  [2.9835, -4.3998, -1.3384]  w:  [1.30799106 0.46371479 1.27971939]
0.14936257677035147  -  13.2692  =  -13.119837423229647
training  [4.4301, 3.6675, 3.0676]  w:  [1.30799106 0.46371479 1.27971939]
11.420872388455145  -  99.3834  =  -87.96252761154486
training  [1.8372, 1.3119, 0.0378]  w:  [1.30799106 0.46371479 1.27971939]
3.0597620048716663  -  74.9026  =  -71.84283799512833
training  [-3.6792, -1.4493, -0.1041]  w:  [1.30799106 0.46371479 1.27971939]
-5.617641349360941  -  4.2442  =  -9.86184134936094
training  [2.2272, 4.97, 3.7705]  w:  [1.30799106 0.46371479 1.27971939]
10.043002147446362  -  99.3199  =  -89.27689785255365
training  [-3.8965, -2.7583, -1.4686]  w:  [1.30799106 0.46371479 1.27971939]
-8.255047570581928  -  1.0337  =  -9.288747570581927
training  [-3.8251, 1.5245, -0.5056]  w:  [1.30799106 0.46371479 1.27971939]
-4.943289539033132  -  12.9762  =  -17.919489539033133
training  [1.4072, 1.0499, 4.6353]  w:  [1.30799106 0.46371479 1.27971939]
8.259342456981518  -  95.4618  =  -87.20245754301848
training  [-1.7119, -1.1275, -4.577]  w:  [1.30799106 0.46371479 1.27971939]
-8.61926396107464  -  1.4655  =  -10.084763961074641
training  [1.5381, -3.5781, 4.7296]  w:  [1.30799106 0.46371479 1.27971939]
6.405163980446733  -  69.9473  =  -63.54213601955327
training  [2.4913, -4.7487, -3.1079]  w:  [1.30799106 0.46371479 1.27971939]
-2.920684170235067  -  3.9825  =  -6.9031841702350665
training  [0.8319, -0.7889, 1.6712]  w:  [1.30799106 0.46371479 1.27971939]
2.8609602078806495  -  58.8336  =  -55.972639792119345
training  [2.4003, -3.159, 0.8644]  w:  [1.30799106 0.46371479 1.27971939]
2.780885366353874  -  39.0041  =  -36.22321463364613
training  [-2.6517, 2.2578, 1.7511]  w:  [1.30799106 0.46371479 1.27971939]
-0.18050802971364588  -  54.4525  =  -54.63300802971364
training  [2.3496, -1.2964, -1.3898]  w:  [1.30799106 0.46371479 1.27971939]
0.6935419428528542  -  33.888  =  -33.194458057147145
training  [4.706, 3.4156, 1.2028]  w:  [1.30799106 0.46371479 1.27971939]
9.278516653464193  -  98.4665  =  -89.1879833465358
training  [3.6693, 2.3423, 3.1115]  w:  [1.30799106 0.46371479 1.27971939]
9.867417630472833  -  98.3069  =  -88.43948236952717
training  [-4.1377, 0.7103, -4.8074]  w:  [1.30799106 0.46371479 1.27971939]
-11.234820987496825  -  0.9782  =  -12.213020987496824
training  [-1.3356, -3.2314, -4.1613]  w:  [1.30799106 0.46371479 1.27971939]
-8.570697120104043  -  0.7659  =  -9.336597120104043
training  [-1.308, 4.5738, 4.748]  w:  [1.30799106 0.46371479 1.27971939]
6.4861940451407865  -  97.0884  =  -90.6022059548592
training  [1.8503, -2.3468, 1.5135]  w:  [1.30799106 0.46371479 1.27971939]
3.2687852882522312  -  50.2125  =  -46.943714711747766
training  [0.9794, 4.2458, -2.6876]  w:  [1.30799106 0.46371479 1.27971939]
-0.18948712673479085  -  68.3262  =  -68.51568712673479
training  [2.8936, -2.7623, -0.9651]  w:  [1.30799106 0.46371479 1.27971939]
1.2688263950538756  -  28.5596  =  -27.290773604946125
training  [-1.3235, -1.2644, -3.7798]  w:  [1.30799106 0.46371479 1.27971939]
-7.154530491400534  -  2.4511  =  -9.605630491400534
training  [-2.9397, -4.125, -2.3156]  w:  [1.30799106 0.46371479 1.27971939]
-8.721243045708668  -  0.554  =  -9.275243045708669
training  [-4.1333, 1.4012, -2.4215]  w:  [1.30799106 0.46371479 1.27971939]
-7.855402792402751  -  4.4072  =  -12.26260279240275
training  [2.7193, -3.1938, -1.6833]  w:  [1.30799106 0.46371479 1.27971939]
-0.07834384277343043  -  17.0949  =  -17.17324384277343
training  [-2.9433, -4.5495, -3.4777]  w:  [1.30799106 0.46371479 1.27971939]
-10.409960641734166  -  0.2509  =  -10.660860641734166
training  [-1.1173, 2.2317, -1.5199]  w:  [1.30799106 0.46371479 1.27971939]
-2.3715916157955683  -  33.1206  =  -35.49219161579557
training  [0.5178, -1.5256, -3.7834]  w:  [1.30799106 0.46371479 1.27971939]
-4.871855840849224  -  5.237  =  -10.108855840849223
training  [-2.7105, 1.6062, 3.8415]  w:  [1.30799106 0.46371479 1.27971939]
2.1155509466184377  -  70.4458  =  -68.33024905338156
training  [1.4194, -1.1613, -4.0572]  w:  [1.30799106 0.46371479 1.27971939]
-3.8740269694766027  -  8.3206  =  -12.194626969476603
training  [-0.1552, 1.2735, 4.3004]  w:  [1.30799106 0.46371479 1.27971939]
5.890845825024181  -  90.1085  =  -84.21765417497582
training  [-3.4815, -4.7835, -1.0098]  w:  [1.30799106 0.46371479 1.27971939]
-8.064211215978025  -  0.5839  =  -8.648111215978025
training  [2.8193, 4.1057, -4.526]  w:  [1.30799106 0.46371479 1.27971939]
-0.20051693476542454  -  66.8081  =  -67.00861693476543
training  [-3.9939, 3.0056, -1.5763]  w:  [1.30799106 0.46371479 1.27971939]
-5.847466004088828  -  14.4018  =  -20.249266004088827
training  [-2.0593, 2.4585, 2.3597]  w:  [1.30799106 0.46371479 1.27971939]
1.4662506530962285  -  70.6698  =  -69.20354934690377
training  [-2.6263, 3.1311, 2.9468]  w:  [1.30799106 0.46371479 1.27971939]
1.7878375403261069  -  77.309  =  -75.52116245967389
training  [0.3087, -1.1669, 0.4491]  w:  [1.30799106 0.46371479 1.27971939]
0.43739003025605444  -  33.0798  =  -32.642409969743944
training  [-4.085, 1.1728, 1.8622]  w:  [1.30799106 0.46371479 1.27971939]
-2.416205341976762  -  26.4056  =  -28.821805341976763
training  [-0.9468, 0.7549, 3.9363]  w:  [1.30799106 0.46371479 1.27971939]
4.149011781285403  -  79.7738  =  -75.62478821871458
training  [-3.9515, 0.3005, -4.4521]  w:  [1.30799106 0.46371479 1.27971939]
-10.726619073960748  -  1.0441  =  -11.770719073960748
training  [-3.8772, -2.2493, -1.9634]  w:  [1.30799106 0.46371479 1.27971939]
-8.626977668232545  -  1.0509  =  -9.677877668232545
training  [2.8443, -2.5137, -4.5381]  w:  [1.30799106 0.46371479 1.27971939]
-3.2528154390361155  -  6.8897  =  -10.142515439036115
training  [-2.0843, -0.4836, -3.0452]  w:  [1.30799106 0.46371479 1.27971939]
-6.84749972222648  -  3.5346  =  -10.382099722226481
training  [1.0353, -2.7229, 2.2017]  w:  [1.30799106 0.46371479 1.27971939]
2.9090723225308732  -  43.9562  =  -41.04712767746913
training  [4.6442, 3.0445, 2.2175]  w:  [1.30799106 0.46371479 1.27971939]
10.324129509934572  -  98.8492  =  -88.52507049006542
training  [-0.6752, 4.861, 3.778]  w:  [1.30799106 0.46371479 1.27971939]
6.205741871132593  -  97.017  =  -90.81125812886741
training  [1.9475, -4.7001, 0.8243]  w:  [1.30799106 0.46371479 1.27971939]
1.4226794040561486  -  18.7839  =  -17.361220595943852
training  [2.581, 0.3566, -4.2932]  w:  [1.30799106 0.46371479 1.27971939]
-1.9528056480907687  -  23.5455  =  -25.49830564809077
training  [-0.6736, -4.1292, 4.2274]  w:  [1.30799106 0.46371479 1.27971939]
2.6140518508494557  -  31.2667  =  -28.652648149150544
training  [1.555, 3.0209, 3.0037]  w:  [1.30799106 0.46371479 1.27971939]
7.278655233159467  -  96.4078  =  -89.12914476684053
training  [-3.9024, 4.8914, -2.1405]  w:  [1.30799106 0.46371479 1.27971939]
-5.575329150620007  -  25.4308  =  -31.00612915062001
training  [4.3376, -4.3305, 0.4366]  w:  [1.30799106 0.46371479 1.27971939]
4.2241506220555545  -  43.0907  =  -38.866549377944445
training  [-3.1254, 4.394, 4.8478]  w:  [1.30799106 0.46371479 1.27971939]
4.1533911639760905  -  92.8121  =  -88.6587088360239
training  [-2.3382, -4.8182, 2.1568]  w:  [1.30799106 0.46371479 1.27971939]
-2.532516525182304  -  4.7434  =  -7.275916525182304
training  [2.9783, 1.8384, 3.3897]  w:  [1.30799106 0.46371479 1.27971939]
9.08594785757397  -  97.3486  =  -88.26265214242603
training  [-0.124, 2.8374, -0.6674]  w:  [1.30799106 0.46371479 1.27971939]
0.29946873221545667  -  62.785  =  -62.48553126778454
training  [2.6896, 0.3414, -0.2938]  w:  [1.30799106 0.46371479 1.27971939]
3.300303434629173  -  70.4455  =  -67.14519656537082
training  [-1.0399, 3.8536, 0.6071]  w:  [1.30799106 0.46371479 1.27971939]
1.2037090462810391  -  77.0369  =  -75.83319095371897
training  [-2.2706, 3.99, -2.3091]  w:  [1.30799106 0.46371479 1.27971939]
-4.074702534687324  -  31.1134  =  -35.188102534687324
training  [-4.6277, 1.2594, 2.4902]  w:  [1.30799106 0.46371479 1.27971939]
-2.2822306155082495  -  28.1093  =  -30.391530615508252
training  [1.7329, -3.6213, 0.0389]  w:  [1.30799106 0.46371479 1.27971939]
0.6371484298443723  -  19.3919  =  -18.754751570155626
training  [-0.7044, -2.822, 1.4681]  w:  [1.30799106 0.46371479 1.27971939]
-0.3511960070785154  -  17.8122  =  -18.163396007078518
training  [-0.4826, -3.1786, -1.9225]  w:  [1.30799106 0.46371479 1.27971939]
-4.565460838345943  -  3.5851  =  -8.150560838345942
training  [1.0986, -4.5818, -3.6128]  w:  [1.30799106 0.46371479 1.27971939]
-5.311059643310749  -  1.7158  =  -7.026859643310749
training  [-4.406, -3.9306, -0.2443]  w:  [1.30799106 0.46371479 1.27971939]
-7.89832141834888  -  0.8241  =  -8.72242141834888
training  [-1.8419, 1.1644, -1.3754]  w:  [1.30799106 0.46371479 1.27971939]
-3.629365282781576  -  17.8517  =  -21.48106528278158
training  [2.7272, 4.3966, 2.8811]  w:  [1.30799106 0.46371479 1.27971939]
9.29292119530584  -  98.904  =  -89.61107880469416
training  [1.9643, -1.4554, 2.803]  w:  [1.30799106 0.46371479 1.27971939]
5.481449782654245  -  76.0591  =  -70.57765021734576
training  [-3.7467, -0.8937, 1.6851]  w:  [1.30799106 0.46371479 1.27971939]
-3.1586168811355164  -  12.1571  =  -15.315716881135517
training  [-3.6985, 4.8435, -3.665]  w:  [1.30799106 0.46371479 1.27971939]
-7.281773917546056  -  14.6793  =  -21.961073917546056
253590.38954498575
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.37380219 0.47280749 1.17025006]
9.440672658373597  -  87.3174  =  -77.8767273416264
training  [-4.1793, -4.9218, 1.7664]  w:  [1.37380219 0.47280749 1.17025006]
-6.00146566113453  -  1.5257  =  -7.52716566113453
training  [-3.9429, -0.7689, 4.883]  w:  [1.37380219 0.47280749 1.17025006]
-0.06597527667173075  -  39.7859  =  -39.85187527667173
training  [-3.5796, 1.5557, 2.6683]  w:  [1.37380219 0.47280749 1.17025006]
-1.0595374729512526  -  45.5674  =  -46.626937472951255
training  [-3.3354, 2.2292, -1.633]  w:  [1.37380219 0.47280749 1.17025006]
-5.439215727211726  -  13.3589  =  -18.798115727211727
training  [1.2096, 0.3121, 1.6238]  w:  [1.37380219 0.47280749 1.17025006]
3.7095663943996766  -  74.5119  =  -70.80233360560032
training  [0.7371, -3.9118, -2.5583]  w:  [1.37380219 0.47280749 1.17025006]
-3.830749459077341  -  3.3358  =  -7.166549459077341
training  [-4.4792, 1.3177, -2.0449]  w:  [1.37380219 0.47280749 1.17025006]
-7.923560694420663  -  4.2974  =  -12.220960694420663
training  [4.312, -3.735, 1.8018]  w:  [1.37380219 0.47280749 1.17025006]
6.266455644679832  -  66.5833  =  -60.316844355320164
training  [2.2866, -3.657, 0.2785]  w:  [1.37380219 0.47280749 1.17025006]
1.7381937553441682  -  26.0005  =  -24.262306244655832
training  [2.3784, -4.0141, -0.8841]  w:  [1.37380219 0.47280749 1.17025006]
0.3349365217461784  -  14.6809  =  -14.345963478253822
training  [-4.366, -3.5797, 1.0264]  w:  [1.37380219 0.47280749 1.17025006]
-6.489384649757621  -  1.8713  =  -8.360684649757621
training  [3.6044, -3.3175, 2.5052]  w:  [1.37380219 0.47280749 1.17025006]
6.314904233880334  -  71.0139  =  -64.69899576611968
training  [4.3441, -3.0375, 0.8353]  w:  [1.37380219 0.47280749 1.17025006]
5.509291231237157  -  63.8979  =  -58.38860876876284
training  [4.844, -1.8252, 0.5179]  w:  [1.37380219 0.47280749 1.17025006]
6.397802090295931  -  78.0461  =  -71.64829790970407
training  [3.5894, -1.8357, 0.8357]  w:  [1.37380219 0.47280749 1.17025006]
5.041170854545251  -  68.8838  =  -63.842629145454744
training  [2.8556, -2.8244, 0.1182]  w:  [1.37380219 0.47280749 1.17025006]
2.7259556282813575  -  39.5252  =  -36.79924437171864
training  [0.1338, -2.4896, -4.1741]  w:  [1.37380219 0.47280749 1.17025006]
-5.87802756420184  -  2.2644  =  -8.14242756420184
training  [-3.224, 3.9292, 2.1957]  w:  [1.37380219 0.47280749 1.17025006]
-0.0018650276967084878  -  72.1211  =  -72.12296502769671
training  [-1.0141, 2.0322, 4.9616]  w:  [1.37380219 0.47280749 1.17025006]
5.373979276784448  -  92.3427  =  -86.96872072321554
training  [-3.6607, 0.5574, -1.4547]  w:  [1.37380219 0.47280749 1.17025006]
-6.467897546982542  -  5.8471  =  -12.314997546982543
training  [-4.6911, -3.1557, 4.7126]  w:  [1.37380219 0.47280749 1.17025006]
-2.4217615906424523  -  11.2337  =  -13.655461590642453
training  [4.3914, -2.8797, -1.5355]  w:  [1.37380219 0.47280749 1.17025006]
2.874452249819547  -  37.475  =  -34.60054775018045
training  [-1.9869, -4.2265, 3.8654]  w:  [1.37380219 0.47280749 1.17025006]
-0.2044438174794294  -  15.7889  =  -15.99334381747943
training  [-2.0447, 4.138, -0.4531]  w:  [1.37380219 0.47280749 1.17025006]
-1.3827762661775416  -  57.936  =  -59.318776266177544
training  [-1.6706, 2.0672, -0.8657]  w:  [1.37380219 0.47280749 1.17025006]
-2.3307717826935948  -  32.4185  =  -34.7492717826936
training  [-0.3293, 0.5779, -2.8227]  w:  [1.37380219 0.47280749 1.17025006]
-3.482422464289632  -  14.3434  =  -17.825822464289633
training  [1.482, -1.8657, -3.7435]  w:  [1.37380219 0.47280749 1.17025006]
-3.2269731860505058  -  7.1519  =  -10.378873186050505
training  [-4.7477, -3.338, -1.9109]  w:  [1.37380219 0.47280749 1.17025006]
-10.336862882317956  -  0.4077  =  -10.744562882317956
training  [3.4221, 1.225, 2.261]  w:  [1.37380219 0.47280749 1.17025006]
7.926413030719943  -  95.0454  =  -87.11898696928006
training  [0.5903, 4.8793, 2.8287]  w:  [1.37380219 0.47280749 1.17025006]
6.42821134369262  -  97.4647  =  -91.03648865630737
training  [3.541, -3.2957, 1.9379]  w:  [1.37380219 0.47280749 1.17025006]
5.574229518286632  -  64.3732  =  -58.79897048171337
training  [-1.5212, -2.4221, -4.902]  w:  [1.37380219 0.47280749 1.17025006]
-8.971580702176809  -  0.7227  =  -9.694280702176808
training  [-0.5397, -1.032, 3.4321]  w:  [1.37380219 0.47280749 1.17025006]
2.7870368703356787  -  60.5921  =  -57.805063129664326
training  [-4.4576, -4.2601, 4.2233]  w:  [1.37380219 0.47280749 1.17025006]
-3.1957507211188894  -  6.0247  =  -9.22045072111889
training  [-3.2289, 1.841, 2.7095]  w:  [1.37380219 0.47280749 1.17025006]
-0.39463876711561907  -  54.0111  =  -54.405738767115615
training  [1.6281, -0.9761, -4.5734]  w:  [1.37380219 0.47280749 1.17025006]
-3.5768416736042954  -  7.8658  =  -11.442641673604296
training  [-1.6917, 4.8284, -1.2181]  w:  [1.37380219 0.47280749 1.17025006]
-1.4666391027864583  -  61.2837  =  -62.75033910278646
training  [3.9849, -0.9782, 2.0434]  w:  [1.37380219 0.47280749 1.17025006]
7.40325303832508  -  88.3402  =  -80.93694696167492
training  [-3.8184, 1.2067, 2.2951]  w:  [1.37380219 0.47280749 1.17025006]
-1.9893485710621444  -  34.1122  =  -36.101548571062146
training  [4.8842, -3.4563, -2.7572]  w:  [1.37380219 0.47280749 1.17025006]
1.8491466725272865  -  23.7819  =  -21.932753327472714
training  [0.3998, -1.1865, -2.3095]  w:  [1.37380219 0.47280749 1.17025006]
-2.7144324830998214  -  11.4246  =  -14.139032483099822
training  [2.0692, -3.3887, 1.7303]  w:  [1.37380219 0.47280749 1.17025006]
3.265352447109837  -  42.6881  =  -39.42274755289016
training  [4.9949, 2.5811, -0.2251]  w:  [1.37380219 0.47280749 1.17025006]
7.818944666411714  -  95.9901  =  -88.17115533358829
training  [-2.1215, 3.7111, 1.2372]  w:  [1.37380219 0.47280749 1.17025006]
0.28794788947630945  -  71.3692  =  -71.08125211052369
training  [-0.8548, -1.4922, -2.6356]  w:  [1.37380219 0.47280749 1.17025006]
-4.964160503133758  -  4.7821  =  -9.746260503133758
training  [-0.3516, 1.8554, -3.2288]  w:  [1.37380219 0.47280749 1.17025006]
-3.384285240942721  -  20.3834  =  -23.767685240942722
training  [2.6396, -2.0585, 3.2964]  w:  [1.37380219 0.47280749 1.17025006]
6.510626354094887  -  80.826  =  -74.31537364590511
training  [3.182, 0.3063, 2.6692]  w:  [1.37380219 0.47280749 1.17025006]
7.639890963669144  -  92.9483  =  -85.30840903633086
training  [-3.9978, 3.3242, 4.3448]  w:  [1.37380219 0.47280749 1.17025006]
1.1640227171714423  -  79.1768  =  -78.01277728282855
training  [-3.2188, 0.9749, -3.9211]  w:  [1.37380219 0.47280749 1.17025006]
-8.549721986502195  -  2.7053  =  -11.255021986502195
training  [-1.4037, -1.6469, -3.1777]  w:  [1.37380219 0.47280749 1.17025006]
-6.425776401216057  -  2.6234  =  -9.049176401216057
training  [-4.433, -2.0077, -4.009]  w:  [1.37380219 0.47280749 1.17025006]
-11.730853190234729  -  0.3253  =  -12.05615319023473
training  [0.2189, -0.4741, -0.1024]  w:  [1.37380219 0.47280749 1.17025006]
-0.04326633574466639  -  33.6531  =  -33.69636633574467
training  [-1.6415, -0.7735, -3.0675]  w:  [1.37380219 0.47280749 1.17025006]
-6.210554947573984  -  3.7641  =  -9.974654947573985
training  [-3.2433, -1.4039, 3.9589]  w:  [1.37380219 0.47280749 1.17025006]
-0.48652409999577984  -  30.0658  =  -30.55232409999578
training  [-2.9105, 0.5832, -4.0091]  w:  [1.37380219 0.47280749 1.17025006]
-8.414359468861312  -  2.4887  =  -10.903059468861311
training  [4.0515, 2.4255, -4.5583]  w:  [1.37380219 0.47280749 1.17025006]
1.3784032692410433  -  61.2853  =  -59.90689673075896
training  [1.7539, -0.7567, 0.573]  w:  [1.37380219 0.47280749 1.17025006]
2.722291521231742  -  57.0797  =  -54.357408478768264
training  [-0.3153, -0.7064, 2.725]  w:  [1.37380219 0.47280749 1.17025006]
2.421780380186699  -  58.7004  =  -56.278619619813306
training  [4.1213, -3.7513, -1.8806]  w:  [1.37380219 0.47280749 1.17025006]
1.6874359782078745  -  22.1789  =  -20.491464021792126
training  [-3.9599, -4.7557, -3.2102]  w:  [1.37380219 0.47280749 1.17025006]
-11.44538659424457  -  0.1558  =  -11.601186594244568
training  [2.4555, -2.0981, -1.6104]  w:  [1.37380219 0.47280749 1.17025006]
0.49680319220633273  -  24.4796  =  -23.98279680779367
training  [2.3627, -1.8248, -2.8985]  w:  [1.37380219 0.47280749 1.17025006]
-1.008866469679814  -  15.7052  =  -16.714066469679814
training  [0.6186, 1.5369, 0.1015]  w:  [1.37380219 0.47280749 1.17025006]
1.6952722394106112  -  65.2154  =  -63.52012776058939
training  [-3.1581, 4.5694, 4.0636]  w:  [1.37380219 0.47280749 1.17025006]
2.5772699786579762  -  90.3564  =  -87.77913002134201
training  [0.9721, 4.3573, 1.2892]  w:  [1.37380219 0.47280749 1.17025006]
4.904323542482472  -  94.3178  =  -89.41347645751753
training  [-2.0006, -0.4211, -3.9847]  w:  [1.37380219 0.47280749 1.17025006]
-7.610623312550894  -  2.4051  =  -10.015723312550893
training  [-3.6588, -2.5952, -1.0915]  w:  [1.37380219 0.47280749 1.17025006]
-7.530825377922323  -  1.5176  =  -9.048425377922323
training  [-2.874, 2.639, -4.4538]  w:  [1.37380219 0.47280749 1.17025006]
-7.9126282635172585  -  5.497  =  -13.40962826351726
training  [3.9494, 2.5933, 0.0128]  w:  [1.37380219 0.47280749 1.17025006]
6.666805218438727  -  94.1462  =  -87.47939478156127
training  [-4.2855, 2.4065, -0.6828]  w:  [1.37380219 0.47280749 1.17025006]
-5.548664811632628  -  14.4193  =  -19.967964811632626
training  [-2.5751, 2.4369, 4.9756]  w:  [1.37380219 0.47280749 1.17025006]
3.4372027493042747  -  87.1991  =  -83.76189725069572
training  [-4.4625, -3.9408, 3.116]  w:  [1.37380219 0.47280749 1.17025006]
-4.3473328151048864  -  4.1344  =  -8.481732815104888
training  [-0.5828, 1.8156, -0.1435]  w:  [1.37380219 0.47280749 1.17025006]
-0.11015352986731675  -  51.1166  =  -51.22675352986732
training  [-4.8672, -0.3674, 3.9445]  w:  [1.37380219 0.47280749 1.17025006]
-2.244228117857886  -  24.1396  =  -26.383828117857888
training  [3.9719, -2.8784, -3.6245]  w:  [1.37380219 0.47280749 1.17025006]
-0.14589549762920218  -  14.6104  =  -14.756295497629203
training  [-3.0334, -4.0148, -1.1]  w:  [1.37380219 0.47280749 1.17025006]
-7.352794120063047  -  1.021  =  -8.373794120063046
training  [-4.0663, 3.2357, 4.2736]  w:  [1.37380219 0.47280749 1.17025006]
0.9447520003832741  -  77.2328  =  -76.28804799961672
training  [-1.9263, -3.2499, 4.1749]  w:  [1.37380219 0.47280749 1.17025006]
0.702744779205764  -  26.8814  =  -26.178655220794234
training  [-0.4394, -3.3643, 2.1357]  w:  [1.37380219 0.47280749 1.17025006]
0.3049881525570557  -  20.85  =  -20.545011847442947
training  [-3.9833, 1.6599, 1.1834]  w:  [1.37380219 0.47280749 1.17025006]
-3.3025791933603914  -  25.5397  =  -28.84227919336039
training  [4.9539, 3.9439, -1.5671]  w:  [1.37380219 0.47280749 1.17025006]
6.83648523461337  -  95.9509  =  -89.11441476538664
training  [-1.6791, 0.1656, 4.3603]  w:  [1.37380219 0.47280749 1.17025006]
2.8741870071511166  -  71.5733  =  -68.69911299284888
training  [-2.0265, 2.027, -3.7523]  w:  [1.37380219 0.47280749 1.17025006]
-6.216758670690162  -  8.503  =  -14.719758670690162
training  [-4.3795, -3.4641, 2.3059]  w:  [1.37380219 0.47280749 1.17025006]
-4.955939480177959  -  3.6654  =  -8.621339480177959
training  [-2.0176, 4.5346, 1.4648]  w:  [1.37380219 0.47280749 1.17025006]
1.0863918149453151  -  81.6212  =  -80.53480818505469
training  [-4.5365, 0.4088, 3.3315]  w:  [1.37380219 0.47280749 1.17025006]
-2.1402818517003577  -  28.9449  =  -31.08518185170036
training  [0.0543, 1.7973, -1.0172]  w:  [1.37380219 0.47280749 1.17025006]
-0.2660040108656755  -  47.9317  =  -48.19770401086568
training  [2.6143, -4.6344, 2.4982]  w:  [1.37380219 0.47280749 1.17025006]
4.323870758673845  -  43.5132  =  -39.18932924132615
training  [1.3107, 3.092, 3.3522]  w:  [1.37380219 0.47280749 1.17025006]
7.1854755300615185  -  96.6993  =  -89.51382446993847
training  [-4.1011, 2.4862, -1.7754]  w:  [1.37380219 0.47280749 1.17025006]
-6.536268148697609  -  10.0187  =  -16.55496814869761
training  [-4.1914, -3.7981, 0.5226]  w:  [1.37380219 0.47280749 1.17025006]
-6.942351923292864  -  1.4295  =  -8.371851923292864
training  [2.7724, 0.2505, 4.7913]  w:  [1.37380219 0.47280749 1.17025006]
9.534186585040025  -  96.7925  =  -87.25831341495999
training  [4.0513, -1.7417, 0.4931]  w:  [1.37380219 0.47280749 1.17025006]
5.319246318283407  -  71.1234  =  -65.8041536817166
training  [0.3377, 0.4645, -1.6958]  w:  [1.37380219 0.47280749 1.17025006]
-1.3009579783551084  -  27.9534  =  -29.254357978355106
training  [-3.9085, -1.0112, 1.1947]  w:  [1.37380219 0.47280749 1.17025006]
-4.4495110373168085  -  8.608  =  -13.057511037316809
training  [3.2581, -0.8491, -1.3936]  w:  [1.37380219 0.47280749 1.17025006]
2.4436635916050755  -  50.1924  =  -47.748736408394926
training  [-1.619, -3.1926, 2.5651]  w:  [1.37380219 0.47280749 1.17025006]
-0.7318624883321379  -  16.4754  =  -17.207262488332137
training  [-2.0603, -2.4461, -0.861]  w:  [1.37380219 0.47280749 1.17025006]
-4.994564343031546  -  3.9784  =  -8.972964343031546
training  [2.4631, -4.7946, -0.0765]  w:  [1.37380219 0.47280749 1.17025006]
1.0273652748478863  -  15.394  =  -14.366634725152114
training  [-4.8966, 4.2368, 1.9474]  w:  [1.37380219 0.47280749 1.17025006]
-2.444824077475403  -  53.5883  =  -56.0331240774754
training  [-4.5155, 1.537, 4.7273]  w:  [1.37380219 0.47280749 1.17025006]
0.05542443497834704  -  59.2523  =  -59.19687556502165
training  [1.6792, 4.3261, -1.7225]  w:  [1.37380219 0.47280749 1.17025006]
2.3365453664083846  -  83.7729  =  -81.43635463359162
training  [1.0347, -3.3649, 3.378]  w:  [1.37380219 0.47280749 1.17025006]
3.7836279269370925  -  50.5979  =  -46.81427207306291
training  [0.261, 4.211, 2.3907]  w:  [1.37380219 0.47280749 1.17025006]
5.147271513464524  -  94.9375  =  -89.79022848653548
training  [2.2971, 2.9466, 4.5417]  w:  [1.37380219 0.47280749 1.17025006]
9.863860249606276  -  98.7784  =  -88.91453975039373
training  [2.0725, 0.7739, -4.6808]  w:  [1.37380219 0.47280749 1.17025006]
-2.2645957383796596  -  19.5109  =  -21.77549573837966
training  [2.8138, -0.5996, -1.4313]  w:  [1.37380219 0.47280749 1.17025006]
1.9071303190874904  -  47.2879  =  -45.38076968091251
training  [-2.1202, -2.4239, 1.6265]  w:  [1.37380219 0.47280749 1.17025006]
-2.155361739691381  -  12.3599  =  -14.51526173969138
training  [1.9253, 2.5195, -2.185]  w:  [1.37380219 0.47280749 1.17025006]
1.2792234291414215  -  65.2467  =  -63.96747657085858
training  [0.5667, -2.7133, -2.6962]  w:  [1.37380219 0.47280749 1.17025006]
-3.659563064763318  -  5.1106  =  -8.770163064763318
training  [-1.0348, -4.3581, 2.1113]  w:  [1.37380219 0.47280749 1.17025006]
-1.0114038511583252  -  10.5192  =  -11.530603851158325
training  [-4.3841, 2.6733, 1.2457]  w:  [1.37380219 0.47280749 1.17025006]
-3.3011494266206007  -  32.4639  =  -35.76504942662061
training  [2.8018, 1.712, 0.9061]  w:  [1.37380219 0.47280749 1.17025006]
5.718928969403599  -  90.1138  =  -84.39487103059639
training  [-1.6242, 2.1521, 1.6044]  w:  [1.37380219 0.47280749 1.17025006]
0.6637486716157979  -  63.7879  =  -63.1241513283842
training  [1.0787, 1.4206, -4.5245]  w:  [1.37380219 0.47280749 1.17025006]
-3.1412056689055183  -  18.0555  =  -21.196705668905516
training  [2.4125, -0.8095, -1.5122]  w:  [1.37380219 0.47280749 1.17025006]
1.1619079794000284  -  38.8276  =  -37.66569202059997
training  [-3.9519, -1.0924, -0.4866]  w:  [1.37380219 0.47280749 1.17025006]
-6.515067448747083  -  3.6777  =  -10.192767448747084
training  [-3.7211, 3.1614, -2.591]  w:  [1.37380219 0.47280749 1.17025006]
-6.6494396530863416  -  11.1518  =  -17.80123965308634
training  [0.4954, -1.8257, 2.1505]  w:  [1.37380219 0.47280749 1.17025006]
2.3339997366176046  -  47.7531  =  -45.4191002633824
training  [-0.1477, 3.1454, 3.5618]  w:  [1.37380219 0.47280749 1.17025006]
5.452454749751951  -  94.1572  =  -88.70474525024805
training  [3.9048, 2.8907, -2.1849]  w:  [1.37380219 0.47280749 1.17025006]
4.174288026407725  -  85.8791  =  -81.70481197359227
training  [2.9896, 3.5226, 2.3105]  w:  [1.37380219 0.47280749 1.17025006]
8.476493439617288  -  98.038  =  -89.56150656038271
training  [2.3434, 0.0564, -3.6224]  w:  [1.37380219 0.47280749 1.17025006]
-0.9930794306050093  -  24.7629  =  -25.75597943060501
training  [-4.4867, 1.3566, 3.3672]  w:  [1.37380219 0.47280749 1.17025006]
-1.5819616411056976  -  40.5785  =  -42.1604616411057
training  [-4.2711, 4.5089, -3.614]  w:  [1.37380219 0.47280749 1.17025006]
-7.965088584118902  -  10.0825  =  -18.047588584118902
training  [-4.1147, -0.5604, 0.8821]  w:  [1.37380219 0.47280749 1.17025006]
-4.885467603747848  -  8.344  =  -13.229467603747848
training  [2.9835, -4.3998, -1.3384]  w:  [1.37380219 0.47280749 1.17025006]
0.45221777651705497  -  13.2692  =  -12.816982223482945
training  [4.4301, 3.6675, 3.0676]  w:  [1.37380219 0.47280749 1.17025006]
11.409961619611241  -  99.3834  =  -87.97343838038876
training  [1.8372, 1.3119, 0.0378]  w:  [1.37380219 0.47280749 1.17025006]
3.1884609742681524  -  74.9026  =  -71.71413902573185
training  [-3.6792, -1.4493, -0.1041]  w:  [1.37380219 0.47280749 1.17025006]
-5.861555934567206  -  4.2442  =  -10.105755934567206
training  [2.2272, 4.97, 3.7705]  w:  [1.37380219 0.47280749 1.17025006]
9.82201329436464  -  99.3199  =  -89.49788670563537
training  [-3.8965, -2.7583, -1.4686]  w:  [1.37380219 0.47280749 1.17025006]
-8.375794357387672  -  1.0337  =  -9.409494357387672
training  [-3.8251, 1.5245, -0.5056]  w:  [1.37380219 0.47280749 1.17025006]
-5.125814174586271  -  12.9762  =  -18.102014174586273
training  [1.4072, 1.0499, 4.6353]  w:  [1.37380219 0.47280749 1.17025006]
7.854075130118486  -  95.4618  =  -87.60772486988151
training  [-1.7119, -1.1275, -4.577]  w:  [1.37380219 0.47280749 1.17025006]
-8.241136939459501  -  1.4655  =  -9.706636939459502
training  [1.5381, -3.5781, 4.7296]  w:  [1.37380219 0.47280749 1.17025006]
5.956107376533127  -  69.9473  =  -63.99119262346687
training  [2.4913, -4.7487, -3.1079]  w:  [1.37380219 0.47280749 1.17025006]
-2.459687676682209  -  3.9825  =  -6.4421876766822095
training  [0.8319, -0.7889, 1.6712]  w:  [1.37380219 0.47280749 1.17025006]
2.725590119327284  -  58.8336  =  -56.10800988067271
training  [2.4003, -3.159, 0.8644]  w:  [1.37380219 0.47280749 1.17025006]
2.815502702956114  -  39.0041  =  -36.188597297043884
training  [-2.6517, 2.2578, 1.7511]  w:  [1.37380219 0.47280749 1.17025006]
-0.5261816427144224  -  54.4525  =  -54.97868164271442
training  [2.3496, -1.2964, -1.3898]  w:  [1.37380219 0.47280749 1.17025006]
0.9885244647457587  -  33.888  =  -32.89947553525424
training  [4.706, 3.4156, 1.2028]  w:  [1.37380219 0.47280749 1.17025006]
9.487611123222791  -  98.4665  =  -88.9788888767772
training  [3.6693, 2.3423, 3.1115]  w:  [1.37380219 0.47280749 1.17025006]
9.789582412431018  -  98.3069  =  -88.51731758756898
training  [-4.1377, 0.7103, -4.8074]  w:  [1.37380219 0.47280749 1.17025006]
-10.974406308465  -  0.9782  =  -11.952606308464999
training  [-1.3356, -3.2314, -4.1613]  w:  [1.37380219 0.47280749 1.17025006]
-8.232441892864589  -  0.7659  =  -8.99834189286459
training  [-1.308, 4.5738, 4.748]  w:  [1.37380219 0.47280749 1.17025006]
5.9219409042696185  -  97.0884  =  -91.16645909573037
training  [1.8503, -2.3468, 1.5135]  w:  [1.37380219 0.47280749 1.17025006]
3.2035350532134776  -  50.2125  =  -47.00896494678652
training  [0.9794, 4.2458, -2.6876]  w:  [1.37380219 0.47280749 1.17025006]
0.2077838187744896  -  68.3262  =  -68.11841618122551
training  [2.8936, -2.7623, -0.9651]  w:  [1.37380219 0.47280749 1.17025006]
1.5397895645328559  -  28.5596  =  -27.019810435467143
training  [-1.3235, -1.2644, -3.7798]  w:  [1.37380219 0.47280749 1.17025006]
-6.8393561646947445  -  2.4511  =  -9.290456164694744
training  [-2.9397, -4.125, -2.3156]  w:  [1.37380219 0.47280749 1.17025006]
-8.698728214699917  -  0.554  =  -9.252728214699918
training  [-4.1333, 1.4012, -2.4215]  w:  [1.37380219 0.47280749 1.17025006]
-7.849599265334735  -  4.4072  =  -12.256799265334735
training  [2.7193, -3.1938, -1.6833]  w:  [1.37380219 0.47280749 1.17025006]
0.25584581885118607  -  17.0949  =  -16.839054181148814
training  [-2.9433, -4.5495, -3.4777]  w:  [1.37380219 0.47280749 1.17025006]
-10.264328276624852  -  0.2509  =  -10.515228276624851
training  [-1.1173, 2.2317, -1.5199]  w:  [1.37380219 0.47280749 1.17025006]
-2.2584477903561724  -  33.1206  =  -35.379047790356175
training  [0.5178, -1.5256, -3.7834]  w:  [1.37380219 0.47280749 1.17025006]
-4.437484408791995  -  5.237  =  -9.674484408791995
training  [-2.7105, 1.6062, 3.8415]  w:  [1.37380219 0.47280749 1.17025006]
1.5312481601079653  -  70.4458  =  -68.91455183989204
training  [1.4194, -1.1613, -4.0572]  w:  [1.37380219 0.47280749 1.17025006]
-3.3470350549422907  -  8.3206  =  -11.667635054942291
training  [-0.1552, 1.2735, 4.3004]  w:  [1.37380219 0.47280749 1.17025006]
5.421449597520185  -  90.1085  =  -84.68705040247983
training  [-3.4815, -4.7835, -1.0098]  w:  [1.37380219 0.47280749 1.17025006]
-8.226285439332631  -  0.5839  =  -8.810185439332631
training  [2.8193, 4.1057, -4.526]  w:  [1.37380219 0.47280749 1.17025006]
0.5178144249715544  -  66.8081  =  -66.29028557502843
training  [-3.9939, 3.0056, -1.5763]  w:  [1.37380219 0.47280749 1.17025006]
-5.910423558975236  -  14.4018  =  -20.312223558975234
training  [-2.0593, 2.4585, 2.3597]  w:  [1.37380219 0.47280749 1.17025006]
1.0947654240167095  -  70.6698  =  -69.57503457598328
training  [-2.6263, 3.1311, 2.9468]  w:  [1.37380219 0.47280749 1.17025006]
1.320883708315936  -  77.309  =  -75.98811629168407
training  [0.3087, -1.1669, 0.4491]  w:  [1.37380219 0.47280749 1.17025006]
0.3979329841805164  -  33.0798  =  -32.681867015819485
training  [-4.085, 1.1728, 1.8622]  w:  [1.37380219 0.47280749 1.17025006]
-2.8782336601652982  -  26.4056  =  -29.2838336601653
training  [-0.9468, 0.7549, 3.9363]  w:  [1.37380219 0.47280749 1.17025006]
3.6626617752330093  -  79.7738  =  -76.11113822476699
training  [-3.9515, 0.3005, -4.4521]  w:  [1.37380219 0.47280749 1.17025006]
-10.496571001300435  -  1.0441  =  -11.540671001300435
training  [-3.8772, -2.2493, -1.9634]  w:  [1.37380219 0.47280749 1.17025006]
-8.68766069572036  -  1.0509  =  -9.738560695720361
training  [2.8443, -2.5137, -4.5381]  w:  [1.37380219 0.47280749 1.17025006]
-2.5917024128244384  -  6.8897  =  -9.481402412824439
training  [-2.0843, -0.4836, -3.0452]  w:  [1.37380219 0.47280749 1.17025006]
-6.65571109071206  -  3.5346  =  -10.190311090712061
training  [1.0353, -2.7229, 2.2017]  w:  [1.37380219 0.47280749 1.17025006]
2.711429466177282  -  43.9562  =  -41.244770533822724
training  [4.6442, 3.0445, 2.2175]  w:  [1.37380219 0.47280749 1.17025006]
10.414704027745165  -  98.8492  =  -88.43449597225484
training  [-0.6752, 4.861, 3.778]  w:  [1.37380219 0.47280749 1.17025006]
5.791930679615848  -  97.017  =  -91.22506932038415
training  [1.9475, -4.7001, 0.8243]  w:  [1.37380219 0.47280749 1.17025006]
1.4178744288847702  -  18.7839  =  -17.36602557111523
training  [2.581, 0.3566, -4.2932]  w:  [1.37380219 0.47280749 1.17025006]
-1.3097309647386375  -  23.5455  =  -24.855230964738638
training  [-0.6736, -4.1292, 4.2274]  w:  [1.37380219 0.47280749 1.17025006]
2.069405288389227  -  31.2667  =  -29.197294711610773
training  [1.555, 3.0209, 3.0037]  w:  [1.37380219 0.47280749 1.17025006]
7.07964664624811  -  96.4078  =  -89.32815335375189
training  [-3.9024, 4.8914, -2.1405]  w:  [1.37380219 0.47280749 1.17025006]
-5.55335538804748  -  25.4308  =  -30.984155388047483
training  [4.3376, -4.3305, 0.4366]  w:  [1.37380219 0.47280749 1.17025006]
4.4224427392160335  -  43.0907  =  -38.66825726078397
training  [-3.1254, 4.394, 4.8478]  w:  [1.37380219 0.47280749 1.17025006]
3.4569729756978926  -  92.8121  =  -89.3551270243021
training  [-2.3382, -4.8182, 2.1568]  w:  [1.37380219 0.47280749 1.17025006]
-2.966309970826491  -  4.7434  =  -7.709709970826491
training  [2.9783, 1.8384, 3.3897]  w:  [1.37380219 0.47280749 1.17025006]
8.927600975009105  -  97.3486  =  -88.4209990249909
training  [-0.124, 2.8374, -0.6674]  w:  [1.37380219 0.47280749 1.17025006]
0.39016759557333935  -  62.785  =  -62.39483240442666
training  [2.6896, 0.3414, -0.2938]  w:  [1.37380219 0.47280749 1.17025006]
3.5125753757461076  -  70.4455  =  -66.93292462425389
training  [-1.0399, 3.8536, 0.6071]  w:  [1.37380219 0.47280749 1.17025006]
1.1038528402548056  -  77.0369  =  -75.9330471597452
training  [-2.2706, 3.99, -2.3091]  w:  [1.37380219 0.47280749 1.17025006]
-3.9350778029332467  -  31.1134  =  -35.04847780293325
training  [-4.6277, 1.2594, 2.4902]  w:  [1.37380219 0.47280749 1.17025006]
-2.8479339414052203  -  28.1093  =  -30.95723394140522
training  [1.7329, -3.6213, 0.0389]  w:  [1.37380219 0.47280749 1.17025006]
0.7140067955576239  -  19.3919  =  -18.677893204442377
training  [-0.7044, -2.822, 1.4681]  w:  [1.37380219 0.47280749 1.17025006]
-0.5839248696014463  -  17.8122  =  -18.396124869601447
training  [-0.4826, -3.1786, -1.9225]  w:  [1.37380219 0.47280749 1.17025006]
-4.415668552161669  -  3.5851  =  -8.00076855216167
training  [1.0986, -4.5818, -3.6128]  w:  [1.37380219 0.47280749 1.17025006]
-4.884929672631805  -  1.7158  =  -6.600729672631805
training  [-4.406, -3.9306, -0.2443]  w:  [1.37380219 0.47280749 1.17025006]
-8.197281637165462  -  0.8241  =  -9.021381637165462
training  [-1.8419, 1.1644, -1.3754]  w:  [1.37380219 0.47280749 1.17025006]
-3.5894311516781414  -  17.8517  =  -21.441131151678142
training  [2.7272, 4.3966, 2.8811]  w:  [1.37380219 0.47280749 1.17025006]
9.196986172268613  -  98.904  =  -89.70701382773139
training  [1.9643, -1.4554, 2.803]  w:  [1.37380219 0.47280749 1.17025006]
5.29064654948051  -  76.0591  =  -70.76845345051949
training  [-3.7467, -0.8937, 1.6851]  w:  [1.37380219 0.47280749 1.17025006]
-3.5977843333591806  -  12.1571  =  -15.75488433335918
training  [-3.6985, 4.8435, -3.665]  w:  [1.37380219 0.47280749 1.17025006]
-7.0799308191368215  -  14.6793  =  -21.75923081913682
254456.3624117591
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.33604503 0.4429423  1.19013001]
9.481873509709418  -  87.3174  =  -77.83552649029059
training  [-4.1793, -4.9218, 1.7664]  w:  [1.33604503 0.4429423  1.19013001]
-5.661560786913955  -  1.5257  =  -7.187260786913955
training  [-3.9429, -0.7689, 4.883]  w:  [1.33604503 0.4429423  1.19013001]
0.20293453300343334  -  39.7859  =  -39.58296546699656
training  [-3.5796, 1.5557, 2.6683]  w:  [1.33604503 0.4429423  1.19013001]
-0.9177975584097626  -  45.5674  =  -46.48519755840976
training  [-3.3354, 2.2292, -1.633]  w:  [1.33604503 0.4429423  1.19013001]
-5.412319925139444  -  13.3589  =  -18.771219925139444
training  [1.2096, 0.3121, 1.6238]  w:  [1.33604503 0.4429423  1.19013001]
3.6868554723275846  -  74.5119  =  -70.82504452767242
training  [0.7371, -3.9118, -2.5583]  w:  [1.33604503 0.4429423  1.19013001]
-3.7926125073006345  -  3.3358  =  -7.128412507300634
training  [-4.4792, 1.3177, -2.0449]  w:  [1.33604503 0.4429423  1.19013001]
-7.8344446935964225  -  4.2974  =  -12.131844693596422
training  [4.312, -3.735, 1.8018]  w:  [1.33604503 0.4429423  1.19013001]
6.251012930010708  -  66.5833  =  -60.332287069989285
training  [2.2866, -3.657, 0.2785]  w:  [1.33604503 0.4429423  1.19013001]
1.76661177792819  -  26.0005  =  -24.23388822207181
training  [2.3784, -4.0141, -0.8841]  w:  [1.33604503 0.4429423  1.19013001]
0.34744086786969053  -  14.6809  =  -14.333459132130308
training  [-4.366, -3.5797, 1.0264]  w:  [1.33604503 0.4429423  1.19013001]
-6.197223735915358  -  1.8713  =  -8.068523735915358
training  [3.6044, -3.3175, 2.5052]  w:  [1.33604503 0.4429423  1.19013001]
6.327693323966143  -  71.0139  =  -64.68620667603386
training  [4.3441, -3.0375, 0.8353]  w:  [1.33604503 0.4429423  1.19013001]
5.452591578849586  -  63.8979  =  -58.445308421150415
training  [4.844, -1.8252, 0.5179]  w:  [1.33604503 0.4429423  1.19013001]
6.279712180160666  -  78.0461  =  -71.76638781983932
training  [3.5894, -1.8357, 0.8357]  w:  [1.33604503 0.4429423  1.19013001]
4.977082504121124  -  68.8838  =  -63.90671749587887
training  [2.8556, -2.8244, 0.1182]  w:  [1.33604503 0.4429423  1.19013001]
2.704837322889117  -  39.5252  =  -36.82036267711088
training  [0.1338, -2.4896, -4.1741]  w:  [1.33604503 0.4429423  1.19013001]
-5.891707999920227  -  2.2644  =  -8.156107999920227
training  [-3.224, 3.9292, 2.1957]  w:  [1.33604503 0.4429423  1.19013001]
0.04616816956875747  -  72.1211  =  -72.07493183043124
training  [-1.0141, 2.0322, 4.9616]  w:  [1.33604503 0.4429423  1.19013001]
5.450213129474238  -  92.3427  =  -86.89248687052576
training  [-3.6607, 0.5574, -1.4547]  w:  [1.33604503 0.4429423  1.19013001]
-6.375246136059544  -  5.8471  =  -12.222346136059544
training  [-4.6911, -3.1557, 4.7126]  w:  [1.33604503 0.4429423  1.19013001]
-2.056707202957144  -  11.2337  =  -13.290407202957145
training  [4.3914, -2.8797, -1.5355]  w:  [1.33604503 0.4429423  1.19013001]
2.764122580553101  -  37.475  =  -34.7108774194469
training  [-1.9869, -4.2265, 3.8654]  w:  [1.33604503 0.4429423  1.19013001]
0.07364501440035731  -  15.7889  =  -15.715254985599643
training  [-2.0447, 4.138, -0.4531]  w:  [1.33604503 0.4429423  1.19013001]
-1.4381639361412422  -  57.936  =  -59.374163936141244
training  [-1.6706, 2.0672, -0.8657]  w:  [1.33604503 0.4429423  1.19013001]
-2.346642051744383  -  32.4185  =  -34.765142051744384
training  [-0.3293, 0.5779, -2.8227]  w:  [1.33604503 0.4429423  1.19013001]
-3.543363247037899  -  14.3434  =  -17.886763247037898
training  [1.482, -1.8657, -3.7435]  w:  [1.33604503 0.4429423  1.19013001]
-3.301630401885597  -  7.1519  =  -10.453530401885597
training  [-4.7477, -3.338, -1.9109]  w:  [1.33604503 0.4429423  1.19013001]
-10.095901843909179  -  0.4077  =  -10.503601843909179
training  [3.4221, 1.225, 2.261]  w:  [1.33604503 0.4429423  1.19013001]
7.805567977746076  -  95.0454  =  -87.23983202225392
training  [0.5903, 4.8793, 2.8287]  w:  [1.33604503 0.4429423  1.19013001]
6.316436516619513  -  97.4647  =  -91.14826348338048
training  [3.541, -3.2957, 1.9379]  w:  [1.33604503 0.4429423  1.19013001]
5.577483457342199  -  64.3732  =  -58.7957165426578
training  [-1.5212, -2.4221, -4.902]  w:  [1.33604503 0.4429423  1.19013001]
-8.939259557295324  -  0.7227  =  -9.661959557295324
training  [-0.5397, -1.032, 3.4321]  w:  [1.33604503 0.4429423  1.19013001]
2.906465240580199  -  60.5921  =  -57.685634759419806
training  [-4.4576, -4.2601, 4.2233]  w:  [1.33604503 0.4429423  1.19013001]
-2.816256780238838  -  6.0247  =  -8.840956780238837
training  [-3.2289, 1.841, 2.7095]  w:  [1.33604503 0.4429423  1.19013001]
-0.27384176991908227  -  54.0111  =  -54.28494176991908
training  [1.6281, -0.9761, -4.5734]  w:  [1.33604503 0.4429423  1.19013001]
-3.7000816437306248  -  7.8658  =  -11.565881643730625
training  [-1.6917, 4.8284, -1.2181]  w:  [1.33604503 0.4429423  1.19013001]
-1.571182129855943  -  61.2837  =  -62.854882129855945
training  [3.9849, -0.9782, 2.0434]  w:  [1.33604503 0.4429423  1.19013001]
7.322631350596184  -  88.3402  =  -81.01756864940381
training  [-3.8184, 1.2067, 2.2951]  w:  [1.33604503 0.4429423  1.19013001]
-1.835588495167956  -  34.1122  =  -35.947788495167956
training  [4.8842, -3.4563, -2.7572]  w:  [1.33604503 0.4429423  1.19013001]
1.7131432097617734  -  23.7819  =  -22.068756790238226
training  [0.3998, -1.1865, -2.3095]  w:  [1.33604503 0.4429423  1.19013001]
-2.7400054925368718  -  11.4246  =  -14.164605492536872
training  [2.0692, -3.3887, 1.7303]  w:  [1.33604503 0.4429423  1.19013001]
3.3228277537374478  -  42.6881  =  -39.36527224626255
training  [4.9949, 2.5811, -0.2251]  w:  [1.33604503 0.4429423  1.19013001]
7.54879144913661  -  95.9901  =  -88.44130855086338
training  [-2.1215, 3.7111, 1.2372]  w:  [1.33604503 0.4429423  1.19013001]
0.281812489267917  -  71.3692  =  -71.08738751073209
training  [-0.8548, -1.4922, -2.6356]  w:  [1.33604503 0.4429423  1.19013001]
-4.939716448790591  -  4.7821  =  -9.721816448790591
training  [-0.3516, 1.8554, -3.2288]  w:  [1.33604503 0.4429423  1.19013001]
-3.4906100555885584  -  20.3834  =  -23.87401005558856
training  [2.6396, -2.0585, 3.2964]  w:  [1.33604503 0.4429423  1.19013001]
6.537972298113417  -  80.826  =  -74.28802770188658
training  [3.182, 0.3063, 2.6692]  w:  [1.33604503 0.4429423  1.19013001]
7.563663540946765  -  92.9483  =  -85.38463645905324
training  [-3.9978, 3.3242, 4.3448]  w:  [1.33604503 0.4429423  1.19013001]
1.3020648305810059  -  79.1768  =  -77.874735169419
training  [-3.2188, 0.9749, -3.9211]  w:  [1.33604503 0.4429423  1.19013001]
-8.53525607701053  -  2.7053  =  -11.24055607701053
training  [-1.4037, -1.6469, -3.1777]  w:  [1.33604503 0.4429423  1.19013001]
-6.386764219245595  -  2.6234  =  -9.010164219245596
training  [-4.433, -2.0077, -4.009]  w:  [1.33604503 0.4429423  1.19013001]
-11.58321409682428  -  0.3253  =  -11.90851409682428
training  [0.2189, -0.4741, -0.1024]  w:  [1.33604503 0.4429423  1.19013001]
-0.0394080009609499  -  33.6531  =  -33.69250800096095
training  [-1.6415, -0.7735, -3.0675]  w:  [1.33604503 0.4429423  1.19013001]
-6.18645759375958  -  3.7641  =  -9.95055759375958
training  [-3.2433, -1.4039, 3.9589]  w:  [1.33604503 0.4429423  1.19013001]
-0.2434358649585393  -  30.0658  =  -30.309235864958538
training  [-2.9105, 0.5832, -4.0091]  w:  [1.33604503 0.4429423  1.19013001]
-8.401585334126887  -  2.4887  =  -10.890285334126887
training  [4.0515, 2.4255, -4.5583]  w:  [1.33604503 0.4429423  1.19013001]
1.0623733904368944  -  61.2853  =  -60.2229266095631
training  [1.7539, -0.7567, 0.573]  w:  [1.33604503 0.4429423  1.19013001]
2.69005943763213  -  57.0797  =  -54.38964056236787
training  [-0.3153, -0.7064, 2.725]  w:  [1.33604503 0.4429423  1.19013001]
2.5089548309616125  -  58.7004  =  -56.19144516903839
training  [4.1213, -3.7513, -1.8806]  w:  [1.33604503 0.4429423  1.19013001]
1.6064744399492858  -  22.1789  =  -20.572425560050714
training  [-3.9599, -4.7557, -3.2102]  w:  [1.33604503 0.4429423  1.19013001]
-11.217660789635453  -  0.1558  =  -11.373460789635452
training  [2.4555, -2.0981, -1.6104]  w:  [1.33604503 0.4429423  1.19013001]
0.43473596739842857  -  24.4796  =  -24.044864032601573
training  [2.3627, -1.8248, -2.8985]  w:  [1.33604503 0.4429423  1.19013001]
-1.1011993440072212  -  15.7052  =  -16.80639934400722
training  [0.6186, 1.5369, 0.1015]  w:  [1.33604503 0.4429423  1.19013001]
1.6280336787838599  -  65.2154  =  -63.587366321216145
training  [-3.1581, 4.5694, 4.0636]  w:  [1.33604503 0.4429423  1.19013001]
2.640829042204865  -  90.3564  =  -87.71557095779512
training  [0.9721, 4.3573, 1.2892]  w:  [1.33604503 0.4429423  1.19013001]
4.763117480248541  -  94.3178  =  -89.55468251975147
training  [-2.0006, -0.4211, -3.9847]  w:  [1.33604503 0.4429423  1.19013001]
-7.601725741215528  -  2.4051  =  -10.006825741215529
training  [-3.6588, -2.5952, -1.0915]  w:  [1.33604503 0.4429423  1.19013001]
-7.336872335884811  -  1.5176  =  -8.854472335884811
training  [-2.874, 2.639, -4.4538]  w:  [1.33604503 0.4429423  1.19013001]
-7.9714697186342125  -  5.497  =  -13.468469718634212
training  [3.9494, 2.5933, 0.0128]  w:  [1.33604503 0.4429423  1.19013001]
6.440492192126733  -  94.1462  =  -87.70570780787327
training  [-4.2855, 2.4065, -0.6828]  w:  [1.33604503 0.4429423  1.19013001]
-5.472301106827777  -  14.4193  =  -19.89160110682778
training  [-2.5751, 2.4369, 4.9756]  w:  [1.33604503 0.4429423  1.19013001]
3.5605674029664343  -  87.1991  =  -83.63853259703356
training  [-4.4625, -3.9408, 3.116]  w:  [1.33604503 0.4429423  1.19013001]
-3.999202881790619  -  4.1344  =  -8.133602881790619
training  [-0.5828, 1.8156, -0.1435]  w:  [1.33604503 0.4429423  1.19013001]
-0.14522465616388328  -  51.1166  =  -51.26182465616388
training  [-4.8672, -0.3674, 3.9445]  w:  [1.33604503 0.4429423  1.19013001]
-1.9710675692529627  -  24.1396  =  -26.110667569252964
training  [3.9719, -2.8784, -3.6245]  w:  [1.33604503 0.4429423  1.19013001]
-0.2819540732556911  -  14.6104  =  -14.892354073255692
training  [-3.0334, -4.0148, -1.1]  w:  [1.33604503 0.4429423  1.19013001]
-7.140226770593823  -  1.021  =  -8.161226770593823
training  [-4.0663, 3.2357, 4.2736]  w:  [1.33604503 0.4429423  1.19013001]
1.0866080954058912  -  77.2328  =  -76.1461919045941
training  [-1.9263, -3.2499, 4.1749]  w:  [1.33604503 0.4429423  1.19013001]
0.9555320340902123  -  26.8814  =  -25.925867965909788
training  [-0.4394, -3.3643, 2.1357]  w:  [1.33604503 0.4429423  1.19013001]
0.464511681314125  -  20.85  =  -20.385488318685876
training  [-3.9833, 1.6599, 1.1834]  w:  [1.33604503 0.4429423  1.19013001]
-3.17822839967924  -  25.5397  =  -28.71792839967924
training  [4.9539, 3.9439, -1.5671]  w:  [1.33604503 0.4429423  1.19013001]
6.500500902106676  -  95.9509  =  -89.45039909789332
training  [-1.6791, 0.1656, 4.3603]  w:  [1.33604503 0.4429423  1.19013001]
3.0193219056896425  -  71.5733  =  -68.55397809431037
training  [-2.0265, 2.027, -3.7523]  w:  [1.33604503 0.4429423  1.19013001]
-6.275376041675615  -  8.503  =  -14.778376041675614
training  [-4.3795, -3.4641, 2.3059]  w:  [1.33604503 0.4429423  1.19013001]
-4.641284867964213  -  3.6654  =  -8.306684867964213
training  [-2.0176, 4.5346, 1.4648]  w:  [1.33604503 0.4429423  1.19013001]
1.0562641446189616  -  81.6212  =  -80.56493585538104
training  [-4.5365, 0.4088, 3.3315]  w:  [1.33604503 0.4429423  1.19013001]
-1.9149753563408538  -  28.9449  =  -30.859875356340854
training  [0.0543, 1.7973, -1.0172]  w:  [1.33604503 0.4429423  1.19013001]
-0.3419527980172059  -  47.9317  =  -48.2736527980172
training  [2.6143, -4.6344, 2.4982]  w:  [1.33604503 0.4429423  1.19013001]
4.413233507837878  -  43.5132  =  -39.09996649216212
training  [1.3107, 3.092, 3.3522]  w:  [1.33604503 0.4429423  1.19013001]
7.110285639680053  -  96.6993  =  -89.58901436031994
training  [-4.1011, 2.4862, -1.7754]  w:  [1.33604503 0.4429423  1.19013001]
-6.490967948291168  -  10.0187  =  -16.509667948291167
training  [-4.1914, -3.7981, 0.5226]  w:  [1.33604503 0.4429423  1.19013001]
-6.660276370314437  -  1.4295  =  -8.089776370314437
training  [2.7724, 0.2505, 4.7913]  w:  [1.33604503 0.4429423  1.19013001]
9.517278205587512  -  96.7925  =  -87.27522179441249
training  [4.0513, -1.7417, 0.4931]  w:  [1.33604503 0.4429423  1.19013001]
5.228099740527112  -  71.1234  =  -65.89530025947289
training  [0.3377, 0.4645, -1.6958]  w:  [1.33604503 0.4429423  1.19013001]
-1.3612933607305369  -  27.9534  =  -29.314693360730537
training  [-3.9085, -1.0112, 1.1947]  w:  [1.33604503 0.4429423  1.19013001]
-4.24798694763625  -  8.608  =  -12.85598694763625
training  [3.2581, -0.8491, -1.3936]  w:  [1.33604503 0.4429423  1.19013001]
2.3183008331998005  -  50.1924  =  -47.8740991668002
training  [-1.619, -3.1926, 2.5651]  w:  [1.33604503 0.4429423  1.19013001]
-0.5243920207077957  -  16.4754  =  -16.999792020707797
training  [-2.0603, -2.4461, -0.861]  w:  [1.33604503 0.4429423  1.19013001]
-4.860836686199224  -  3.9784  =  -8.839236686199223
training  [2.4631, -4.7946, -0.0765]  w:  [1.33604503 0.4429423  1.19013001]
1.0760364094213901  -  15.394  =  -14.31796359057861
training  [-4.8966, 4.2368, 1.9474]  w:  [1.33604503 0.4429423  1.19013001]
-2.34776098143976  -  53.5883  =  -55.93606098143976
training  [-4.5155, 1.537, 4.7273]  w:  [1.33604503 0.4429423  1.19013001]
0.2739925612329941  -  59.2523  =  -58.978307438767004
training  [1.6792, 4.3261, -1.7225]  w:  [1.33604503 0.4429423  1.19013001]
2.1097005771704547  -  83.7729  =  -81.66319942282955
training  [1.0347, -3.3649, 3.378]  w:  [1.33604503 0.4429423  1.19013001]
3.9122084085647533  -  50.5979  =  -46.68569159143525
training  [0.261, 4.211, 2.3907]  w:  [1.33604503 0.4429423  1.19013001]
5.059181602480798  -  94.9375  =  -89.8783183975192
training  [2.2971, 2.9466, 4.5417]  w:  [1.33604503 0.4429423  1.19013001]
9.779416294381164  -  98.7784  =  -88.99898370561884
training  [2.0725, 0.7739, -4.6808]  w:  [1.33604503 0.4429423  1.19013001]
-2.459014163684633  -  19.5109  =  -21.96991416368463
training  [2.8138, -0.5996, -1.4313]  w:  [1.33604503 0.4429423  1.19013001]
1.7903422282824772  -  47.2879  =  -45.497557771717524
training  [-2.1202, -2.4239, 1.6265]  w:  [1.33604503 0.4429423  1.19013001]
-1.9705840688074343  -  12.3599  =  -14.330484068807435
training  [1.9253, 2.5195, -2.185]  w:  [1.33604503 0.4429423  1.19013001]
1.0878465663671015  -  65.2467  =  -64.1588534336329
training  [0.5667, -2.7133, -2.6962]  w:  [1.33604503 0.4429423  1.19013001]
-3.6535271589507694  -  5.1106  =  -8.76412715895077
training  [-1.0348, -4.3581, 2.1113]  w:  [1.33604503 0.4429423  1.19013001]
-0.8002047643033117  -  10.5192  =  -11.31940476430331
training  [-4.3841, 2.6733, 1.2457]  w:  [1.33604503 0.4429423  1.19013001]
-3.1906924195665383  -  32.4639  =  -35.65459241956654
training  [2.8018, 1.712, 0.9061]  w:  [1.33604503 0.4429423  1.19013001]
5.580024996980533  -  90.1138  =  -84.53377500301947
training  [-1.6242, 2.1521, 1.6044]  w:  [1.33604503 0.4429423  1.19013001]
0.6926963729169369  -  63.7879  =  -63.095203627083066
training  [1.0787, 1.4206, -4.5245]  w:  [1.33604503 0.4429423  1.19013001]
-3.314307609915193  -  18.0555  =  -21.369807609915192
training  [2.4125, -0.8095, -1.5122]  w:  [1.33604503 0.4429423  1.19013001]
1.064932249432277  -  38.8276  =  -37.76266775056772
training  [-3.9519, -1.0924, -0.4866]  w:  [1.33604503 0.4429423  1.19013001]
-6.342903800098205  -  3.6777  =  -10.020603800098206
training  [-3.7211, 3.1614, -2.591]  w:  [1.33604503 0.4429423  1.19013001]
-6.654866227540101  -  11.1518  =  -17.8066662275401
training  [0.4954, -1.8257, 2.1505]  w:  [1.33604503 0.4429423  1.19013001]
2.4125715297514994  -  47.7531  =  -45.3405284702485
training  [-0.1477, 3.1454, 3.5618]  w:  [1.33604503 0.4429423  1.19013001]
5.434901932156579  -  94.1572  =  -88.72229806784343
training  [3.9048, 2.8907, -2.1849]  w:  [1.33604503 0.4429423  1.19013001]
3.8970869052313644  -  85.8791  =  -81.98201309476863
training  [2.9896, 3.5226, 2.3105]  w:  [1.33604503 0.4429423  1.19013001]
8.304344171707516  -  98.038  =  -89.73365582829248
training  [2.3434, 0.0564, -3.6224]  w:  [1.33604503 0.4429423  1.19013001]
-1.1552570657920564  -  24.7629  =  -25.918157065792055
training  [-4.4867, 1.3566, 3.3672]  w:  [1.33604503 0.4429423  1.19013001]
-1.3861319576181774  -  40.5785  =  -41.964631957618174
training  [-4.2711, 4.5089, -3.614]  w:  [1.33604503 0.4429423  1.19013001]
-8.010329240985584  -  10.0825  =  -18.092829240985584
training  [-4.1147, -0.5604, 0.8821]  w:  [1.33604503 0.4429423  1.19013001]
-4.695835683876199  -  8.344  =  -13.039835683876198
training  [2.9835, -4.3998, -1.3384]  w:  [1.33604503 0.4429423  1.19013001]
0.44436280833584507  -  13.2692  =  -12.824837191664155
training  [4.4301, 3.6675, 3.0676]  w:  [1.33604503 0.4429423  1.19013001]
11.194146810885202  -  99.3834  =  -88.1892531891148
training  [1.8372, 1.3119, 0.0378]  w:  [1.33604503 0.4429423  1.19013001]
3.080664856396691  -  74.9026  =  -71.82193514360331
training  [-3.6792, -1.4493, -0.1041]  w:  [1.33604503 0.4429423  1.19013001]
-5.681425699323991  -  4.2442  =  -9.92562569932399
training  [2.2272, 4.97, 3.7705]  w:  [1.33604503 0.4429423  1.19013001]
9.664447940013389  -  99.3199  =  -89.65545205998662
training  [-3.8965, -2.7583, -1.4686]  w:  [1.33604503 0.4429423  1.19013001]
-8.175492156012643  -  1.0337  =  -9.209192156012643
training  [-3.8251, 1.5245, -0.5056]  w:  [1.33604503 0.4429423  1.19013001]
-5.036970047357684  -  12.9762  =  -18.013170047357683
training  [1.4072, 1.0499, 4.6353]  w:  [1.33604503 0.4429423  1.19013001]
7.86173732213145  -  95.4618  =  -87.60006267786855
training  [-1.7119, -1.1275, -4.577]  w:  [1.33604503 0.4429423  1.19013001]
-8.233817986938565  -  1.4655  =  -9.699317986938565
training  [1.5381, -3.5781, 4.7296]  w:  [1.33604503 0.4429423  1.19013001]
6.098917898494739  -  69.9473  =  -63.84838210150526
training  [2.4913, -4.7487, -3.1079]  w:  [1.33604503 0.4429423  1.19013001]
-2.473716176221772  -  3.9825  =  -6.456216176221772
training  [0.8319, -0.7889, 1.6712]  w:  [1.33604503 0.4429423  1.19013001]
2.75096395013075  -  58.8336  =  -56.082636049869244
training  [2.4003, -3.159, 0.8644]  w:  [1.33604503 0.4429423  1.19013001]
2.836402536967496  -  39.0041  =  -36.1676974630325
training  [-2.6517, 2.2578, 1.7511]  w:  [1.33604503 0.4429423  1.19013001]
-0.4586788249281679  -  54.4525  =  -54.91117882492817
training  [2.3496, -1.2964, -1.3898]  w:  [1.33604503 0.4429423  1.19013001]
0.9108983225445475  -  33.888  =  -32.97710167745545
training  [4.706, 3.4156, 1.2028]  w:  [1.33604503 0.4429423  1.19013001]
9.231830029835875  -  98.4665  =  -89.23466997016412
training  [3.6693, 2.3423, 3.1115]  w:  [1.33604503 0.4429423  1.19013001]
9.642943317153069  -  98.3069  =  -88.66395668284693
training  [-4.1377, 0.7103, -4.8074]  w:  [1.33604503 0.4429423  1.19013001]
-10.93496261767688  -  0.9782  =  -11.91316261767688
training  [-1.3356, -3.2314, -4.1613]  w:  [1.33604503 0.4429423  1.19013001]
-8.16823350778952  -  0.7659  =  -8.93413350778952
training  [-1.308, 4.5738, 4.748]  w:  [1.33604503 0.4429423  1.19013001]
5.929119881757314  -  97.0884  =  -91.15928011824268
training  [1.8503, -2.3468, 1.5135]  w:  [1.33604503 0.4429423  1.19013001]
3.233848895675821  -  50.2125  =  -46.97865110432418
training  [0.9794, 4.2458, -2.6876]  w:  [1.33604503 0.4429423  1.19013001]
-0.009426474962449305  -  68.3262  =  -68.33562647496245
training  [2.8936, -2.7623, -0.9651]  w:  [1.33604503 0.4429423  1.19013001]
1.4938459131269277  -  28.5596  =  -27.06575408687307
training  [-1.3235, -1.2644, -3.7798]  w:  [1.33604503 0.4429423  1.19013001]
-6.82676525471898  -  2.4511  =  -9.27786525471898
training  [-2.9397, -4.125, -2.3156]  w:  [1.33604503 0.4429423  1.19013001]
-8.510573630922405  -  0.554  =  -9.064573630922405
training  [-4.1333, 1.4012, -2.4215]  w:  [1.33604503 0.4429423  1.19013001]
-7.783523995493334  -  4.4072  =  -12.190723995493332
training  [2.7193, -3.1938, -1.6833]  w:  [1.33604503 0.4429423  1.19013001]
0.21509228812827086  -  17.0949  =  -16.879807711871727
training  [-2.9433, -4.5495, -3.4777]  w:  [1.33604503 0.4429423  1.19013001]
-10.08646248335483  -  0.2509  =  -10.33736248335483
training  [-1.1173, 2.2317, -1.5199]  w:  [1.33604503 0.4429423  1.19013001]
-2.313127377552277  -  33.1206  =  -35.43372737755228
training  [0.5178, -1.5256, -3.7834]  w:  [1.33604503 0.4429423  1.19013001]
-4.4866865328710706  -  5.237  =  -9.72368653287107
training  [-2.7105, 1.6062, 3.8415]  w:  [1.33604503 0.4429423  1.19013001]
1.6619882919309341  -  70.4458  =  -68.78381170806907
training  [1.4194, -1.1613, -4.0572]  w:  [1.33604503 0.4429423  1.19013001]
-3.4466020463445197  -  8.3206  =  -11.76720204634452
training  [-0.1552, 1.2735, 4.3004]  w:  [1.33604503 0.4429423  1.19013001]
5.474767921595176  -  90.1085  =  -84.63373207840483
training  [-3.4815, -4.7835, -1.0098]  w:  [1.33604503 0.4429423  1.19013001]
-7.97204857147813  -  0.5839  =  -8.55594857147813
training  [2.8193, 4.1057, -4.526]  w:  [1.33604503 0.4429423  1.19013001]
0.1987715574284037  -  66.8081  =  -66.6093284425716
training  [-3.9939, 3.0056, -1.5763]  w:  [1.33604503 0.4429423  1.19013001]
-5.880724803908983  -  14.4018  =  -20.282524803908984
training  [-2.0593, 2.4585, 2.3597]  w:  [1.33604503 0.4429423  1.19013001]
1.1460058959583932  -  70.6698  =  -69.5237941040416
training  [-2.6263, 3.1311, 2.9468]  w:  [1.33604503 0.4429423  1.19013001]
1.3851166830892572  -  77.309  =  -75.92388331691075
training  [0.3087, -1.1669, 0.4491]  w:  [1.33604503 0.4429423  1.19013001]
0.4300551150960008  -  33.0798  =  -32.649744884903996
training  [-4.085, 1.1728, 1.8622]  w:  [1.33604503 0.4429423  1.19013001]
-2.7220011256705905  -  26.4056  =  -29.12760112567059
training  [-0.9468, 0.7549, 3.9363]  w:  [1.33604503 0.4429423  1.19013001]
3.754118459035657  -  79.7738  =  -76.01968154096434
training  [-3.9515, 0.3005, -4.4521]  w:  [1.33604503 0.4429423  1.19013001]
-10.444855596319758  -  1.0441  =  -11.488955596319759
training  [-3.8772, -2.2493, -1.9634]  w:  [1.33604503 0.4429423  1.19013001]
-8.513125182777296  -  1.0509  =  -9.564025182777296
training  [2.8443, -2.5137, -4.5381]  w:  [1.33604503 0.4429423  1.19013001]
-2.7142401702807972  -  6.8897  =  -9.603940170280797
training  [-2.0843, -0.4836, -3.0452]  w:  [1.33604503 0.4429423  1.19013001]
-6.623109461585903  -  3.5346  =  -10.157709461585902
training  [1.0353, -2.7229, 2.2017]  w:  [1.33604503 0.4429423  1.19013001]
2.797429065295456  -  43.9562  =  -41.15877093470455
training  [4.6442, 3.0445, 2.2175]  w:  [1.33604503 0.4429423  1.19013001]
10.192511477613468  -  98.8492  =  -88.65668852238653
training  [-0.6752, 4.861, 3.778]  w:  [1.33604503 0.4429423  1.19013001]
5.747356100023054  -  97.017  =  -91.26964389997694
training  [1.9475, -4.7001, 0.8243]  w:  [1.33604503 0.4429423  1.19013001]
1.5010987495087056  -  18.7839  =  -17.282801250491293
training  [2.581, 0.3566, -4.2932]  w:  [1.33604503 0.4429423  1.19013001]
-1.5031806961671914  -  23.5455  =  -25.048680696167192
training  [-0.6736, -4.1292, 4.2274]  w:  [1.33604503 0.4429423  1.19013001]
2.3021983054517534  -  31.2667  =  -28.964501694548247
training  [1.555, 3.0209, 3.0037]  w:  [1.33604503 0.4429423  1.19013001]
6.990427935613251  -  96.4078  =  -89.41737206438674
training  [-3.9024, 4.8914, -2.1405]  w:  [1.33604503 0.4429423  1.19013001]
-5.594647439102217  -  25.4308  =  -31.02544743910222
training  [4.3376, -4.3305, 0.4366]  w:  [1.33604503 0.4429423  1.19013001]
4.396678054038509  -  43.0907  =  -38.69402194596149
training  [-3.1254, 4.394, 4.8478]  w:  [1.33604503 0.4429423  1.19013001]
3.540125587382353  -  92.8121  =  -89.27197441261765
training  [-2.3382, -4.8182, 2.1568]  w:  [1.33604503 0.4429423  1.19013001]
-2.69125269865444  -  4.7434  =  -7.434652698654441
training  [2.9783, 1.8384, 3.3897]  w:  [1.33604503 0.4429423  1.19013001]
8.82763174113307  -  97.3486  =  -88.52096825886693
training  [-0.124, 2.8374, -0.6674]  w:  [1.33604503 0.4429423  1.19013001]
0.29684213884480004  -  62.785  =  -62.488157861155194
training  [2.6896, 0.3414, -0.2938]  w:  [1.33604503 0.4429423  1.19013001]
3.394987026777593  -  70.4455  =  -67.0505129732224
training  [-1.0399, 3.8536, 0.6071]  w:  [1.33604503 0.4429423  1.19013001]
1.0400971569741033  -  77.0369  =  -75.9968028430259
training  [-2.2706, 3.99, -2.3091]  w:  [1.33604503 0.4429423  1.19013001]
-4.014413265438316  -  31.1134  =  -35.12781326543831
training  [-4.6277, 1.2594, 2.4902]  w:  [1.33604503 0.4429423  1.19013001]
-2.6613123164488366  -  28.1093  =  -30.770612316448837
training  [1.7329, -3.6213, 0.0389]  w:  [1.33604503 0.4429423  1.19013001]
0.7575015333273654  -  19.3919  =  -18.634398466672636
training  [-0.7044, -2.822, 1.4681]  w:  [1.33604503 0.4429423  1.19013001]
-0.44386343510822557  -  17.8122  =  -18.256063435108228
training  [-0.4826, -3.1786, -1.9225]  w:  [1.33604503 0.4429423  1.19013001]
-4.340736678296912  -  3.5851  =  -7.925836678296912
training  [1.0986, -4.5818, -3.6128]  w:  [1.33604503 0.4429423  1.19013001]
-4.861395664641109  -  1.7158  =  -6.577195664641109
training  [-4.406, -3.9306, -0.2443]  w:  [1.33604503 0.4429423  1.19013001]
-7.918392192957548  -  0.8241  =  -8.742492192957547
training  [-1.8419, 1.1644, -1.3754]  w:  [1.33604503 0.4429423  1.19013001]
-3.582004142305631  -  17.8517  =  -21.433704142305633
training  [2.7272, 4.3966, 2.8811]  w:  [1.33604503 0.4429423  1.19013001]
9.019985710601421  -  98.904  =  -89.88401428939858
training  [1.9643, -1.4554, 2.803]  w:  [1.33604503 0.4429423  1.19013001]
5.315669444091126  -  76.0591  =  -70.74343055590887
training  [-3.7467, -0.8937, 1.6851]  w:  [1.33604503 0.4429423  1.19013001]
-3.396129384591109  -  12.1571  =  -15.55322938459111
training  [-3.6985, 4.8435, -3.665]  w:  [1.33604503 0.4429423  1.19013001]
-7.157797990884709  -  14.6793  =  -21.837097990884708
254654.9319307194
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.31487332 0.43803003 1.15919775]
9.269235963571278  -  87.3174  =  -78.04816403642873
training  [-4.1793, -4.9218, 1.7664]  w:  [1.31487332 0.43803003 1.15919775]
-5.603539379707683  -  1.5257  =  -7.129239379707682
training  [-3.9429, -0.7689, 4.883]  w:  [1.31487332 0.43803003 1.15919775]
0.13914731634895983  -  39.7859  =  -39.64675268365104
training  [-3.5796, 1.5557, 2.6683]  w:  [1.31487332 0.43803003 1.15919775]
-0.9321898483279063  -  45.5674  =  -46.49958984832791
training  [-3.3354, 2.2292, -1.633]  w:  [1.31487332 0.43803003 1.15919775]
-5.302141843872848  -  13.3589  =  -18.661041843872848
training  [1.2096, 0.3121, 1.6238]  w:  [1.31487332 0.43803003 1.15919775]
3.609485249665844  -  74.5119  =  -70.90241475033416
training  [0.7371, -3.9118, -2.5583]  w:  [1.31487332 0.43803003 1.15919775]
-3.7098683737409375  -  3.3358  =  -7.045668373740938
training  [-4.4792, 1.3177, -2.0449]  w:  [1.31487332 0.43803003 1.15919775]
-7.682831876901204  -  4.2974  =  -11.980231876901204
training  [4.312, -3.735, 1.8018]  w:  [1.31487332 0.43803003 1.15919775]
6.1223340816598295  -  66.5833  =  -60.460965918340165
training  [2.2866, -3.657, 0.2785]  w:  [1.31487332 0.43803003 1.15919775]
1.7275500687064147  -  26.0005  =  -24.272949931293585
training  [2.3784, -4.0141, -0.8841]  w:  [1.31487332 0.43803003 1.15919775]
0.34415160814324075  -  14.6809  =  -14.336748391856759
training  [-4.366, -3.5797, 1.0264]  w:  [1.31487332 0.43803003 1.15919775]
-6.118952454945641  -  1.8713  =  -7.990252454945641
training  [3.6044, -3.3175, 2.5052]  w:  [1.31487332 0.43803003 1.15919775]
6.19018695883851  -  71.0139  =  -64.8237130411615
training  [4.3441, -3.0375, 0.8353]  w:  [1.31487332 0.43803003 1.15919775]
5.349702837596407  -  63.8979  =  -58.548197162403596
training  [4.844, -1.8252, 0.5179]  w:  [1.31487332 0.43803003 1.15919775]
6.170102454633653  -  78.0461  =  -71.87599754536635
training  [3.5894, -1.8357, 0.8357]  w:  [1.31487332 0.43803003 1.15919775]
4.884256118355617  -  68.8838  =  -63.99954388164438
training  [2.8556, -2.8244, 0.1182]  w:  [1.31487332 0.43803003 1.15919775]
2.654597394688133  -  39.5252  =  -36.870602605311866
training  [0.1338, -2.4896, -4.1741]  w:  [1.31487332 0.43803003 1.15919775]
-5.753196858754311  -  2.2644  =  -8.017596858754311
training  [-3.224, 3.9292, 2.1957]  w:  [1.31487332 0.43803003 1.15919775]
0.027206534001180227  -  72.1211  =  -72.09389346599882
training  [-1.0141, 2.0322, 4.9616]  w:  [1.31487332 0.43803003 1.15919775]
5.308227167240697  -  92.3427  =  -87.03447283275929
training  [-3.6607, 0.5574, -1.4547]  w:  [1.31487332 0.43803003 1.15919775]
-6.255483787543957  -  5.8471  =  -12.102583787543956
training  [-4.6911, -3.1557, 4.7126]  w:  [1.31487332 0.43803003 1.15919775]
-2.0876582847877785  -  11.2337  =  -13.32135828478778
training  [4.3914, -2.8797, -1.5355]  w:  [1.31487332 0.43803003 1.15919775]
2.7327914558443966  -  37.475  =  -34.7422085441556
training  [-1.9869, -4.2265, 3.8654]  w:  [1.31487332 0.43803003 1.15919775]
0.01690724892484141  -  15.7889  =  -15.771992751075159
training  [-2.0447, 4.138, -0.4531]  w:  [1.31487332 0.43803003 1.15919775]
-1.401185693498895  -  57.936  =  -59.337185693498895
training  [-1.6706, 2.0672, -0.8657]  w:  [1.31487332 0.43803003 1.15919775]
-2.294649172882247  -  32.4185  =  -34.71314917288225
training  [-0.3293, 0.5779, -2.8227]  w:  [1.31487332 0.43803003 1.15919775]
-3.4519177201041327  -  14.3434  =  -17.795317720104133
training  [1.482, -1.8657, -3.7435]  w:  [1.31487332 0.43803003 1.15919775]
-3.208047159296636  -  7.1519  =  -10.359947159296636
training  [-4.7477, -3.338, -1.9109]  w:  [1.31487332 0.43803003 1.15919775]
-9.919879296964687  -  0.4077  =  -10.327579296964688
training  [3.4221, 1.225, 2.261]  w:  [1.31487332 0.43803003 1.15919775]
7.657160894440289  -  95.0454  =  -87.3882391055597
training  [0.5903, 4.8793, 2.8287]  w:  [1.31487332 0.43803003 1.15919775]
6.192472348291924  -  97.4647  =  -91.27222765170806
training  [3.541, -3.2957, 1.9379]  w:  [1.31487332 0.43803003 1.15919775]
5.458760160734973  -  64.3732  =  -58.91443983926502
training  [-1.5212, -2.4221, -4.902]  w:  [1.31487332 0.43803003 1.15919775]
-8.743525218086539  -  0.7227  =  -9.466225218086539
training  [-0.5397, -1.032, 3.4321]  w:  [1.31487332 0.43803003 1.15919775]
2.8167984766725604  -  60.5921  =  -57.77530152332744
training  [-4.4576, -4.2601, 4.2233]  w:  [1.31487332 0.43803003 1.15919775]
-2.8315911948653847  -  6.0247  =  -8.856291194865385
training  [-3.2289, 1.841, 2.7095]  w:  [1.31487332 0.43803003 1.15919775]
-0.298334859004743  -  54.0111  =  -54.30943485900474
training  [1.6281, -0.9761, -4.5734]  w:  [1.31487332 0.43803003 1.15919775]
-3.5882908624463017  -  7.8658  =  -11.454090862446302
training  [-1.6917, 4.8284, -1.2181]  w:  [1.31487332 0.43803003 1.15919775]
-1.5214057557350584  -  61.2837  =  -62.80510575573506
training  [3.9849, -0.9782, 2.0434]  w:  [1.31487332 0.43803003 1.15919775]
7.179862395346436  -  88.3402  =  -81.16033760465356
training  [-3.8184, 1.2067, 2.2951]  w:  [1.31487332 0.43803003 1.15919775]
-1.8316666799308137  -  34.1122  =  -35.943866679930814
training  [4.8842, -3.4563, -2.7572]  w:  [1.31487332 0.43803003 1.15919775]
1.7120010165731183  -  23.7819  =  -22.06989898342688
training  [0.3998, -1.1865, -2.3095]  w:  [1.31487332 0.43803003 1.15919775]
-2.671203490192995  -  11.4246  =  -14.095803490192996
training  [2.0692, -3.3887, 1.7303]  w:  [1.31487332 0.43803003 1.15919775]
3.242143363020423  -  42.6881  =  -39.445956636979574
training  [4.9949, 2.5811, -0.2251]  w:  [1.31487332 0.43803003 1.15919775]
7.437324651042877  -  95.9901  =  -88.55277534895713
training  [-2.1215, 3.7111, 1.2372]  w:  [1.31487332 0.43803003 1.15919775]
0.27022897311022187  -  71.3692  =  -71.09897102688979
training  [-0.8548, -1.4922, -2.6356]  w:  [1.31487332 0.43803003 1.15919775]
-4.832763724897067  -  4.7821  =  -9.614863724897067
training  [-0.3516, 1.8554, -3.2288]  w:  [1.31487332 0.43803003 1.15919775]
-3.3924062326762563  -  20.3834  =  -23.77580623267626
training  [2.6396, -2.0585, 3.2964]  w:  [1.31487332 0.43803003 1.15919775]
6.3902342550839  -  80.826  =  -74.4357657449161
training  [3.182, 0.3063, 2.6692]  w:  [1.31487332 0.43803003 1.15919775]
7.41222613976778  -  92.9483  =  -85.53607386023222
training  [-3.9978, 3.3242, 4.3448]  w:  [1.31487332 0.43803003 1.15919775]
1.2359812762930025  -  79.1768  =  -77.940818723707
training  [-3.2188, 0.9749, -3.9211]  w:  [1.31487332 0.43803003 1.15919775]
-8.350609062549378  -  2.7053  =  -11.055909062549377
training  [-1.4037, -1.6469, -3.1777]  w:  [1.31487332 0.43803003 1.15919775]
-6.250662037285323  -  2.6234  =  -8.874062037285324
training  [-4.433, -2.0077, -4.009]  w:  [1.31487332 0.43803003 1.15919775]
-11.355490110633937  -  0.3253  =  -11.680790110633938
training  [0.2189, -0.4741, -0.1024]  w:  [1.31487332 0.43803003 1.15919775]
-0.038546119617865596  -  33.6531  =  -33.691646119617864
training  [-1.6415, -0.7735, -3.0675]  w:  [1.31487332 0.43803003 1.15919775]
-6.053019888084883  -  3.7641  =  -9.817119888084882
training  [-3.2433, -1.4039, 3.9589]  w:  [1.31487332 0.43803003 1.15919775]
-0.29033102368398556  -  30.0658  =  -30.356131023683986
training  [-2.9105, 0.5832, -4.0091]  w:  [1.31487332 0.43803003 1.15919775]
-8.218819384945355  -  2.4887  =  -10.707519384945355
training  [4.0515, 2.4255, -4.5583]  w:  [1.31487332 0.43803003 1.15919775]
1.1056799915108346  -  61.2853  =  -60.17962000848917
training  [1.7539, -0.7567, 0.573]  w:  [1.31487332 0.43803003 1.15919775]
2.6389192989871795  -  57.0797  =  -54.44078070101283
training  [-0.3153, -0.7064, 2.725]  w:  [1.31487332 0.43803003 1.15919775]
2.4348098987336386  -  58.7004  =  -56.26559010126636
training  [4.1213, -3.7513, -1.8806]  w:  [1.31487332 0.43803003 1.15919775]
1.5958180500325123  -  22.1789  =  -20.583081949967486
training  [-3.9599, -4.7557, -3.2102]  w:  [1.31487332 0.43803003 1.15919775]
-11.011162914755795  -  0.1558  =  -11.166962914755795
training  [2.4555, -2.0981, -1.6104]  w:  [1.31487332 0.43803003 1.15919775]
0.44286856063312574  -  24.4796  =  -24.036731439366875
training  [2.3627, -1.8248, -2.8985]  w:  [1.31487332 0.43803003 1.15919775]
-1.0526006986026175  -  15.7052  =  -16.757800698602615
training  [0.6186, 1.5369, 0.1015]  w:  [1.31487332 0.43803003 1.15919775]
1.6042475673940735  -  65.2154  =  -63.61115243260593
training  [-3.1581, 4.5694, 4.0636]  w:  [1.31487332 0.43803003 1.15919775]
2.5595489939583436  -  90.3564  =  -87.79685100604165
training  [0.9721, 4.3573, 1.2892]  w:  [1.31487332 0.43803003 1.15919775]
4.681254365054977  -  94.3178  =  -89.63654563494502
training  [-2.0006, -0.4211, -3.9847]  w:  [1.31487332 0.43803003 1.15919775]
-7.434045290466532  -  2.4051  =  -9.839145290466533
training  [-3.6588, -2.5952, -1.0915]  w:  [1.31487332 0.43803003 1.15919775]
-7.212898392285521  -  1.5176  =  -8.730498392285522
training  [-2.874, 2.639, -4.4538]  w:  [1.31487332 0.43803003 1.15919775]
-7.785819603547376  -  5.497  =  -13.282819603547376
training  [3.9494, 2.5933, 0.0128]  w:  [1.31487332 0.43803003 1.15919775]
6.343741707264687  -  94.1462  =  -87.80245829273531
training  [-4.2855, 2.4065, -0.6828]  w:  [1.31487332 0.43803003 1.15919775]
-5.3722705558805375  -  14.4193  =  -19.791570555880536
training  [-2.5751, 2.4369, 4.9756]  w:  [1.31487332 0.43803003 1.15919775]
3.449209439447573  -  87.1991  =  -83.74989056055243
training  [-4.4625, -3.9408, 3.116]  w:  [1.31487332 0.43803003 1.15919775]
-3.981750754273502  -  4.1344  =  -8.116150754273502
training  [-0.5828, 1.8156, -0.1435]  w:  [1.31487332 0.43803003 1.15919775]
-0.13736571680251322  -  51.1166  =  -51.25396571680251
training  [-4.8672, -0.3674, 3.9445]  w:  [1.31487332 0.43803003 1.15919775]
-1.9882281234783372  -  24.1396  =  -26.127828123478338
training  [3.9719, -2.8784, -3.6245]  w:  [1.31487332 0.43803003 1.15919775]
-0.2397925653964572  -  14.6104  =  -14.850192565396458
training  [-3.0334, -4.0148, -1.1]  w:  [1.31487332 0.43803003 1.15919775]
-7.022257236568593  -  1.021  =  -8.043257236568593
training  [-4.0663, 3.2357, 4.2736]  w:  [1.31487332 0.43803003 1.15919775]
1.0246119159473506  -  77.2328  =  -76.20818808405265
training  [-1.9263, -3.2499, 4.1749]  w:  [1.31487332 0.43803003 1.15919775]
0.8831404080432224  -  26.8814  =  -25.998259591956778
training  [-0.4394, -3.3643, 2.1357]  w:  [1.31487332 0.43803003 1.15919775]
0.4242788556386192  -  20.85  =  -20.425721144361383
training  [-3.9833, 1.6599, 1.1834]  w:  [1.31487332 0.43803003 1.15919775]
-3.1386542188801414  -  25.5397  =  -28.67835421888014
training  [4.9539, 3.9439, -1.5671]  w:  [1.31487332 0.43803003 1.15919775]
6.424718793742679  -  95.9509  =  -89.52618120625732
training  [-1.6791, 0.1656, 4.3603]  w:  [1.31487332 0.43803003 1.15919775]
2.9191839391995433  -  71.5733  =  -68.65411606080046
training  [-2.0265, 2.027, -3.7523]  w:  [1.31487332 0.43803003 1.15919775]
-6.126361624045419  -  8.503  =  -14.62936162404542
training  [-4.3795, -3.4641, 2.3059]  w:  [1.31487332 0.43803003 1.15919775]
-4.602873449715427  -  3.6654  =  -8.268273449715426
training  [-2.0176, 4.5346, 1.4648]  w:  [1.31487332 0.43803003 1.15919775]
1.0313954527931914  -  81.6212  =  -80.58980454720681
training  [-4.5365, 0.4088, 3.3315]  w:  [1.31487332 0.43803003 1.15919775]
-1.9239888255305968  -  28.9449  =  -30.868888825530597
training  [0.0543, 1.7973, -1.0172]  w:  [1.31487332 0.43803003 1.15919775]
-0.32046695021565774  -  47.9317  =  -48.25216695021566
training  [2.6143, -4.6344, 2.4982]  w:  [1.31487332 0.43803003 1.15919775]
4.303374748490578  -  43.5132  =  -39.20982525150942
training  [1.3107, 3.092, 3.3522]  w:  [1.31487332 0.43803003 1.15919775]
6.963656029371293  -  96.6993  =  -89.7356439706287
training  [-4.1011, 2.4862, -1.7754]  w:  [1.31487332 0.43803003 1.15919775]
-6.3614363853205305  -  10.0187  =  -16.380136385320533
training  [-4.1914, -3.7981, 0.5226]  w:  [1.31487332 0.43803003 1.15919775]
-6.569045160181561  -  1.4295  =  -7.998545160181561
training  [2.7724, 0.2505, 4.7913]  w:  [1.31487332 0.43803003 1.15919775]
9.309145500697987  -  96.7925  =  -87.48335449930201
training  [4.0513, -1.7417, 0.4931]  w:  [1.31487332 0.43803003 1.15919775]
5.135629778121018  -  71.1234  =  -65.98777022187899
training  [0.3377, 0.4645, -1.6958]  w:  [1.31487332 0.43803003 1.15919775]
-1.318269875944173  -  27.9534  =  -29.27166987594417
training  [-3.9085, -1.0112, 1.1947]  w:  [1.31487332 0.43803003 1.15919775]
-4.197224785689688  -  8.608  =  -12.805224785689688
training  [3.2581, -0.8491, -1.3936]  w:  [1.31487332 0.43803003 1.15919775]
2.296599472527072  -  50.1924  =  -47.89580052747293
training  [-1.619, -3.1926, 2.5651]  w:  [1.31487332 0.43803003 1.15919775]
-0.5537764403072973  -  16.4754  =  -17.029176440307296
training  [-2.0603, -2.4461, -0.861]  w:  [1.31487332 0.43803003 1.15919775]
-4.778568031565802  -  3.9784  =  -8.756968031565803
training  [2.4631, -4.7946, -0.0765]  w:  [1.31487332 0.43803003 1.15919775]
1.0498070403041915  -  15.394  =  -14.344192959695809
training  [-4.8966, 4.2368, 1.9474]  w:  [1.31487332 0.43803003 1.15919775]
-2.3251413428052476  -  53.5883  =  -55.91344134280524
training  [-4.5155, 1.537, 4.7273]  w:  [1.31487332 0.43803003 1.15919775]
0.21581722084707256  -  59.2523  =  -59.03648277915293
training  [1.6792, 4.3261, -1.7225]  w:  [1.31487332 0.43803003 1.15919775]
2.1061788838604043  -  83.7729  =  -81.6667211161396
training  [1.0347, -3.3649, 3.378]  w:  [1.31487332 0.43803003 1.15919775]
3.8023421642045045  -  50.5979  =  -46.7955578357955
training  [0.261, 4.211, 2.3907]  w:  [1.31487332 0.43803003 1.15919775]
4.959020476921012  -  94.9375  =  -89.97847952307899
training  [2.2971, 2.9466, 4.5417]  w:  [1.31487332 0.43803003 1.15919775]
9.575823229833947  -  98.7784  =  -89.20257677016606
training  [2.0725, 0.7739, -4.6808]  w:  [1.31487332 0.43803003 1.15919775]
-2.3619064371581007  -  19.5109  =  -21.8728064371581
training  [2.8138, -0.5996, -1.4313]  w:  [1.31487332 0.43803003 1.15919775]
1.7779879952083446  -  47.2879  =  -45.50991200479166
training  [-2.1202, -2.4239, 1.6265]  w:  [1.31487332 0.43803003 1.15919775]
-1.9641002697921104  -  12.3599  =  -14.32400026979211
training  [1.9253, 2.5195, -2.185]  w:  [1.31487332 0.43803003 1.15919775]
1.1022951869804127  -  65.2467  =  -64.14440481301959
training  [0.5667, -2.7133, -2.6962]  w:  [1.31487332 0.43803003 1.15919775]
-3.5687971606866626  -  5.1106  =  -8.679397160686662
training  [-1.0348, -4.3581, 2.1113]  w:  [1.31487332 0.43803003 1.15919775]
-0.8221953922645793  -  10.5192  =  -11.341395392264578
training  [-4.3841, 2.6733, 1.2457]  w:  [1.31487332 0.43803003 1.15919775]
-3.1495377881567514  -  32.4639  =  -35.61343778815675
training  [2.8018, 1.712, 0.9061]  w:  [1.31487332 0.43803003 1.15919775]
5.484268567913358  -  90.1138  =  -84.62953143208664
training  [-1.6242, 2.1521, 1.6044]  w:  [1.31487332 0.43803003 1.15919775]
0.6668840650278602  -  63.7879  =  -63.12101593497214
training  [1.0787, 1.4206, -4.5245]  w:  [1.31487332 0.43803003 1.15919775]
-3.2041709098364417  -  18.0555  =  -21.25967090983644
training  [2.4125, -0.8095, -1.5122]  w:  [1.31487332 0.43803003 1.15919775]
1.0646077298130499  -  38.8276  =  -37.76299227018695
training  [-3.9519, -1.0924, -0.4866]  w:  [1.31487332 0.43803003 1.15919775]
-6.238817506139805  -  3.6777  =  -9.916517506139805
training  [-3.7211, 3.1614, -2.591]  w:  [1.31487332 0.43803003 1.15919775]
-6.511468330689532  -  11.1518  =  -17.663268330689533
training  [0.4954, -1.8257, 2.1505]  w:  [1.31487332 0.43803003 1.15919775]
2.3445315725859164  -  47.7531  =  -45.40856842741409
training  [-0.1477, 3.1454, 3.5618]  w:  [1.31487332 0.43803003 1.15919775]
5.312403433135379  -  94.1572  =  -88.84479656686463
training  [3.9048, 2.8907, -2.1849]  w:  [1.31487332 0.43803003 1.15919775]
3.8677995910996192  -  85.8791  =  -82.01130040890037
training  [2.9896, 3.5226, 2.3105]  w:  [1.31487332 0.43803003 1.15919775]
8.152276280283324  -  98.038  =  -89.88572371971668
training  [2.3434, 0.0564, -3.6224]  w:  [1.31487332 0.43803003 1.15919775]
-1.0930989046927775  -  24.7629  =  -25.855998904692775
training  [-4.4867, 1.3566, 3.3672]  w:  [1.31487332 0.43803003 1.15919775]
-1.401959907616917  -  40.5785  =  -41.98045990761692
training  [-4.2711, 4.5089, -3.614]  w:  [1.31487332 0.43803003 1.15919775]
-7.830262484296409  -  10.0825  =  -17.912762484296408
training  [-4.1147, -0.5604, 0.8821]  w:  [1.31487332 0.43803003 1.15919775]
-4.6332529415933275  -  8.344  =  -12.977252941593328
training  [2.9835, -4.3998, -1.3384]  w:  [1.31487332 0.43803003 1.15919775]
0.4442097307400654  -  13.2692  =  -12.824990269259935
training  [4.4301, 3.6675, 3.0676]  w:  [1.31487332 0.43803003 1.15919775]
10.987450466348763  -  99.3834  =  -88.39594953365123
training  [1.8372, 1.3119, 0.0378]  w:  [1.31487332 0.43803003 1.15919775]
3.034154539660727  -  74.9026  =  -71.86844546033927
training  [-3.6792, -1.4493, -0.1041]  w:  [1.31487332 0.43803003 1.15919775]
-5.593191331418589  -  4.2442  =  -9.837391331418589
training  [2.2272, 4.97, 3.7705]  w:  [1.31487332 0.43803003 1.15919775]
9.476250251078168  -  99.3199  =  -89.84364974892183
training  [-3.8965, -2.7583, -1.4686]  w:  [1.31487332 0.43803003 1.15919775]
-8.034019951017711  -  1.0337  =  -9.067719951017711
training  [-3.8251, 1.5245, -0.5056]  w:  [1.31487332 0.43803003 1.15919775]
-4.947835528735647  -  12.9762  =  -17.924035528735647
training  [1.4072, 1.0499, 4.6353]  w:  [1.31487332 0.43803003 1.15919775]
7.683406805757169  -  95.4618  =  -87.77839319424282
training  [-1.7119, -1.1275, -4.577]  w:  [1.31487332 0.43803003 1.15919775]
-8.0504586079148  -  1.4655  =  -9.5159586079148
training  [1.5381, -3.5781, 4.7296]  w:  [1.31487332 0.43803003 1.15919775]
5.937633070630967  -  69.9473  =  -64.00966692936903
training  [2.4913, -4.7487, -3.1079]  w:  [1.31487332 0.43803003 1.15919775]
-2.4070000173613373  -  3.9825  =  -6.389500017361337
training  [0.8319, -0.7889, 1.6712]  w:  [1.31487332 0.43803003 1.15919775]
2.685532502201572  -  58.8336  =  -56.14806749779842
training  [2.4003, -3.159, 0.8644]  w:  [1.31487332 0.43803003 1.15919775]
2.774364084982106  -  39.0041  =  -36.2297359150179
training  [-2.6517, 2.2578, 1.7511]  w:  [1.31487332 0.43803003 1.15919775]
-0.46779418569521214  -  54.4525  =  -54.92029418569521
training  [2.3496, -1.2964, -1.3898]  w:  [1.31487332 0.43803003 1.15919775]
0.9105111789196791  -  33.888  =  -32.97748882108032
training  [4.706, 3.4156, 1.2028]  w:  [1.31487332 0.43803003 1.15919775]
9.078212282415585  -  98.4665  =  -89.3882877175844
training  [3.6693, 2.3423, 3.1115]  w:  [1.31487332 0.43803003 1.15919775]
9.457506224368629  -  98.3069  =  -88.84939377563137
training  [-4.1377, 0.7103, -4.8074]  w:  [1.31487332 0.43803003 1.15919775]
-10.702145869937297  -  0.9782  =  -11.680345869937296
training  [-1.3356, -3.2314, -4.1613]  w:  [1.31487332 0.43803003 1.15919775]
-7.995364662586669  -  0.7659  =  -8.761264662586669
training  [-1.308, 4.5738, 4.748]  w:  [1.31487332 0.43803003 1.15919775]
5.787478395182163  -  97.0884  =  -91.30092160481783
training  [1.8503, -2.3468, 1.5135]  w:  [1.31487332 0.43803003 1.15919775]
3.159387014064751  -  50.2125  =  -47.05311298593525
training  [0.9794, 4.2458, -2.6876]  w:  [1.31487332 0.43803003 1.15919775]
0.03211497329869317  -  68.3262  =  -68.29408502670131
training  [2.8936, -2.7623, -0.9651]  w:  [1.31487332 0.43803003 1.15919775]
1.476005321787444  -  28.5596  =  -27.083594678212556
training  [-1.3235, -1.2644, -3.7798]  w:  [1.31487332 0.43803003 1.15919775]
-6.675615674980171  -  2.4511  =  -9.12671567498017
training  [-2.9397, -4.125, -2.3156]  w:  [1.31487332 0.43803003 1.15919775]
-8.35644530308714  -  0.554  =  -8.91044530308714
training  [-4.1333, 1.4012, -2.4215]  w:  [1.31487332 0.43803003 1.15919775]
-7.627995561084245  -  4.4072  =  -12.035195561084244
training  [2.7193, -3.1938, -1.6833]  w:  [1.31487332 0.43803003 1.15919775]
0.22527711715046284  -  17.0949  =  -16.869622882849537
training  [-2.9433, -4.5495, -3.4777]  w:  [1.31487332 0.43803003 1.15919775]
-9.894226303770083  -  0.2509  =  -10.145126303770082
training  [-1.1173, 2.2317, -1.5199]  w:  [1.31487332 0.43803003 1.15919775]
-2.2534209936544896  -  33.1206  =  -35.37402099365449
training  [0.5178, -1.5256, -3.7834]  w:  [1.31487332 0.43803003 1.15919775]
-4.373125989205397  -  5.237  =  -9.610125989205397
training  [-2.7105, 1.6062, 3.8415]  w:  [1.31487332 0.43803003 1.15919775]
1.592657872234267  -  70.4458  =  -68.85314212776574
training  [1.4194, -1.1613, -4.0572]  w:  [1.31487332 0.43803003 1.15919775]
-3.3454502072825836  -  8.3206  =  -11.666050207282584
training  [-0.1552, 1.2735, 4.3004]  w:  [1.31487332 0.43803003 1.15919775]
5.338776920539085  -  90.1085  =  -84.76972307946092
training  [-3.4815, -4.7835, -1.0098]  w:  [1.31487332 0.43803003 1.15919775]
-7.84360602141457  -  0.5839  =  -8.42750602141457
training  [2.8193, 4.1057, -4.526]  w:  [1.31487332 0.43803003 1.15919775]
0.25891323919799536  -  66.8081  =  -66.549186760802
training  [-3.9939, 3.0056, -1.5763]  w:  [1.31487332 0.43803003 1.15919775]
-5.762172893153069  -  14.4018  =  -20.16397289315307
training  [-2.0593, 2.4585, 2.3597]  w:  [1.31487332 0.43803003 1.15919775]
1.1045371481506778  -  70.6698  =  -69.56526285184931
training  [-2.6263, 3.1311, 2.9468]  w:  [1.31487332 0.43803003 1.15919775]
1.3341879773699032  -  77.309  =  -75.97481202263009
training  [0.3087, -1.1669, 0.4491]  w:  [1.31487332 0.43803003 1.15919775]
0.41535985635817807  -  33.0798  =  -32.66444014364182
training  [-4.085, 1.1728, 1.8622]  w:  [1.31487332 0.43803003 1.15919775]
-2.698877831639525  -  26.4056  =  -29.104477831639525
training  [-0.9468, 0.7549, 3.9363]  w:  [1.31487332 0.43803003 1.15919775]
3.6486969237060913  -  79.7738  =  -76.1251030762939
training  [-3.9515, 0.3005, -4.4521]  w:  [1.31487332 0.43803003 1.15919775]
-10.224958205007589  -  1.0441  =  -11.269058205007589
training  [-3.8772, -2.2493, -1.9634]  w:  [1.31487332 0.43803003 1.15919775]
-8.359256655731194  -  1.0509  =  -9.410156655731194
training  [2.8443, -2.5137, -4.5381]  w:  [1.31487332 0.43803003 1.15919775]
-2.6217372322930137  -  6.8897  =  -9.511437232293014
training  [-2.0843, -0.4836, -3.0452]  w:  [1.31487332 0.43803003 1.15919775]
-6.482410776933644  -  3.5346  =  -10.017010776933645
training  [1.0353, -2.7229, 2.2017]  w:  [1.31487332 0.43803003 1.15919775]
2.720782055396622  -  43.9562  =  -41.235417944603384
training  [4.6442, 3.0445, 2.2175]  w:  [1.31487332 0.43803003 1.15919775]
10.010638123844275  -  98.8492  =  -88.83856187615572
training  [-0.6752, 4.861, 3.778]  w:  [1.31487332 0.43803003 1.15919775]
5.6209106386281285  -  97.017  =  -91.39608936137186
training  [1.9475, -4.7001, 0.8243]  w:  [1.31487332 0.43803003 1.15919775]
1.4574575297160621  -  18.7839  =  -17.326442470283936
training  [2.581, 0.3566, -4.2932]  w:  [1.31487332 0.43803003 1.15919775]
-1.4267782393198472  -  23.5455  =  -24.97227823931985
training  [-0.6736, -4.1292, 4.2274]  w:  [1.31487332 0.43803003 1.15919775]
2.205980287516529  -  31.2667  =  -29.060719712483472
training  [1.555, 3.0209, 3.0037]  w:  [1.31487332 0.43803003 1.15919775]
6.8497552294045185  -  96.4078  =  -89.55804477059547
training  [-3.9024, 4.8914, -2.1405]  w:  [1.31487332 0.43803003 1.15919775]
-5.46984431639757  -  25.4308  =  -30.90064431639757
training  [4.3376, -4.3305, 0.4366]  w:  [1.31487332 0.43803003 1.15919775]
4.3126111826385305  -  43.0907  =  -38.778088817361464
training  [-3.1254, 4.394, 4.8478]  w:  [1.31487332 0.43803003 1.15919775]
3.4347577601289476  -  92.8121  =  -89.37734223987106
training  [-2.3382, -4.8182, 2.1568]  w:  [1.31487332 0.43803003 1.15919775]
-2.684795397852634  -  4.7434  =  -7.428195397852635
training  [2.9783, 1.8384, 3.3897]  w:  [1.31487332 0.43803003 1.15919775]
8.650694240743523  -  97.3486  =  -88.69790575925649
training  [-0.124, 2.8374, -0.6674]  w:  [1.31487332 0.43803003 1.15919775]
0.30617354952112263  -  62.785  =  -62.47882645047888
training  [2.6896, 0.3414, -0.2938]  w:  [1.31487332 0.43803003 1.15919775]
3.3454544339254335  -  70.4455  =  -67.10004556607456
training  [-1.0399, 3.8536, 0.6071]  w:  [1.31487332 0.43803003 1.15919775]
1.0244047319476173  -  77.0369  =  -76.01249526805239
training  [-2.2706, 3.99, -2.3091]  w:  [1.31487332 0.43803003 1.15919775]
-3.9145150482157494  -  31.1134  =  -35.027915048215746
training  [-4.6277, 1.2594, 2.4902]  w:  [1.31487332 0.43803003 1.15919775]
-2.646549993059528  -  28.1093  =  -30.755849993059527
training  [1.7329, -3.6213, 0.0389]  w:  [1.31487332 0.43803003 1.15919775]
0.7373986028173813  -  19.3919  =  -18.654501397182617
training  [-0.7044, -2.822, 1.4681]  w:  [1.31487332 0.43803003 1.15919775]
-0.4604993050406134  -  17.8122  =  -18.272699305040614
training  [-0.4826, -3.1786, -1.9225]  w:  [1.31487332 0.43803003 1.15919775]
-4.255437809398929  -  3.5851  =  -7.8405378093989295
training  [1.0986, -4.5818, -3.6128]  w:  [1.31487332 0.43803003 1.15919775]
-4.750395821022295  -  1.7158  =  -6.4661958210222945
training  [-4.406, -3.9306, -0.2443]  w:  [1.31487332 0.43803003 1.15919775]
-7.798244709707293  -  0.8241  =  -8.622344709707294
training  [-1.8419, 1.1644, -1.3754]  w:  [1.31487332 0.43803003 1.15919775]
-3.5061835817293137  -  17.8517  =  -21.357883581729315
training  [2.7272, 4.3966, 2.8811]  w:  [1.31487332 0.43803003 1.15919775]
8.851530008636063  -  98.904  =  -90.05246999136394
training  [1.9643, -1.4554, 2.803]  w:  [1.31487332 0.43803003 1.15919775]
5.19452804593343  -  76.0591  =  -70.86457195406658
training  [-3.7467, -0.8937, 1.6851]  w:  [1.31487332 0.43803003 1.15919775]
-3.364539176227529  -  12.1571  =  -15.521639176227529
training  [-3.6985, 4.8435, -3.665]  w:  [1.31487332 0.43803003 1.15919775]
-6.989920257407283  -  14.6793  =  -21.669220257407282
255131.35445000205
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.23472971 0.5429849  1.07978006]
8.128530812481038  -  87.3174  =  -79.18886918751897
training  [-4.1793, -4.9218, 1.7664]  w:  [1.23472971 0.5429849  1.07978006]
-5.92544546820555  -  1.5257  =  -7.451145468205549
training  [-3.9429, -0.7689, 4.883]  w:  [1.23472971 0.5429849  1.07978006]
-0.013350828831285355  -  39.7859  =  -39.79925082883128
training  [-3.5796, 1.5557, 2.6683]  w:  [1.23472971 0.5429849  1.07978006]
-0.6939397175282074  -  45.5674  =  -46.26133971752821
training  [-3.3354, 2.2292, -1.633]  w:  [1.23472971 0.5429849  1.07978006]
-4.6711763594512865  -  13.3589  =  -18.030076359451286
training  [1.2096, 0.3121, 1.6238]  w:  [1.23472971 0.5429849  1.07978006]
3.416341503389476  -  74.5119  =  -71.09555849661052
training  [0.7371, -3.9118, -2.5583]  w:  [1.23472971 0.5429849  1.07978006]
-3.9763304013141663  -  3.3358  =  -7.312130401314166
training  [-4.4792, 1.3177, -2.0449]  w:  [1.23472971 0.5429849  1.07978006]
-7.023152345113939  -  4.2974  =  -11.320552345113938
training  [4.312, -3.735, 1.8018]  w:  [1.23472971 0.5429849  1.07978006]
5.241653599454452  -  66.5833  =  -61.34164640054554
training  [2.2866, -3.657, 0.2785]  w:  [1.23472971 0.5429849  1.07978006]
1.1383559067906526  -  26.0005  =  -24.862144093209345
training  [2.3784, -4.0141, -0.8841]  w:  [1.23472971 0.5429849  1.07978006]
-0.19754811174726072  -  14.6809  =  -14.878448111747261
training  [-4.366, -3.5797, 1.0264]  w:  [1.23472971 0.5429849  1.07978006]
-6.226266710219  -  1.8713  =  -8.097566710219
training  [3.6044, -3.3175, 2.5052]  w:  [1.23472971 0.5429849  1.07978006]
5.354172348661313  -  71.0139  =  -65.6597276513387
training  [4.3441, -3.0375, 0.8353]  w:  [1.23472971 0.5429849  1.07978006]
4.61641296567819  -  63.8979  =  -59.28148703432181
training  [4.844, -1.8252, 0.5179]  w:  [1.23472971 0.5429849  1.07978006]
5.549192753893992  -  78.0461  =  -72.496907246106
training  [3.5894, -1.8357, 0.8357]  w:  [1.23472971 0.5429849  1.07978006]
4.337553623417365  -  68.8838  =  -64.54624637658263
training  [2.8556, -2.8244, 0.1182]  w:  [1.23472971 0.5429849  1.07978006]
2.119917597471086  -  39.5252  =  -37.40528240252891
training  [0.1338, -2.4896, -4.1741]  w:  [1.23472971 0.5429849  1.07978006]
-5.693718324890657  -  2.2644  =  -7.958118324890657
training  [-3.224, 3.9292, 2.1957]  w:  [1.23472971 0.5429849  1.07978006]
0.5236007779899294  -  72.1211  =  -71.59749922201007
training  [-1.0141, 2.0322, 4.9616]  w:  [1.23472971 0.5429849  1.07978006]
5.208751264837999  -  92.3427  =  -87.133948735162
training  [-3.6607, 0.5574, -1.4547]  w:  [1.23472971 0.5429849  1.07978006]
-5.788071309803348  -  5.8471  =  -11.635171309803347
training  [-4.6911, -3.1557, 4.7126]  w:  [1.23472971 0.5429849  1.07978006]
-2.417166485066679  -  11.2337  =  -13.650866485066679
training  [4.3914, -2.8797, -1.5355]  w:  [1.23472971 0.5429849  1.07978006]
2.2005561341111406  -  37.475  =  -35.27444386588886
training  [-1.9869, -4.2265, 3.8654]  w:  [1.23472971 0.5429849  1.07978006]
-0.5744283086751985  -  15.7889  =  -16.3633283086752
training  [-2.0447, 4.138, -0.4531]  w:  [1.23472971 0.5429849  1.07978006]
-0.767028650387495  -  57.936  =  -58.703028650387495
training  [-1.6706, 2.0672, -0.8657]  w:  [1.23472971 0.5429849  1.07978006]
-1.875046656182299  -  32.4185  =  -34.2935466561823
training  [-0.3293, 0.5779, -2.8227]  w:  [1.23472971 0.5429849  1.07978006]
-3.140700690665961  -  14.3434  =  -17.48410069066596
training  [1.482, -1.8657, -3.7435]  w:  [1.23472971 0.5429849  1.07978006]
-3.225334157884875  -  7.1519  =  -10.377234157884875
training  [-4.7477, -3.338, -1.9109]  w:  [1.23472971 0.5429849  1.07978006]
-9.737961556774078  -  0.4077  =  -10.145661556774078
training  [3.4221, 1.225, 2.261]  w:  [1.23472971 0.5429849  1.07978006]
7.3319077543453215  -  95.0454  =  -87.71349224565468
training  [0.5903, 4.8793, 2.8287]  w:  [1.23472971 0.5429849  1.07978006]
6.4326210375756245  -  97.4647  =  -91.03207896242436
training  [3.541, -3.2957, 1.9379]  w:  [1.23472971 0.5429849  1.07978006]
4.675168328441895  -  64.3732  =  -59.6980316715581
training  [-1.5212, -2.4221, -4.902]  w:  [1.23472971 0.5429849  1.07978006]
-8.48651641602059  -  0.7227  =  -9.20921641602059
training  [-0.5397, -1.032, 3.4321]  w:  [1.23472971 0.5429849  1.07978006]
2.479169097943661  -  60.5921  =  -58.11293090205634
training  [-4.4576, -4.2601, 4.2233]  w:  [1.23472971 0.5429849  1.07978006]
-3.256866008095604  -  6.0247  =  -9.281566008095604
training  [-3.2289, 1.841, 2.7095]  w:  [1.23472971 0.5429849  1.07978006]
-0.061519477615195495  -  54.0111  =  -54.07261947761519
training  [1.6281, -0.9761, -4.5734]  w:  [1.23472971 0.5429849  1.07978006]
-3.45801024897209  -  7.8658  =  -11.32381024897209
training  [-1.6917, 4.8284, -1.2181]  w:  [1.23472971 0.5429849  1.07978006]
-0.7823240316976463  -  61.2837  =  -62.06602403169765
training  [3.9849, -0.9782, 2.0434]  w:  [1.23472971 0.5429849  1.07978006]
6.59554915486869  -  88.3402  =  -81.7446508451313
training  [-3.8184, 1.2067, 2.2951]  w:  [1.23472971 0.5429849  1.07978006]
-1.581268821092487  -  34.1122  =  -35.69346882109249
training  [4.8842, -3.4563, -2.7572]  w:  [1.23472971 0.5429849  1.07978006]
1.17677854082125  -  23.7819  =  -22.60512145917875
training  [0.3998, -1.1865, -2.3095]  w:  [1.23472971 0.5429849  1.07978006]
-2.6443586969412785  -  11.4246  =  -14.068958696941278
training  [2.0692, -3.3887, 1.7303]  w:  [1.23472971 0.5429849  1.07978006]
2.5832332077330085  -  42.6881  =  -40.10486679226699
training  [4.9949, 2.5811, -0.2251]  w:  [1.23472971 0.5429849  1.07978006]
7.325791260985854  -  95.9901  =  -88.66430873901415
training  [-2.1215, 3.7111, 1.2372]  w:  [1.23472971 0.5429849  1.07978006]
0.7314960870723568  -  71.3692  =  -70.63770391292765
training  [-0.8548, -1.4922, -2.6356]  w:  [1.23472971 0.5429849  1.07978006]
-4.711557350935522  -  4.7821  =  -9.493657350935521
training  [-0.3516, 1.8554, -3.2288]  w:  [1.23472971 0.5429849  1.07978006]
-2.913070631615369  -  20.3834  =  -23.29647063161537
training  [2.6396, -2.0585, 3.2964]  w:  [1.23472971 0.5429849  1.07978006]
5.700845102025043  -  80.826  =  -75.12515489797495
training  [3.182, 0.3063, 2.6692]  w:  [1.23472971 0.5429849  1.07978006]
6.977375141206854  -  92.9483  =  -85.97092485879315
training  [-3.9978, 3.3242, 4.3448]  w:  [1.23472971 0.5429849  1.07978006]
1.56021638883605  -  79.1768  =  -77.61658361116395
training  [-3.2188, 0.9749, -3.9211]  w:  [1.23472971 0.5429849  1.07978006]
-7.678917592892228  -  2.7053  =  -10.384217592892227
training  [-1.4037, -1.6469, -3.1777]  w:  [1.23472971 0.5429849  1.07978006]
-6.058649022342356  -  2.6234  =  -8.682049022342357
training  [-4.433, -2.0077, -4.009]  w:  [1.23472971 0.5429849  1.07978006]
-10.892545843445781  -  0.3253  =  -11.217845843445781
training  [0.2189, -0.4741, -0.1024]  w:  [1.23472971 0.5429849  1.07978006]
-0.09771628747572422  -  33.6531  =  -33.75081628747573
training  [-1.6415, -0.7735, -3.0675]  w:  [1.23472971 0.5429849  1.07978006]
-5.75903297011447  -  3.7641  =  -9.523132970114471
training  [-3.2433, -1.4039, 3.9589]  w:  [1.23472971 0.5429849  1.07978006]
-0.4921540911842115  -  30.0658  =  -30.55795409118421
training  [-2.9105, 0.5832, -4.0091]  w:  [1.23472971 0.5429849  1.07978006]
-7.605958255599379  -  2.4887  =  -10.094658255599379
training  [4.0515, 2.4255, -4.5583]  w:  [1.23472971 0.5429849  1.07978006]
1.397555850705329  -  61.2853  =  -59.88774414929467
training  [1.7539, -0.7567, 0.573]  w:  [1.23472971 0.5429849  1.07978006]
2.3734297329295138  -  57.0797  =  -54.70627026707049
training  [-0.3153, -0.7064, 2.725]  w:  [1.23472971 0.5429849  1.07978006]
2.169525848978199  -  58.7004  =  -56.530874151021806
training  [4.1213, -3.7513, -1.8806]  w:  [1.23472971 0.5429849  1.07978006]
1.0211579000316289  -  22.1789  =  -21.15774209996837
training  [-3.9599, -4.7557, -3.2102]  w:  [1.23472971 0.5429849  1.07978006]
-10.937989420687927  -  0.1558  =  -11.093789420687926
training  [2.4555, -2.0981, -1.6104]  w:  [1.23472971 0.5429849  1.07978006]
0.15376436589639342  -  24.4796  =  -24.32583563410361
training  [2.3627, -1.8248, -2.8985]  w:  [1.23472971 0.5429849  1.07978006]
-1.2032854713375367  -  15.7052  =  -16.908485471337535
training  [0.6186, 1.5369, 0.1015]  w:  [1.23472971 0.5429849  1.07978006]
1.707914970907303  -  65.2154  =  -63.5074850290927
training  [-3.1581, 4.5694, 4.0636]  w:  [1.23472971 0.5429849  1.07978006]
2.969509573329095  -  90.3564  =  -87.3868904266709
training  [0.9721, 4.3573, 1.2892]  w:  [1.23472971 0.5429849  1.07978006]
4.958281319559656  -  94.3178  =  -89.35951868044035
training  [-2.0006, -0.4211, -3.9847]  w:  [1.23472971 0.5429849  1.07978006]
-7.001450798821734  -  2.4051  =  -9.406550798821733
training  [-3.6588, -2.5952, -1.0915]  w:  [1.23472971 0.5429849  1.07978006]
-7.105363411084239  -  1.5176  =  -8.622963411084239
training  [-2.874, 2.639, -4.4538]  w:  [1.23472971 0.5429849  1.07978006]
-6.9248004499811335  -  5.497  =  -12.421800449981134
training  [3.9494, 2.5933, 0.0128]  w:  [1.23472971 0.5429849  1.07978006]
6.298385443044496  -  94.1462  =  -87.8478145569555
training  [-4.2855, 2.4065, -0.6828]  w:  [1.23472971 0.5429849  1.07978006]
-4.72201481954906  -  14.4193  =  -19.14131481954906
training  [-2.5751, 2.4369, 4.9756]  w:  [1.23472971 0.5429849  1.07978006]
3.516201101522732  -  87.1991  =  -83.68289889847728
training  [-4.4625, -3.9408, 3.116]  w:  [1.23472971 0.5429849  1.07978006]
-4.285181563734568  -  4.1344  =  -8.419581563734567
training  [-0.5828, 1.8156, -0.1435]  w:  [1.23472971 0.5429849  1.07978006]
0.11129447751222346  -  51.1166  =  -51.005305522487774
training  [-4.8672, -0.3674, 3.9445]  w:  [1.23472971 0.5429849  1.07978006]
-1.9499766450988947  -  24.1396  =  -26.089576645098894
training  [3.9719, -2.8784, -3.6245]  w:  [1.23472971 0.5429849  1.07978006]
-0.5723676418387553  -  14.6104  =  -15.182767641838755
training  [-3.0334, -4.0148, -1.1]  w:  [1.23472971 0.5429849  1.07978006]
-7.113162950441414  -  1.021  =  -8.134162950441414
training  [-4.0663, 3.2357, 4.2736]  w:  [1.23472971 0.5429849  1.07978006]
1.3507028996939545  -  77.2328  =  -75.88209710030604
training  [-1.9263, -3.2499, 4.1749]  w:  [1.23472971 0.5429849  1.07978006]
0.3648672962579953  -  26.8814  =  -26.516532703742005
training  [-0.4394, -3.3643, 2.1357]  w:  [1.23472971 0.5429849  1.07978006]
-0.06321807043663918  -  20.85  =  -20.913218070436642
training  [-3.9833, 1.6599, 1.1834]  w:  [1.23472971 0.5429849  1.07978006]
-2.7391864837796547  -  25.5397  =  -28.278886483779655
training  [4.9539, 3.9439, -1.5671]  w:  [1.23472971 0.5429849  1.07978006]
6.566082329274369  -  95.9509  =  -89.38481767072564
training  [-1.6791, 0.1656, 4.3603]  w:  [1.23472971 0.5429849  1.07978006]
2.7248486393388958  -  71.5733  =  -68.8484513606611
training  [-2.0265, 2.027, -3.7523]  w:  [1.23472971 0.5429849  1.07978006]
-5.453208071423687  -  8.503  =  -13.956208071423687
training  [-4.3795, -3.4641, 2.3059]  w:  [1.23472971 0.5429849  1.07978006]
-4.79858792068665  -  3.6654  =  -8.46398792068665
training  [-2.0176, 4.5346, 1.4648]  w:  [1.23472971 0.5429849  1.07978006]
1.5526905128639965  -  81.6212  =  -80.06850948713601
training  [-4.5365, 0.4088, 3.3315]  w:  [1.23472971 0.5429849  1.07978006]
-1.7820918252165416  -  28.9449  =  -30.726991825216544
training  [0.0543, 1.7973, -1.0172]  w:  [1.23472971 0.5429849  1.07978006]
-0.055399686923900626  -  47.9317  =  -47.9870996869239
training  [2.6143, -4.6344, 2.4982]  w:  [1.23472971 0.5429849  1.07978006]
3.4090511854446657  -  43.5132  =  -40.10414881455533
training  [1.3107, 3.092, 3.3522]  w:  [1.23472971 0.5429849  1.07978006]
6.91690826317074  -  96.6993  =  -89.78239173682925
training  [-4.1011, 2.4862, -1.7754]  w:  [1.23472971 0.5429849  1.07978006]
-5.630822457329973  -  10.0187  =  -15.649522457329974
training  [-4.1914, -3.7981, 0.5226]  w:  [1.23472971 0.5429849  1.07978006]
-6.67326399984498  -  1.4295  =  -8.10276399984498
training  [2.7724, 0.2505, 4.7913]  w:  [1.23472971 0.5429849  1.07978006]
8.732732558890852  -  96.7925  =  -88.05976744110916
training  [4.0513, -1.7417, 0.4931]  w:  [1.23472971 0.5429849  1.07978006]
4.588983208189868  -  71.1234  =  -66.53441679181013
training  [0.3377, 0.4645, -1.6958]  w:  [1.23472971 0.5429849  1.07978006]
-1.1619063145805941  -  27.9534  =  -29.115306314580593
training  [-3.9085, -1.0112, 1.1947]  w:  [1.23472971 0.5429849  1.07978006]
-4.084994161384356  -  8.608  =  -12.692994161384355
training  [3.2581, -0.8491, -1.3936]  w:  [1.23472971 0.5429849  1.07978006]
2.0570428903530615  -  50.1924  =  -48.13535710964694
training  [-1.619, -3.1926, 2.5651]  w:  [1.23472971 0.5429849  1.07978006]
-0.9628171688623484  -  16.4754  =  -17.438217168862348
training  [-2.0603, -2.4461, -0.861]  w:  [1.23472971 0.5429849  1.07978006]
-4.801799619939145  -  3.9784  =  -8.780199619939145
training  [2.4631, -4.7946, -0.0765]  w:  [1.23472971 0.5429849  1.07978006]
0.355264153574662  -  15.394  =  -15.038735846425338
training  [-4.8966, 4.2368, 1.9474]  w:  [1.23472971 0.5429849  1.07978006]
-1.642695364375537  -  53.5883  =  -55.23099536437553
training  [-4.5155, 1.537, 4.7273]  w:  [1.23472971 0.5429849  1.07978006]
0.3635900729291919  -  59.2523  =  -58.888709927070806
training  [1.6792, 4.3261, -1.7225]  w:  [1.23472971 0.5429849  1.07978006]
2.562443962778662  -  83.7729  =  -81.21045603722135
training  [1.0347, -3.3649, 3.378]  w:  [1.23472971 0.5429849  1.07978006]
3.0979819689793127  -  50.5979  =  -47.49991803102069
training  [0.261, 4.211, 2.3907]  w:  [1.23472971 0.5429849  1.07978006]
5.190204068053718  -  94.9375  =  -89.74729593194628
training  [2.2971, 2.9466, 4.5417]  w:  [1.23472971 0.5429849  1.07978006]
9.340294022845857  -  98.7784  =  -89.43810597715415
training  [2.0725, 0.7739, -4.6808]  w:  [1.23472971 0.5429849  1.07978006]
-2.075041164765258  -  19.5109  =  -21.58594116476526
training  [2.8138, -0.5996, -1.4313]  w:  [1.23472971 0.5429849  1.07978006]
1.6032195060984533  -  47.2879  =  -45.684680493901546
training  [-2.1202, -2.4239, 1.6265]  w:  [1.23472971 0.5429849  1.07978006]
-2.177752767238064  -  12.3599  =  -14.537652767238065
training  [1.9253, 2.5195, -2.185]  w:  [1.23472971 0.5429849  1.07978006]
1.3859561407630667  -  65.2467  =  -63.86074385923694
training  [0.5667, -2.7133, -2.6962]  w:  [1.23472971 0.5429849  1.07978006]
-3.6848626074867066  -  5.1106  =  -8.795462607486707
training  [-1.0348, -4.3581, 2.1113]  w:  [1.23472971 0.5429849  1.07978006]
-1.364341168720236  -  10.5192  =  -11.883541168720235
training  [-4.3841, 2.6733, 1.2457]  w:  [1.23472971 0.5429849  1.07978006]
-2.6165349523931267  -  32.4639  =  -35.08043495239313
training  [2.8018, 1.712, 0.9061]  w:  [1.23472971 0.5429849  1.07978006]
5.367444561888217  -  90.1138  =  -84.74635543811178
training  [-1.6242, 2.1521, 1.6044]  w:  [1.23472971 0.5429849  1.07978006]
0.8955089448814217  -  63.7879  =  -62.89239105511858
training  [1.0787, 1.4206, -4.5245]  w:  [1.23472971 0.5429849  1.07978006]
-2.7821975886677333  -  18.0555  =  -20.83769758866773
training  [2.4125, -0.8095, -1.5122]  w:  [1.23472971 0.5429849  1.07978006]
0.9063957362892299  -  38.8276  =  -37.92120426371077
training  [-3.9519, -1.0924, -0.4866]  w:  [1.23472971 0.5429849  1.07978006]
-5.998106018450274  -  3.6777  =  -9.675806018450274
training  [-3.7211, 3.1614, -2.591]  w:  [1.23472971 0.5429849  1.07978006]
-5.675670378044156  -  11.1518  =  -16.827470378044154
training  [0.4954, -1.8257, 2.1505]  w:  [1.23472971 0.5429849  1.07978006]
1.9424245773807458  -  47.7531  =  -45.810675422619255
training  [-0.1477, 3.1454, 3.5618]  w:  [1.23472971 0.5429849  1.07978006]
5.371495751069079  -  94.1572  =  -88.78570424893093
training  [3.9048, 2.8907, -2.1849]  w:  [1.23472971 0.5429849  1.07978006]
4.031767572016187  -  85.8791  =  -81.8473324279838
training  [2.9896, 3.5226, 2.3105]  w:  [1.23472971 0.5429849  1.07978006]
8.098898381677152  -  98.038  =  -89.93910161832284
training  [2.3434, 0.0564, -3.6224]  w:  [1.23472971 0.5429849  1.07978006]
-0.9873053400405718  -  24.7629  =  -25.75020534004057
training  [-4.4867, 1.3566, 3.3672]  w:  [1.23472971 0.5429849  1.07978006]
-1.1674130465592087  -  40.5785  =  -41.74591304655921
training  [-4.2711, 4.5089, -3.614]  w:  [1.23472971 0.5429849  1.07978006]
-6.727714561312101  -  10.0825  =  -16.8102145613121
training  [-4.1147, -0.5604, 0.8821]  w:  [1.23472971 0.5429849  1.07978006]
-4.432357079442157  -  8.344  =  -12.776357079442157
training  [2.9835, -4.3998, -1.3384]  w:  [1.23472971 0.5429849  1.07978006]
-0.1503865233639663  -  13.2692  =  -13.419586523363966
training  [4.4301, 3.6675, 3.0676]  w:  [1.23472971 0.5429849  1.07978006]
10.773706521542941  -  99.3834  =  -88.60969347845705
training  [1.8372, 1.3119, 0.0378]  w:  [1.23472971 0.5429849  1.07978006]
3.021603000285297  -  74.9026  =  -71.88099699971471
training  [-3.6792, -1.4493, -0.1041]  w:  [1.23472971 0.5429849  1.07978006]
-5.442170666267381  -  4.2442  =  -9.686370666267381
training  [2.2272, 4.97, 3.7705]  w:  [1.23472971 0.5429849  1.07978006]
9.51993568731773  -  99.3199  =  -89.79996431268228
training  [-3.8965, -2.7583, -1.4686]  w:  [1.23472971 0.5429849  1.07978006]
-7.894604560730202  -  1.0337  =  -8.928304560730203
training  [-3.8251, 1.5245, -0.5056]  w:  [1.23472971 0.5429849  1.07978006]
-4.441120919885655  -  12.9762  =  -17.417320919885654
training  [1.4072, 1.0499, 4.6353]  w:  [1.23472971 0.5429849  1.07978006]
7.312696003576197  -  95.4618  =  -88.1491039964238
training  [-1.7119, -1.1275, -4.577]  w:  [1.23472971 0.5429849  1.07978006]
-7.668102596664119  -  1.4655  =  -9.133602596664119
training  [1.5381, -3.5781, 4.7296]  w:  [1.23472971 0.5429849  1.07978006]
5.063211250805642  -  69.9473  =  -64.88408874919436
training  [2.4913, -4.7487, -3.1079]  w:  [1.23472971 0.5429849  1.07978006]
-2.8582387332021333  -  3.9825  =  -6.840738733202134
training  [0.8319, -0.7889, 1.6712]  w:  [1.23472971 0.5429849  1.07978006]
2.4033392892169103  -  58.8336  =  -56.43026071078309
training  [2.4003, -3.159, 0.8644]  w:  [1.23472971 0.5429849  1.07978006]
2.1817942930181062  -  39.0041  =  -36.82230570698189
training  [-2.6517, 2.2578, 1.7511]  w:  [1.23472971 0.5429849  1.07978006]
-0.15737859128480025  -  54.4525  =  -54.6098785912848
training  [2.3496, -1.2964, -1.3898]  w:  [1.23472971 0.5429849  1.07978006]
0.696516967621416  -  33.888  =  -33.191483032378585
training  [4.706, 3.4156, 1.2028]  w:  [1.23472971 0.5429849  1.07978006]
8.964016696467695  -  98.4665  =  -89.5024833035323
training  [3.6693, 2.3423, 3.1115]  w:  [1.23472971 0.5429849  1.07978006]
9.162162910721594  -  98.3069  =  -89.14473708927841
training  [-4.1377, 0.7103, -4.8074]  w:  [1.23472971 0.5429849  1.07978006]
-9.914193593541412  -  0.9782  =  -10.892393593541412
training  [-1.3356, -3.2314, -4.1613]  w:  [1.23472971 0.5429849  1.07978006]
-7.8969951743184  -  0.7659  =  -8.6628951743184
training  [-1.308, 4.5738, 4.748]  w:  [1.23472971 0.5429849  1.07978006]
5.995273612465274  -  97.0884  =  -91.09312638753472
training  [1.8503, -2.3468, 1.5135]  w:  [1.23472971 0.5429849  1.07978006]
2.644590528229539  -  50.2125  =  -47.56790947177046
training  [0.9794, 4.2458, -2.6876]  w:  [1.23472971 0.5429849  1.07978006]
0.6126826901384086  -  68.3262  =  -67.71351730986159
training  [2.8936, -2.7623, -0.9651]  w:  [1.23472971 0.5429849  1.07978006]
1.0308309506775026  -  28.5596  =  -27.5287690493225
training  [-1.3235, -1.2644, -3.7798]  w:  [1.23472971 0.5429849  1.07978006]
-6.402067548018283  -  2.4511  =  -8.853167548018282
training  [-2.9397, -4.125, -2.3156]  w:  [1.23472971 0.5429849  1.07978006]
-8.369886353119528  -  0.554  =  -8.923886353119528
training  [-4.1333, 1.4012, -2.4215]  w:  [1.23472971 0.5429849  1.07978006]
-6.957365269980775  -  4.4072  =  -11.364565269980774
training  [2.7193, -3.1938, -1.6833]  w:  [1.23472971 0.5429849  1.07978006]
-0.1941784616503801  -  17.0949  =  -17.28907846165038
training  [-2.9433, -4.5495, -3.4777]  w:  [1.23472971 0.5429849  1.07978006]
-9.85964087824684  -  0.2509  =  -10.11054087824684
training  [-1.1173, 2.2317, -1.5199]  w:  [1.23472971 0.5429849  1.07978006]
-1.8089418068846195  -  33.1206  =  -34.92954180688462
training  [0.5178, -1.5256, -3.7834]  w:  [1.23472971 0.5429849  1.07978006]
-4.274274601314746  -  5.237  =  -9.511274601314746
training  [-2.7105, 1.6062, 3.8415]  w:  [1.23472971 0.5429849  1.07978006]
1.6733825749178592  -  70.4458  =  -68.77241742508215
training  [1.4194, -1.1613, -4.0572]  w:  [1.23472971 0.5429849  1.07978006]
-3.2588766765155106  -  8.3206  =  -11.579476676515512
training  [-0.1552, 1.2735, 4.3004]  w:  [1.23472971 0.5429849  1.07978006]
5.143347390063099  -  90.1085  =  -84.96515260993691
training  [-3.4815, -4.7835, -1.0098]  w:  [1.23472971 0.5429849  1.07978006]
-7.986441666259055  -  0.5839  =  -8.570341666259056
training  [2.8193, 4.1057, -4.526]  w:  [1.23472971 0.5429849  1.07978006]
0.8233220343033896  -  66.8081  =  -65.98477796569661
training  [-3.9939, 3.0056, -1.5763]  w:  [1.23472971 0.5429849  1.07978006]
-5.001448864196732  -  14.4018  =  -19.403248864196733
training  [-2.0593, 2.4585, 2.3597]  w:  [1.23472971 0.5429849  1.07978006]
1.340206501904245  -  70.6698  =  -69.32959349809575
training  [-2.6263, 3.1311, 2.9468]  w:  [1.23472971 0.5429849  1.07978006]
1.639265275943405  -  77.309  =  -75.6697347240566
training  [0.3087, -1.1669, 0.4491]  w:  [1.23472971 0.5429849  1.07978006]
0.2324812021794821  -  33.0798  =  -32.84731879782051
training  [-4.085, 1.1728, 1.8622]  w:  [1.23472971 0.5429849  1.07978006]
-2.3962917371398387  -  26.4056  =  -28.80189173713984
training  [-0.9468, 0.7549, 3.9363]  w:  [1.23472971 0.5429849  1.07978006]
3.4911954628310498  -  79.7738  =  -76.28260453716895
training  [-3.9515, 0.3005, -4.4521]  w:  [1.23472971 0.5429849  1.07978006]
-9.523156280092909  -  1.0441  =  -10.56725628009291
training  [-3.8772, -2.2493, -1.9634]  w:  [1.23472971 0.5429849  1.07978006]
-8.128670135043079  -  1.0509  =  -9.179570135043079
training  [2.8443, -2.5137, -4.5381]  w:  [1.23472971 0.5429849  1.07978006]
-2.7531093287254347  -  6.8897  =  -9.642809328725434
training  [-2.0843, -0.4836, -3.0452]  w:  [1.23472971 0.5429849  1.07978006]
-6.124280866170403  -  3.5346  =  -9.658880866170403
training  [1.0353, -2.7229, 2.2017]  w:  [1.23472971 0.5429849  1.07978006]
2.17717383085002  -  43.9562  =  -41.77902616914998
training  [4.6442, 3.0445, 2.2175]  w:  [1.23472971 0.5429849  1.07978006]
9.781861529112003  -  98.8492  =  -89.06733847088799
training  [-0.6752, 4.861, 3.778]  w:  [1.23472971 0.5429849  1.07978006]
5.8851691784498925  -  97.017  =  -91.1318308215501
training  [1.9475, -4.7001, 0.8243]  w:  [1.23472971 0.5429849  1.07978006]
0.7426154667641263  -  18.7839  =  -18.041284533235874
training  [2.581, 0.3566, -4.2932]  w:  [1.23472971 0.5429849  1.07978006]
-1.2552459572446741  -  23.5455  =  -24.800745957244676
training  [-0.6736, -4.1292, 4.2274]  w:  [1.23472971 0.5429849  1.07978006]
1.4908550295250498  -  31.2667  =  -29.77584497047495
training  [1.555, 3.0209, 3.0037]  w:  [1.23472971 0.5429849  1.07978006]
6.803643153616359  -  96.4078  =  -89.60415684638363
training  [-3.9024, 4.8914, -2.1405]  w:  [1.23472971 0.5429849  1.07978006]
-4.473722075223442  -  25.4308  =  -29.904522075223444
training  [4.3376, -4.3305, 0.4366]  w:  [1.23472971 0.5429849  1.07978006]
3.4757994333564906  -  43.0907  =  -39.614900566643506
training  [-3.1254, 4.394, 4.8478]  w:  [1.23472971 0.5429849  1.07978006]
3.7614092052559776  -  92.8121  =  -89.05069079474403
training  [-2.3382, -4.8182, 2.1568]  w:  [1.23472971 0.5429849  1.07978006]
-3.174385231481461  -  4.7434  =  -7.917785231481462
training  [2.9783, 1.8384, 3.3897]  w:  [1.23472971 0.5429849  1.07978006]
8.33574940225488  -  97.3486  =  -89.01285059774513
training  [-0.124, 2.8374, -0.6674]  w:  [1.23472971 0.5429849  1.07978006]
0.6669136684654496  -  62.785  =  -62.11808633153455
training  [2.6896, 0.3414, -0.2938]  w:  [1.23472971 0.5429849  1.07978006]
3.1890646874760957  -  70.4455  =  -67.2564353125239
training  [-1.0399, 3.8536, 0.6071]  w:  [1.23472971 0.5429849  1.07978006]
1.4639856727378766  -  77.0369  =  -75.57291432726213
training  [-2.2706, 3.99, -2.3091]  w:  [1.23472971 0.5429849  1.07978006]
-3.1303876470590177  -  31.1134  =  -34.243787647059015
training  [-4.6277, 1.2594, 2.4902]  w:  [1.23472971 0.5429849  1.07978006]
-2.3412551799365433  -  28.1093  =  -30.450555179936543
training  [1.7329, -3.6213, 0.0389]  w:  [1.23472971 0.5429849  1.07978006]
0.21535532624030843  -  19.3919  =  -19.17654467375969
training  [-0.7044, -2.822, 1.4681]  w:  [1.23472971 0.5429849  1.07978006]
-0.816821897738669  -  17.8122  =  -18.62902189773867
training  [-0.4826, -3.1786, -1.9225]  w:  [1.23472971 0.5429849  1.07978006]
-4.397689533765138  -  3.5851  =  -7.982789533765137
training  [1.0986, -4.5818, -3.6128]  w:  [1.23472971 0.5429849  1.07978006]
-5.032403569317695  -  1.7158  =  -6.7482035693176945
training  [-4.406, -3.9306, -0.2443]  w:  [1.23472971 0.5429849  1.07978006]
-7.838265822294434  -  0.8241  =  -8.662365822294435
training  [-1.8419, 1.1644, -1.3754]  w:  [1.23472971 0.5429849  1.07978006]
-3.127126521824068  -  17.8517  =  -20.978826521824068
training  [2.7272, 4.3966, 2.8811]  w:  [1.23472971 0.5429849  1.07978006]
8.865596613303067  -  98.904  =  -90.03840338669693
training  [1.9643, -1.4554, 2.803]  w:  [1.23472971 0.5429849  1.07978006]
4.6617428439  -  76.0591  =  -71.3973571561
training  [-3.7467, -0.8937, 1.6851]  w:  [1.23472971 0.5429849  1.07978006]
-3.291890027450685  -  12.1571  =  -15.448990027450684
training  [-3.6985, 4.8435, -3.665]  w:  [1.23472971 0.5429849  1.07978006]
-5.894094364908246  -  14.6793  =  -20.573394364908246
255422.0046893479
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.32192711 0.46361587 1.03999081]
8.665369081505926  -  87.3174  =  -78.65203091849408
training  [-4.1793, -4.9218, 1.7664]  w:  [1.32192711 0.46361587 1.03999081]
-5.969514772446704  -  1.5257  =  -7.495214772446705
training  [-3.9429, -0.7689, 4.883]  w:  [1.32192711 0.46361587 1.03999081]
-0.4904255206824173  -  39.7859  =  -40.27632552068241
training  [-3.5796, 1.5557, 2.6683]  w:  [1.32192711 0.46361587 1.03999081]
-1.235715607122477  -  45.5674  =  -46.80311560712248
training  [-3.3354, 2.2292, -1.633]  w:  [1.32192711 0.46361587 1.03999081]
-5.073968190267838  -  13.3589  =  -18.43286819026784
training  [1.2096, 0.3121, 1.6238]  w:  [1.32192711 0.46361587 1.03999081]
3.4324346209184036  -  74.5119  =  -71.0794653790816
training  [0.7371, -3.9118, -2.5583]  w:  [1.32192711 0.46361587 1.03999081]
-3.4997885555610644  -  3.3358  =  -6.835588555561064
training  [-4.4792, 1.3177, -2.0449]  w:  [1.32192711 0.46361587 1.03999081]
-7.436946494857202  -  4.2974  =  -11.734346494857203
training  [4.312, -3.735, 1.8018]  w:  [1.32192711 0.46361587 1.03999081]
5.842399885533089  -  66.5833  =  -60.7409001144669
training  [2.2866, -3.657, 0.2785]  w:  [1.32192711 0.46361587 1.03999081]
1.616912753062862  -  26.0005  =  -24.383587246937136
training  [2.3784, -4.0141, -0.8841]  w:  [1.32192711 0.46361587 1.03999081]
0.36361512133378227  -  14.6809  =  -14.317284878666218
training  [-4.366, -3.5797, 1.0264]  w:  [1.32192711 0.46361587 1.03999081]
-6.363692910481787  -  1.8713  =  -8.234992910481788
training  [3.6044, -3.3175, 2.5052]  w:  [1.32192711 0.46361587 1.03999081]
5.83209342107488  -  71.0139  =  -65.18180657892512
training  [4.3441, -3.0375, 0.8353]  w:  [1.32192711 0.46361587 1.03999081]
5.203054694339859  -  63.8979  =  -58.69484530566014
training  [4.844, -1.8252, 0.5179]  w:  [1.32192711 0.46361587 1.03999081]
6.095834487263882  -  78.0461  =  -71.95026551273611
training  [3.5894, -1.8357, 0.8357]  w:  [1.32192711 0.46361587 1.03999081]
4.762985846904014  -  68.8838  =  -64.12081415309598
training  [2.8556, -2.8244, 0.1182]  w:  [1.32192711 0.46361587 1.03999081]
2.5883853215285697  -  39.5252  =  -36.93681467847143
training  [0.1338, -2.4896, -4.1741]  w:  [1.32192711 0.46361587 1.03999081]
-5.3183698480176815  -  2.2644  =  -7.582769848017682
training  [-3.224, 3.9292, 2.1957]  w:  [1.32192711 0.46361587 1.03999081]
-0.15674572736683912  -  72.1211  =  -72.27784572736684
training  [-1.0141, 2.0322, 4.9616]  w:  [1.32192711 0.46361587 1.03999081]
4.761612278271095  -  92.3427  =  -87.58108772172889
training  [-3.6607, 0.5574, -1.4547]  w:  [1.32192711 0.46361587 1.03999081]
-6.093633721269233  -  5.8471  =  -11.940733721269233
training  [-4.6911, -3.1557, 4.7126]  w:  [1.32192711 0.46361587 1.03999081]
-2.7632641655617034  -  11.2337  =  -13.996964165561703
training  [4.3914, -2.8797, -1.5355]  w:  [1.32192711 0.46361587 1.03999081]
2.873130219134694  -  37.475  =  -34.60186978086531
training  [-1.9869, -4.2265, 3.8654]  w:  [1.32192711 0.46361587 1.03999081]
-0.566028955034299  -  15.7889  =  -16.3549289550343
training  [-2.0447, 4.138, -0.4531]  w:  [1.32192711 0.46361587 1.03999081]
-1.2557217492259989  -  57.936  =  -59.191721749226
training  [-1.6706, 2.0672, -0.8657]  w:  [1.32192711 0.46361587 1.03999081]
-2.150344758509321  -  32.4185  =  -34.56884475850932
training  [-0.3293, 0.5779, -2.8227]  w:  [1.32192711 0.46361587 1.03999081]
-3.1029690469487123  -  14.3434  =  -17.446369046948714
training  [1.482, -1.8657, -3.7435]  w:  [1.32192711 0.46361587 1.03999081]
-2.799077736670496  -  7.1519  =  -9.950977736670497
training  [-4.7477, -3.338, -1.9109]  w:  [1.32192711 0.46361587 1.03999081]
-9.810981538629889  -  0.4077  =  -10.21868153862989
training  [3.4221, 1.225, 2.261]  w:  [1.32192711 0.46361587 1.03999081]
7.443115420238927  -  95.0454  =  -87.60228457976108
training  [0.5903, 4.8793, 2.8287]  w:  [1.32192711 0.46361587 1.03999081]
5.9842764665724015  -  97.4647  =  -91.4804235334276
training  [3.541, -3.2957, 1.9379]  w:  [1.32192711 0.46361587 1.03999081]
5.168403281916509  -  64.3732  =  -59.204796718083486
training  [-1.5212, -2.4221, -4.902]  w:  [1.32192711 0.46361587 1.03999081]
-8.23187445544904  -  0.7227  =  -8.95457445544904
training  [-0.5397, -1.032, 3.4321]  w:  [1.32192711 0.46361587 1.03999081]
2.3774568227438886  -  60.5921  =  -58.214643177256114
training  [-4.4576, -4.2601, 4.2233]  w:  [1.32192711 0.46361587 1.03999081]
-3.4754790496786816  -  6.0247  =  -9.500179049678682
training  [-3.2289, 1.841, 2.7095]  w:  [1.32192711 0.46361587 1.03999081]
-0.5969985417625447  -  54.0111  =  -54.608098541762544
training  [1.6281, -0.9761, -4.5734]  w:  [1.32192711 0.46361587 1.03999081]
-3.0565998849977367  -  7.8658  =  -10.922399884997738
training  [-1.6917, 4.8284, -1.2181]  w:  [1.32192711 0.46361587 1.03999081]
-1.2645940551494996  -  61.2837  =  -62.548294055149505
training  [3.9849, -0.9782, 2.0434]  w:  [1.32192711 0.46361587 1.03999081]
6.93935552404219  -  88.3402  =  -81.40084447595781
training  [-3.8184, 1.2067, 2.2951]  w:  [1.32192711 0.46361587 1.03999081]
-2.1013183081439744  -  34.1122  =  -36.213518308143975
training  [4.8842, -3.4563, -2.7572]  w:  [1.32192711 0.46361587 1.03999081]
1.986698219553316  -  23.7819  =  -21.795201780446686
training  [0.3998, -1.1865, -2.3095]  w:  [1.32192711 0.46361587 1.03999081]
-2.4234325395023966  -  11.4246  =  -13.848032539502396
training  [2.0692, -3.3887, 1.7303]  w:  [1.32192711 0.46361587 1.03999081]
2.9637725929691427  -  42.6881  =  -39.724327407030856
training  [4.9949, 2.5811, -0.2251]  w:  [1.32192711 0.46361587 1.03999081]
7.565430703118536  -  95.9901  =  -88.42466929688146
training  [-2.1215, 3.7111, 1.2372]  w:  [1.32192711 0.46361587 1.03999081]
0.20273310109155163  -  71.3692  =  -71.16646689890845
training  [-0.8548, -1.4922, -2.6356]  w:  [1.32192711 0.46361587 1.03999081]
-4.562790665438264  -  4.7821  =  -9.344890665438264
training  [-0.3516, 1.8554, -3.2288]  w:  [1.32192711 0.46361587 1.03999081]
-2.962519021601074  -  20.3834  =  -23.345919021601077
training  [2.6396, -2.0585, 3.2964]  w:  [1.32192711 0.46361587 1.03999081]
5.963231247288244  -  80.826  =  -74.86276875271174
training  [3.182, 0.3063, 2.6692]  w:  [1.32192711 0.46361587 1.03999081]
7.12432107414576  -  92.9483  =  -85.82397892585425
training  [-3.9978, 3.3242, 4.3448]  w:  [1.32192711 0.46361587 1.03999081]
0.7749037246348358  -  79.1768  =  -78.40189627536516
training  [-3.2188, 0.9749, -3.9211]  w:  [1.32192711 0.46361587 1.03999081]
-7.880947839835867  -  2.7053  =  -10.586247839835867
training  [-1.4037, -1.6469, -3.1777]  w:  [1.32192711 0.46361587 1.03999081]
-5.923896848604309  -  2.6234  =  -8.547296848604308
training  [-4.433, -2.0077, -4.009]  w:  [1.32192711 0.46361587 1.03999081]
-10.960227608909568  -  0.3253  =  -11.285527608909568
training  [0.2189, -0.4741, -0.1024]  w:  [1.32192711 0.46361587 1.03999081]
-0.036925495998847174  -  33.6531  =  -33.690025495998846
training  [-1.6415, -0.7735, -3.0675]  w:  [1.32192711 0.46361587 1.03999081]
-5.718722031758537  -  3.7641  =  -9.482822031758538
training  [-3.2433, -1.4039, 3.9589]  w:  [1.32192711 0.46361587 1.03999081]
-0.8210568954091801  -  30.0658  =  -30.88685689540918
training  [-2.9105, 0.5832, -4.0091]  w:  [1.32192711 0.46361587 1.03999081]
-7.746515237204404  -  2.4887  =  -10.235215237204404
training  [4.0515, 2.4255, -4.5583]  w:  [1.32192711 0.46361587 1.03999081]
1.7396978628111501  -  61.2853  =  -59.54560213718885
training  [1.7539, -0.7567, 0.573]  w:  [1.32192711 0.46361587 1.03999081]
2.563624568080778  -  57.0797  =  -54.516075431919226
training  [-0.3153, -0.7064, 2.725]  w:  [1.32192711 0.46361587 1.03999081]
2.0896730906787857  -  58.7004  =  -56.610726909321215
training  [4.1213, -3.7513, -1.8806]  w:  [1.32192711 0.46361587 1.03999081]
1.7530892902072472  -  22.1789  =  -20.425810709792753
training  [-3.9599, -4.7557, -3.2102]  w:  [1.32192711 0.46361587 1.03999081]
-10.77809563149787  -  0.1558  =  -10.933895631497869
training  [2.4555, -2.0981, -1.6104]  w:  [1.32192711 0.46361587 1.03999081]
0.5984783741439725  -  24.4796  =  -23.88112162585603
training  [2.3627, -1.8248, -2.8985]  w:  [1.32192711 0.46361587 1.03999081]
-0.7371024074537731  -  15.7052  =  -16.442302407453774
training  [0.6186, 1.5369, 0.1015]  w:  [1.32192711 0.46361587 1.03999081]
1.6358344008406729  -  65.2154  =  -63.57956559915933
training  [-3.1581, 4.5694, 4.0636]  w:  [1.32192711 0.46361587 1.03999081]
2.1697749790205116  -  90.3564  =  -88.18662502097948
training  [0.9721, 4.3573, 1.2892]  w:  [1.32192711 0.46361587 1.03999081]
4.64591490469838  -  94.3178  =  -89.67188509530163
training  [-2.0006, -0.4211, -3.9847]  w:  [1.32192711 0.46361587 1.03999081]
-6.983927396769108  -  2.4051  =  -9.389027396769109
training  [-3.6588, -2.5952, -1.0915]  w:  [1.32192711 0.46361587 1.03999081]
-7.174992774001816  -  1.5176  =  -8.692592774001817
training  [-2.874, 2.639, -4.4538]  w:  [1.32192711 0.46361587 1.03999081]
-7.207647315207519  -  5.497  =  -12.70464731520752
training  [3.9494, 2.5933, 0.0128]  w:  [1.32192711 0.46361587 1.03999081]
6.436425836057407  -  94.1462  =  -87.70977416394258
training  [-4.2855, 2.4065, -0.6828]  w:  [1.32192711 0.46361587 1.03999081]
-5.259532778076825  -  14.4193  =  -19.678832778076824
training  [-2.5751, 2.4369, 4.9756]  w:  [1.32192711 0.46361587 1.03999081]
2.9002692704761497  -  87.1991  =  -84.29883072952386
training  [-4.4625, -3.9408, 3.116]  w:  [1.32192711 0.46361587 1.03999081]
-4.485505770108087  -  4.1344  =  -8.619905770108087
training  [-0.5828, 1.8156, -0.1435]  w:  [1.32192711 0.46361587 1.03999081]
-0.0779168366122849  -  51.1166  =  -51.19451683661228
training  [-4.8672, -0.3674, 3.9445]  w:  [1.32192711 0.46361587 1.03999081]
-2.5021723538979534  -  24.1396  =  -26.641772353897956
training  [3.9719, -2.8784, -3.6245]  w:  [1.32192711 0.46361587 1.03999081]
0.14664369589775816  -  14.6104  =  -14.463756304102242
training  [-3.0334, -4.0148, -1.1]  w:  [1.32192711 0.46361587 1.03999081]
-7.015248562942794  -  1.021  =  -8.036248562942795
training  [-4.0663, 3.2357, 4.2736]  w:  [1.32192711 0.46361587 1.03999081]
0.5692743678632839  -  77.2328  =  -76.66352563213671
training  [-1.9263, -3.2499, 4.1749]  w:  [1.32192711 0.46361587 1.03999081]
0.288724237228581  -  26.8814  =  -26.592675762771417
training  [-0.4394, -3.3643, 2.1357]  w:  [1.32192711 0.46361587 1.03999081]
0.08051074445446371  -  20.85  =  -20.769489255545537
training  [-3.9833, 1.6599, 1.1834]  w:  [1.32192711 0.46361587 1.03999081]
-3.2653511615052606  -  25.5397  =  -28.80505116150526
training  [4.9539, 3.9439, -1.5671]  w:  [1.32192711 0.46361587 1.03999081]
6.747379726222242  -  95.9509  =  -89.20352027377777
training  [-1.6791, 0.1656, 4.3603]  w:  [1.32192711 0.46361587 1.03999081]
2.3917989022171815  -  71.5733  =  -69.18150109778283
training  [-2.0265, 2.027, -3.7523]  w:  [1.32192711 0.46361587 1.03999081]
-5.641493445528141  -  8.503  =  -14.144493445528141
training  [-4.3795, -3.4641, 2.3059]  w:  [1.32192711 0.46361587 1.03999081]
-4.99727669177963  -  3.6654  =  -8.66267669177963
training  [-2.0176, 4.5346, 1.4648]  w:  [1.32192711 0.46361587 1.03999081]
0.9585709010084633  -  81.6212  =  -80.66262909899154
training  [-4.5365, 0.4088, 3.3315]  w:  [1.32192711 0.46361587 1.03999081]
-2.3426667901288556  -  28.9449  =  -31.287566790128857
training  [0.0543, 1.7973, -1.0172]  w:  [1.32192711 0.46361587 1.03999081]
-0.15284121496646907  -  47.9317  =  -48.08454121496647
training  [2.6143, -4.6344, 2.4982]  w:  [1.32192711 0.46361587 1.03999081]
3.9054377204377735  -  43.5132  =  -39.60776227956222
training  [1.3107, 3.092, 3.3522]  w:  [1.32192711 0.46361587 1.03999081]
6.652407310183202  -  96.6993  =  -90.04689268981679
training  [-4.1011, 2.4862, -1.7754]  w:  [1.32192711 0.46361587 1.03999081]
-6.115113192833414  -  10.0187  =  -16.133813192833415
training  [-4.1914, -3.7981, 0.5226]  w:  [1.32192711 0.46361587 1.03999081]
-6.758085511696544  -  1.4295  =  -8.187585511696543
training  [2.7724, 0.2505, 4.7913]  w:  [1.32192711 0.46361587 1.03999081]
8.763954461089838  -  96.7925  =  -88.02854553891017
training  [4.0513, -1.7417, 0.4931]  w:  [1.32192711 0.46361587 1.03999081]
5.0608630193117605  -  71.1234  =  -66.06253698068824
training  [0.3377, 0.4645, -1.6958]  w:  [1.32192711 0.46361587 1.03999081]
-1.1018520600743789  -  27.9534  =  -29.055252060074377
training  [-3.9085, -1.0112, 1.1947]  w:  [1.32192711 0.46361587 1.03999081]
-4.393083454683888  -  8.608  =  -13.001083454683888
training  [3.2581, -0.8491, -1.3936]  w:  [1.32192711 0.46361587 1.03999081]
2.4639832961187222  -  50.1924  =  -47.72841670388128
training  [-1.619, -3.1926, 2.5651]  w:  [1.32192711 0.46361587 1.03999081]
-0.9526595776552584  -  16.4754  =  -17.428059577655258
training  [-2.0603, -2.4461, -0.861]  w:  [1.32192711 0.46361587 1.03999081]
-4.753049280568066  -  3.9784  =  -8.731449280568066
training  [2.4631, -4.7946, -0.0765]  w:  [1.32192711 0.46361587 1.03999081]
0.9536267426277387  -  15.394  =  -14.440373257372261
training  [-4.8966, 4.2368, 1.9474]  w:  [1.32192711 0.46361587 1.03999081]
-2.483422490528142  -  53.5883  =  -56.07172249052814
training  [-4.5155, 1.537, 4.7273]  w:  [1.32192711 0.46361587 1.03999081]
-0.34023572999509355  -  59.2523  =  -59.59253572999509
training  [1.6792, 4.3261, -1.7225]  w:  [1.32192711 0.46361587 1.03999081]
2.4340444288227694  -  83.7729  =  -81.33885557117723
training  [1.0347, -3.3649, 3.378]  w:  [1.32192711 0.46361587 1.03999081]
3.3208659113248054  -  50.5979  =  -47.277034088675194
training  [0.261, 4.211, 2.3907]  w:  [1.32192711 0.46361587 1.03999081]
4.783615411866242  -  94.9375  =  -90.15388458813376
training  [2.2971, 2.9466, 4.5417]  w:  [1.32192711 0.46361587 1.03999081]
9.1260155331881  -  98.7784  =  -89.65238446681191
training  [2.0725, 0.7739, -4.6808]  w:  [1.32192711 0.46361587 1.03999081]
-1.769502726079058  -  19.5109  =  -21.280402726079057
training  [2.8138, -0.5996, -1.4313]  w:  [1.32192711 0.46361587 1.03999081]
1.9531155856772597  -  47.2879  =  -45.33478441432274
training  [-2.1202, -2.4239, 1.6265]  w:  [1.32192711 0.46361587 1.03999081]
-2.2349633037805745  -  12.3599  =  -14.594863303780574
training  [1.9253, 2.5195, -2.185]  w:  [1.32192711 0.46361587 1.03999081]
1.4408065195375688  -  65.2467  =  -63.80589348046244
training  [0.5667, -2.7133, -2.6962]  w:  [1.32192711 0.46361587 1.03999081]
-3.312816053546575  -  5.1106  =  -8.423416053546575
training  [-1.0348, -4.3581, 2.1113]  w:  [1.32192711 0.46361587 1.03999081]
-1.1926818796881768  -  10.5192  =  -11.711881879688177
training  [-4.3841, 2.6733, 1.2457]  w:  [1.32192711 0.46361587 1.03999081]
-3.2605598023575038  -  32.4639  =  -35.72445980235751
training  [2.8018, 1.712, 0.9061]  w:  [1.32192711 0.46361587 1.03999081]
5.439821412068992  -  90.1138  =  -84.673978587931
training  [-1.6242, 2.1521, 1.6044]  w:  [1.32192711 0.46361587 1.03999081]
0.5192349447959121  -  63.7879  =  -63.26866505520409
training  [1.0787, 1.4206, -4.5245]  w:  [1.32192711 0.46361587 1.03999081]
-2.620862945180755  -  18.0555  =  -20.676362945180752
training  [2.4125, -0.8095, -1.5122]  w:  [1.32192711 0.46361587 1.03999081]
1.2411780096099196  -  38.8276  =  -37.58642199039008
training  [-3.9519, -1.0924, -0.4866]  w:  [1.32192711 0.46361587 1.03999081]
-6.236637247461021  -  3.6777  =  -9.914337247461022
training  [-3.7211, 3.1614, -2.591]  w:  [1.32192711 0.46361587 1.03999081]
-6.14796396287678  -  11.1518  =  -17.29976396287678
training  [0.4954, -1.8257, 2.1505]  w:  [1.32192711 0.46361587 1.03999081]
2.0449594414735404  -  47.7531  =  -45.708140558526466
training  [-0.1477, 3.1454, 3.5618]  w:  [1.32192711 0.46361587 1.03999081]
4.9672479728687025  -  94.1572  =  -89.1899520271313
training  [3.9048, 2.8907, -2.1849]  w:  [1.32192711 0.46361587 1.03999081]
4.229759443264134  -  85.8791  =  -81.64934055673586
training  [2.9896, 3.5226, 2.3105]  w:  [1.32192711 0.46361587 1.03999081]
7.988065301547515  -  98.038  =  -90.04993469845249
training  [2.3434, 0.0564, -3.6224]  w:  [1.32192711 0.46361587 1.03999081]
-0.6433107822720769  -  24.7629  =  -25.406210782272076
training  [-4.4867, 1.3566, 3.3672]  w:  [1.32192711 0.46361587 1.03999081]
-1.8002920312029778  -  40.5785  =  -42.37879203120298
training  [-4.2711, 4.5089, -3.614]  w:  [1.32192711 0.46361587 1.03999081]
-7.314212093614037  -  10.0825  =  -17.396712093614035
training  [-4.1147, -0.5604, 0.8821]  w:  [1.32192711 0.46361587 1.03999081]
-4.781767919958434  -  8.344  =  -13.125767919958435
training  [2.9835, -4.3998, -1.3384]  w:  [1.32192711 0.46361587 1.03999081]
0.5122287520942292  -  13.2692  =  -12.75697124790577
training  [4.4301, 3.6675, 3.0676]  w:  [1.32192711 0.46361587 1.03999081]
10.746856285122583  -  99.3834  =  -88.6365437148774
training  [1.8372, 1.3119, 0.0378]  w:  [1.32192711 0.46361587 1.03999081]
3.076173793673635  -  74.9026  =  -71.82642620632637
training  [-3.6792, -1.4493, -0.1041]  w:  [1.32192711 0.46361587 1.03999081]
-5.643815742017103  -  4.2442  =  -9.888015742017103
training  [2.2272, 4.97, 3.7705]  w:  [1.32192711 0.46361587 1.03999081]
9.169652257297571  -  99.3199  =  -90.15024774270243
training  [-3.8965, -2.7583, -1.4686]  w:  [1.32192711 0.46361587 1.03999081]
-7.957011130041009  -  1.0337  =  -8.990711130041008
training  [-3.8251, 1.5245, -0.5056]  w:  [1.32192711 0.46361587 1.03999081]
-4.875540357895395  -  12.9762  =  -17.851740357895395
training  [1.4072, 1.0499, 4.6353]  w:  [1.32192711 0.46361587 1.03999081]
7.167635525898337  -  95.4618  =  -88.29416447410166
training  [-1.7119, -1.1275, -4.577]  w:  [1.32192711 0.46361587 1.03999081]
-7.545771843451896  -  1.4655  =  -9.011271843451896
training  [1.5381, -3.5781, 4.7296]  w:  [1.32192711 0.46361587 1.03999081]
5.293132694446227  -  69.9473  =  -64.65416730555377
training  [2.4913, -4.7487, -3.1079]  w:  [1.32192711 0.46361587 1.03999081]
-2.140443084416409  -  3.9825  =  -6.122943084416409
training  [0.8319, -0.7889, 1.6712]  w:  [1.32192711 0.46361587 1.03999081]
2.471997248146633  -  58.8336  =  -56.36160275185336
training  [2.4003, -3.159, 0.8644]  w:  [1.32192711 0.46361587 1.03999081]
2.6074271816086902  -  39.0041  =  -36.39667281839131
training  [-2.6517, 2.2578, 1.7511]  w:  [1.32192711 0.46361587 1.03999081]
-0.637474312710995  -  54.4525  =  -55.08997431271099
training  [2.3496, -1.2964, -1.3898]  w:  [1.32192711 0.46361587 1.03999081]
1.0595891047219201  -  33.888  =  -32.828410895278076
training  [4.706, 3.4156, 1.2028]  w:  [1.32192711 0.46361587 1.03999081]
9.055416277073014  -  98.4665  =  -89.41108372292697
training  [3.6693, 2.3423, 3.1115]  w:  [1.32192711 0.46361587 1.03999081]
9.172405991478257  -  98.3069  =  -89.13449400852174
training  [-4.1377, 0.7103, -4.8074]  w:  [1.32192711 0.46361587 1.03999081]
-10.140083274127022  -  0.9782  =  -11.118283274127021
training  [-1.3356, -3.2314, -4.1613]  w:  [1.32192711 0.46361587 1.03999081]
-7.591407910757066  -  0.7659  =  -8.357307910757065
training  [-1.308, 4.5738, 4.748]  w:  [1.32192711 0.46361587 1.03999081]
5.329281946227251  -  97.0884  =  -91.75911805377274
training  [1.8503, -2.3468, 1.5135]  w:  [1.32192711 0.46361587 1.03999081]
2.9319741107806747  -  50.2125  =  -47.28052588921933
training  [0.9794, 4.2458, -2.6876]  w:  [1.32192711 0.46361587 1.03999081]
0.4680363526233693  -  68.3262  =  -67.85816364737663
training  [2.8936, -2.7623, -0.9651]  w:  [1.32192711 0.46361587 1.03999081]
1.540787053075542  -  28.5596  =  -27.018812946924456
training  [-1.3235, -1.2644, -3.7798]  w:  [1.32192711 0.46361587 1.03999081]
-6.266723692309819  -  2.4511  =  -8.71782369230982
training  [-2.9397, -4.125, -2.3156]  w:  [1.32192711 0.46361587 1.03999081]
-8.206687288975543  -  0.554  =  -8.760687288975543
training  [-4.1333, 1.4012, -2.4215]  w:  [1.32192711 0.46361587 1.03999081]
-7.3326405213893855  -  4.4072  =  -11.739840521389386
training  [2.7193, -3.1938, -1.6833]  w:  [1.32192711 0.46361587 1.03999081]
0.3634035125614343  -  17.0949  =  -16.731496487438566
training  [-2.9433, -4.5495, -3.4777]  w:  [1.32192711 0.46361587 1.03999081]
-9.616824480961872  -  0.2509  =  -9.867724480961872
training  [-1.1173, 2.2317, -1.5199]  w:  [1.32192711 0.46361587 1.03999081]
-2.0230196659255615  -  33.1206  =  -35.14361966592556
training  [0.5178, -1.5256, -3.7834]  w:  [1.32192711 0.46361587 1.03999081]
-3.9574997343433846  -  5.237  =  -9.194499734343385
training  [-2.7105, 1.6062, 3.8415]  w:  [1.32192711 0.46361587 1.03999081]
1.1567010635774335  -  70.4458  =  -69.28909893642258
training  [1.4194, -1.1613, -4.0572]  w:  [1.32192711 0.46361587 1.03999081]
-2.8815044753632053  -  8.3206  =  -11.202104475363207
training  [-0.1552, 1.2735, 4.3004]  w:  [1.32192711 0.46361587 1.03999081]
4.857628193565748  -  90.1085  =  -85.25087180643426
training  [-3.4815, -4.7835, -1.0098]  w:  [1.32192711 0.46361587 1.03999081]
-7.8701784456952915  -  0.5839  =  -8.454078445695291
training  [2.8193, 4.1057, -4.526]  w:  [1.32192711 0.46361587 1.03999081]
0.9233783567138012  -  66.8081  =  -65.8847216432862
training  [-3.9939, 3.0056, -1.5763]  w:  [1.32192711 0.46361587 1.03999081]
-5.5255383560900535  -  14.4018  =  -19.927338356090054
training  [-2.0593, 2.4585, 2.3597]  w:  [1.32192711 0.46361587 1.03999081]
0.8716214183902615  -  70.6698  =  -69.79817858160973
training  [-2.6263, 3.1311, 2.9468]  w:  [1.32192711 0.46361587 1.03999081]
1.044495381730739  -  77.309  =  -76.26450461826926
training  [0.3087, -1.1669, 0.4491]  w:  [1.32192711 0.46361587 1.03999081]
0.33414541862596253  -  33.0798  =  -32.74565458137403
training  [-4.085, 1.1728, 1.8622]  w:  [1.32192711 0.46361587 1.03999081]
-2.9196726750806214  -  26.4056  =  -29.325272675080623
training  [-0.9468, 0.7549, 3.9363]  w:  [1.32192711 0.46361587 1.03999081]
3.1920988514267465  -  79.7738  =  -76.58170114857325
training  [-3.9515, 0.3005, -4.4521]  w:  [1.32192711 0.46361587 1.03999081]
-9.714421493033797  -  1.0441  =  -10.758521493033797
training  [-3.8772, -2.2493, -1.9634]  w:  [1.32192711 0.46361587 1.03999081]
-8.2101049139989  -  1.0509  =  -9.261004913998901
training  [2.8443, -2.5137, -4.5381]  w:  [1.32192711 0.46361587 1.03999081]
-2.125016211592146  -  6.8897  =  -9.014716211592146
training  [-2.0843, -0.4836, -3.0452]  w:  [1.32192711 0.46361587 1.03999081]
-6.146477322017901  -  3.5346  =  -9.681077322017902
training  [1.0353, -2.7229, 2.2017]  w:  [1.32192711 0.46361587 1.03999081]
2.395959263811534  -  43.9562  =  -41.56024073618847
training  [4.6442, 3.0445, 2.2175]  w:  [1.32192711 0.46361587 1.03999081]
9.856952008456027  -  98.8492  =  -88.99224799154396
training  [-0.6752, 4.861, 3.778]  w:  [1.32192711 0.46361587 1.03999081]
5.290156813127522  -  97.017  =  -91.72684318687247
training  [1.9475, -4.7001, 0.8243]  w:  [1.32192711 0.46361587 1.03999081]
1.2526765447806363  -  18.7839  =  -17.53122345521936
training  [2.581, 0.3566, -4.2932]  w:  [1.32192711 0.46361587 1.03999081]
-0.8876692530664276  -  23.5455  =  -24.433169253066428
training  [-0.6736, -4.1292, 4.2274]  w:  [1.32192711 0.46361587 1.03999081]
1.5916444160743355  -  31.2667  =  -29.675055583925666
training  [1.555, 3.0209, 3.0037]  w:  [1.32192711 0.46361587 1.03999081]
6.579954218214063  -  96.4078  =  -89.82784578178592
training  [-3.9024, 4.8914, -2.1405]  w:  [1.32192711 0.46361587 1.03999081]
-5.117058041799689  -  25.4308  =  -30.547858041799692
training  [4.3376, -4.3305, 0.4366]  w:  [1.32192711 0.46361587 1.03999081]
4.180362518850268  -  43.0907  =  -38.91033748114973
training  [-3.1254, 4.394, 4.8478]  w:  [1.32192711 0.46361587 1.03999081]
2.947244565576468  -  92.8121  =  -89.86485543442353
training  [-2.3382, -4.8182, 2.1568]  w:  [1.32192711 0.46361587 1.03999081]
-3.0816717533991134  -  4.7434  =  -7.825071753399113
training  [2.9783, 1.8384, 3.3897]  w:  [1.32192711 0.46361587 1.03999081]
8.314663766797874  -  97.3486  =  -89.03393623320213
training  [-0.124, 2.8374, -0.6674]  w:  [1.32192711 0.46361587 1.03999081]
0.45745482761552003  -  62.785  =  -62.327545172384475
training  [2.6896, 0.3414, -0.2938]  w:  [1.32192711 0.46361587 1.03999081]
3.4081843133214007  -  70.4455  =  -67.0373156866786
training  [-1.0399, 3.8536, 0.6071]  w:  [1.32192711 0.46361587 1.03999081]
1.0432965157073262  -  77.0369  =  -75.99360348429268
training  [-2.2706, 3.99, -2.3091]  w:  [1.32192711 0.46361587 1.03999081]
-3.553183173894779  -  31.1134  =  -34.66658317389478
training  [-4.6277, 1.2594, 2.4902]  w:  [1.32192711 0.46361587 1.03999081]
-2.943819155778786  -  28.1093  =  -31.053119155778788
training  [1.7329, -3.6213, 0.0389]  w:  [1.32192711 0.46361587 1.03999081]
0.652331000335083  -  19.3919  =  -18.739568999664918
training  [-0.7044, -2.822, 1.4681]  w:  [1.32192711 0.46361587 1.03999081]
-0.7126789206271762  -  17.8122  =  -18.524878920627177
training  [-0.4826, -3.1786, -1.9225]  w:  [1.32192711 0.46361587 1.03999081]
-4.110993743497373  -  3.5851  =  -7.696093743497373
training  [1.0986, -4.5818, -3.6128]  w:  [1.32192711 0.46361587 1.03999081]
-4.429204843228373  -  1.7158  =  -6.145004843228373
training  [-4.406, -3.9306, -0.2443]  w:  [1.32192711 0.46361587 1.03999081]
-7.9007691235326565  -  0.8241  =  -8.724869123532656
training  [-1.8419, 1.1644, -1.3754]  w:  [1.32192711 0.46361587 1.03999081]
-3.325426591130708  -  17.8517  =  -21.17712659113071
training  [2.7272, 4.3966, 2.8811]  w:  [1.32192711 0.46361587 1.03999081]
8.639810649661852  -  98.904  =  -90.26418935033814
training  [1.9643, -1.4554, 2.803]  w:  [1.32192711 0.46361587 1.03999081]
4.837009132310326  -  76.0591  =  -71.22209086768967
training  [-3.7467, -0.8937, 1.6851]  w:  [1.32192711 0.46361587 1.03999081]
-3.6147092910795204  -  12.1571  =  -15.77180929107952
training  [-3.6985, 4.8435, -3.665]  w:  [1.32192711 0.46361587 1.03999081]
-6.455190292884318  -  14.6793  =  -21.134490292884315
256218.68307938543
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.20576445 0.47507232 1.34164291]
9.442440863839987  -  87.3174  =  -77.87495913616002
training  [-4.1793, -4.9218, 1.7664]  w:  [1.20576445 0.47507232 1.34164291]
-5.007584293718336  -  1.5257  =  -6.533284293718337
training  [-3.9429, -0.7689, 4.883]  w:  [1.20576445 0.47507232 1.34164291]
1.4317505565976472  -  39.7859  =  -38.35414944340235
training  [-3.5796, 1.5557, 2.6683]  w:  [1.20576445 0.47507232 1.34164291]
0.0028213511175749773  -  45.5674  =  -45.564578648882424
training  [-3.3354, 2.2292, -1.633]  w:  [1.20576445 0.47507232 1.34164291]
-5.153578404170666  -  13.3589  =  -18.512478404170665
training  [1.2096, 0.3121, 1.6238]  w:  [1.20576445 0.47507232 1.34164291]
3.785322508044594  -  74.5119  =  -70.7265774919554
training  [0.7371, -3.9118, -2.5583]  w:  [1.20576445 0.47507232 1.34164291]
-4.401943983470277  -  3.3358  =  -7.737743983470277
training  [-4.4792, 1.3177, -2.0449]  w:  [1.20576445 0.47507232 1.34164291]
-7.518382919825294  -  4.2974  =  -11.815782919825294
training  [4.312, -3.735, 1.8018]  w:  [1.20576445 0.47507232 1.34164291]
5.842233389181658  -  66.5833  =  -60.741066610818336
training  [2.2866, -3.657, 0.2785]  w:  [1.20576445 0.47507232 1.34164291]
1.3934090660699054  -  26.0005  =  -24.607090933930092
training  [2.3784, -4.0141, -0.8841]  w:  [1.20576445 0.47507232 1.34164291]
-0.22534412892675948  -  14.6809  =  -14.906244128926758
training  [-4.366, -3.5797, 1.0264]  w:  [1.20576445 0.47507232 1.34164291]
-5.58792170646943  -  1.8713  =  -7.45922170646943
training  [3.6044, -3.3175, 2.5052]  w:  [1.20576445 0.47507232 1.34164291]
6.131088779099265  -  71.0139  =  -64.88281122090075
training  [4.3441, -3.0375, 0.8353]  w:  [1.20576445 0.47507232 1.34164291]
4.915603501204361  -  63.8979  =  -58.98229649879564
training  [4.844, -1.8252, 0.5179]  w:  [1.20576445 0.47507232 1.34164291]
5.668457867163977  -  78.0461  =  -72.37764213283602
training  [3.5894, -1.8357, 0.8357]  w:  [1.20576445 0.47507232 1.34164291]
4.577091642493091  -  68.8838  =  -64.3067083575069
training  [2.8556, -2.8244, 0.1182]  w:  [1.20576445 0.47507232 1.34164291]
2.259968896095297  -  39.5252  =  -37.2652311039047
training  [0.1338, -2.4896, -4.1741]  w:  [1.20576445 0.47507232 1.34164291]
-6.621560433453867  -  2.2644  =  -8.885960433453867
training  [-3.224, 3.9292, 2.1957]  w:  [1.20576445 0.47507232 1.34164291]
0.9251149071106393  -  72.1211  =  -71.19598509288936
training  [-1.0141, 2.0322, 4.9616]  w:  [1.20576445 0.47507232 1.34164291]
6.399371696887281  -  92.3427  =  -85.94332830311271
training  [-3.6607, 0.5574, -1.4547]  w:  [1.20576445 0.47507232 1.34164291]
-6.10082455718374  -  5.8471  =  -11.94792455718374
training  [-4.6911, -3.1557, 4.7126]  w:  [1.20576445 0.47507232 1.34164291]
-0.8329209754763118  -  11.2337  =  -12.066620975476312
training  [4.3914, -2.8797, -1.5355]  w:  [1.20576445 0.47507232 1.34164291]
1.8668355642307897  -  37.475  =  -35.60816443576921
training  [-1.9869, -4.2265, 3.8654]  w:  [1.20576445 0.47507232 1.34164291]
0.7823599417724605  -  15.7889  =  -15.00654005822754
training  [-2.0447, 4.138, -0.4531]  w:  [1.20576445 0.47507232 1.34164291]
-1.1074757102334476  -  57.936  =  -59.043475710233444
training  [-1.6706, 2.0672, -0.8657]  w:  [1.20576445 0.47507232 1.34164291]
-2.193740856493732  -  32.4185  =  -34.612240856493734
training  [-0.3293, 0.5779, -2.8227]  w:  [1.20576445 0.47507232 1.34164291]
-3.909569377763582  -  14.3434  =  -18.252969377763584
training  [1.482, -1.8657, -3.7435]  w:  [1.20576445 0.47507232 1.34164291]
-4.121839741094645  -  7.1519  =  -11.273739741094644
training  [-4.7477, -3.338, -1.9109]  w:  [1.20576445 0.47507232 1.34164291]
-9.874144733402673  -  0.4077  =  -10.281844733402673
training  [3.4221, 1.225, 2.261]  w:  [1.20576445 0.47507232 1.34164291]
7.741664742295839  -  95.0454  =  -87.30373525770416
training  [0.5903, 4.8793, 2.8287]  w:  [1.20576445 0.47507232 1.34164291]
6.824888430974102  -  97.4647  =  -90.6398115690259
training  [3.541, -3.2957, 1.9379]  w:  [1.20576445 0.47507232 1.34164291]
5.303885867345892  -  64.3732  =  -59.06931413265411
training  [-1.5212, -2.4221, -4.902]  w:  [1.20576445 0.47507232 1.34164291]
-9.56161509329393  -  0.7227  =  -10.28431509329393
training  [-0.5397, -1.032, 3.4321]  w:  [1.20576445 0.47507232 1.34164291]
3.4636269161304547  -  60.5921  =  -57.12847308386955
training  [-4.4576, -4.2601, 4.2233]  w:  [1.20576445 0.47507232 1.34164291]
-1.7325107231569046  -  6.0247  =  -7.757210723156905
training  [-3.2289, 1.841, 2.7095]  w:  [1.20576445 0.47507232 1.34164291]
0.6164967656952474  -  54.0111  =  -53.39460323430475
training  [1.6281, -0.9761, -4.5734]  w:  [1.20576445 0.47507232 1.34164291]
-4.636482667209099  -  7.8658  =  -12.502282667209098
training  [-1.6917, 4.8284, -1.2181]  w:  [1.20576445 0.47507232 1.34164291]
-1.3802077528970562  -  61.2837  =  -62.66390775289706
training  [3.9849, -0.9782, 2.0434]  w:  [1.20576445 0.47507232 1.34164291]
7.081648139964177  -  88.3402  =  -81.25855186003582
training  [-3.8184, 1.2067, 2.2951]  w:  [1.20576445 0.47507232 1.34164291]
-0.9516165738378928  -  34.1122  =  -35.0638165738379
training  [4.8842, -3.4563, -2.7572]  w:  [1.20576445 0.47507232 1.34164291]
0.548024444041427  -  23.7819  =  -23.233875555958573
training  [0.3998, -1.1865, -2.3095]  w:  [1.20576445 0.47507232 1.34164291]
-3.1801329792893824  -  11.4246  =  -14.604732979289382
training  [2.0692, -3.3887, 1.7303]  w:  [1.20576445 0.47507232 1.34164291]
3.206534952905309  -  42.6881  =  -39.48156504709469
training  [4.9949, 2.5811, -0.2251]  w:  [1.20576445 0.47507232 1.34164291]
6.946878212755508  -  95.9901  =  -89.04322178724449
training  [-2.1215, 3.7111, 1.2372]  w:  [1.20576445 0.47507232 1.34164291]
0.8648922142813502  -  71.3692  =  -70.50430778571865
training  [-0.8548, -1.4922, -2.6356]  w:  [1.20576445 0.47507232 1.34164291]
-5.275624422217701  -  4.7821  =  -10.057724422217701
training  [-0.3516, 1.8554, -3.2288]  w:  [1.20576445 0.47507232 1.34164291]
-3.8743942193483116  -  20.3834  =  -24.257794219348312
training  [2.6396, -2.0585, 3.2964]  w:  [1.20576445 0.47507232 1.34164291]
6.627391157979476  -  80.826  =  -74.19860884202052
training  [3.182, 0.3063, 2.6692]  w:  [1.20576445 0.47507232 1.34164291]
7.563370390753622  -  92.9483  =  -85.38492960924638
training  [-3.9978, 3.3242, 4.3448]  w:  [1.20576445 0.47507232 1.34164291]
2.5880003944919454  -  79.1768  =  -76.58879960550806
training  [-3.2188, 0.9749, -3.9211]  w:  [1.20576445 0.47507232 1.34164291]
-8.678682621472962  -  2.7053  =  -11.383982621472962
training  [-1.4037, -1.6469, -3.1777]  w:  [1.20576445 0.47507232 1.34164291]
-6.738266838966179  -  2.6234  =  -9.36166683896618
training  [-4.433, -2.0077, -4.009]  w:  [1.20576445 0.47507232 1.34164291]
-11.677602937527872  -  0.3253  =  -12.002902937527873
training  [0.2189, -0.4741, -0.1024]  w:  [1.20576445 0.47507232 1.34164291]
-0.09867418297028993  -  33.6531  =  -33.751774182970294
training  [-1.6415, -0.7735, -3.0675]  w:  [1.20576445 0.47507232 1.34164291]
-6.4622204114162844  -  3.7641  =  -10.226320411416285
training  [-3.2433, -1.4039, 3.9589]  w:  [1.20576445 0.47507232 1.34164291]
0.733820231154942  -  30.0658  =  -29.33197976884506
training  [-2.9105, 0.5832, -4.0091]  w:  [1.20576445 0.47507232 1.34164291]
-8.611095845230894  -  2.4887  =  -11.099795845230894
training  [4.0515, 2.4255, -4.5583]  w:  [1.20576445 0.47507232 1.34164291]
-0.07816827658574343  -  61.2853  =  -61.36346827658574
training  [1.7539, -0.7567, 0.573]  w:  [1.20576445 0.47507232 1.34164291]
2.5240644335165663  -  57.0797  =  -54.55563556648344
training  [-0.3153, -0.7064, 2.725]  w:  [1.20576445 0.47507232 1.34164291]
2.940208306392246  -  58.7004  =  -55.76019169360776
training  [4.1213, -3.7513, -1.8806]  w:  [1.20576445 0.47507232 1.34164291]
0.6640845823591159  -  22.1789  =  -21.514815417640882
training  [-3.9599, -4.7557, -3.2102]  w:  [1.20576445 0.47507232 1.34164291]
-11.340950159665868  -  0.1558  =  -11.496750159665867
training  [2.4555, -2.0981, -1.6104]  w:  [1.20576445 0.47507232 1.34164291]
-0.19657636595127492  -  24.4796  =  -24.676176365951278
training  [2.3627, -1.8248, -2.8985]  w:  [1.20576445 0.47507232 1.34164291]
-1.9068042722837841  -  15.7052  =  -17.612004272283784
training  [0.6186, 1.5369, 0.1015]  w:  [1.20576445 0.47507232 1.34164291]
1.6122012964898043  -  65.2154  =  -63.603198703510195
training  [-3.1581, 4.5694, 4.0636]  w:  [1.20576445 0.47507232 1.34164291]
3.8147708739711073  -  90.3564  =  -86.54162912602888
training  [0.9721, 4.3573, 1.2892]  w:  [1.20576445 0.47507232 1.34164291]
4.971802288976807  -  94.3178  =  -89.3459977110232
training  [-2.0006, -0.4211, -3.9847]  w:  [1.20576445 0.47507232 1.34164291]
-7.958349815882359  -  2.4051  =  -10.363449815882358
training  [-3.6588, -2.5952, -1.0915]  w:  [1.20576445 0.47507232 1.34164291]
-7.108961901544463  -  1.5176  =  -8.626561901544463
training  [-2.874, 2.639, -4.4538]  w:  [1.20576445 0.47507232 1.34164291]
-8.187060365358708  -  5.497  =  -13.684060365358707
training  [3.9494, 2.5933, 0.0128]  w:  [1.20576445 0.47507232 1.34164291]
6.011224208327812  -  94.1462  =  -88.13497579167218
training  [-4.2855, 2.4065, -0.6828]  w:  [1.20576445 0.47507232 1.34164291]
-4.940115795698553  -  14.4193  =  -19.359415795698553
training  [-2.5751, 2.4369, 4.9756]  w:  [1.20576445 0.47507232 1.34164291]
4.728218156368323  -  87.1991  =  -82.47088184363167
training  [-4.4625, -3.9408, 3.116]  w:  [1.20576445 0.47507232 1.34164291]
-3.0723295694578816  -  4.1344  =  -7.206729569457882
training  [-0.5828, 1.8156, -0.1435]  w:  [1.20576445 0.47507232 1.34164291]
-0.03270397291295518  -  51.1166  =  -51.14930397291295
training  [-4.8672, -0.3674, 3.9445]  w:  [1.20576445 0.47507232 1.34164291]
-0.7511278591885624  -  24.1396  =  -24.890727859188566
training  [3.9719, -2.8784, -3.6245]  w:  [1.20576445 0.47507232 1.34164291]
-1.4410570656800443  -  14.6104  =  -16.051457065680044
training  [-3.0334, -4.0148, -1.1]  w:  [1.20576445 0.47507232 1.34164291]
-7.040693445714169  -  1.021  =  -8.06169344571417
training  [-4.0663, 3.2357, 4.2736]  w:  [1.20576445 0.47507232 1.34164291]
2.367836653954045  -  77.2328  =  -74.86496334604595
training  [-1.9263, -3.2499, 4.1749]  w:  [1.20576445 0.47507232 1.34164291]
1.7346233771421735  -  26.8814  =  -25.146776622857825
training  [-0.4394, -3.3643, 2.1357]  w:  [1.20576445 0.47507232 1.34164291]
0.7372480480580283  -  20.85  =  -20.112751951941974
training  [-3.9833, 1.6599, 1.1834]  w:  [1.20576445 0.47507232 1.34164291]
-2.426648777412167  -  25.5397  =  -27.966348777412165
training  [4.9539, 3.9439, -1.5671]  w:  [1.20576445 0.47507232 1.34164291]
5.744385646711506  -  95.9509  =  -90.2065143532885
training  [-1.6791, 0.1656, 4.3603]  w:  [1.20576445 0.47507232 1.34164291]
3.904038459604825  -  71.5733  =  -67.66926154039518
training  [-2.0265, 2.027, -3.7523]  w:  [1.20576445 0.47507232 1.34164291]
-6.514756752565929  -  8.503  =  -15.01775675256593
training  [-4.3795, -3.4641, 2.3059]  w:  [1.20576445 0.47507232 1.34164291]
-3.8326490645234483  -  3.6654  =  -7.498049064523448
training  [-2.0176, 4.5346, 1.4648]  w:  [1.20576445 0.47507232 1.34164291]
1.6867511237621806  -  81.6212  =  -79.93444887623782
training  [-4.5365, 0.4088, 3.3315]  w:  [1.20576445 0.47507232 1.34164291]
-0.8060575218164798  -  28.9449  =  -29.75095752181648
training  [0.0543, 1.7973, -1.0172]  w:  [1.20576445 0.47507232 1.34164291]
-0.44539867325173155  -  47.9317  =  -48.37709867325173
training  [2.6143, -4.6344, 2.4982]  w:  [1.20576445 0.47507232 1.34164291]
4.302247154269143  -  43.5132  =  -39.21095284573086
training  [1.3107, 3.092, 3.3522]  w:  [1.20576445 0.47507232 1.34164291]
7.5467744445080935  -  96.6993  =  -89.1525255554919
training  [-4.1011, 2.4862, -1.7754]  w:  [1.20576445 0.47507232 1.34164291]
-6.1457886087177105  -  10.0187  =  -16.16448860871771
training  [-4.1914, -3.7981, 0.5226]  w:  [1.20576445 0.47507232 1.34164291]
-6.157070725570008  -  1.4295  =  -7.586570725570008
training  [2.7724, 0.2505, 4.7913]  w:  [1.20576445 0.47507232 1.34164291]
9.89008065212941  -  96.7925  =  -86.90241934787059
training  [4.0513, -1.7417, 0.4931]  w:  [1.20576445 0.47507232 1.34164291]
4.719044180662998  -  71.1234  =  -66.40435581933701
training  [0.3377, 0.4645, -1.6958]  w:  [1.20576445 0.47507232 1.34164291]
-1.6473002956508513  -  27.9534  =  -29.60070029565085
training  [-3.9085, -1.0112, 1.1947]  w:  [1.20576445 0.47507232 1.34164291]
-3.5902627099003412  -  8.608  =  -12.198262709900341
training  [3.2581, -0.8491, -1.3936]  w:  [1.20576445 0.47507232 1.34164291]
1.6554036957019307  -  50.1924  =  -48.53699630429807
training  [-1.619, -3.1926, 2.5651]  w:  [1.20576445 0.47507232 1.34164291]
-0.027400317085695125  -  16.4754  =  -16.502800317085697
training  [-2.0603, -2.4461, -0.861]  w:  [1.20576445 0.47507232 1.34164291]
-4.801465451161836  -  3.9784  =  -8.779865451161836
training  [2.4631, -4.7946, -0.0765]  w:  [1.20576445 0.47507232 1.34164291]
0.5895009861742543  -  15.394  =  -14.804499013825746
training  [-4.8966, 4.2368, 1.9474]  w:  [1.20576445 0.47507232 1.34164291]
-1.2786444036506963  -  53.5883  =  -54.86694440365069
training  [-4.5155, 1.537, 4.7273]  w:  [1.20576445 0.47507232 1.34164291]
1.6279052969190353  -  59.2523  =  -57.62439470308097
training  [1.6792, 4.3261, -1.7225]  w:  [1.20576445 0.47507232 1.34164291]
1.7689501285641858  -  83.7729  =  -82.00394987143582
training  [1.0347, -3.3649, 3.378]  w:  [1.20576445 0.47507232 1.34164291]
4.181103369051172  -  50.5979  =  -46.41679663094883
training  [0.261, 4.211, 2.3907]  w:  [1.20576445 0.47507232 1.34164291]
5.522699770310513  -  94.9375  =  -89.41480022968949
training  [2.2971, 2.9466, 4.5417]  w:  [1.20576445 0.47507232 1.34164291]
10.26294922443023  -  98.7784  =  -88.51545077556978
training  [2.0725, 0.7739, -4.6808]  w:  [1.20576445 0.47507232 1.34164291]
-3.413356830164716  -  19.5109  =  -22.924256830164715
training  [2.8138, -0.5996, -1.4313]  w:  [1.20576445 0.47507232 1.34164291]
1.1876331562049705  -  47.2879  =  -46.10026684379503
training  [-2.1202, -2.4239, 1.6265]  w:  [1.20576445 0.47507232 1.34164291]
-1.5258074009432834  -  12.3599  =  -13.885707400943282
training  [1.9253, 2.5195, -2.185]  w:  [1.20576445 0.47507232 1.34164291]
0.5869132586661623  -  65.2467  =  -64.65978674133385
training  [0.5667, -2.7133, -2.6962]  w:  [1.20576445 0.47507232 1.34164291]
-4.2230446257199885  -  5.1106  =  -9.333644625719987
training  [-1.0348, -4.3581, 2.1113]  w:  [1.20576445 0.47507232 1.34164291]
-0.48552706699006887  -  10.5192  =  -11.004727066990068
training  [-4.3841, 2.6733, 1.2457]  w:  [1.20576445 0.47507232 1.34164291]
-2.3448965258578665  -  32.4639  =  -34.80879652585787
training  [2.8018, 1.712, 0.9061]  w:  [1.20576445 0.47507232 1.34164291]
5.40729729628887  -  90.1138  =  -84.70650270371112
training  [-1.6242, 2.1521, 1.6044]  w:  [1.20576445 0.47507232 1.34164291]
1.2165324029456868  -  63.7879  =  -62.57136759705431
training  [1.0787, 1.4206, -4.5245]  w:  [1.20576445 0.47507232 1.34164291]
-4.094717485673647  -  18.0555  =  -22.150217485673647
training  [2.4125, -0.8095, -1.5122]  w:  [1.20576445 0.47507232 1.34164291]
0.49550328992622195  -  38.8276  =  -38.33209671007378
training  [-3.9519, -1.0924, -0.4866]  w:  [1.20576445 0.47507232 1.34164291]
-5.936872982019911  -  3.6777  =  -9.614572982019912
training  [-3.7211, 3.1614, -2.591]  w:  [1.20576445 0.47507232 1.34164291]
-6.461073241641921  -  11.1518  =  -17.61287324164192
training  [0.4954, -1.8257, 2.1505]  w:  [1.20576445 0.47507232 1.34164291]
2.615199247083029  -  47.7531  =  -45.13790075291698
training  [-0.1477, 3.1454, 3.5618]  w:  [1.20576445 0.47507232 1.34164291]
6.094864783121677  -  94.1572  =  -88.06233521687832
training  [3.9048, 2.8907, -2.1849]  w:  [1.20576445 0.47507232 1.34164291]
3.1502050017983514  -  85.8791  =  -82.72889499820164
training  [2.9896, 3.5226, 2.3105]  w:  [1.20576445 0.47507232 1.34164291]
8.378109106957314  -  98.038  =  -89.65989089304269
training  [2.3434, 0.0564, -3.6224]  w:  [1.20576445 0.47507232 1.34164291]
-2.007584776308919  -  24.7629  =  -26.77048477630892
training  [-4.4867, 1.3566, 3.3672]  w:  [1.20576445 0.47507232 1.34164291]
-0.2478402537925959  -  40.5785  =  -40.826340253792594
training  [-4.2711, 4.5089, -3.614]  w:  [1.20576445 0.47507232 1.34164291]
-7.856584432483011  -  10.0825  =  -17.93908443248301
training  [-4.1147, -0.5604, 0.8821]  w:  [1.20576445 0.47507232 1.34164291]
-4.044126310587883  -  8.344  =  -12.388126310587882
training  [2.9835, -4.3998, -1.3384]  w:  [1.20576445 0.47507232 1.34164291]
-0.28847982680741335  -  13.2692  =  -13.557679826807412
training  [4.4301, 3.6675, 3.0676]  w:  [1.20576445 0.47507232 1.34164291]
11.199608625863583  -  99.3834  =  -88.1837913741364
training  [1.8372, 1.3119, 0.0378]  w:  [1.20576445 0.47507232 1.34164291]
2.8891919322305673  -  74.9026  =  -72.01340806776943
training  [-3.6792, -1.4493, -0.1041]  w:  [1.20576445 0.47507232 1.34164291]
-5.26443591494313  -  4.2442  =  -9.508635914943131
training  [2.2272, 4.97, 3.7705]  w:  [1.20576445 0.47507232 1.34164291]
10.105252613684668  -  99.3199  =  -89.21464738631533
training  [-3.8965, -2.7583, -1.4686]  w:  [1.20576445 0.47507232 1.34164291]
-7.978989948350437  -  1.0337  =  -9.012689948350436
training  [-3.8251, 1.5245, -0.5056]  w:  [1.20576445 0.47507232 1.34164291]
-4.566256506207837  -  12.9762  =  -17.542456506207838
training  [1.4072, 1.0499, 4.6353]  w:  [1.20576445 0.47507232 1.34164291]
8.414447542223508  -  95.4618  =  -87.04735245777648
training  [-1.7119, -1.1275, -4.577]  w:  [1.20576445 0.47507232 1.34164291]
-8.740491801379413  -  1.4655  =  -10.205991801379414
training  [1.5381, -3.5781, 4.7296]  w:  [1.20576445 0.47507232 1.34164291]
6.500164330672108  -  69.9473  =  -63.44713566932789
training  [2.4913, -4.7487, -3.1079]  w:  [1.20576445 0.47507232 1.34164291]
-3.4217469501083175  -  3.9825  =  -7.404246950108318
training  [0.8319, -0.7889, 1.6712]  w:  [1.20576445 0.47507232 1.34164291]
2.870444522193001  -  58.8336  =  -55.96315547780699
training  [2.4003, -3.159, 0.8644]  w:  [1.20576445 0.47507232 1.34164291]
2.553159080665541  -  39.0041  =  -36.45094091933446
training  [-2.6517, 2.2578, 1.7511]  w:  [1.20576445 0.47507232 1.34164291]
0.22464358745934554  -  54.4525  =  -54.22785641254065
training  [2.3496, -1.2964, -1.3898]  w:  [1.20576445 0.47507232 1.34164291]
0.3525650844943431  -  33.888  =  -33.535434915505654
training  [4.706, 3.4156, 1.2028]  w:  [1.20576445 0.47507232 1.34164291]
8.910712624266235  -  98.4665  =  -89.55578737573376
training  [3.6693, 2.3423, 3.1115]  w:  [1.20576445 0.47507232 1.34164291]
9.711595313695248  -  98.3069  =  -88.59530468630476
training  [-4.1377, 0.7103, -4.8074]  w:  [1.20576445 0.47507232 1.34164291]
-11.101461822839632  -  0.9782  =  -12.07966182283963
training  [-1.3356, -3.2314, -4.1613]  w:  [1.20576445 0.47507232 1.34164291]
-8.72854633842536  -  0.7659  =  -9.49444633842536
training  [-1.308, 4.5738, 4.748]  w:  [1.20576445 0.47507232 1.34164291]
6.9658664118259495  -  97.0884  =  -90.12253358817404
training  [1.8503, -2.3468, 1.5135]  w:  [1.20576445 0.47507232 1.34164291]
3.146702783659082  -  50.2125  =  -47.06579721634092
training  [0.9794, 4.2458, -2.6876]  w:  [1.20576445 0.47507232 1.34164291]
-0.40781171365843427  -  68.3262  =  -68.73401171365843
training  [2.8936, -2.7623, -0.9651]  w:  [1.20576445 0.47507232 1.34164291]
0.8818881734701767  -  28.5596  =  -27.677711826529823
training  [-1.3235, -1.2644, -3.7798]  w:  [1.20576445 0.47507232 1.34164291]
-7.267652562190709  -  2.4511  =  -9.718752562190708
training  [-2.9397, -4.125, -2.3156]  w:  [1.20576445 0.47507232 1.34164291]
-8.610967406195137  -  0.554  =  -9.164967406195137
training  [-4.1333, 1.4012, -2.4215]  w:  [1.20576445 0.47507232 1.34164291]
-7.566903176378251  -  4.4072  =  -11.97410317637825
training  [2.7193, -3.1938, -1.6833]  w:  [1.20576445 0.47507232 1.34164291]
-0.49683821435536535  -  17.0949  =  -17.591738214355363
training  [-2.9433, -4.5495, -3.4777]  w:  [1.20576445 0.47507232 1.34164291]
-10.376099582952788  -  0.2509  =  -10.626999582952788
training  [-1.1173, 2.2317, -1.5199]  w:  [1.20576445 0.47507232 1.34164291]
-2.326144779067228  -  33.1206  =  -35.44674477906723
training  [0.5178, -1.5256, -3.7834]  w:  [1.20576445 0.47507232 1.34164291]
-5.17639728132438  -  5.237  =  -10.41339728132438
training  [-2.7105, 1.6062, 3.8415]  w:  [1.20576445 0.47507232 1.34164291]
2.6487578492028026  -  70.4458  =  -67.7970421507972
training  [1.4194, -1.1613, -4.0572]  w:  [1.20576445 0.47507232 1.34164291]
-4.28355303288  -  8.3206  =  -12.604153032880001
training  [-0.1552, 1.2735, 4.3004]  w:  [1.20576445 0.47507232 1.34164291]
6.187471123178163  -  90.1085  =  -83.92102887682185
training  [-3.4815, -4.7835, -1.0098]  w:  [1.20576445 0.47507232 1.34164291]
-7.8251684000191  -  0.5839  =  -8.4090684000191
training  [2.8193, 4.1057, -4.526]  w:  [1.20576445 0.47507232 1.34164291]
-0.7223596537335899  -  66.8081  =  -67.53045965373359
training  [-3.9939, 3.0056, -1.5763]  w:  [1.20576445 0.47507232 1.34164291]
-5.502656992458229  -  14.4018  =  -19.90445699245823
training  [-2.0593, 2.4585, 2.3597]  w:  [1.20576445 0.47507232 1.34164291]
1.8508093381005783  -  70.6698  =  -68.81899066189942
training  [-2.6263, 3.1311, 2.9468]  w:  [1.20576445 0.47507232 1.34164291]
2.274353088965508  -  77.309  =  -75.03464691103449
training  [0.3087, -1.1669, 0.4491]  w:  [1.20576445 0.47507232 1.34164291]
0.42038942453097583  -  33.0798  =  -32.659410575469025
training  [-4.085, 1.1728, 1.8622]  w:  [1.20576445 0.47507232 1.34164291]
-1.8699755436579046  -  26.4056  =  -28.275575543657904
training  [-0.9468, 0.7549, 3.9363]  w:  [1.20576445 0.47507232 1.34164291]
4.49812329378706  -  79.7738  =  -75.27567670621293
training  [-3.9515, 0.3005, -4.4521]  w:  [1.20576445 0.47507232 1.34164291]
-10.594947393806288  -  1.0441  =  -11.639047393806289
training  [-3.8772, -2.2493, -1.9634]  w:  [1.20576445 0.47507232 1.34164291]
-8.377751793919417  -  1.0509  =  -9.428651793919418
training  [2.8443, -2.5137, -4.5381]  w:  [1.20576445 0.47507232 1.34164291]
-3.853143147600153  -  6.8897  =  -10.742843147600153
training  [-2.0843, -0.4836, -3.0452]  w:  [1.20576445 0.47507232 1.34164291]
-6.828490807918783  -  3.5346  =  -10.363090807918784
training  [1.0353, -2.7229, 2.2017]  w:  [1.20576445 0.47507232 1.34164291]
2.9086487047362297  -  43.9562  =  -41.04755129526377
training  [4.6442, 3.0445, 2.2175]  w:  [1.20576445 0.47507232 1.34164291]
10.021262102002071  -  98.8492  =  -88.82793789799793
training  [-0.6752, 4.861, 3.778]  w:  [1.20576445 0.47507232 1.34164291]
6.563921306502396  -  97.017  =  -90.4530786934976
training  [1.9475, -4.7001, 0.8243]  w:  [1.20576445 0.47507232 1.34164291]
1.2212551011856556  -  18.7839  =  -17.562644898814344
training  [2.581, 0.3566, -4.2932]  w:  [1.20576445 0.47507232 1.34164291]
-2.4784524946633733  -  23.5455  =  -26.023952494663373
training  [-0.6736, -4.1292, 4.2274]  w:  [1.20576445 0.47507232 1.34164291]
2.897789666630942  -  31.2667  =  -28.368910333369058
training  [1.555, 3.0209, 3.0037]  w:  [1.20576445 0.47507232 1.34164291]
7.3400025044221024  -  96.4078  =  -89.06779749557789
training  [-3.9024, 4.8914, -2.1405]  w:  [1.20576445 0.47507232 1.34164291]
-5.253393089987379  -  25.4308  =  -30.68419308998738
training  [4.3376, -4.3305, 0.4366]  w:  [1.20576445 0.47507232 1.34164291]
3.7585844926690597  -  43.0907  =  -39.33211550733094
training  [-3.1254, 4.394, 4.8478]  w:  [1.20576445 0.47507232 1.34164291]
4.822988055331278  -  92.8121  =  -87.98911194466872
training  [-2.3382, -4.8182, 2.1568]  w:  [1.20576445 0.47507232 1.34164291]
-2.2146564767788703  -  4.7434  =  -6.958056476778871
training  [2.9783, 1.8384, 3.3897]  w:  [1.20576445 0.47507232 1.34164291]
9.012268191569802  -  97.3486  =  -88.3363318084302
training  [-0.124, 2.8374, -0.6674]  w:  [1.20576445 0.47507232 1.34164291]
0.3030429361433179  -  62.785  =  -62.481957063856676
training  [2.6896, 0.3414, -0.2938]  w:  [1.20576445 0.47507232 1.34164291]
3.0110390745591484  -  70.4455  =  -67.43446092544085
training  [-1.0399, 3.8536, 0.6071]  w:  [1.20576445 0.47507232 1.34164291]
1.39137565480467  -  77.0369  =  -75.64552434519533
training  [-2.2706, 3.99, -2.3091]  w:  [1.20576445 0.47507232 1.34164291]
-3.9402578421059453  -  31.1134  =  -35.05365784210594
training  [-4.6277, 1.2594, 2.4902]  w:  [1.20576445 0.47507232 1.34164291]
-1.6406509021311542  -  28.1093  =  -29.749950902131154
training  [1.7329, -3.6213, 0.0389]  w:  [1.20576445 0.47507232 1.34164291]
0.42127972987272544  -  19.3919  =  -18.970620270127274
training  [-0.7044, -2.822, 1.4681]  w:  [1.20576445 0.47507232 1.34164291]
-0.2203286175689796  -  17.8122  =  -18.032528617568982
training  [-0.4826, -3.1786, -1.9225]  w:  [1.20576445 0.47507232 1.34164291]
-4.671275298181882  -  3.5851  =  -8.256375298181883
training  [1.0986, -4.5818, -3.6128]  w:  [1.20576445 0.47507232 1.34164291]
-5.69912103673777  -  1.7158  =  -7.41492103673777
training  [-4.406, -3.9306, -0.2443]  w:  [1.20576445 0.47507232 1.34164291]
-7.507680806295145  -  0.8241  =  -8.331780806295145
training  [-1.8419, 1.1644, -1.3754]  w:  [1.20576445 0.47507232 1.34164291]
-3.513018989698189  -  17.8517  =  -21.36471898969819
training  [2.7272, 4.3966, 2.8811]  w:  [1.20576445 0.47507232 1.34164291]
9.242471167537218  -  98.904  =  -89.66152883246278
training  [1.9643, -1.4554, 2.803]  w:  [1.20576445 0.47507232 1.34164291]
5.437687929483186  -  76.0591  =  -70.62141207051681
training  [-3.7467, -0.8937, 1.6851]  w:  [1.20576445 0.47507232 1.34164291]
-2.6814073413261696  -  12.1571  =  -14.838507341326169
training  [-3.6985, 4.8435, -3.665]  w:  [1.20576445 0.47507232 1.34164291]
-7.075628296695349  -  14.6793  =  -21.754928296695347
253241.7126459223
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.26849841 0.47658218 1.2446695 ]
9.285196045021651  -  87.3174  =  -78.03220395497836
training  [-4.1793, -4.9218, 1.7664]  w:  [1.26849841 0.47658218 1.2446695 ]
-5.448493334713875  -  1.5257  =  -6.974193334713876
training  [-3.9429, -0.7689, 4.883]  w:  [1.26849841 0.47658218 1.2446695 ]
0.7097147895070401  -  39.7859  =  -39.07618521049296
training  [-3.5796, 1.5557, 2.6683]  w:  [1.26849841 0.47658218 1.2446695 ]
-0.47814636279150813  -  45.5674  =  -46.045546362791505
training  [-3.3354, 2.2292, -1.633]  w:  [1.26849841 0.47658218 1.2446695 ]
-5.201097896078284  -  13.3589  =  -18.559997896078286
training  [1.2096, 0.3121, 1.6238]  w:  [1.26849841 0.47658218 1.2446695 ]
3.70421131118264  -  74.5119  =  -70.80768868881735
training  [0.7371, -3.9118, -2.5583]  w:  [1.26849841 0.47658218 1.2446695 ]
-4.113521978492437  -  3.3358  =  -7.449321978492437
training  [-4.4792, 1.3177, -2.0449]  w:  [1.26849841 0.47658218 1.2446695 ]
-7.599090396360433  -  4.2974  =  -11.896490396360432
training  [4.312, -3.735, 1.8018]  w:  [1.26849841 0.47658218 1.2446695 ]
5.932376209812578  -  66.5833  =  -60.65092379018742
training  [2.2866, -3.657, 0.2785]  w:  [1.26849841 0.47658218 1.2446695 ]
1.5043278913306224  -  26.0005  =  -24.496172108669377
training  [2.3784, -4.0141, -0.8841]  w:  [1.26849841 0.47658218 1.2446695 ]
0.003535783523859193  -  14.6809  =  -14.67736421647614
training  [-4.366, -3.5797, 1.0264]  w:  [1.26849841 0.47658218 1.2446695 ]
-5.966756480827987  -  1.8713  =  -7.838056480827987
training  [3.6044, -3.3175, 2.5052]  w:  [1.26849841 0.47658218 1.2446695 ]
6.10926032605589  -  71.0139  =  -64.90463967394412
training  [4.3441, -3.0375, 0.8353]  w:  [1.26849841 0.47658218 1.2446695 ]
5.102538000877994  -  63.8979  =  -58.79536199912201
training  [4.844, -1.8252, 0.5179]  w:  [1.26849841 0.47658218 1.2446695 ]
5.919362826531615  -  78.0461  =  -72.12673717346838
training  [3.5894, -1.8357, 0.8357]  w:  [1.26849841 0.47658218 1.2446695 ]
4.718456581851861  -  68.8838  =  -64.16534341814813
training  [2.8556, -2.8244, 0.1182]  w:  [1.26849841 0.47658218 1.2446695 ]
2.4233852834231704  -  39.5252  =  -37.101814716576826
training  [0.1338, -2.4896, -4.1741]  w:  [1.26849841 0.47658218 1.2446695 ]
-6.212148880402704  -  2.2644  =  -8.476548880402703
training  [-3.224, 3.9292, 2.1957]  w:  [1.26849841 0.47658218 1.2446695 ]
0.5158686596613293  -  72.1211  =  -71.60523134033866
training  [-1.0141, 2.0322, 4.9616]  w:  [1.26849841 0.47658218 1.2446695 ]
5.857678280582644  -  92.3427  =  -86.48502171941735
training  [-3.6607, 0.5574, -1.4547]  w:  [1.26849841 0.47658218 1.2446695 ]
-6.188565938438128  -  5.8471  =  -12.035665938438129
training  [-4.6911, -3.1557, 4.7126]  w:  [1.26849841 0.47658218 1.2446695 ]
-1.588973741646341  -  11.2337  =  -12.82267374164634
training  [4.3914, -2.8797, -1.5355]  w:  [1.26849841 0.47658218 1.2446695 ]
2.2868801814331823  -  37.475  =  -35.18811981856682
training  [-1.9869, -4.2265, 3.8654]  w:  [1.26849841 0.47658218 1.2446695 ]
0.2764914488910444  -  15.7889  =  -15.512408551108955
training  [-2.0447, 4.138, -0.4531]  w:  [1.26849841 0.47658218 1.2446695 ]
-1.185561395248583  -  57.936  =  -59.121561395248584
training  [-1.6706, 2.0672, -0.8657]  w:  [1.26849841 0.47658218 1.2446695 ]
-2.2114731512365693  -  32.4185  =  -34.62997315123657
training  [-0.3293, 0.5779, -2.8227]  w:  [1.26849841 0.47658218 1.2446695 ]
-3.6556282957997808  -  14.3434  =  -17.999028295799782
training  [1.482, -1.8657, -3.7435]  w:  [1.26849841 0.47658218 1.2446695 ]
-3.6686650202652755  -  7.1519  =  -10.820565020265276
training  [-4.7477, -3.338, -1.9109]  w:  [1.26849841 0.47658218 1.2446695 ]
-9.991720146249548  -  0.4077  =  -10.399420146249549
training  [3.4221, 1.225, 2.261]  w:  [1.26849841 0.47658218 1.2446695 ]
7.738939312591891  -  95.0454  =  -87.3064606874081
training  [0.5903, 4.8793, 2.8287]  w:  [1.26849841 0.47658218 1.2446695 ]
6.594978653155453  -  97.4647  =  -90.86972134684454
training  [3.541, -3.2957, 1.9379]  w:  [1.26849841 0.47658218 1.2446695 ]
5.333126008583451  -  64.3732  =  -59.04007399141655
training  [-1.5212, -2.4221, -4.902]  w:  [1.26849841 0.47658218 1.2446695 ]
-9.185339378107583  -  0.7227  =  -9.908039378107583
training  [-0.5397, -1.032, 3.4321]  w:  [1.26849841 0.47658218 1.2446695 ]
3.0953888103782523  -  60.5921  =  -57.49671118962175
training  [-4.4576, -4.2601, 4.2233]  w:  [1.26849841 0.47658218 1.2446695 ]
-2.42813350869769  -  6.0247  =  -8.45283350869769
training  [-3.2289, 1.841, 2.7095]  w:  [1.26849841 0.47658218 1.2446695 ]
0.15396530694454658  -  54.0111  =  -53.85713469305545
training  [1.6281, -0.9761, -4.5734]  w:  [1.26849841 0.47658218 1.2446695 ]
-4.092321120360844  -  7.8658  =  -11.958121120360843
training  [-1.6917, 4.8284, -1.2181]  w:  [1.26849841 0.47658218 1.2446695 ]
-1.3609212939126634  -  61.2837  =  -62.644621293912664
training  [3.9849, -0.9782, 2.0434]  w:  [1.26849841 0.47658218 1.2446695 ]
7.132004279019336  -  88.3402  =  -81.20819572098065
training  [-3.8184, 1.2067, 2.2951]  w:  [1.26849841 0.47658218 1.2446695 ]
-1.411901621089401  -  34.1122  =  -35.5241016210894
training  [4.8842, -3.4563, -2.7572]  w:  [1.26849841 0.47658218 1.2446695 ]
1.1165861789298073  -  23.7819  =  -22.665313821070193
training  [0.3998, -1.1865, -2.3095]  w:  [1.26849841 0.47658218 1.2446695 ]
-2.932883311170795  -  11.4246  =  -14.357483311170794
training  [2.0692, -3.3887, 1.7303]  w:  [1.26849841 0.47658218 1.2446695 ]
3.1634345227439633  -  42.6881  =  -39.524665477256036
training  [4.9949, 2.5811, -0.2251]  w:  [1.26849841 0.47658218 1.2446695 ]
7.285953840588129  -  95.9901  =  -88.70414615941186
training  [-2.1215, 3.7111, 1.2372]  w:  [1.26849841 0.47658218 1.2446695 ]
0.6174298594799019  -  71.3692  =  -70.75177014052011
training  [-0.8548, -1.4922, -2.6356]  w:  [1.26849841 0.47658218 1.2446695 ]
-5.07591930853458  -  4.7821  =  -9.85801930853458
training  [-0.3516, 1.8554, -3.2288]  w:  [1.26849841 0.47658218 1.2446695 ]
-3.580542364974438  -  20.3834  =  -23.96394236497444
training  [2.6396, -2.0585, 3.2964]  w:  [1.26849841 0.47658218 1.2446695 ]
6.470212536680485  -  80.826  =  -74.3557874633195
training  [3.182, 0.3063, 2.6692]  w:  [1.26849841 0.47658218 1.2446695 ]
7.50461089105147  -  92.9483  =  -85.44368910894853
training  [-3.9978, 3.3242, 4.3448]  w:  [1.26849841 0.47658218 1.2446695 ]
1.9208916082848964  -  79.1768  =  -77.25590839171511
training  [-3.2188, 0.9749, -3.9211]  w:  [1.26849841 0.47658218 1.2446695 ]
-8.498896300080713  -  2.7053  =  -11.204196300080712
training  [-1.4037, -1.6469, -3.1777]  w:  [1.26849841 0.47658218 1.2446695 ]
-6.520660684931071  -  2.6234  =  -9.144060684931071
training  [-4.433, -2.0077, -4.009]  w:  [1.26849841 0.47658218 1.2446695 ]
-11.569967515437428  -  0.3253  =  -11.895267515437428
training  [0.2189, -0.4741, -0.1024]  w:  [1.26849841 0.47658218 1.2446695 ]
-0.0757274662765117  -  33.6531  =  -33.72882746627651
training  [-1.6415, -0.7735, -3.0675]  w:  [1.26849841 0.47658218 1.2446695 ]
-6.26890015311983  -  3.7641  =  -10.03300015311983
training  [-3.2433, -1.4039, 3.9589]  w:  [1.26849841 0.47658218 1.2446695 ]
0.1443275028443347  -  30.0658  =  -29.921472497155666
training  [-2.9105, 0.5832, -4.0091]  w:  [1.26849841 0.47658218 1.2446695 ]
-8.404026396593292  -  2.4887  =  -10.892726396593291
training  [4.0515, 2.4255, -4.5583]  w:  [1.26849841 0.47658218 1.2446695 ]
0.6216943599742581  -  61.2853  =  -60.66360564002574
training  [1.7539, -0.7567, 0.573]  w:  [1.26849841 0.47658218 1.2446695 ]
2.5773852474210717  -  57.0797  =  -54.50231475257893
training  [-0.3153, -0.7064, 2.725]  w:  [1.26849841 0.47658218 1.2446695 ]
2.6551092028287355  -  58.7004  =  -56.04529079717127
training  [4.1213, -3.7513, -1.8806]  w:  [1.26849841 0.47658218 1.2446695 ]
1.0993342904027923  -  22.1789  =  -21.079565709597205
training  [-3.9599, -4.7557, -3.2102]  w:  [1.26849841 0.47658218 1.2446695 ]
-11.28524674156251  -  0.1558  =  -11.44104674156251
training  [2.4555, -2.0981, -1.6104]  w:  [1.26849841 0.47658218 1.2446695 ]
0.11046500055295105  -  24.4796  =  -24.36913499944705
training  [2.3627, -1.8248, -2.8985]  w:  [1.26849841 0.47658218 1.2446695 ]
-1.4802605314866866  -  15.7052  =  -17.185460531486687
training  [0.6186, 1.5369, 0.1015]  w:  [1.26849841 0.47658218 1.2446695 ]
1.6434862166122692  -  65.2154  =  -63.571913783387735
training  [-3.1581, 4.5694, 4.0636]  w:  [1.26849841 0.47658218 1.2446695 ]
3.2294887820496774  -  90.3564  =  -87.12691121795032
training  [0.9721, 4.3573, 1.2892]  w:  [1.26849841 0.47658218 1.2446695 ]
4.914346745857297  -  94.3178  =  -89.4034532541427
training  [-2.0006, -0.4211, -3.9847]  w:  [1.26849841 0.47658218 1.2446695 ]
-7.698081241255852  -  2.4051  =  -10.103181241255852
training  [-3.6588, -2.5952, -1.0915]  w:  [1.26849841 0.47658218 1.2446695 ]
-7.236564798587754  -  1.5176  =  -8.754164798587754
training  [-2.874, 2.639, -4.4538]  w:  [1.26849841 0.47658218 1.2446695 ]
-7.931473094005703  -  5.497  =  -13.428473094005703
training  [3.9494, 2.5933, 0.0128]  w:  [1.26849841 0.47658218 1.2446695 ]
6.26165993463829  -  94.1462  =  -87.8845400653617
training  [-4.2855, 2.4065, -0.6828]  w:  [1.26849841 0.47658218 1.2446695 ]
-5.139115248504936  -  14.4193  =  -19.558415248504936
training  [-2.5751, 2.4369, 4.9756]  w:  [1.26849841 0.47658218 1.2446695 ]
4.087850448630875  -  87.1991  =  -83.11124955136913
training  [-4.4625, -3.9408, 3.116]  w:  [1.26849841 0.47658218 1.2446695 ]
-3.660399004254222  -  4.1344  =  -7.794799004254222
training  [-0.5828, 1.8156, -0.1435]  w:  [1.26849841 0.47658218 1.2446695 ]
-0.05260834447908741  -  51.1166  =  -51.16920834447909
training  [-4.8672, -0.3674, 3.9445]  w:  [1.26849841 0.47658218 1.2446695 ]
-1.4395328733603305  -  24.1396  =  -25.579132873360333
training  [3.9719, -2.8784, -3.6245]  w:  [1.26849841 0.47658218 1.2446695 ]
-0.84474993831093  -  14.6104  =  -15.45514993831093
training  [-3.0334, -4.0148, -1.1]  w:  [1.26849841 0.47658218 1.2446695 ]
-7.13038164461852  -  1.021  =  -8.151381644618521
training  [-4.0663, 3.2357, 4.2736]  w:  [1.26849841 0.47658218 1.2446695 ]
1.7032014760672087  -  77.2328  =  -75.52959852393279
training  [-1.9263, -3.2499, 4.1749]  w:  [1.26849841 0.47658218 1.2446695 ]
1.2040178180464354  -  26.8814  =  -25.677382181953565
training  [-0.4394, -3.3643, 2.1357]  w:  [1.26849841 0.47658218 1.2446695 ]
0.4974970432970225  -  20.85  =  -20.352502956702978
training  [-3.9833, 1.6599, 1.1834]  w:  [1.26849841 0.47658218 1.2446695 ]
-2.788789053955149  -  25.5397  =  -28.32848905395515
training  [4.9539, 3.9439, -1.5671]  w:  [1.26849841 0.47658218 1.2446695 ]
6.213085121528414  -  95.9509  =  -89.7378148784716
training  [-1.6791, 0.1656, 4.3603]  w:  [1.26849841 0.47658218 1.2446695 ]
3.376118775750958  -  71.5733  =  -68.19718122424905
training  [-2.0265, 2.027, -3.7523]  w:  [1.26849841 0.47658218 1.2446695 ]
-6.274953329589502  -  8.503  =  -14.777953329589502
training  [-4.3795, -3.4641, 2.3059]  w:  [1.26849841 0.47658218 1.2446695 ]
-4.336233678470588  -  3.6654  =  -8.001633678470588
training  [-2.0176, 4.5346, 1.4648]  w:  [1.26849841 0.47658218 1.2446695 ]
1.4249790458949163  -  81.6212  =  -80.19622095410509
training  [-4.5365, 0.4088, 3.3315]  w:  [1.26849841 0.47658218 1.2446695 ]
-1.4130997709913453  -  28.9449  =  -30.357999770991345
training  [0.0543, 1.7973, -1.0172]  w:  [1.26849841 0.47658218 1.2446695 ]
-0.3406372099396906  -  47.9317  =  -48.27233720993969
training  [2.6143, -4.6344, 2.4982]  w:  [1.26849841 0.47658218 1.2446695 ]
4.216996298675118  -  43.5132  =  -39.29620370132488
training  [1.3107, 3.092, 3.3522]  w:  [1.26849841 0.47658218 1.2446695 ]
7.308594065695143  -  96.6993  =  -89.39070593430485
training  [-4.1011, 2.4862, -1.7754]  w:  [1.26849841 0.47658218 1.2446695 ]
-6.2271464436621375  -  10.0187  =  -16.24584644366214
training  [-4.1914, -3.7981, 0.5226]  w:  [1.26849841 0.47658218 1.2446695 ]
-6.476426703000139  -  1.4295  =  -7.905926703000139
training  [2.7724, 0.2505, 4.7913]  w:  [1.26849841 0.47658218 1.2446695 ]
9.599753814188288  -  96.7925  =  -87.19274618581171
training  [4.0513, -1.7417, 0.4931]  w:  [1.26849841 0.47658218 1.2446695 ]
4.922750948016711  -  71.1234  =  -66.20064905198329
training  [0.3377, 0.4645, -1.6958]  w:  [1.26849841 0.47658218 1.2446695 ]
-1.4609662129763359  -  27.9534  =  -29.414366212976333
training  [-3.9085, -1.0112, 1.1947]  w:  [1.26849841 0.47658218 1.2446695 ]
-3.952839260750446  -  8.608  =  -12.560839260750447
training  [3.2581, -0.8491, -1.3936]  w:  [1.26849841 0.47658218 1.2446695 ]
1.9936573090290082  -  50.1924  =  -48.19874269097099
training  [-1.619, -3.1926, 2.5651]  w:  [1.26849841 0.47658218 1.2446695 ]
-0.3825334315529014  -  16.4754  =  -16.8579334315529
training  [-2.0603, -2.4461, -0.861]  w:  [1.26849841 0.47658218 1.2446695 ]
-4.850915372899459  -  3.9784  =  -8.82931537289946
training  [2.4631, -4.7946, -0.0765]  w:  [1.26849841 0.47658218 1.2446695 ]
0.7442003013230546  -  15.394  =  -14.649799698676945
training  [-4.8966, 4.2368, 1.9474]  w:  [1.26849841 0.47658218 1.2446695 ]
-1.768276534872347  -  53.5883  =  -55.356576534872346
training  [-4.5155, 1.537, 4.7273]  w:  [1.26849841 0.47658218 1.2446695 ]
0.8885284021966848  -  59.2523  =  -58.363771597803314
training  [1.6792, 4.3261, -1.7225]  w:  [1.26849841 0.47658218 1.2446695 ]
2.0478614578374947  -  83.7729  =  -81.72503854216251
training  [1.0347, -3.3649, 3.378]  w:  [1.26849841 0.47658218 1.2446695 ]
3.9133575201490096  -  50.5979  =  -46.68454247985099
training  [0.261, 4.211, 2.3907]  w:  [1.26849841 0.47658218 1.2446695 ]
5.313597016082371  -  94.9375  =  -89.62390298391763
training  [2.2971, 2.9466, 4.5417]  w:  [1.26849841 0.47658218 1.2446695 ]
9.97108022077883  -  98.7784  =  -88.80731977922117
training  [2.0725, 0.7739, -4.6808]  w:  [1.26849841 0.47658218 1.2446695 ]
-2.8282591237050507  -  19.5109  =  -22.339159123705052
training  [2.8138, -0.5996, -1.4313]  w:  [1.26849841 0.47658218 1.2446695 ]
1.5020466799993286  -  47.2879  =  -45.78585332000067
training  [-2.1202, -2.4239, 1.6265]  w:  [1.26849841 0.47658218 1.2446695 ]
-1.8202029103219952  -  12.3599  =  -14.180102910321995
training  [1.9253, 2.5195, -2.185]  w:  [1.26849841 0.47658218 1.2446695 ]
0.9233859087400687  -  65.2467  =  -64.32331409125993
training  [0.5667, -2.7133, -2.6962]  w:  [1.26849841 0.47658218 1.2446695 ]
-3.9301302924623203  -  5.1106  =  -9.040730292462321
training  [-1.0348, -4.3581, 2.1113]  w:  [1.26849841 0.47658218 1.2446695 ]
-0.761764211156799  -  10.5192  =  -11.2809642111568
training  [-4.3841, 2.6733, 1.2457]  w:  [1.26849841 0.47658218 1.2446695 ]
-2.736691926843577  -  32.4639  =  -35.20059192684358
training  [2.8018, 1.712, 0.9061]  w:  [1.26849841 0.47658218 1.2446695 ]
5.497782559606952  -  90.1138  =  -84.61601744039305
training  [-1.6242, 2.1521, 1.6044]  w:  [1.26849841 0.47658218 1.2446695 ]
0.9623051450350364  -  63.7879  =  -62.82559485496496
training  [1.0787, 1.4206, -4.5245]  w:  [1.26849841 0.47658218 1.2446695 ]
-3.586145302328151  -  18.0555  =  -21.64164530232815
training  [2.4125, -0.8095, -1.5122]  w:  [1.26849841 0.47658218 1.2446695 ]
0.7922699077222151  -  38.8276  =  -38.03533009227778
training  [-3.9519, -1.0924, -0.4866]  w:  [1.26849841 0.47658218 1.2446695 ]
-6.1392534024929235  -  3.6777  =  -9.816953402492924
training  [-3.7211, 3.1614, -2.591]  w:  [1.26849841 0.47658218 1.2446695 ]
-6.438481211384223  -  11.1518  =  -17.590281211384223
training  [0.4954, -1.8257, 2.1505]  w:  [1.26849841 0.47658218 1.2446695 ]
2.434979799592667  -  47.7531  =  -45.318120200407336
training  [-0.1477, 3.1454, 3.5618]  w:  [1.26849841 0.47658218 1.2446695 ]
5.744948206544528  -  94.1572  =  -88.41225179345548
training  [3.9048, 2.8907, -2.1849]  w:  [1.26849841 0.47658218 1.2446695 ]
3.611410274826671  -  85.8791  =  -82.26768972517333
training  [2.9896, 3.5226, 2.3105]  w:  [1.26849841 0.47658218 1.2446695 ]
8.346920102269346  -  98.038  =  -89.69107989773065
training  [2.3434, 0.0564, -3.6224]  w:  [1.26849841 0.47658218 1.2446695 ]
-1.5092124137618153  -  24.7629  =  -26.272112413761814
training  [-4.4867, 1.3566, 3.3672]  w:  [1.26849841 0.47658218 1.2446695 ]
-0.8537892616891787  -  40.5785  =  -41.43228926168918
training  [-4.2711, 4.5089, -3.614]  w:  [1.26849841 0.47658218 1.2446695 ]
-7.767257754519502  -  10.0825  =  -17.8497577545195
training  [-4.1147, -0.5604, 0.8821]  w:  [1.26849841 0.47658218 1.2446695 ]
-4.388644073862819  -  8.344  =  -12.732644073862819
training  [2.9835, -4.3998, -1.3384]  w:  [1.26849841 0.47658218 1.2446695 ]
0.02183306748003755  -  13.2692  =  -13.247366932519963
training  [4.4301, 3.6675, 3.0676]  w:  [1.26849841 0.47658218 1.2446695 ]
11.18558809577825  -  99.3834  =  -88.19781190422174
training  [1.8372, 1.3119, 0.0378]  w:  [1.26849841 0.47658218 1.2446695 ]
3.002761937114066  -  74.9026  =  -71.89983806288595
training  [-3.6792, -1.4493, -0.1041]  w:  [1.26849841 0.47658218 1.2446695 ]
-5.48733998057546  -  4.2442  =  -9.73153998057546
training  [2.2272, 4.97, 3.7705]  w:  [1.26849841 0.47658218 1.2446695 ]
9.886839437150904  -  99.3199  =  -89.4330605628491
training  [-3.8965, -2.7583, -1.4686]  w:  [1.26849841 0.47658218 1.2446695 ]
-8.085182293002953  -  1.0337  =  -9.118882293002953
training  [-3.8251, 1.5245, -0.5056]  w:  [1.26849841 0.47658218 1.2446695 ]
-4.754888626190617  -  12.9762  =  -17.73108862619062
training  [1.4072, 1.0499, 4.6353]  w:  [1.26849841 0.47658218 1.2446695 ]
8.054811139640009  -  95.4618  =  -87.40698886035999
training  [-1.7119, -1.1275, -4.577]  w:  [1.26849841 0.47658218 1.2446695 ]
-8.405741148818091  -  1.4655  =  -9.871241148818092
training  [1.5381, -3.5781, 4.7296]  w:  [1.26849841 0.47658218 1.2446695 ]
6.132607600148264  -  69.9473  =  -63.81469239985174
training  [2.4913, -4.7487, -3.1079]  w:  [1.26849841 0.47658218 1.2446695 ]
-2.9712440580474584  -  3.9825  =  -6.953744058047459
training  [0.8319, -0.7889, 1.6712]  w:  [1.26849841 0.47658218 1.2446695 ]
2.7593798208128706  -  58.8336  =  -56.07422017918713
training  [2.4003, -3.159, 0.8644]  w:  [1.26849841 0.47658218 1.2446695 ]
2.615145947023823  -  39.0041  =  -36.388954052976175
training  [-2.6517, 2.2578, 1.7511]  w:  [1.26849841 0.47658218 1.2446695 ]
-0.10810921487688319  -  54.4525  =  -54.560609214876884
training  [2.3496, -1.2964, -1.3898]  w:  [1.26849841 0.47658218 1.2446695 ]
0.6327810433602832  -  33.888  =  -33.255218956639716
training  [4.706, 3.4156, 1.2028]  w:  [1.26849841 0.47658218 1.2446695 ]
9.094456063415192  -  98.4665  =  -89.3720439365848
training  [3.6693, 2.3423, 3.1115]  w:  [1.26849841 0.47658218 1.2446695 ]
9.643588798651487  -  98.3069  =  -88.6633112013485
training  [-4.1377, 0.7103, -4.8074]  w:  [1.26849841 0.47658218 1.2446695 ]
-10.893773711511308  -  0.9782  =  -11.871973711511307
training  [-1.3356, -3.2314, -4.1613]  w:  [1.26849841 0.47658218 1.2446695 ]
-8.413677327682366  -  0.7659  =  -9.179577327682367
training  [-1.308, 4.5738, 4.748]  w:  [1.26849841 0.47658218 1.2446695 ]
6.430286453874955  -  97.0884  =  -90.65811354612504
training  [1.8503, -2.3468, 1.5135]  w:  [1.26849841 0.47658218 1.2446695 ]
3.112466843240738  -  50.2125  =  -47.10003315675926
training  [0.9794, 4.2458, -2.6876]  w:  [1.26849841 0.47658218 1.2446695 ]
-0.07933381454336708  -  68.3262  =  -68.40553381454336
training  [2.8936, -2.7623, -0.9651]  w:  [1.26849841 0.47658218 1.2446695 ]
1.1528335016790674  -  28.5596  =  -27.406766498320934
training  [-1.3235, -1.2644, -3.7798]  w:  [1.26849841 0.47658218 1.2446695 ]
-6.986049938794001  -  2.4511  =  -9.437149938794
training  [-2.9397, -4.125, -2.3156]  w:  [1.26849841 0.47658218 1.2446695 ]
-8.577062949698306  -  0.554  =  -9.131062949698306
training  [-4.1333, 1.4012, -2.4215]  w:  [1.26849841 0.47658218 1.2446695 ]
-7.589264721328583  -  4.4072  =  -11.996464721328582
training  [2.7193, -3.1938, -1.6833]  w:  [1.26849841 0.47658218 1.2446695 ]
-0.16783261812143602  -  17.0949  =  -17.262732618121436
training  [-2.9433, -4.5495, -3.4777]  w:  [1.26849841 0.47658218 1.2446695 ]
-10.230369109432058  -  0.2509  =  -10.481269109432057
training  [-1.1173, 2.2317, -1.5199]  w:  [1.26849841 0.47658218 1.2446695 ]
-2.2454780049125524  -  33.1206  =  -35.36607800491255
training  [0.5178, -1.5256, -3.7834]  w:  [1.26849841 0.47658218 1.2446695 ]
-4.7793278983423795  -  5.237  =  -10.016327898342379
training  [-2.7105, 1.6062, 3.8415]  w:  [1.26849841 0.47658218 1.2446695 ]
2.108619264795612  -  70.4458  =  -68.3371807352044
training  [1.4194, -1.1613, -4.0572]  w:  [1.26849841 0.47658218 1.2446695 ]
-3.8028213586184676  -  8.3206  =  -12.123421358618469
training  [-0.1552, 1.2735, 4.3004]  w:  [1.26849841 0.47658218 1.2446695 ]
5.762633187498229  -  90.1085  =  -84.34586681250178
training  [-3.4815, -4.7835, -1.0098]  w:  [1.26849841 0.47658218 1.2446695 ]
-7.952875310568532  -  0.5839  =  -8.536775310568533
training  [2.8193, 4.1057, -4.526]  w:  [1.26849841 0.47658218 1.2446695 ]
-0.10039317732929298  -  66.8081  =  -66.90849317732929
training  [-3.9939, 3.0056, -1.5763]  w:  [1.26849841 0.47658218 1.2446695 ]
-5.595812933413974  -  14.4018  =  -19.997612933413976
training  [-2.0593, 2.4585, 2.3597]  w:  [1.26849841 0.47658218 1.2446695 ]
1.4965051443885755  -  70.6698  =  -69.17329485561142
training  [-2.6263, 3.1311, 2.9468]  w:  [1.26849841 0.47658218 1.2446695 ]
1.8285611865041291  -  77.309  =  -75.48043881349587
training  [0.3087, -1.1669, 0.4491]  w:  [1.26849841 0.47658218 1.2446695 ]
0.3944427901800543  -  33.0798  =  -32.68535720981995
training  [-4.085, 1.1728, 1.8622]  w:  [1.26849841 0.47658218 1.2446695 ]
-2.305056860533649  -  26.4056  =  -28.71065686053365
training  [-0.9468, 0.7549, 3.9363]  w:  [1.26849841 0.47658218 1.2446695 ]
4.058150165537003  -  79.7738  =  -75.715649834463
training  [-3.9515, 0.3005, -4.4521]  w:  [1.26849841 0.47658218 1.2446695 ]
-10.410651609417727  -  1.0441  =  -11.454751609417727
training  [-3.8772, -2.2493, -1.9634]  w:  [1.26849841 0.47658218 1.2446695 ]
-8.433982416564719  -  1.0509  =  -9.48488241656472
training  [2.8443, -2.5137, -4.5381]  w:  [1.26849841 0.47658218 1.2446695 ]
-3.2384292806029418  -  6.8897  =  -10.128129280602941
training  [-2.0843, -0.4836, -3.0452]  w:  [1.26849841 0.47658218 1.2446695 ]
-6.66467394431144  -  3.5346  =  -10.19927394431144
training  [1.0353, -2.7229, 2.2017]  w:  [1.26849841 0.47658218 1.2446695 ]
2.75597963852402  -  43.9562  =  -41.200220361475985
training  [4.6442, 3.0445, 2.2175]  w:  [1.26849841 0.47658218 1.2446695 ]
10.102169362381819  -  98.8492  =  -88.74703063761818
training  [-0.6752, 4.861, 3.778]  w:  [1.26849841 0.47658218 1.2446695 ]
6.162537227044432  -  97.017  =  -90.85446277295557
training  [1.9475, -4.7001, 0.8243]  w:  [1.26849841 0.47658218 1.2446695 ]
1.2563978285974546  -  18.7839  =  -17.527502171402546
training  [2.581, 0.3566, -4.2932]  w:  [1.26849841 0.47658218 1.2446695 ]
-1.8996715266272708  -  23.5455  =  -25.44517152662727
training  [-0.6736, -4.1292, 4.2274]  w:  [1.26849841 0.47658218 1.2446695 ]
2.439352212227576  -  31.2667  =  -28.827347787772425
training  [1.555, 3.0209, 3.0037]  w:  [1.26849841 0.47658218 1.2446695 ]
7.150835911175354  -  96.4078  =  -89.25696408882465
training  [-3.9024, 4.8914, -2.1405]  w:  [1.26849841 0.47658218 1.2446695 ]
-5.283249194379976  -  25.4308  =  -30.714049194379978
training  [4.3376, -4.3305, 0.4366]  w:  [1.26849841 0.47658218 1.2446695 ]
3.981822274881334  -  43.0907  =  -39.10887772511867
training  [-3.1254, 4.394, 4.8478]  w:  [1.26849841 0.47658218 1.2446695 ]
4.163445991620668  -  92.8121  =  -88.64865400837934
training  [-2.3382, -4.8182, 2.1568]  w:  [1.26849841 0.47658218 1.2446695 ]
-2.5777680309485422  -  4.7434  =  -7.3211680309485425
training  [2.9783, 1.8384, 3.3897]  w:  [1.26849841 0.47658218 1.2446695 ]
8.873173697180638  -  97.3486  =  -88.47542630281937
training  [-0.124, 2.8374, -0.6674]  w:  [1.26849841 0.47658218 1.2446695 ]
0.36426803925532536  -  62.785  =  -62.42073196074467
training  [2.6896, 0.3414, -0.2938]  w:  [1.26849841 0.47658218 1.2446695 ]
3.2087745680287827  -  70.4455  =  -67.23672543197121
training  [-1.0399, 3.8536, 0.6071]  w:  [1.26849841 0.47658218 1.2446695 ]
1.2730844409568327  -  77.0369  =  -75.76381555904317
training  [-2.2706, 3.99, -2.3091]  w:  [1.26849841 0.47658218 1.2446695 ]
-3.8527559480021383  -  31.1134  =  -34.96615594800214
training  [-4.6277, 1.2594, 2.4902]  w:  [1.26849841 0.47658218 1.2446695 ]
-2.1705464801293215  -  28.1093  =  -30.279846480129322
training  [1.7329, -3.6213, 0.0389]  w:  [1.26849841 0.47658218 1.2446695 ]
0.5207514942368635  -  19.3919  =  -18.871148505763138
training  [-0.7044, -2.822, 1.4681]  w:  [1.26849841 0.47658218 1.2446695 ]
-0.41114588104867456  -  17.8122  =  -18.223345881048676
training  [-0.4826, -3.1786, -1.9225]  w:  [1.26849841 0.47658218 1.2446695 ]
-4.519918561289133  -  3.5851  =  -8.105018561289134
training  [1.0986, -4.5818, -3.6128]  w:  [1.26849841 0.47658218 1.2446695 ]
-5.2867738558840625  -  1.7158  =  -7.002573855884062
training  [-4.406, -3.9306, -0.2443]  w:  [1.26849841 0.47658218 1.2446695 ]
-7.766330642522948  -  0.8241  =  -8.590430642522948
training  [-1.8419, 1.1644, -1.3754]  w:  [1.26849841 0.47658218 1.2446695 ]
-3.493433364121504  -  17.8517  =  -21.345133364121505
training  [2.7272, 4.3966, 2.8811]  w:  [1.26849841 0.47658218 1.2446695 ]
9.140807362528468  -  98.904  =  -89.76319263747153
training  [1.9643, -1.4554, 2.803]  w:  [1.26849841 0.47658218 1.2446695 ]
5.28690234034773  -  76.0591  =  -70.77219765965228
training  [-3.7467, -0.8937, 1.6851]  w:  [1.26849841 0.47658218 1.2446695 ]
-3.0812118877603836  -  12.1571  =  -15.238311887760384
training  [-3.6985, 4.8435, -3.665]  w:  [1.26849841 0.47658218 1.2446695 ]
-6.9449293154532725  -  14.6793  =  -21.62422931545327
254026.09533075633
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.23427745 0.44852429 1.25271449]
9.282134941991483  -  87.3174  =  -78.03526505800852
training  [-4.1793, -4.9218, 1.7664]  w:  [1.23427745 0.44852429 1.25271449]
-5.153167717568918  -  1.5257  =  -6.678867717568918
training  [-3.9429, -0.7689, 4.883]  w:  [1.23427745 0.44852429 1.25271449]
0.9055019466674636  -  39.7859  =  -38.880398053332534
training  [-3.5796, 1.5557, 2.6683]  w:  [1.23427745 0.44852429 1.25271449]
-0.3778322711544737  -  45.5674  =  -45.945232271154474
training  [-3.3354, 2.2292, -1.633]  w:  [1.23427745 0.44852429 1.25271449]
-5.162641428511516  -  13.3589  =  -18.521541428511515
training  [1.2096, 0.3121, 1.6238]  w:  [1.23427745 0.44852429 1.25271449]
3.667124217217321  -  74.5119  =  -70.84477578278268
training  [0.7371, -3.9118, -2.5583]  w:  [1.23427745 0.44852429 1.25271449]
-4.049570862286261  -  3.3358  =  -7.385370862286261
training  [-4.4792, 1.3177, -2.0449]  w:  [1.23427745 0.44852429 1.25271449]
-7.499230961222282  -  4.2974  =  -11.79663096122228
training  [4.312, -3.735, 1.8018]  w:  [1.23427745 0.44852429 1.25271449]
5.904107122753043  -  66.5833  =  -60.67919287724695
training  [2.2866, -3.657, 0.2785]  w:  [1.23427745 0.44852429 1.25271449]
1.5309264904080249  -  26.0005  =  -24.469573509591974
training  [2.3784, -4.0141, -0.8841]  w:  [1.23427745 0.44852429 1.25271449]
0.027659276658053233  -  14.6809  =  -14.653240723341947
training  [-4.366, -3.5797, 1.0264]  w:  [1.23427745 0.44852429 1.25271449]
-5.7086515927490815  -  1.8713  =  -7.579951592749081
training  [3.6044, -3.3175, 2.5052]  w:  [1.23427745 0.44852429 1.25271449]
6.09915065682182  -  71.0139  =  -64.91474934317819
training  [4.3441, -3.0375, 0.8353]  w:  [1.23427745 0.44852429 1.25271449]
5.045824568051155  -  63.8979  =  -58.85207543194885
training  [4.844, -1.8252, 0.5179]  w:  [1.23427745 0.44852429 1.25271449]
5.808974280480667  -  78.0461  =  -72.23712571951933
training  [3.5894, -1.8357, 0.8357]  w:  [1.23427745 0.44852429 1.25271449]
4.653852948305844  -  68.8838  =  -64.22994705169415
training  [2.8556, -2.8244, 0.1182]  w:  [1.23427745 0.44852429 1.25271449]
2.4058615489868833  -  39.5252  =  -37.119338451013114
training  [0.1338, -2.4896, -4.1741]  w:  [1.23427745 0.44852429 1.25271449]
-6.180455275140381  -  2.2644  =  -8.44485527514038
training  [-3.224, 3.9292, 2.1957]  w:  [1.23427745 0.44852429 1.25271449]
0.5336163179656066  -  72.1211  =  -71.58748368203439
training  [-1.0141, 2.0322, 4.9616]  w:  [1.23427745 0.44852429 1.25271449]
5.875278483568242  -  92.3427  =  -86.46742151643176
training  [-3.6607, 0.5574, -1.4547]  w:  [1.23427745 0.44852429 1.25271449]
-6.090635792385162  -  5.8471  =  -11.937735792385162
training  [-4.6911, -3.1557, 4.7126]  w:  [1.23427745 0.44852429 1.25271449]
-1.301984757325159  -  11.2337  =  -12.53568475732516
training  [4.3914, -2.8797, -1.5355]  w:  [1.23427745 0.44852429 1.25271449]
2.2050475209258114  -  37.475  =  -35.26995247907419
training  [-1.9869, -4.2265, 3.8654]  w:  [1.23427745 0.44852429 1.25271449]
0.49416880919873485  -  15.7889  =  -15.294731190801265
training  [-2.0447, 4.138, -0.4531]  w:  [1.23427745 0.44852429 1.25271449]
-1.235338542422511  -  57.936  =  -59.17133854242251
training  [-1.6706, 2.0672, -0.8657]  w:  [1.23427745 0.44852429 1.25271449]
-2.219269436519755  -  32.4185  =  -34.637769436519754
training  [-0.3293, 0.5779, -2.8227]  w:  [1.23427745 0.44852429 1.25271449]
-3.6832825588898506  -  14.3434  =  -18.026682558889853
training  [1.482, -1.8657, -3.7435]  w:  [1.23427745 0.44852429 1.25271449]
-3.6971492551561003  -  7.1519  =  -10.8490492551561
training  [-4.7477, -3.338, -1.9109]  w:  [1.23427745 0.44852429 1.25271449]
-9.750965235200498  -  0.4077  =  -10.158665235200498
training  [3.4221, 1.225, 2.261]  w:  [1.23427745 0.44852429 1.25271449]
7.605650570090134  -  95.0454  =  -87.43974942990987
training  [0.5903, 4.8793, 2.8287]  w:  [1.23427745 0.44852429 1.25271449]
6.460631995394445  -  97.4647  =  -91.00406800460554
training  [3.541, -3.2957, 1.9379]  w:  [1.23427745 0.44852429 1.25271449]
5.320010368032793  -  64.3732  =  -59.05318963196721
training  [-1.5212, -2.4221, -4.902]  w:  [1.23427745 0.44852429 1.25271449]
-9.104759942413038  -  0.7227  =  -9.827459942413038
training  [-0.5397, -1.032, 3.4321]  w:  [1.23427745 0.44852429 1.25271449]
3.170424782743007  -  60.5921  =  -57.421675217257
training  [-4.4576, -4.2601, 4.2233]  w:  [1.23427745 0.44852429 1.25271449]
-2.1220843919796177  -  6.0247  =  -8.146784391979619
training  [-3.2289, 1.841, 2.7095]  w:  [1.23427745 0.44852429 1.25271449]
0.23460464678849968  -  54.0111  =  -53.7764953532115
training  [1.6281, -0.9761, -4.5734]  w:  [1.23427745 0.44852429 1.25271449]
-4.157441866234439  -  7.8658  =  -12.02324186623444
training  [-1.6917, 4.8284, -1.2181]  w:  [1.23427745 0.44852429 1.25271449]
-1.448304016452814  -  61.2837  =  -62.73200401645282
training  [3.9849, -0.9782, 2.0434]  w:  [1.23427745 0.44852429 1.25271449]
7.039522540344571  -  88.3402  =  -81.30067745965542
training  [-3.8184, 1.2067, 2.2951]  w:  [1.23427745 0.44852429 1.25271449]
-1.2966257485846087  -  34.1122  =  -35.40882574858461
training  [4.8842, -3.4563, -2.7572]  w:  [1.23427745 0.44852429 1.25271449]
1.0242390583264358  -  23.7819  =  -22.757660941673564
training  [0.3998, -1.1865, -2.3095]  w:  [1.23427745 0.44852429 1.25271449]
-2.931854045418833  -  11.4246  =  -14.356454045418833
training  [2.0692, -3.3887, 1.7303]  w:  [1.23427745 0.44852429 1.25271449]
3.2016245289183196  -  42.6881  =  -39.486475471081675
training  [4.9949, 2.5811, -0.2251]  w:  [1.23427745 0.44852429 1.25271449]
7.040792447314623  -  95.9901  =  -88.94930755268537
training  [-2.1215, 3.7111, 1.2372]  w:  [1.23427745 0.44852429 1.25271449]
0.5958572268696611  -  71.3692  =  -70.77334277313035
training  [-0.8548, -1.4922, -2.6356]  w:  [1.23427745 0.44852429 1.25271449]
-5.026002604294728  -  4.7821  =  -9.808102604294728
training  [-0.3516, 1.8554, -3.2288]  w:  [1.23427745 0.44852429 1.25271449]
-3.646544523108046  -  20.3834  =  -24.02994452310805
training  [2.6396, -2.0585, 3.2964]  w:  [1.23427745 0.44852429 1.25271449]
6.464159549045596  -  80.826  =  -74.3618404509544
training  [3.182, 0.3063, 2.6692]  w:  [1.23427745 0.44852429 1.25271449]
7.408599345326067  -  92.9483  =  -85.53970065467394
training  [-3.9978, 3.3242, 4.3448]  w:  [1.23427745 0.44852429 1.25271449]
1.999383934216164  -  79.1768  =  -77.17741606578383
training  [-3.2188, 0.9749, -3.9211]  w:  [1.23427745 0.44852429 1.25271449]
-8.447644704828331  -  2.7053  =  -11.15294470482833
training  [-1.4037, -1.6469, -3.1777]  w:  [1.23427745 0.44852429 1.25271449]
-6.451980727302811  -  2.6234  =  -9.07538072730281
training  [-4.433, -2.0077, -4.009]  w:  [1.23427745 0.44852429 1.25271449]
-11.394186525906841  -  0.3253  =  -11.719486525906841
training  [0.2189, -0.4741, -0.1024]  w:  [1.23427745 0.44852429 1.25271449]
-0.07073999328853306  -  33.6531  =  -33.723839993288536
training  [-1.6415, -0.7735, -3.0675]  w:  [1.23427745 0.44852429 1.25271449]
-6.215701657374774  -  3.7641  =  -9.979801657374775
training  [-3.2433, -1.4039, 3.9589]  w:  [1.23427745 0.44852429 1.25271449]
0.3265560737170228  -  30.0658  =  -29.739243926282978
training  [-2.9105, 0.5832, -4.0091]  w:  [1.23427745 0.44852429 1.25271449]
-8.353042804165511  -  2.4887  =  -10.841742804165511
training  [4.0515, 2.4255, -4.5583]  w:  [1.23427745 0.44852429 1.25271449]
0.37832231065783795  -  61.2853  =  -60.90697768934216
training  [1.7539, -0.7567, 0.573]  w:  [1.23427745 0.44852429 1.25271449]
2.543206295324466  -  57.0797  =  -54.536493704675536
training  [-0.3153, -0.7064, 2.725]  w:  [1.23427745 0.44852429 1.25271449]
2.7076417375562336  -  58.7004  =  -55.99275826244377
training  [4.1213, -3.7513, -1.8806]  w:  [1.23427745 0.44852429 1.25271449]
1.0484236443368808  -  22.1789  =  -21.130476355663117
training  [-3.9599, -4.7557, -3.2102]  w:  [1.23427745 0.44852429 1.25271449]
-11.042126270815238  -  0.1558  =  -11.197926270815238
training  [2.4555, -2.0981, -1.6104]  w:  [1.23427745 0.44852429 1.25271449]
0.07234806951973294  -  24.4796  =  -24.407251930480268
training  [2.3627, -1.8248, -2.8985]  w:  [1.23427745 0.44852429 1.25271449]
-1.5332327197323967  -  15.7052  =  -17.238432719732398
training  [0.6186, 1.5369, 0.1015]  w:  [1.23427745 0.44852429 1.25271449]
1.5800115273419948  -  65.2154  =  -63.63538847265801
training  [-3.1581, 4.5694, 4.0636]  w:  [1.23427745 0.44852429 1.25271449]
3.2420458380969714  -  90.3564  =  -87.11435416190302
training  [0.9721, 4.3573, 1.2892]  w:  [1.23427745 0.44852429 1.25271449]
4.769195498107099  -  94.3178  =  -89.54860450189291
training  [-2.0006, -0.4211, -3.9847]  w:  [1.23427745 0.44852429 1.25271449]
-7.649860458158942  -  2.4051  =  -10.054960458158941
training  [-3.6588, -2.5952, -1.0915]  w:  [1.23427745 0.44852429 1.25271449]
-7.047322428699915  -  1.5176  =  -8.564922428699916
training  [-2.874, 2.639, -4.4538]  w:  [1.23427745 0.44852429 1.25271449]
-7.942997581422415  -  5.497  =  -13.439997581422414
training  [3.9494, 2.5933, 0.0128]  w:  [1.23427745 0.44852429 1.25271449]
6.053848144147397  -  94.1462  =  -88.0923518558526
training  [-4.2855, 2.4065, -0.6828]  w:  [1.23427745 0.44852429 1.25271449]
-5.065475774903694  -  14.4193  =  -19.484775774903696
training  [-2.5751, 2.4369, 4.9756]  w:  [1.23427745 0.44852429 1.25271449]
4.147627163075681  -  87.1991  =  -83.05147283692432
training  [-4.4625, -3.9408, 3.116]  w:  [1.23427745 0.44852429 1.25271449]
-3.372049297037768  -  4.1344  =  -7.5064492970377685
training  [-0.5828, 1.8156, -0.1435]  w:  [1.23427745 0.44852429 1.25271449]
-0.08476073344731322  -  51.1166  =  -51.20136073344731
training  [-4.8672, -0.3674, 3.9445]  w:  [1.23427745 0.44852429 1.25271449]
-1.2309307458472691  -  24.1396  =  -25.37053074584727
training  [3.9719, -2.8784, -3.6245]  w:  [1.23427745 0.44852429 1.25271449]
-0.9290693492917397  -  14.6104  =  -15.539469349291739
training  [-3.0334, -4.0148, -1.1]  w:  [1.23427745 0.44852429 1.25271449]
-6.9227784603169775  -  1.021  =  -7.943778460316977
training  [-4.0663, 3.2357, 4.2736]  w:  [1.23427745 0.44852429 1.25271449]
1.785948258063235  -  77.2328  =  -75.44685174193677
training  [-1.9263, -3.2499, 4.1749]  w:  [1.23427745 0.44852429 1.25271449]
1.394709974038295  -  26.8814  =  -25.486690025961703
training  [-0.4394, -3.3643, 2.1357]  w:  [1.23427745 0.44852429 1.25271449]
0.6241105590010929  -  20.85  =  -20.22588944099891
training  [-3.9833, 1.6599, 1.1834]  w:  [1.23427745 0.44852429 1.25271449]
-2.689529587709917  -  25.5397  =  -28.229229587709916
training  [4.9539, 3.9439, -1.5671]  w:  [1.23427745 0.44852429 1.25271449]
5.92029312909959  -  95.9509  =  -90.03060687090041
training  [-1.6791, 0.1656, 4.3603]  w:  [1.23427745 0.44852429 1.25271449]
3.464011325301949  -  71.5733  =  -68.10928867469805
training  [-2.0265, 2.027, -3.7523]  w:  [1.23427745 0.44852429 1.25271449]
-6.29266509257356  -  8.503  =  -14.79566509257356
training  [-4.3795, -3.4641, 2.3059]  w:  [1.23427745 0.44852429 1.25271449]
-4.070616746269851  -  3.6654  =  -7.736016746269851
training  [-2.0176, 4.5346, 1.4648]  w:  [1.23427745 0.44852429 1.25271449]
1.3785762207559837  -  81.6212  =  -80.24262377924401
training  [-4.5365, 0.4088, 3.3315]  w:  [1.23427745 0.44852429 1.25271449]
-1.2425246214482035  -  28.9449  =  -30.187424621448205
training  [0.0543, 1.7973, -1.0172]  w:  [1.23427745 0.44852429 1.25271449]
-0.40110720972913205  -  47.9317  =  -48.33280720972913
training  [2.6143, -4.6344, 2.4982]  w:  [1.23427745 0.44852429 1.25271449]
4.277661918091649  -  43.5132  =  -39.235538081908345
training  [1.3107, 3.092, 3.3522]  w:  [1.23427745 0.44852429 1.25271449]
7.20395404808618  -  96.6993  =  -89.49534595191382
training  [-4.1011, 2.4862, -1.7754]  w:  [1.23427745 0.44852429 1.25271449]
-6.170843474412228  -  10.0187  =  -16.18954347441223
training  [-4.1914, -3.7981, 0.5226]  w:  [1.23427745 0.44852429 1.25271449]
-6.2222220117606675  -  1.4295  =  -7.6517220117606675
training  [2.7724, 0.2505, 4.7913]  w:  [1.23427745 0.44852429 1.25271449]
9.536397056315826  -  96.7925  =  -87.25610294368418
training  [4.0513, -1.7417, 0.4931]  w:  [1.23427745 0.44852429 1.25271449]
4.836947003259891  -  71.1234  =  -66.28645299674011
training  [0.3377, 0.4645, -1.6958]  w:  [1.23427745 0.44852429 1.25271449]
-1.4991981986838754  -  27.9534  =  -29.452598198683873
training  [-3.9085, -1.0112, 1.1947]  w:  [1.23427745 0.44852429 1.25271449]
-3.7811031815474356  -  8.608  =  -12.389103181547437
training  [3.2581, -0.8491, -1.3936]  w:  [1.23427745 0.44852429 1.25271449]
1.8947744861659388  -  50.1924  =  -48.29762551383406
training  [-1.619, -3.1926, 2.5651]  w:  [1.23427745 0.44852429 1.25271449]
-0.2169159027406833  -  16.4754  =  -16.692315902740685
training  [-2.0603, -2.4461, -0.861]  w:  [1.23427745 0.44852429 1.25271449]
-4.718704262288028  -  3.9784  =  -8.697104262288029
training  [2.4631, -4.7946, -0.0765]  w:  [1.23427745 0.44852429 1.25271449]
0.7938215901547117  -  15.394  =  -14.600178409845288
training  [-4.8966, 4.2368, 1.9474]  w:  [1.23427745 0.44852429 1.25271449]
-1.7039190839422553  -  53.5883  =  -55.29221908394225
training  [-4.5155, 1.537, 4.7273]  w:  [1.23427745 0.44852429 1.25271449]
1.037959184030112  -  59.2523  =  -58.214340815969884
training  [1.6792, 4.3261, -1.7225]  w:  [1.23427745 0.44852429 1.25271449]
1.855158909489961  -  83.7729  =  -81.91774109051005
training  [1.0347, -3.3649, 3.378]  w:  [1.23427745 0.44852429 1.25271449]
3.999537041528505  -  50.5979  =  -46.5983629584715
training  [0.261, 4.211, 2.3907]  w:  [1.23427745 0.44852429 1.25271449]
5.205746705327519  -  94.9375  =  -89.73175329467249
training  [2.2971, 2.9466, 4.5417]  w:  [1.23427745 0.44852429 1.25271449]
9.846333775981124  -  98.7784  =  -88.93206622401888
training  [2.0725, 0.7739, -4.6808]  w:  [1.23427745 0.44852429 1.25271449]
-2.958553001651393  -  19.5109  =  -22.46945300165139
training  [2.8138, -0.5996, -1.4313]  w:  [1.23427745 0.44852429 1.25271449]
1.411064487722054  -  47.2879  =  -45.87683551227795
training  [-2.1202, -2.4239, 1.6265]  w:  [1.23427745 0.44852429 1.25271449]
-1.6665529590405646  -  12.3599  =  -14.026452959040565
training  [1.9253, 2.5195, -2.185]  w:  [1.23427745 0.44852429 1.25271449]
0.7692301651657512  -  65.2467  =  -64.47746983483425
training  [0.5667, -2.7133, -2.6962]  w:  [1.23427745 0.44852429 1.25271449]
-3.895084710601843  -  5.1106  =  -9.005684710601843
training  [-1.0348, -4.3581, 2.1113]  w:  [1.23427745 0.44852429 1.25271449]
-0.5870879047657285  -  10.5192  =  -11.106287904765729
training  [-4.3841, 2.6733, 1.2457]  w:  [1.23427745 0.44852429 1.25271449]
-2.6516493661904708  -  32.4639  =  -35.11554936619047
training  [2.8018, 1.712, 0.9061]  w:  [1.23427745 0.44852429 1.25271449]
5.3611567374388045  -  90.1138  =  -84.7526432625612
training  [-1.6242, 2.1521, 1.6044]  w:  [1.23427745 0.44852429 1.25271449]
0.9704108005237955  -  63.7879  =  -62.817489199476206
training  [1.0787, 1.4206, -4.5245]  w:  [1.23427745 0.44852429 1.25271449]
-3.6993180030108035  -  18.0555  =  -21.7548180030108
training  [2.4125, -0.8095, -1.5122]  w:  [1.23427745 0.44852429 1.25271449]
0.7202590968228739  -  38.8276  =  -38.107340903177125
training  [-3.9519, -1.0924, -0.4866]  w:  [1.23427745 0.44852429 1.25271449]
-5.977279859973135  -  3.6777  =  -9.654979859973135
training  [-3.7211, 3.1614, -2.591]  w:  [1.23427745 0.44852429 1.25271449]
-6.420688379381986  -  11.1518  =  -17.572488379381987
training  [0.4954, -1.8257, 2.1505]  w:  [1.23427745 0.44852429 1.25271449]
2.4865527619014913  -  47.7531  =  -45.26654723809851
training  [-0.1477, 3.1454, 3.5618]  w:  [1.23427745 0.44852429 1.25271449]
5.690403965803091  -  94.1572  =  -88.46679603419692
training  [3.9048, 2.8907, -2.1849]  w:  [1.23427745 0.44852429 1.25271449]
3.3790998670699075  -  85.8791  =  -82.50000013293008
training  [2.9896, 3.5226, 2.3105]  w:  [1.23427745 0.44852429 1.25271449]
8.16436433933178  -  98.038  =  -89.87363566066821
training  [2.3434, 0.0564, -3.6224]  w:  [1.23427745 0.44852429 1.25271449]
-1.62013040359784  -  24.7629  =  -26.38303040359784
training  [-4.4867, 1.3566, 3.3672]  w:  [1.23427745 0.44852429 1.25271449]
-0.7112243787425179  -  40.5785  =  -41.28972437874252
training  [-4.2711, 4.5089, -3.614]  w:  [1.23427745 0.44852429 1.25271449]
-7.776681421060735  -  10.0825  =  -17.859181421060732
training  [-4.1147, -0.5604, 0.8821]  w:  [1.23427745 0.44852429 1.25271449]
-4.225014992102217  -  8.344  =  -12.569014992102217
training  [2.9835, -4.3998, -1.3384]  w:  [1.23427745 0.44852429 1.25271449]
0.03241655451776593  -  13.2692  =  -13.236783445482233
training  [4.4301, 3.6675, 3.0676]  w:  [1.23427745 0.44852429 1.25271449]
10.955762314616761  -  99.3834  =  -88.42763768538323
training  [1.8372, 1.3119, 0.0378]  w:  [1.23427745 0.44852429 1.25271449]
2.903386152699808  -  74.9026  =  -71.9992138473002
training  [-3.6792, -1.4493, -0.1041]  w:  [1.23427745 0.44852429 1.25271449]
-5.321607425854588  -  4.2442  =  -9.565807425854588
training  [2.2272, 4.97, 3.7705]  w:  [1.23427745 0.44852429 1.25271449]
9.701508411386428  -  99.3199  =  -89.61839158861358
training  [-3.8965, -2.7583, -1.4686]  w:  [1.23427745 0.44852429 1.25271449]
-7.886263122620804  -  1.0337  =  -8.919963122620803
training  [-3.8251, 1.5245, -0.5056]  w:  [1.23427745 0.44852429 1.25271449]
-4.6708318497495265  -  12.9762  =  -17.647031849749528
training  [1.4072, 1.0499, 4.6353]  w:  [1.23427745 0.44852429 1.25271449]
8.014488334025156  -  95.4618  =  -87.44731166597484
training  [-1.7119, -1.1275, -4.577]  w:  [1.23427745 0.44852429 1.25271449]
-8.35234490361086  -  1.4655  =  -9.81784490361086
training  [1.5381, -3.5781, 4.7296]  w:  [1.23427745 0.44852429 1.25271449]
6.218415831851695  -  69.9473  =  -63.728884168148305
training  [2.4913, -4.7487, -3.1079]  w:  [1.23427745 0.44852429 1.25271449]
-2.948263213246958  -  3.9825  =  -6.9307632132469585
training  [0.8319, -0.7889, 1.6712]  w:  [1.23427745 0.44852429 1.25271449]
2.76649105125939  -  58.8336  =  -56.06710894874061
training  [2.4003, -3.159, 0.8644]  w:  [1.23427745 0.44852429 1.25271449]
2.6285943484217285  -  39.0041  =  -36.37550565157827
training  [-2.6517, 2.2578, 1.7511]  w:  [1.23427745 0.44852429 1.25271449]
-0.06662704885945026  -  54.4525  =  -54.51912704885945
training  [2.3496, -1.2964, -1.3898]  w:  [1.23427745 0.44852429 1.25271449]
0.5775688232233629  -  33.888  =  -33.31043117677663
training  [4.706, 3.4156, 1.2028]  w:  [1.23427745 0.44852429 1.25271449]
8.847254222680057  -  98.4665  =  -89.61924577731995
training  [3.6693, 2.3423, 3.1115]  w:  [1.23427745 0.44852429 1.25271449]
9.47733381128706  -  98.3069  =  -88.82956618871293
training  [-4.1377, 0.7103, -4.8074]  w:  [1.23427745 0.44852429 1.25271449]
-10.810782629992426  -  0.9782  =  -11.788982629992425
training  [-1.3356, -3.2314, -4.1613]  w:  [1.23427745 0.44852429 1.25271449]
-8.310783132594834  -  0.7659  =  -9.076683132594834
training  [-1.308, 4.5738, 4.748]  w:  [1.23427745 0.44852429 1.25271449]
6.384913852220105  -  97.0884  =  -90.70348614777988
training  [1.8503, -2.3468, 1.5135]  w:  [1.23427745 0.44852429 1.25271449]
3.127170148049644  -  50.2125  =  -47.085329851950355
training  [0.9794, 4.2458, -2.6876]  w:  [1.23427745 0.44852429 1.25271449]
-0.2535997015641467  -  68.3262  =  -68.57979970156414
training  [2.8936, -2.7623, -0.9651]  w:  [1.23427745 0.44852429 1.25271449]
1.1235518478469038  -  28.5596  =  -27.436048152153095
training  [-1.3235, -1.2644, -3.7798]  w:  [1.23427745 0.44852429 1.25271449]
-6.9356905281129375  -  2.4511  =  -9.386790528112938
training  [-2.9397, -4.125, -2.3156]  w:  [1.23427745 0.44852429 1.25271449]
-8.379353768390487  -  0.554  =  -8.933353768390488
training  [-4.1333, 1.4012, -2.4215]  w:  [1.23427745 0.44852429 1.25271449]
-7.506614888174788  -  4.4072  =  -11.913814888174787
training  [2.7193, -3.1938, -1.6833]  w:  [1.23427745 0.44852429 1.25271449]
-0.18482048517183736  -  17.0949  =  -17.279720485171836
training  [-2.9433, -4.5495, -3.4777]  w:  [1.23427745 0.44852429 1.25271449]
-10.0299752306696  -  0.2509  =  -10.280875230669599
training  [-1.1173, 2.2317, -1.5199]  w:  [1.23427745 0.44852429 1.25271449]
-2.282087294090024  -  33.1206  =  -35.40268729409003
training  [0.5178, -1.5256, -3.7834]  w:  [1.23427745 0.44852429 1.25271449]
-4.784679772216961  -  5.237  =  -10.021679772216961
training  [-2.7105, 1.6062, 3.8415]  w:  [1.23427745 0.44852429 1.25271449]
2.187213373220162  -  70.4458  =  -68.25858662677985
training  [1.4194, -1.1613, -4.0572]  w:  [1.23427745 0.44852429 1.25271449]
-3.8514510506138038  -  8.3206  =  -12.172051050613804
training  [-0.1552, 1.2735, 4.3004]  w:  [1.23427745 0.44852429 1.25271449]
5.766809192769192  -  90.1085  =  -84.34169080723082
training  [-3.4815, -4.7835, -1.0098]  w:  [1.23427745 0.44852429 1.25271449]
-7.707643958565147  -  0.5839  =  -8.291543958565148
training  [2.8193, 4.1057, -4.526]  w:  [1.23427745 0.44852429 1.25271449]
-0.34848118159751884  -  66.8081  =  -67.15658118159752
training  [-3.9939, 3.0056, -1.5763]  w:  [1.23427745 0.44852429 1.25271449]
-5.556149963218778  -  14.4018  =  -19.957949963218777
training  [-2.0593, 2.4585, 2.3597]  w:  [1.23427745 0.44852429 1.25271449]
1.5169797737645543  -  70.6698  =  -69.15282022623543
training  [-2.6263, 3.1311, 2.9468]  w:  [1.23427745 0.44852429 1.25271449]
1.8542905682400743  -  77.309  =  -75.45470943175992
training  [0.3087, -1.1669, 0.4491]  w:  [1.23427745 0.44852429 1.25271449]
0.4202325352971365  -  33.0798  =  -32.65956746470286
training  [-4.085, 1.1728, 1.8622]  w:  [1.23427745 0.44852429 1.25271449]
-2.183189191385485  -  26.4056  =  -28.588789191385484
training  [-0.9468, 0.7549, 3.9363]  w:  [1.23427745 0.44852429 1.25271449]
4.1010371229817055  -  79.7738  =  -75.67276287701829
training  [-3.9515, 0.3005, -4.4521]  w:  [1.23427745 0.44852429 1.25271449]
-10.319675964190651  -  1.0441  =  -11.363775964190651
training  [-3.8772, -2.2493, -1.9634]  w:  [1.23427745 0.44852429 1.25271449]
-8.253985833699398  -  1.0509  =  -9.304885833699398
training  [2.8443, -2.5137, -4.5381]  w:  [1.23427745 0.44852429 1.25271449]
-3.301743750749842  -  6.8897  =  -10.191443750749842
training  [-2.0843, -0.4836, -3.0452]  w:  [1.23427745 0.44852429 1.25271449]
-6.604276989329858  -  3.5346  =  -10.138876989329859
training  [1.0353, -2.7229, 2.2017]  w:  [1.23427745 0.44852429 1.25271449]
2.8146621500946285  -  43.9562  =  -41.141537849905376
training  [4.6442, 3.0445, 2.2175]  w:  [1.23427745 0.44852429 1.25271449]
9.87565790230592  -  98.8492  =  -88.97354209769408
training  [-0.6752, 4.861, 3.778]  w:  [1.23427745 0.44852429 1.25271449]
6.079647747351631  -  97.017  =  -90.93735225264837
training  [1.9475, -4.7001, 0.8243]  w:  [1.23427745 0.44852429 1.25271449]
1.328258889978985  -  18.7839  =  -17.455641110021013
training  [2.581, 0.3566, -4.2932]  w:  [1.23427745 0.44852429 1.25271449]
-2.032539967458746  -  23.5455  =  -25.578039967458746
training  [-0.6736, -4.1292, 4.2274]  w:  [1.23427745 0.44852429 1.25271449]
2.612269443276176  -  31.2667  =  -28.654430556723824
training  [1.555, 3.0209, 3.0037]  w:  [1.23427745 0.44852429 1.25271449]
7.037026954455118  -  96.4078  =  -89.37077304554488
training  [-3.9024, 4.8914, -2.1405]  w:  [1.23427745 0.44852429 1.25271449]
-5.304167990348708  -  25.4308  =  -30.734967990348707
training  [4.3376, -4.3305, 0.4366]  w:  [1.23427745 0.44852429 1.25271449]
3.9584025970503736  -  43.0907  =  -39.132297402949625
training  [-3.1254, 4.394, 4.8478]  w:  [1.23427745 0.44852429 1.25271449]
4.186114250731303  -  92.8121  =  -88.6259857492687
training  [-2.3382, -4.8182, 2.1568]  w:  [1.23427745 0.44852429 1.25271449]
-2.3452126501447297  -  4.7434  =  -7.08861265014473
training  [2.9783, 1.8384, 3.3897]  w:  [1.23427745 0.44852429 1.25271449]
8.746941874369856  -  97.3486  =  -88.60165812563015
training  [-0.124, 2.8374, -0.6674]  w:  [1.23427745 0.44852429 1.25271449]
0.28353075787928794  -  62.785  =  -62.501469242120706
training  [2.6896, 0.3414, -0.2938]  w:  [1.23427745 0.44852429 1.25271449]
3.104791309167166  -  70.4455  =  -67.34070869083283
training  [-1.0399, 3.8536, 0.6071]  w:  [1.23427745 0.44852429 1.25271449]
1.205431031783113  -  77.0369  =  -75.8314689682169
training  [-2.2706, 3.99, -2.3091]  w:  [1.23427745 0.44852429 1.25271449]
-3.905581498751982  -  31.1134  =  -35.018981498751984
training  [-4.6277, 1.2594, 2.4902]  w:  [1.23427745 0.44852429 1.25271449]
-2.0274846640882536  -  28.1093  =  -30.136784664088253
training  [1.7329, -3.6213, 0.0389]  w:  [1.23427745 0.44852429 1.25271449]
0.5633689916838845  -  19.3919  =  -18.828531008316116
training  [-0.7044, -2.822, 1.4681]  w:  [1.23427745 0.44852429 1.25271449]
-0.29605043597961744  -  17.8122  =  -18.108250435979617
training  [-0.4826, -3.1786, -1.9225]  w:  [1.23427745 0.44852429 1.25271449]
-4.429685193257107  -  3.5851  =  -8.014785193257108
training  [1.0986, -4.5818, -3.6128]  w:  [1.23427745 0.44852429 1.25271449]
-5.224878260584318  -  1.7158  =  -6.940678260584318
training  [-4.406, -3.9306, -0.2443]  w:  [1.23427745 0.44852429 1.25271449]
-7.507234159959139  -  0.8241  =  -8.33133415995914
training  [-1.8419, 1.1644, -1.3754]  w:  [1.23427745 0.44852429 1.25271449]
-3.4741374629856705  -  17.8517  =  -21.32583746298567
training  [2.7272, 4.3966, 2.8811]  w:  [1.23427745 0.44852429 1.25271449]
8.947299047787823  -  98.904  =  -89.95670095221217
training  [1.9643, -1.4554, 2.803]  w:  [1.23427745 0.44852429 1.25271449]
5.283067655708734  -  76.0591  =  -70.77603234429127
training  [-3.7467, -0.8937, 1.6851]  w:  [1.23427745 0.44852429 1.25271449]
-2.9143643024113497  -  12.1571  =  -15.07146430241135
training  [-3.6985, 4.8435, -3.665]  w:  [1.23427745 0.44852429 1.25271449]
-6.983746364892006  -  14.6793  =  -21.663046364892004
254332.77251364986
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.30029437 0.45764542 1.14290284]
9.051363543536713  -  87.3174  =  -78.2660364564633
training  [-4.1793, -4.9218, 1.7664]  w:  [1.30029437 0.45764542 1.14290284]
-5.667935892121319  -  1.5257  =  -7.1936358921213195
training  [-3.9429, -0.7689, 4.883]  w:  [1.30029437 0.45764542 1.14290284]
0.10198034819060187  -  39.7859  =  -39.6839196518094
training  [-3.5796, 1.5557, 2.6683]  w:  [1.30029437 0.45764542 1.14290284]
-0.892967103840443  -  45.5674  =  -46.46036710384044
training  [-3.3354, 2.2292, -1.633]  w:  [1.30029437 0.45764542 1.14290284]
-5.18317903639119  -  13.3589  =  -18.54207903639119
training  [1.2096, 0.3121, 1.6238]  w:  [1.30029437 0.45764542 1.14290284]
3.5715128464633326  -  74.5119  =  -70.94038715353666
training  [0.7371, -3.9118, -2.5583]  w:  [1.30029437 0.45764542 1.14290284]
-3.7556587006773157  -  3.3358  =  -7.0914587006773155
training  [-4.4792, 1.3177, -2.0449]  w:  [1.30029437 0.45764542 1.14290284]
-7.558361217646002  -  4.2974  =  -11.855761217646002
training  [4.312, -3.735, 1.8018]  w:  [1.30029437 0.45764542 1.14290284]
5.9568460546739965  -  66.5833  =  -60.626453945326
training  [2.2866, -3.657, 0.2785]  w:  [1.30029437 0.45764542 1.14290284]
1.6179422713078089  -  26.0005  =  -24.38255772869219
training  [2.3784, -4.0141, -0.8841]  w:  [1.30029437 0.45764542 1.14290284]
0.24514526978085915  -  14.6809  =  -14.43575473021914
training  [-4.366, -3.5797, 1.0264]  w:  [1.30029437 0.45764542 1.14290284]
-6.142243044700752  -  1.8713  =  -8.013543044700752
training  [3.6044, -3.3175, 2.5052]  w:  [1.30029437 0.45764542 1.14290284]
6.031742578300309  -  71.0139  =  -64.9821574216997
training  [4.3441, -3.0375, 0.8353]  w:  [1.30029437 0.45764542 1.14290284]
5.213177581863749  -  63.8979  =  -58.68472241813625
training  [4.844, -1.8252, 0.5179]  w:  [1.30029437 0.45764542 1.14290284]
6.055240912842535  -  78.0461  =  -71.99085908715746
training  [3.5894, -1.8357, 0.8357]  w:  [1.30029437 0.45764542 1.14290284]
4.78230083996069  -  68.8838  =  -64.10149916003931
training  [2.8556, -2.8244, 0.1182]  w:  [1.30029437 0.45764542 1.14290284]
2.555638016155945  -  39.5252  =  -36.96956198384405
training  [0.1338, -2.4896, -4.1741]  w:  [1.30029437 0.45764542 1.14290284]
-5.735965402494493  -  2.2644  =  -8.000365402494493
training  [-3.224, 3.9292, 2.1957]  w:  [1.30029437 0.45764542 1.14290284]
0.11550308387416308  -  72.1211  =  -72.00559691612584
training  [-1.0141, 2.0322, 4.9616]  w:  [1.30029437 0.45764542 1.14290284]
5.28202524336437  -  92.3427  =  -87.06067475663562
training  [-3.6607, 0.5574, -1.4547]  w:  [1.30029437 0.45764542 1.14290284]
-6.167476823890555  -  5.8471  =  -12.014576823890554
training  [-4.6911, -3.1557, 4.7126]  w:  [1.30029437 0.45764542 1.14290284]
-2.1579586233747223  -  11.2337  =  -13.391658623374724
training  [4.3914, -2.8797, -1.5355]  w:  [1.30029437 0.45764542 1.14290284]
2.637303888202761  -  37.475  =  -34.83769611179724
training  [-1.9869, -4.2265, 3.8654]  w:  [1.30029437 0.45764542 1.14290284]
-0.10001658123532664  -  15.7889  =  -15.888916581235327
training  [-2.0447, 4.138, -0.4531]  w:  [1.30029437 0.45764542 1.14290284]
-1.2828244544689769  -  57.936  =  -59.21882445446898
training  [-1.6706, 2.0672, -0.8657]  w:  [1.30029437 0.45764542 1.14290284]
-2.215638169249169  -  32.4185  =  -34.63413816924917
training  [-0.3293, 0.5779, -2.8227]  w:  [1.30029437 0.45764542 1.14290284]
-3.3897855109649484  -  14.3434  =  -17.73318551096495
training  [1.482, -1.8657, -3.7435]  w:  [1.30029437 0.45764542 1.14290284]
-3.205249589687569  -  7.1519  =  -10.35714958968757
training  [-4.7477, -3.338, -1.9109]  w:  [1.30029437 0.45764542 1.14290284]
-9.885001035403079  -  0.4077  =  -10.292701035403079
training  [3.4221, 1.225, 2.261]  w:  [1.30029437 0.45764542 1.14290284]
7.594456338340571  -  95.0454  =  -87.45094366165944
training  [0.5903, 4.8793, 2.8287]  w:  [1.30029437 0.45764542 1.14290284]
6.233482319508866  -  97.4647  =  -91.23121768049113
training  [3.541, -3.2957, 1.9379]  w:  [1.30029437 0.45764542 1.14290284]
5.310911801369452  -  64.3732  =  -59.06228819863055
training  [-1.5212, -2.4221, -4.902]  w:  [1.30029437 0.45764542 1.14290284]
-8.688980504448352  -  0.7227  =  -9.411680504448352
training  [-0.5397, -1.032, 3.4321]  w:  [1.30029437 0.45764542 1.14290284]
2.748497911490692  -  60.5921  =  -57.84360208850931
training  [-4.4576, -4.2601, 4.2233]  w:  [1.30029437 0.45764542 1.14290284]
-2.918985845831287  -  6.0247  =  -8.943685845831286
training  [-3.2289, 1.841, 2.7095]  w:  [1.30029437 0.45764542 1.14290284]
-0.2593000331463662  -  54.0111  =  -54.270400033146366
training  [1.6281, -0.9761, -4.5734]  w:  [1.30029437 0.45764542 1.14290284]
-3.556650291157837  -  7.8658  =  -11.422450291157837
training  [-1.6917, 4.8284, -1.2181]  w:  [1.30029437 0.45764542 1.14290284]
-1.3821828223243895  -  61.2837  =  -62.66588282232439
training  [3.9849, -0.9782, 2.0434]  w:  [1.30029437 0.45764542 1.14290284]
7.069281973415946  -  88.3402  =  -81.27091802658406
training  [-3.8184, 1.2067, 2.2951]  w:  [1.30029437 0.45764542 1.14290284]
-1.7897269915904483  -  34.1122  =  -35.90192699159045
training  [4.8842, -3.4563, -2.7572]  w:  [1.30029437 0.45764542 1.14290284]
1.617926203377193  -  23.7819  =  -22.163973796622805
training  [0.3998, -1.1865, -2.3095]  w:  [1.30029437 0.45764542 1.14290284]
-2.6626727146369626  -  11.4246  =  -14.087272714636963
training  [2.0692, -3.3887, 1.7303]  w:  [1.30029437 0.45764542 1.14290284]
3.117310889406379  -  42.6881  =  -39.57078911059362
training  [4.9949, 2.5811, -0.2251]  w:  [1.30029437 0.45764542 1.14290284]
7.418801513425406  -  95.9901  =  -88.57129848657459
training  [-2.1215, 3.7111, 1.2372]  w:  [1.30029437 0.45764542 1.14290284]
0.3537927881853724  -  71.3692  =  -71.01540721181463
training  [-0.8548, -1.4922, -2.6356]  w:  [1.30029437 0.45764542 1.14290284]
-4.806624855755004  -  4.7821  =  -9.588724855755004
training  [-0.3516, 1.8554, -3.2288]  w:  [1.30029437 0.45764542 1.14290284]
-3.2982729026739213  -  20.3834  =  -23.681672902673924
training  [2.6396, -2.0585, 3.2964]  w:  [1.30029437 0.45764542 1.14290284]
6.257658875961554  -  80.826  =  -74.56834112403844
training  [3.182, 0.3063, 2.6692]  w:  [1.30029437 0.45764542 1.14290284]
7.32834975761345  -  92.9483  =  -85.61995024238655
training  [-3.9978, 3.3242, 4.3448]  w:  [1.30029437 0.45764542 1.14290284]
1.2886723253797383  -  79.1768  =  -77.88812767462026
training  [-3.2188, 0.9749, -3.9211]  w:  [1.30029437 0.45764542 1.14290284]
-8.2206653556687  -  2.7053  =  -10.9259653556687
training  [-1.4037, -1.6469, -3.1777]  w:  [1.30029437 0.45764542 1.14290284]
-6.210721814761854  -  2.6234  =  -8.834121814761854
training  [-4.433, -2.0077, -4.009]  w:  [1.30029437 0.45764542 1.14290284]
-11.264917158666062  -  0.3253  =  -11.590217158666063
training  [0.2189, -0.4741, -0.1024]  w:  [1.30029437 0.45764542 1.14290284]
-0.04936850447354178  -  33.6531  =  -33.70246850447354
training  [-1.6415, -0.7735, -3.0675]  w:  [1.30029437 0.45764542 1.14290284]
-5.994276417429303  -  3.7641  =  -9.758376417429304
training  [-3.2433, -1.4039, 3.9589]  w:  [1.30029437 0.45764542 1.14290284]
-0.3350950660452634  -  30.0658  =  -30.400895066045262
training  [-2.9105, 0.5832, -4.0091]  w:  [1.30029437 0.45764542 1.14290284]
-8.099619760038735  -  2.4887  =  -10.588319760038734
training  [4.0515, 2.4255, -4.5583]  w:  [1.30029437 0.45764542 1.14290284]
1.1684675692666033  -  61.2853  =  -60.116832430733396
training  [1.7539, -0.7567, 0.573]  w:  [1.30029437 0.45764542 1.14290284]
2.5891693445851534  -  57.0797  =  -54.49053065541485
training  [-0.3153, -0.7064, 2.725]  w:  [1.30029437 0.45764542 1.14290284]
2.3811467145150305  -  58.7004  =  -56.31925328548497
training  [4.1213, -3.7513, -1.8806]  w:  [1.30029437 0.45764542 1.14290284]
1.4927948625016034  -  22.1789  =  -20.686105137498394
training  [-3.9599, -4.7557, -3.2102]  w:  [1.30029437 0.45764542 1.14290284]
-10.994406699792744  -  0.1558  =  -11.150206699792744
training  [2.4555, -2.0981, -1.6104]  w:  [1.30029437 0.45764542 1.14290284]
0.3921562455231147  -  24.4796  =  -24.087443754476887
training  [2.3627, -1.8248, -2.8985]  w:  [1.30029437 0.45764542 1.14290284]
-1.0756097344276312  -  15.7052  =  -16.78080973442763
training  [0.6186, 1.5369, 0.1015]  w:  [1.30029437 0.45764542 1.14290284]
1.6237219764291182  -  65.2154  =  -63.591678023570886
training  [-3.1581, 4.5694, 4.0636]  w:  [1.30029437 0.45764542 1.14290284]
2.629005301353439  -  90.3564  =  -87.72739469864655
training  [0.9721, 4.3573, 1.2892]  w:  [1.30029437 0.45764542 1.14290284]
4.731544874962914  -  94.3178  =  -89.5862551250371
training  [-2.0006, -0.4211, -3.9847]  w:  [1.30029437 0.45764542 1.14290284]
-7.3482083714246285  -  2.4051  =  -9.753308371424628
training  [-3.6588, -2.5952, -1.0915]  w:  [1.30029437 0.45764542 1.14290284]
-7.192676887585282  -  1.5176  =  -8.710276887585282
training  [-2.874, 2.639, -4.4538]  w:  [1.30029437 0.45764542 1.14290284]
-7.6195804657310955  -  5.497  =  -13.116580465731095
training  [3.9494, 2.5933, 0.0128]  w:  [1.30029437 0.45764542 1.14290284]
6.3368236075253135  -  94.1462  =  -87.80937639247468
training  [-4.2855, 2.4065, -0.6828]  w:  [1.30029437 0.45764542 1.14290284]
-5.251461904849823  -  14.4193  =  -19.670761904849822
training  [-2.5751, 2.4369, 4.9756]  w:  [1.30029437 0.45764542 1.14290284]
3.453475466898145  -  87.1991  =  -83.74562453310186
training  [-4.4625, -3.9408, 3.116]  w:  [1.30029437 0.45764542 1.14290284]
-4.044767427008871  -  4.1344  =  -8.17916742700887
training  [-0.5828, 1.8156, -0.1435]  w:  [1.30029437 0.45764542 1.14290284]
-0.09091710267898653  -  51.1166  =  -51.207517102678985
training  [-4.8672, -0.3674, 3.9445]  w:  [1.30029437 0.45764542 1.14290284]
-1.9887514259788812  -  24.1396  =  -26.128351425978884
training  [3.9719, -2.8784, -3.6245]  w:  [1.30029437 0.45764542 1.14290284]
-0.2950987045296234  -  14.6104  =  -14.905498704529624
training  [-3.0334, -4.0148, -1.1]  w:  [1.30029437 0.45764542 1.14290284]
-7.038860892564056  -  1.021  =  -8.059860892564057
training  [-4.0663, 3.2357, 4.2736]  w:  [1.30029437 0.45764542 1.14290284]
1.0777258590590906  -  77.2328  =  -76.15507414094091
training  [-1.9263, -3.2499, 4.1749]  w:  [1.30029437 0.45764542 1.14290284]
0.7794462007110825  -  26.8814  =  -26.101953799288918
training  [-0.4394, -3.3643, 2.1357]  w:  [1.30029437 0.45764542 1.14290284]
0.3298917872883269  -  20.85  =  -20.520108212711676
training  [-3.9833, 1.6599, 1.1834]  w:  [1.30029437 0.45764542 1.14290284]
-3.0673057238188113  -  25.5397  =  -28.607005723818812
training  [4.9539, 3.9439, -1.5671]  w:  [1.30029437 0.45764542 1.14290284]
6.455392998590273  -  95.9509  =  -89.49550700140973
training  [-1.6791, 0.1656, 4.3603]  w:  [1.30029437 0.45764542 1.14290284]
2.8758610728866496  -  71.5733  =  -68.69743892711335
training  [-2.0265, 2.027, -3.7523]  w:  [1.30029437 0.45764542 1.14290284]
-5.9959136334761745  -  8.503  =  -14.498913633476175
training  [-4.3795, -3.4641, 2.3059]  w:  [1.30029437 0.45764542 1.14290284]
-4.644549019039092  -  3.6654  =  -8.309949019039092
training  [-2.0176, 4.5346, 1.4648]  w:  [1.30029437 0.45764542 1.14290284]
1.1258890604199971  -  81.6212  =  -80.49531093958001
training  [-4.5365, 0.4088, 3.3315]  w:  [1.30029437 0.45764542 1.14290284]
-1.9041191493346288  -  28.9449  =  -30.84901914933463
training  [0.0543, 1.7973, -1.0172]  w:  [1.30029437 0.45764542 1.14290284]
-0.2694286842477571  -  47.9317  =  -48.201128684247756
training  [2.6143, -4.6344, 2.4982]  w:  [1.30029437 0.45764542 1.14290284]
4.13364755257279  -  43.5132  =  -39.37955244742721
training  [1.3107, 3.092, 3.3522]  w:  [1.30029437 0.45764542 1.14290284]
6.950574374083972  -  96.6993  =  -89.74872562591602
training  [-4.1011, 2.4862, -1.7754]  w:  [1.30029437 0.45764542 1.14290284]
-6.223948930949383  -  10.0187  =  -16.242648930949386
training  [-4.1914, -3.7981, 0.5226]  w:  [1.30029437 0.45764542 1.14290284]
-6.5909558590328805  -  1.4295  =  -8.02045585903288
training  [2.7724, 0.2505, 4.7913]  w:  [1.30029437 0.45764542 1.14290284]
9.195566694930903  -  96.7925  =  -87.5969333050691
training  [4.0513, -1.7417, 0.4931]  w:  [1.30029437 0.45764542 1.14290284]
5.034366965198734  -  71.1234  =  -66.08903303480128
training  [0.3377, 0.4645, -1.6958]  w:  [1.30029437 0.45764542 1.14290284]
-1.2864489388375435  -  27.9534  =  -29.239848938837543
training  [-3.9085, -1.0112, 1.1947]  w:  [1.30029437 0.45764542 1.14290284]
-4.1795455713111425  -  8.608  =  -12.787545571311142
training  [3.2581, -0.8491, -1.3936]  w:  [1.30029437 0.45764542 1.14290284]
2.2551529694659562  -  50.1924  =  -47.937247030534046
training  [-1.619, -3.1926, 2.5651]  w:  [1.30029437 0.45764542 1.14290284]
-0.6345952555170369  -  16.4754  =  -17.10999525551704
training  [-2.0603, -2.4461, -0.861]  w:  [1.30029437 0.45764542 1.14290284]
-4.782482295657702  -  3.9784  =  -8.760882295657701
training  [2.4631, -4.7946, -0.0765]  w:  [1.30029437 0.45764542 1.14290284]
0.9210962938503701  -  15.394  =  -14.47290370614963
training  [-4.8966, 4.2368, 1.9474]  w:  [1.30029437 0.45764542 1.14290284]
-2.202380330555673  -  53.5883  =  -55.790680330555666
training  [-4.5155, 1.537, 4.7273]  w:  [1.30029437 0.45764542 1.14290284]
0.23476638051425436  -  59.2523  =  -59.01753361948575
training  [1.6792, 4.3261, -1.7225]  w:  [1.30029437 0.45764542 1.14290284]
2.19462399183554  -  83.7729  =  -81.57827600816447
training  [1.0347, -3.3649, 3.378]  w:  [1.30029437 0.45764542 1.14290284]
3.666209338766166  -  50.5979  =  -46.93169066123384
training  [0.261, 4.211, 2.3907]  w:  [1.30029437 0.45764542 1.14290284]
4.998859505600022  -  94.9375  =  -89.93864049439998
training  [2.2971, 2.9466, 4.5417]  w:  [1.30029437 0.45764542 1.14290284]
9.526126033649513  -  98.7784  =  -89.25227396635049
training  [2.0725, 0.7739, -4.6808]  w:  [1.30029437 0.45764542 1.14290284]
-2.3006677607077455  -  19.5109  =  -21.811567760707746
training  [2.8138, -0.5996, -1.4313]  w:  [1.30029437 0.45764542 1.14290284]
1.7485272735238269  -  47.2879  =  -45.539372726476174
training  [-2.1202, -2.4239, 1.6265]  w:  [1.30029437 0.45764542 1.14290284]
-2.0072393743784014  -  12.3599  =  -14.3671393743784
training  [1.9253, 2.5195, -2.185]  w:  [1.30029437 0.45764542 1.14290284]
1.1592516641113528  -  65.2467  =  -64.08744833588865
training  [0.5667, -2.7133, -2.6962]  w:  [1.30029437 0.45764542 1.14290284]
-3.5863471338687187  -  5.1106  =  -8.696947133868719
training  [-1.0348, -4.3581, 2.1113]  w:  [1.30029437 0.45764542 1.14290284]
-0.9269983253420602  -  10.5192  =  -11.44619832534206
training  [-4.3841, 2.6733, 1.2457]  w:  [1.30029437 0.45764542 1.14290284]
-3.0534829973630275  -  32.4639  =  -35.51738299736303
training  [2.8018, 1.712, 0.9061]  w:  [1.30029437 0.45764542 1.14290284]
5.462237991990706  -  90.1138  =  -84.6515620080093
training  [-1.6242, 2.1521, 1.6044]  w:  [1.30029437 0.45764542 1.14290284]
0.7066339018933647  -  63.7879  =  -63.08126609810664
training  [1.0787, 1.4206, -4.5245]  w:  [1.30029437 0.45764542 1.14290284]
-3.118305303671545  -  18.0555  =  -21.173805303671543
training  [2.4125, -0.8095, -1.5122]  w:  [1.30029437 0.45764542 1.14290284]
1.0381985289487738  -  38.8276  =  -37.78940147105122
training  [-3.9519, -1.0924, -0.4866]  w:  [1.30029437 0.45764542 1.14290284]
-6.194701707464189  -  3.6777  =  -9.872401707464189
training  [-3.7211, 3.1614, -2.591]  w:  [1.30029437 0.45764542 1.14290284]
-6.352986444990505  -  11.1518  =  -17.504786444990504
training  [0.4954, -1.8257, 2.1505]  w:  [1.30029437 0.45764542 1.14290284]
2.2664551649557945  -  47.7531  =  -45.48664483504421
training  [-0.1477, 3.1454, 3.5618]  w:  [1.30029437 0.45764542 1.14290284]
5.318215762285288  -  94.1572  =  -88.83898423771471
training  [3.9048, 2.8907, -2.1849]  w:  [1.30029437 0.45764542 1.14290284]
3.903176643383963  -  85.8791  =  -81.97592335661604
training  [2.9896, 3.5226, 2.3105]  w:  [1.30029437 0.45764542 1.14290284]
8.140138819054208  -  98.038  =  -89.8978611809458
training  [2.3434, 0.0564, -3.6224]  w:  [1.30029437 0.45764542 1.14290284]
-1.0671302298418133  -  24.7629  =  -25.83003022984181
training  [-4.4867, 1.3566, 3.3672]  w:  [1.30029437 0.45764542 1.14290284]
-1.3648065334299364  -  40.5785  =  -41.94330653342993
training  [-4.2711, 4.5089, -3.614]  w:  [1.30029437 0.45764542 1.14290284]
-7.620660762971333  -  10.0825  =  -17.703160762971333
training  [-4.1147, -0.5604, 0.8821]  w:  [1.30029437 0.45764542 1.14290284]
-4.598631146996012  -  8.344  =  -12.94263114699601
training  [2.9835, -4.3998, -1.3384]  w:  [1.30029437 0.45764542 1.14290284]
0.33621879574840685  -  13.2692  =  -12.932981204251593
training  [4.4301, 3.6675, 3.0676]  w:  [1.30029437 0.45764542 1.14290284]
10.944817427320457  -  99.3834  =  -88.43858257267954
training  [1.8372, 1.3119, 0.0378]  w:  [1.30029437 0.45764542 1.14290284]
3.032487569414552  -  74.9026  =  -71.87011243058545
training  [-3.6792, -1.4493, -0.1041]  w:  [1.30029437 0.45764542 1.14290284]
-5.56628474265972  -  4.2442  =  -9.810484742659721
training  [2.2272, 4.97, 3.7705]  w:  [1.30029437 0.45764542 1.14290284]
9.47982851647504  -  99.3199  =  -89.84007148352497
training  [-3.8965, -2.7583, -1.4686]  w:  [1.30029437 0.45764542 1.14290284]
-8.007387489921296  -  1.0337  =  -9.041087489921296
training  [-3.8251, 1.5245, -0.5056]  w:  [1.30029437 0.45764542 1.14290284]
-4.853927247838206  -  12.9762  =  -17.830127247838206
training  [1.4072, 1.0499, 4.6353]  w:  [1.30029437 0.45764542 1.14290284]
7.607953718467906  -  95.4618  =  -87.85384628153209
training  [-1.7119, -1.1275, -4.577]  w:  [1.30029437 0.45764542 1.14290284]
-7.973035462225591  -  1.4655  =  -9.438535462225591
training  [1.5381, -3.5781, 4.7296]  w:  [1.30029437 0.45764542 1.14290284]
5.767955008255225  -  69.9473  =  -64.17934499174477
training  [2.4913, -4.7487, -3.1079]  w:  [1.30029437 0.45764542 1.14290284]
-2.4858251634530006  -  3.9825  =  -6.468325163453001
training  [0.8319, -0.7889, 1.6712]  w:  [1.30029437 0.45764542 1.14290284]
2.6306976545057634  -  58.8336  =  -56.20290234549423
training  [2.4003, -3.159, 0.8644]  w:  [1.30029437 0.45764542 1.14290284]
2.6633199349528223  -  39.0041  =  -36.34078006504718
training  [-2.6517, 2.2578, 1.7511]  w:  [1.30029437 0.45764542 1.14290284]
-0.4133815983991669  -  54.4525  =  -54.86588159839917
training  [2.3496, -1.2964, -1.3898]  w:  [1.30029437 0.45764542 1.14290284]
0.8734737683914915  -  33.888  =  -33.01452623160851
training  [4.706, 3.4156, 1.2028]  w:  [1.30029437 0.45764542 1.14290284]
9.057002540010329  -  98.4665  =  -89.40949745998967
training  [3.6693, 2.3423, 3.1115]  w:  [1.30029437 0.45764542 1.14290284]
9.399255199106861  -  98.3069  =  -88.90764480089314
training  [-4.1377, 0.7103, -4.8074]  w:  [1.30029437 0.45764542 1.14290284]
-10.549553622845133  -  0.9782  =  -11.527753622845132
training  [-1.3356, -3.2314, -4.1613]  w:  [1.30029437 0.45764542 1.14290284]
-7.971470166433866  -  0.7659  =  -8.737370166433866
training  [-1.308, 4.5738, 4.748]  w:  [1.30029437 0.45764542 1.14290284]
5.818896267045871  -  97.0884  =  -91.26950373295412
training  [1.8503, -2.3468, 1.5135]  w:  [1.30029437 0.45764542 1.14290284]
3.0617158726659666  -  50.2125  =  -47.150784127334035
training  [0.9794, 4.2458, -2.6876]  w:  [1.30029437 0.45764542 1.14290284]
0.14491352760437115  -  68.3262  =  -68.18128647239563
training  [2.8936, -2.7623, -0.9651]  w:  [1.30029437 0.45764542 1.14290284]
1.395362331033327  -  28.5596  =  -27.164237668966674
training  [-1.3235, -1.2644, -3.7798]  w:  [1.30029437 0.45764542 1.14290284]
-6.619530637473254  -  2.4511  =  -9.070630637473254
training  [-2.9397, -4.125, -2.3156]  w:  [1.30029437 0.45764542 1.14290284]
-8.356768532518332  -  0.554  =  -8.910768532518333
training  [-4.1333, 1.4012, -2.4215]  w:  [1.30029437 0.45764542 1.14290284]
-7.5007932132232575  -  4.4072  =  -11.907993213223257
training  [2.7193, -3.1938, -1.6833]  w:  [1.30029437 0.45764542 1.14290284]
0.15041420217241708  -  17.0949  =  -16.944485797827582
training  [-2.9433, -4.5495, -3.4777]  w:  [1.30029437 0.45764542 1.14290284]
-9.883887466771432  -  0.2509  =  -10.134787466771431
training  [-1.1173, 2.2317, -1.5199]  w:  [1.30029437 0.45764542 1.14290284]
-2.1685896629493158  -  33.1206  =  -35.28918966294932
training  [0.5178, -1.5256, -3.7834]  w:  [1.30029437 0.45764542 1.14290284]
-4.348950041652922  -  5.237  =  -9.585950041652922
training  [-2.7105, 1.6062, 3.8415]  w:  [1.30029437 0.45764542 1.14290284]
1.6010834462859203  -  70.4458  =  -68.84471655371408
training  [1.4194, -1.1613, -4.0572]  w:  [1.30029437 0.45764542 1.14290284]
-3.322811209264363  -  8.3206  =  -11.643411209264364
training  [-0.1552, 1.2735, 4.3004]  w:  [1.30029437 0.45764542 1.14290284]
5.2959451426878665  -  90.1085  =  -84.81255485731214
training  [-3.4815, -4.7835, -1.0098]  w:  [1.30029437 0.45764542 1.14290284]
-7.870224995119996  -  0.5839  =  -8.454124995119995
training  [2.8193, 4.1057, -4.526]  w:  [1.30029437 0.45764542 1.14290284]
0.37209643178626184  -  66.8081  =  -66.43600356821374
training  [-3.9939, 3.0056, -1.5763]  w:  [1.30029437 0.45764542 1.14290284]
-5.619304389138783  -  14.4018  =  -20.021104389138785
training  [-2.0593, 2.4585, 2.3597]  w:  [1.30029437 0.45764542 1.14290284]
1.1443328940912778  -  70.6698  =  -69.52546710590872
training  [-2.6263, 3.1311, 2.9468]  w:  [1.30029437 0.45764542 1.14290284]
1.385876551130334  -  77.309  =  -75.92312344886966
training  [0.3087, -1.1669, 0.4491]  w:  [1.30029437 0.45764542 1.14290284]
0.3806521053090938  -  33.0798  =  -32.6991478946909
training  [-4.085, 1.1728, 1.8622]  w:  [1.30029437 0.45764542 1.14290284]
-2.646662292375981  -  26.4056  =  -29.052262292375982
training  [-0.9468, 0.7549, 3.9363]  w:  [1.30029437 0.45764542 1.14290284]
3.613166279143367  -  79.7738  =  -76.16063372085662
training  [-3.9515, 0.3005, -4.4521]  w:  [1.30029437 0.45764542 1.14290284]
-10.08890852112398  -  1.0441  =  -11.13300852112398
training  [-3.8772, -2.2493, -1.9634]  w:  [1.30029437 0.45764542 1.14290284]
-8.314858619673942  -  1.0509  =  -9.365758619673942
training  [2.8443, -2.5137, -4.5381]  w:  [1.30029437 0.45764542 1.14290284]
-2.6385633951282097  -  6.8897  =  -9.52826339512821
training  [-2.0843, -0.4836, -3.0452]  w:  [1.30029437 0.45764542 1.14290284]
-6.411888626358477  -  3.5346  =  -9.946488626358477
training  [1.0353, -2.7229, 2.2017]  w:  [1.30029437 0.45764542 1.14290284]
2.6164012558664114  -  43.9562  =  -41.33979874413359
training  [4.6442, 3.0445, 2.2175]  w:  [1.30029437 0.45764542 1.14290284]
9.966515650603643  -  98.8492  =  -88.88268434939636
training  [-0.6752, 4.861, 3.778]  w:  [1.30029437 0.45764542 1.14290284]
5.664542550101413  -  97.017  =  -91.35245744989858
training  [1.9475, -4.7001, 0.8243]  w:  [1.30029437 0.45764542 1.14290284]
1.3234388894396403  -  18.7839  =  -17.46046111056036
training  [2.581, 0.3566, -4.2932]  w:  [1.30029437 0.45764542 1.14290284]
-1.387454361385414  -  23.5455  =  -24.932954361385413
training  [-0.6736, -4.1292, 4.2274]  w:  [1.30029437 0.45764542 1.14290284]
2.0659197471429405  -  31.2667  =  -29.200780252857058
training  [1.555, 3.0209, 3.0037]  w:  [1.30029437 0.45764542 1.14290284]
6.837396058969819  -  96.4078  =  -89.57040394103018
training  [-3.9024, 4.8914, -2.1405]  w:  [1.30029437 0.45764542 1.14290284]
-5.282125514857493  -  25.4308  =  -30.712925514857496
training  [4.3376, -4.3305, 0.4366]  w:  [1.30029437 0.45764542 1.14290284]
4.157314782352478  -  43.0907  =  -38.93338521764752
training  [-3.1254, 4.394, 4.8478]  w:  [1.30029437 0.45764542 1.14290284]
3.4875183322539223  -  92.8121  =  -89.32458166774607
training  [-2.3382, -4.8182, 2.1568]  w:  [1.30029437 0.45764542 1.14290284]
-2.780362586906881  -  4.7434  =  -7.523762586906882
training  [2.9783, 1.8384, 3.3897]  w:  [1.30029437 0.45764542 1.14290284]
8.588099834162769  -  97.3486  =  -88.76050016583724
training  [-0.124, 2.8374, -0.6674]  w:  [1.30029437 0.45764542 1.14290284]
0.37451324055827795  -  62.785  =  -62.41048675944172
training  [2.6896, 0.3414, -0.2938]  w:  [1.30029437 0.45764542 1.14290284]
3.3177270339479823  -  70.4455  =  -67.127772966052
training  [-1.0399, 3.8536, 0.6071]  w:  [1.30029437 0.45764542 1.14290284]
1.1052625710238762  -  77.0369  =  -75.93163742897613
training  [-2.2706, 3.99, -2.3091]  w:  [1.30029437 0.45764542 1.14290284]
-3.765520154341872  -  31.1134  =  -34.87892015434187
training  [-4.6277, 1.2594, 2.4902]  w:  [1.30029437 0.45764542 1.14290284]
-2.5949569690804273  -  28.1093  =  -30.70425696908043
training  [1.7329, -3.6213, 0.0389]  w:  [1.30029437 0.45764542 1.14290284]
0.6404676968754706  -  19.3919  =  -18.751432303124528
training  [-0.7044, -2.822, 1.4681]  w:  [1.30029437 0.45764542 1.14290284]
-0.5295070518563068  -  17.8122  =  -18.341707051856307
training  [-0.4826, -3.1786, -1.9225]  w:  [1.30029437 0.45764542 1.14290284]
-4.279424500028448  -  3.5851  =  -7.864524500028448
training  [1.0986, -4.5818, -3.6128]  w:  [1.30029437 0.45764542 1.14290284]
-4.797415762809522  -  1.7158  =  -6.513215762809522
training  [-4.406, -3.9306, -0.2443]  w:  [1.30029437 0.45764542 1.14290284]
-7.80712924048357  -  0.8241  =  -8.63122924048357
training  [-1.8419, 1.1644, -1.3754]  w:  [1.30029437 0.45764542 1.14290284]
-3.434078456103938  -  17.8517  =  -21.28577845610394
training  [2.7272, 4.3966, 2.8811]  w:  [1.30029437 0.45764542 1.14290284]
8.851064031728667  -  98.904  =  -90.05293596827133
training  [1.9643, -1.4554, 2.803]  w:  [1.30029437 0.45764542 1.14290284]
5.091667772461842  -  76.0591  =  -70.96743222753815
training  [-3.7467, -0.8937, 1.6851]  w:  [1.30029437 0.45764542 1.14290284]
-3.3549050505070968  -  12.1571  =  -15.512005050507096
training  [-3.6985, 4.8435, -3.665]  w:  [1.30029437 0.45764542 1.14290284]
-6.781272094267138  -  14.6793  =  -21.460572094267135
255197.38506982065
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.34704957 0.41330695 1.23682914]
9.860056622420682  -  87.3174  =  -77.45734337757932
training  [-4.1793, -4.9218, 1.7664]  w:  [1.34704957 0.41330695 1.23682914]
-5.47920339699653  -  1.5257  =  -7.00490339699653
training  [-3.9429, -0.7689, 4.883]  w:  [1.34704957 0.41330695 1.23682914]
0.41036321729349634  -  39.7859  =  -39.375536782706504
training  [-3.5796, 1.5557, 2.6683]  w:  [1.34704957 0.41330695 1.23682914]
-0.8786858345106769  -  45.5674  =  -46.446085834510676
training  [-3.3354, 2.2292, -1.633]  w:  [1.34704957 0.41330695 1.23682914]
-5.591347260786865  -  13.3589  =  -18.950247260786867
training  [1.2096, 0.3121, 1.6238]  w:  [1.34704957 0.41330695 1.23682914]
3.7667474036538007  -  74.5119  =  -70.7451525963462
training  [0.7371, -3.9118, -2.5583]  w:  [1.34704957 0.41330695 1.23682914]
-3.788043849952338  -  3.3358  =  -7.123843849952338
training  [-4.4792, 1.3177, -2.0449]  w:  [1.34704957 0.41330695 1.23682914]
-8.01828175738667  -  4.2974  =  -12.31568175738667
training  [4.312, -3.735, 1.8018]  w:  [1.34704957 0.41330695 1.23682914]
6.4932950274145504  -  66.5833  =  -60.09000497258545
training  [2.2866, -3.657, 0.2785]  w:  [1.34704957 0.41330695 1.23682914]
1.913156954387106  -  26.0005  =  -24.087343045612894
training  [2.3784, -4.0141, -0.8841]  w:  [1.34704957 0.41330695 1.23682914]
0.45128664200861524  -  14.6809  =  -14.229613357991385
training  [-4.366, -3.5797, 1.0264]  w:  [1.34704957 0.41330695 1.23682914]
-6.091251859408887  -  1.8713  =  -7.962551859408887
training  [3.6044, -3.3175, 2.5052]  w:  [1.34704957 0.41330695 1.23682914]
6.582664017024118  -  71.0139  =  -64.43123598297589
training  [4.3441, -3.0375, 0.8353]  w:  [1.34704957 0.41330695 1.23682914]
5.629421554087009  -  63.8979  =  -58.26847844591299
training  [4.844, -1.8252, 0.5179]  w:  [1.34704957 0.41330695 1.23682914]
6.4112940754348084  -  78.0461  =  -71.63480592456519
training  [3.5894, -1.8357, 0.8357]  w:  [1.34704957 0.41330695 1.23682914]
5.110010264602408  -  68.8838  =  -63.773789735397585
training  [2.8556, -2.8244, 0.1182]  w:  [1.34704957 0.41330695 1.23682914]
2.8254838106933726  -  39.5252  =  -36.69971618930663
training  [0.1338, -2.4896, -4.1741]  w:  [1.34704957 0.41330695 1.23682914]
-6.011382232166913  -  2.2644  =  -8.275782232166913
training  [-3.224, 3.9292, 2.1957]  w:  [1.34704957 0.41330695 1.23682914]
-0.0032164222274686516  -  72.1211  =  -72.12431642222747
training  [-1.0141, 2.0322, 4.9616]  w:  [1.34704957 0.41330695 1.23682914]
5.610530845065065  -  92.3427  =  -86.73216915493492
training  [-3.6607, 0.5574, -1.4547]  w:  [1.34704957 0.41330695 1.23682914]
-6.49998240188799  -  5.8471  =  -12.34708240188799
training  [-4.6911, -3.1557, 4.7126]  w:  [1.34704957 0.41330695 1.23682914]
-1.794735971266486  -  11.2337  =  -13.028435971266486
training  [4.3914, -2.8797, -1.5355]  w:  [1.34704957 0.41330695 1.23682914]
2.8260823213318087  -  37.475  =  -34.64891767866819
training  [-1.9869, -4.2265, 3.8654]  w:  [1.34704957 0.41330695 1.23682914]
0.35754474782054313  -  15.7889  =  -15.431355252179458
training  [-2.0447, 4.138, -0.4531]  w:  [1.34704957 0.41330695 1.23682914]
-1.604455390218543  -  57.936  =  -59.54045539021854
training  [-1.6706, 2.0672, -0.8657]  w:  [1.34704957 0.41330695 1.23682914]
-2.4667158711970725  -  32.4185  =  -34.885215871197076
training  [-0.3293, 0.5779, -2.8227]  w:  [1.34704957 0.41330695 1.23682914]
-3.6959309380292362  -  14.3434  =  -18.039330938029238
training  [1.482, -1.8657, -3.7435]  w:  [1.34704957 0.41330695 1.23682914]
-3.404849176762325  -  7.1519  =  -10.556749176762326
training  [-4.7477, -3.338, -1.9109]  w:  [1.34704957 0.41330695 1.23682914]
-10.138462608745272  -  0.4077  =  -10.546162608745272
training  [3.4221, 1.225, 2.261]  w:  [1.34704957 0.41330695 1.23682914]
7.912510006566285  -  95.0454  =  -87.13288999343372
training  [0.5903, 4.8793, 2.8287]  w:  [1.34704957 0.41330695 1.23682914]
6.310430513439412  -  97.4647  =  -91.15426948656058
training  [3.541, -3.2957, 1.9379]  w:  [1.34704957 0.41330695 1.23682914]
5.804617997582023  -  64.3732  =  -58.568582002417976
training  [-1.5212, -2.4221, -4.902]  w:  [1.34704957 0.41330695 1.23682914]
-9.113138974438167  -  0.7227  =  -9.835838974438166
training  [-0.5397, -1.032, 3.4321]  w:  [1.34704957 0.41330695 1.23682914]
3.091385855010585  -  60.5921  =  -57.500714144989416
training  [-4.4576, -4.2601, 4.2233]  w:  [1.34704957 0.41330695 1.23682914]
-2.54183658381607  -  6.0247  =  -8.56653658381607
training  [-3.2289, 1.841, 2.7095]  w:  [1.34704957 0.41330695 1.23682914]
-0.23740171934868082  -  54.0111  =  -54.24850171934868
training  [1.6281, -0.9761, -4.5734]  w:  [1.34704957 0.41330695 1.23682914]
-3.8668118753344523  -  7.8658  =  -11.732611875334452
training  [-1.6917, 4.8284, -1.2181]  w:  [1.34704957 0.41330695 1.23682914]
-1.7897740660384982  -  61.2837  =  -63.0734740660385
training  [3.9849, -0.9782, 2.0434]  w:  [1.34704957 0.41330695 1.23682914]
7.490897620649143  -  88.3402  =  -80.84930237935086
training  [-3.8184, 1.2067, 2.2951]  w:  [1.34704957 0.41330695 1.23682914]
-1.8061900283637562  -  34.1122  =  -35.91839002836376
training  [4.8842, -3.4563, -2.7572]  w:  [1.34704957 0.41330695 1.23682914]
1.740561408961471  -  23.7819  =  -22.041338591038528
training  [0.3998, -1.1865, -2.3095]  w:  [1.34704957 0.41330695 1.23682914]
-2.808295161317665  -  11.4246  =  -14.232895161317664
training  [2.0692, -3.3887, 1.7303]  w:  [1.34704957 0.41330695 1.23682914]
3.526827170202348  -  42.6881  =  -39.16127282979765
training  [4.9949, 2.5811, -0.2251]  w:  [1.34704957 0.41330695 1.23682914]
7.516754202230389  -  95.9901  =  -88.47334579776961
training  [-2.1215, 3.7111, 1.2372]  w:  [1.34704957 0.41330695 1.23682914]
0.206262754861958  -  71.3692  =  -71.16293724513805
training  [-0.8548, -1.4922, -2.6356]  w:  [1.34704957 0.41330695 1.23682914]
-5.027981462530948  -  4.7821  =  -9.810081462530949
training  [-0.3516, 1.8554, -3.2288]  w:  [1.34704957 0.41330695 1.23682914]
-3.70024683209716  -  20.3834  =  -24.083646832097163
training  [2.6396, -2.0585, 3.2964]  w:  [1.34704957 0.41330695 1.23682914]
6.781963250731101  -  80.826  =  -74.0440367492689
training  [3.182, 0.3063, 2.6692]  w:  [1.34704957 0.41330695 1.23682914]
7.714251967467192  -  92.9483  =  -85.23404803253281
training  [-3.9978, 3.3242, 4.3448]  w:  [1.34704957 0.41330695 1.23682914]
1.362455414646723  -  79.1768  =  -77.81434458535328
training  [-3.2188, 0.9749, -3.9211]  w:  [1.34704957 0.41330695 1.23682914]
-8.782680926958964  -  2.7053  =  -11.487980926958963
training  [-1.4037, -1.6469, -3.1777]  w:  [1.34704957 0.41330695 1.23682914]
-6.501800628546828  -  2.6234  =  -9.125200628546828
training  [-4.433, -2.0077, -4.009]  w:  [1.34704957 0.41330695 1.23682914]
-11.759715088388289  -  0.3253  =  -12.085015088388289
training  [0.2189, -0.4741, -0.1024]  w:  [1.34704957 0.41330695 1.23682914]
-0.02773097607694308  -  33.6531  =  -33.68083097607695
training  [-1.6415, -0.7735, -3.0675]  w:  [1.34704957 0.41330695 1.23682914]
-6.324848158656457  -  3.7641  =  -10.088948158656457
training  [-3.2433, -1.4039, 3.9589]  w:  [1.34704957 0.41330695 1.23682914]
-0.05264461962141809  -  30.0658  =  -30.118444619621418
training  [-2.9105, 0.5832, -4.0091]  w:  [1.34704957 0.41330695 1.23682914]
-8.638118839865827  -  2.4887  =  -11.126818839865827
training  [4.0515, 2.4255, -4.5583]  w:  [1.34704957 0.41330695 1.23682914]
0.8222090719356556  -  61.2853  =  -60.46309092806435
training  [1.7539, -0.7567, 0.573]  w:  [1.34704957 0.41330695 1.23682914]
2.7585439645417553  -  57.0797  =  -54.321156035458245
training  [-0.3153, -0.7064, 2.725]  w:  [1.34704957 0.41330695 1.23682914]
2.6536746380089147  -  58.7004  =  -56.046725361991086
training  [4.1213, -3.7513, -1.8806]  w:  [1.34704957 0.41330695 1.23682914]
1.6751761649456798  -  22.1789  =  -20.50372383505432
training  [-3.9599, -4.7557, -3.2102]  w:  [1.34704957 0.41330695 1.23682914]
-11.270214311617345  -  0.1558  =  -11.426014311617344
training  [2.4555, -2.0981, -1.6104]  w:  [1.34704957 0.41330695 1.23682914]
0.4487312706572124  -  24.4796  =  -24.03086872934279
training  [2.3627, -1.8248, -2.8985]  w:  [1.34704957 0.41330695 1.23682914]
-1.1564777497616796  -  15.7052  =  -16.86167774976168
training  [0.6186, 1.5369, 0.1015]  w:  [1.34704957 0.41330695 1.23682914]
1.5940344641773976  -  65.2154  =  -63.621365535822605
training  [-3.1581, 4.5694, 4.0636]  w:  [1.34704957 0.41330695 1.23682914]
2.6604263921280067  -  90.3564  =  -87.69597360787199
training  [0.9721, 4.3573, 1.2892]  w:  [1.34704957 0.41330695 1.23682914]
4.704889359230982  -  94.3178  =  -89.61291064076903
training  [-2.0006, -0.4211, -3.9847]  w:  [1.34704957 0.41330695 1.23682914]
-7.797343973245803  -  2.4051  =  -10.202443973245803
training  [-3.6588, -2.5952, -1.0915]  w:  [1.34704957 0.41330695 1.23682914]
-7.351198142588786  -  1.5176  =  -8.868798142588787
training  [-2.874, 2.639, -4.4538]  w:  [1.34704957 0.41330695 1.23682914]
-8.289293028228908  -  5.497  =  -13.786293028228908
training  [3.9494, 2.5933, 0.0128]  w:  [1.34704957 0.41330695 1.23682914]
6.407697875677348  -  94.1462  =  -87.73850212432265
training  [-4.2855, 2.4065, -0.6828]  w:  [1.34704957 0.41330695 1.23682914]
-5.622664689036  -  14.4193  =  -20.041964689036
training  [-2.5751, 2.4369, 4.9756]  w:  [1.34704957 0.41330695 1.23682914]
3.692367399438928  -  87.1991  =  -83.50673260056108
training  [-4.4625, -3.9408, 3.116]  w:  [1.34704957 0.41330695 1.23682914]
-3.7860091201687562  -  4.1344  =  -7.920409120168756
training  [-0.5828, 1.8156, -0.1435]  w:  [1.34704957 0.41330695 1.23682914]
-0.21214537819870377  -  51.1166  =  -51.328745378198704
training  [-4.8672, -0.3674, 3.9445]  w:  [1.34704957 0.41330695 1.23682914]
-1.829536102225327  -  24.1396  =  -25.969136102225328
training  [3.9719, -2.8784, -3.6245]  w:  [1.34704957 0.41330695 1.23682914]
-0.3222037361327734  -  14.6104  =  -14.932603736132773
training  [-3.0334, -4.0148, -1.1]  w:  [1.34704957 0.41330695 1.23682914]
-7.105996930890066  -  1.021  =  -8.126996930890066
training  [-4.0663, 3.2357, 4.2736]  w:  [1.34704957 0.41330695 1.23682914]
1.14554262019396  -  77.2328  =  -76.08725737980603
training  [-1.9263, -3.2499, 4.1749]  w:  [1.34704957 0.41330695 1.23682914]
1.225610131959729  -  26.8814  =  -25.65578986804027
training  [-0.4394, -3.3643, 2.1357]  w:  [1.34704957 0.41330695 1.23682914]
0.6591138467272506  -  20.85  =  -20.19088615327275
training  [-3.9833, 1.6599, 1.1834]  w:  [1.34704957 0.41330695 1.23682914]
-3.215990743646296  -  25.5397  =  -28.755690743646294
training  [4.9539, 3.9439, -1.5671]  w:  [1.34704957 0.41330695 1.23682914]
6.364955176252687  -  95.9509  =  -89.58594482374731
training  [-1.6791, 0.1656, 4.3603]  w:  [1.34704957 0.41330695 1.23682914]
3.199558779321269  -  71.5733  =  -68.37374122067874
training  [-2.0265, 2.027, -3.7523]  w:  [1.34704957 0.41330695 1.23682914]
-6.532976732520512  -  8.503  =  -15.035976732520513
training  [-4.3795, -3.4641, 2.3059]  w:  [1.34704957 0.41330695 1.23682914]
-4.479135867398659  -  3.6654  =  -8.144535867398659
training  [-2.0176, 4.5346, 1.4648]  w:  [1.34704957 0.41330695 1.23682914]
0.9680817857307884  -  81.6212  =  -80.65311821426921
training  [-4.5365, 0.4088, 3.3315]  w:  [1.34704957 0.41330695 1.23682914]
-1.821434218938193  -  28.9449  =  -30.766334218938194
training  [0.0543, 1.7973, -1.0172]  w:  [1.34704957 0.41330695 1.23682914]
-0.44212123130374514  -  47.9317  =  -48.373821231303744
training  [2.6143, -4.6344, 2.4982]  w:  [1.34704957 0.41330695 1.23682914]
4.6960085199234785  -  43.5132  =  -38.81719148007652
training  [1.3107, 3.092, 3.3522]  w:  [1.34704957 0.41330695 1.23682914]
7.189621569952631  -  96.6993  =  -89.50967843004736
training  [-4.1011, 2.4862, -1.7754]  w:  [1.34704957 0.41330695 1.23682914]
-6.692687698199654  -  10.0187  =  -16.711387698199655
training  [-4.1914, -3.7981, 0.5226]  w:  [1.34704957 0.41330695 1.23682914]
-6.569437760117677  -  1.4295  =  -7.998937760117677
training  [2.7724, 0.2505, 4.7913]  w:  [1.34704957 0.41330695 1.23682914]
9.764113044597773  -  96.7925  =  -87.02838695540223
training  [4.0513, -1.7417, 0.4931]  w:  [1.34704957 0.41330695 1.23682914]
5.347325650923046  -  71.1234  =  -65.77607434907696
training  [0.3377, 0.4645, -1.6958]  w:  [1.34704957 0.41330695 1.23682914]
-1.450535132085192  -  27.9534  =  -29.40393513208519
training  [-3.9085, -1.0112, 1.1947]  w:  [1.34704957 0.41330695 1.23682914]
-4.205239449201621  -  8.608  =  -12.813239449201621
training  [3.2581, -0.8491, -1.3936]  w:  [1.34704957 0.41330695 1.23682914]
2.3142381848275098  -  50.1924  =  -47.87816181517249
training  [-1.619, -3.1926, 2.5651]  w:  [1.34704957 0.41330695 1.23682914]
-0.3278065896075786  -  16.4754  =  -16.80320658960758
training  [-2.0603, -2.4461, -0.861]  w:  [1.34704957 0.41330695 1.23682914]
-4.851226228204158  -  3.9784  =  -8.829626228204159
training  [2.4631, -4.7946, -0.0765]  w:  [1.34704957 0.41330695 1.23682914]
1.241658878745773  -  15.394  =  -14.152341121254228
training  [-4.8966, 4.2368, 1.9474]  w:  [1.34704957 0.41330695 1.23682914]
-2.4362629860869305  -  53.5883  =  -56.02456298608693
training  [-4.5155, 1.537, 4.7273]  w:  [1.34704957 0.41330695 1.23682914]
0.3995128246635833  -  59.2523  =  -58.85278717533642
training  [1.6792, 4.3261, -1.7225]  w:  [1.34704957 0.41330695 1.23682914]
1.9195346255634917  -  83.7729  =  -81.85336537443652
training  [1.0347, -3.3649, 3.378]  w:  [1.34704957 0.41330695 1.23682914]
4.181064464005824  -  50.5979  =  -46.41683553599418
training  [0.261, 4.211, 2.3907]  w:  [1.34704957 0.41330695 1.23682914]
5.0489028980734  -  94.9375  =  -89.8885971019266
training  [2.2971, 2.9466, 4.5417]  w:  [1.34704957 0.41330695 1.23682914]
9.92946468925388  -  98.7784  =  -88.84893531074613
training  [2.0725, 0.7739, -4.6808]  w:  [1.34704957 0.41330695 1.23682914]
-2.677731341960364  -  19.5109  =  -22.188631341960363
training  [2.8138, -0.5996, -1.4313]  w:  [1.34704957 0.41330695 1.23682914]
1.772235686657931  -  47.2879  =  -45.51566431334207
training  [-2.1202, -2.4239, 1.6265]  w:  [1.34704957 0.41330695 1.23682914]
-1.846126609730066  -  12.3599  =  -14.206026609730065
training  [1.9253, 2.5195, -2.185]  w:  [1.34704957 0.41330695 1.23682914]
0.9323297211747144  -  65.2467  =  -64.3143702788253
training  [0.5667, -2.7133, -2.6962]  w:  [1.34704957 0.41330695 1.23682914]
-3.6927914596140052  -  5.1106  =  -8.803391459614005
training  [-1.0348, -4.3581, 2.1113]  w:  [1.34704957 0.41330695 1.23682914]
-0.5838425390226334  -  10.5192  =  -11.103042539022633
training  [-4.3841, 2.6733, 1.2457]  w:  [1.34704957 0.41330695 1.23682914]
-3.2599884963924706  -  32.4639  =  -35.723888496392476
training  [2.8018, 1.712, 0.9061]  w:  [1.34704957 0.41330695 1.23682914]
5.6024358475048555  -  90.1138  =  -84.51136415249515
training  [-1.6242, 2.1521, 1.6044]  w:  [1.34704957 0.41330695 1.23682914]
0.685968634810818  -  63.7879  =  -63.10193136518918
training  [1.0787, 1.4206, -4.5245]  w:  [1.34704957 0.41330695 1.23682914]
-3.555827206319589  -  18.0555  =  -21.611327206319586
training  [2.4125, -0.8095, -1.5122]  w:  [1.34704957 0.41330695 1.23682914]
1.0448520904339584  -  38.8276  =  -37.78274790956604
training  [-3.9519, -1.0924, -0.4866]  w:  [1.34704957 0.41330695 1.23682914]
-6.376742749107031  -  3.6777  =  -10.05444274910703
training  [-3.7211, 3.1614, -2.591]  w:  [1.34704957 0.41330695 1.23682914]
-6.910501855510257  -  11.1518  =  -18.062301855510256
training  [0.4954, -1.8257, 2.1505]  w:  [1.34704957 0.41330695 1.23682914]
2.5725549198555493  -  47.7531  =  -45.180545080144455
training  [-0.1477, 3.1454, 3.5618]  w:  [1.34704957 0.41330695 1.23682914]
5.50639445873964  -  94.1572  =  -88.65080554126037
training  [3.9048, 2.8907, -2.1849]  w:  [1.34704957 0.41330695 1.23682914]
3.7523575605744175  -  85.8791  =  -82.12674243942557
training  [2.9896, 3.5226, 2.3105]  w:  [1.34704957 0.41330695 1.23682914]
8.340748149158589  -  98.038  =  -89.69725185084141
training  [2.3434, 0.0564, -3.6224]  w:  [1.34704957 0.41330695 1.23682914]
-1.3003033911744417  -  24.7629  =  -26.06320339117444
training  [-4.4867, 1.3566, 3.3672]  w:  [1.34704957 0.41330695 1.23682914]
-1.318464027326149  -  40.5785  =  -41.89696402732615
training  [-4.2711, 4.5089, -3.614]  w:  [1.34704957 0.41330695 1.23682914]
-8.359724213391075  -  10.0825  =  -18.442224213391075
training  [-4.1147, -0.5604, 0.8821]  w:  [1.34704957 0.41330695 1.23682914]
-4.6833150864862585  -  8.344  =  -13.027315086486258
training  [2.9835, -4.3998, -1.3384]  w:  [1.34704957 0.41330695 1.23682914]
0.5450823701640213  -  13.2692  =  -12.724117629835979
training  [4.4301, 3.6675, 3.0676]  w:  [1.34704957 0.41330695 1.23682914]
11.277464565254116  -  99.3834  =  -88.10593543474587
training  [1.8372, 1.3119, 0.0378]  w:  [1.34704957 0.41330695 1.23682914]
3.0637689881083845  -  74.9026  =  -71.83883101189163
training  [-3.6792, -1.4493, -0.1041]  w:  [1.34704957 0.41330695 1.23682914]
-5.683824436873286  -  4.2442  =  -9.928024436873287
training  [2.2272, 4.97, 3.7705]  w:  [1.34704957 0.41330695 1.23682914]
9.717748569319479  -  99.3199  =  -89.60215143068052
training  [-3.8965, -2.7583, -1.4686]  w:  [1.34704957 0.41330695 1.23682914]
-8.205210454356386  -  1.0337  =  -9.238910454356386
training  [-3.8251, 1.5245, -0.5056]  w:  [1.34704957 0.41330695 1.23682914]
-5.147853671595158  -  12.9762  =  -18.124053671595156
training  [1.4072, 1.0499, 4.6353]  w:  [1.34704957 0.41330695 1.23682914]
8.062573202707464  -  95.4618  =  -87.39922679729253
training  [-1.7119, -1.1275, -4.577]  w:  [1.34704957 0.41330695 1.23682914]
-8.432984686241529  -  1.4655  =  -9.89848468624153
training  [1.5381, -3.5781, 4.7296]  w:  [1.34704957 0.41330695 1.23682914]
6.442750434222604  -  69.9473  =  -63.504549565777396
training  [2.4913, -4.7487, -3.1079]  w:  [1.34704957 0.41330695 1.23682914]
-2.4507073745491255  -  3.9825  =  -6.433207374549125
training  [0.8319, -0.7889, 1.6712]  w:  [1.34704957 0.41330695 1.23682914]
2.861541536009237  -  58.8336  =  -55.97205846399076
training  [2.4003, -3.159, 0.8644]  w:  [1.34704957 0.41330695 1.23682914]
2.9968015392967375  -  39.0041  =  -36.00729846070326
training  [-2.6517, 2.2578, 1.7511]  w:  [1.34704957 0.41330695 1.23682914]
-0.47299541723206495  -  54.4525  =  -54.925495417232064
training  [2.3496, -1.2964, -1.3898]  w:  [1.34704957 0.41330695 1.23682914]
0.910271406967629  -  33.888  =  -32.97772859303237
training  [4.706, 3.4156, 1.2028]  w:  [1.34704957 0.41330695 1.23682914]
9.238564550265755  -  98.4665  =  -89.22793544973425
training  [3.6693, 2.3423, 3.1115]  w:  [1.34704957 0.41330695 1.23682914]
9.759211689236887  -  98.3069  =  -88.5476883107631
training  [-4.1377, 0.7103, -4.8074]  w:  [1.34704957 0.41330695 1.23682914]
-11.226047454435012  -  0.9782  =  -12.204247454435011
training  [-1.3356, -3.2314, -4.1613]  w:  [1.34704957 0.41330695 1.23682914]
-8.281496545536424  -  0.7659  =  -9.047396545536424
training  [-1.308, 4.5738, 4.748]  w:  [1.34704957 0.41330695 1.23682914]
6.000907206976246  -  97.0884  =  -91.08749279302374
training  [1.8503, -2.3468, 1.5135]  w:  [1.34704957 0.41330695 1.23682914]
3.394437970096571  -  50.2125  =  -46.81806202990343
training  [0.9794, 4.2458, -2.6876]  w:  [1.34704957 0.41330695 1.23682914]
-0.2499830075027467  -  68.3262  =  -68.57618300750275
training  [2.8936, -2.7623, -0.9651]  w:  [1.34704957 0.41330695 1.23682914]
1.5624810536042797  -  28.5596  =  -26.99711894639572
training  [-1.3235, -1.2644, -3.7798]  w:  [1.34704957 0.41330695 1.23682914]
-6.980372168757241  -  2.4511  =  -9.43147216875724
training  [-2.9397, -4.125, -2.3156]  w:  [1.34704957 0.41330695 1.23682914]
-8.528814308376738  -  0.554  =  -9.082814308376738
training  [-4.1333, 1.4012, -2.4215]  w:  [1.34704957 0.41330695 1.23682914]
-7.983616034380992  -  4.4072  =  -12.390816034380991
training  [2.7193, -3.1938, -1.6833]  w:  [1.34704957 0.41330695 1.23682914]
0.26105768224209625  -  17.0949  =  -16.833842317757902
training  [-2.9433, -4.5495, -3.4777]  w:  [1.34704957 0.41330695 1.23682914]
-10.146431623032669  -  0.2509  =  -10.397331623032668
training  [-1.1173, 2.2317, -1.5199]  w:  [1.34704957 0.41330695 1.23682914]
-2.4625379732405  -  33.1206  =  -35.583137973240504
training  [0.5178, -1.5256, -3.7834]  w:  [1.34704957 0.41330695 1.23682914]
-4.612458159745624  -  5.237  =  -9.849458159745623
training  [-2.7105, 1.6062, 3.8415]  w:  [1.34704957 0.41330695 1.23682914]
1.763954886301116  -  70.4458  =  -68.68184511369888
training  [1.4194, -1.1613, -4.0572]  w:  [1.34704957 0.41330695 1.23682914]
-3.586034366839564  -  8.3206  =  -11.906634366839565
training  [-0.1552, 1.2735, 4.3004]  w:  [1.34704957 0.41330695 1.23682914]
5.636144314630274  -  90.1085  =  -84.47235568536973
training  [-3.4815, -4.7835, -1.0098]  w:  [1.34704957 0.41330695 1.23682914]
-7.9157569030620945  -  0.5839  =  -8.499656903062094
training  [2.8193, 4.1057, -4.526]  w:  [1.34704957 0.41330695 1.23682914]
-0.10323749370322055  -  66.8081  =  -66.91133749370321
training  [-3.9939, 3.0056, -1.5763]  w:  [1.34704957 0.41330695 1.23682914]
-6.0873596762658035  -  14.4018  =  -20.489159676265803
training  [-2.0593, 2.4585, 2.3597]  w:  [1.34704957 0.41330695 1.23682914]
1.160681661933683  -  70.6698  =  -69.50911833806632
training  [-2.6263, 3.1311, 2.9468]  w:  [1.34704957 0.41330695 1.23682914]
1.4010371941133872  -  77.309  =  -75.90796280588661
training  [0.3087, -1.1669, 0.4491]  w:  [1.34704957 0.41330695 1.23682914]
0.4890062911044915  -  33.0798  =  -32.590793708895504
training  [-4.085, 1.1728, 1.8622]  w:  [1.34704957 0.41330695 1.23682914]
-2.7147478809852332  -  26.4056  =  -29.120347880985232
training  [-0.9468, 0.7549, 3.9363]  w:  [1.34704957 0.41330695 1.23682914]
3.9051494071815744  -  79.7738  =  -75.86865059281843
training  [-3.9515, 0.3005, -4.4521]  w:  [1.34704957 0.41330695 1.23682914]
-10.70515461965932  -  1.0441  =  -11.74925461965932
training  [-3.8772, -2.2493, -1.9634]  w:  [1.34704957 0.41330695 1.23682914]
-8.580822218402869  -  1.0509  =  -9.631722218402869
training  [2.8443, -2.5137, -4.5381]  w:  [1.34704957 0.41330695 1.23682914]
-2.8203708828002103  -  6.8897  =  -9.71007088280021
training  [-2.0843, -0.4836, -3.0452]  w:  [1.34704957 0.41330695 1.23682914]
-6.773922733771681  -  3.5346  =  -10.308522733771682
training  [1.0353, -2.7229, 2.2017]  w:  [1.34704957 0.41330695 1.23682914]
2.9923336413035218  -  43.9562  =  -40.96386635869648
training  [4.6442, 3.0445, 2.2175]  w:  [1.34704957 0.41330695 1.23682914]
10.256949202800993  -  98.8492  =  -88.592250797199
training  [-0.6752, 4.861, 3.778]  w:  [1.34704957 0.41330695 1.23682914]
5.772297666912594  -  97.017  =  -91.2447023330874
training  [1.9475, -4.7001, 0.8243]  w:  [1.34704957 0.41330695 1.23682914]
1.700313313080067  -  18.7839  =  -17.083586686919933
training  [2.581, 0.3566, -4.2932]  w:  [1.34704957 0.41330695 1.23682914]
-1.6858346527062769  -  23.5455  =  -25.231334652706277
training  [-0.6736, -4.1292, 4.2274]  w:  [1.34704957 0.41330695 1.23682914]
2.614571857111497  -  31.2667  =  -28.652128142888504
training  [1.555, 3.0209, 3.0037]  w:  [1.34704957 0.41330695 1.23682914]
7.058284701833877  -  96.4078  =  -89.34951529816612
training  [-3.9024, 4.8914, -2.1405]  w:  [1.34704957 0.41330695 1.23682914]
-5.882509400820382  -  25.4308  =  -31.313309400820383
training  [4.3376, -4.3305, 0.4366]  w:  [1.34704957 0.41330695 1.23682914]
4.593136075100191  -  43.0907  =  -38.49756392489981
training  [-3.1254, 4.394, 4.8478]  w:  [1.34704957 0.41330695 1.23682914]
3.601902282397314  -  92.8121  =  -89.21019771760268
training  [-2.3382, -4.8182, 2.1568]  w:  [1.34704957 0.41330695 1.23682914]
-2.473473744944282  -  4.7434  =  -7.216873744944282
training  [2.9783, 1.8384, 3.3897]  w:  [1.34704957 0.41330695 1.23682914]
8.964220933771172  -  97.3486  =  -88.38437906622883
training  [-0.124, 2.8374, -0.6674]  w:  [1.34704957 0.41330695 1.23682914]
0.18022321641796035  -  62.785  =  -62.60477678358204
training  [2.6896, 0.3414, -0.2938]  w:  [1.34704957 0.41330695 1.23682914]
3.400747107309365  -  70.4455  =  -67.04475289269062
training  [-1.0399, 3.8536, 0.6071]  w:  [1.34704957 0.41330695 1.23682914]
0.9428017685222045  -  77.0369  =  -76.0940982314778
training  [-2.2706, 3.99, -2.3091]  w:  [1.34704957 0.41330695 1.23682914]
-4.265478189992503  -  31.1134  =  -35.378878189992506
training  [-4.6277, 1.2594, 2.4902]  w:  [1.34704957 0.41330695 1.23682914]
-2.6332706028253003  -  28.1093  =  -30.742570602825303
training  [1.7329, -3.6213, 0.0389]  w:  [1.34704957 0.41330695 1.23682914]
0.8857064062349279  -  19.3919  =  -18.506193593765072
training  [-0.7044, -2.822, 1.4681]  w:  [1.34704957 0.41330695 1.23682914]
-0.29942506251731893  -  17.8122  =  -18.11162506251732
training  [-0.4826, -3.1786, -1.9225]  w:  [1.34704957 0.41330695 1.23682914]
-4.341627590506605  -  3.5851  =  -7.926727590506605
training  [1.0986, -4.5818, -3.6128]  w:  [1.34704957 0.41330695 1.23682914]
-4.882237407840952  -  1.7158  =  -6.598037407840952
training  [-4.406, -3.9306, -0.2443]  w:  [1.34704957 0.41330695 1.23682914]
-7.861802031177346  -  0.8241  =  -8.685902031177346
training  [-1.8419, 1.1644, -1.3754]  w:  [1.34704957 0.41330695 1.23682914]
-3.7010107826704477  -  17.8517  =  -21.55271078267045
training  [2.7272, 4.3966, 2.8811]  w:  [1.34704957 0.41330695 1.23682914]
9.054247317625391  -  98.904  =  -89.8497526823746
training  [1.9643, -1.4554, 2.803]  w:  [1.34704957 0.41330695 1.23682914]
5.511314601676309  -  76.0591  =  -70.5477853983237
training  [-3.7467, -0.8937, 1.6851]  w:  [1.34704957 0.41330695 1.23682914]
-3.332182255306787  -  12.1571  =  -15.489282255306787
training  [-3.6985, 4.8435, -3.665]  w:  [1.34704957 0.41330695 1.23682914]
-7.513189413097133  -  14.6793  =  -22.19248941309713
254358.6795263879
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.35697928 0.42696507 1.18696594]
9.626676992965518  -  87.3174  =  -77.69072300703449
training  [-4.1793, -4.9218, 1.7664]  w:  [1.35697928 0.42696507 1.18696594]
-5.676003547585751  -  1.5257  =  -7.201703547585751
training  [-3.9429, -0.7689, 4.883]  w:  [1.35697928 0.42696507 1.18696594]
0.1172276611956633  -  39.7859  =  -39.668672338804335
training  [-3.5796, 1.5557, 2.6683]  w:  [1.35697928 0.42696507 1.18696594]
-1.0260322293499704  -  45.5674  =  -46.59343222934997
training  [-3.3354, 2.2292, -1.633]  w:  [1.35697928 0.42696507 1.18696594]
-5.512593518696329  -  13.3589  =  -18.87149351869633
training  [1.2096, 0.3121, 1.6238]  w:  [1.35697928 0.42696507 1.18696594]
3.702053228126707  -  74.5119  =  -70.8098467718733
training  [0.7371, -3.9118, -2.5583]  w:  [1.35697928 0.42696507 1.18696594]
-3.706587518968014  -  3.3358  =  -7.042387518968014
training  [-4.4792, 1.3177, -2.0449]  w:  [1.35697928 0.42696507 1.18696594]
-7.9427963506038335  -  4.2974  =  -12.240196350603833
training  [4.312, -3.735, 1.8018]  w:  [1.35697928 0.42696507 1.18696594]
6.395255323073427  -  66.5833  =  -60.188044676926566
training  [2.2866, -3.657, 0.2785]  w:  [1.35697928 0.42696507 1.18696594]
1.872027553822608  -  26.0005  =  -24.12847244617739
training  [2.3784, -4.0141, -0.8841]  w:  [1.35697928 0.42696507 1.18696594]
0.46416241966944893  -  14.6809  =  -14.21673758033055
training  [-4.366, -3.5797, 1.0264]  w:  [1.35697928 0.42696507 1.18696594]
-6.234676550270076  -  1.8713  =  -8.105976550270077
training  [3.6044, -3.3175, 2.5052]  w:  [1.35697928 0.42696507 1.18696594]
6.44822654896001  -  71.0139  =  -64.56567345104
training  [4.3441, -3.0375, 0.8353]  w:  [1.35697928 0.42696507 1.18696594]
5.589419913814804  -  63.8979  =  -58.3084800861852
training  [4.844, -1.8252, 0.5179]  w:  [1.35697928 0.42696507 1.18696594]
6.408640622574903  -  78.0461  =  -71.63745937742509
training  [3.5894, -1.8357, 0.8357]  w:  [1.35697928 0.42696507 1.18696594]
5.078909065823331  -  68.8838  =  -63.80489093417666
training  [2.8556, -2.8244, 0.1182]  w:  [1.35697928 0.42696507 1.18696594]
2.809369241622705  -  39.5252  =  -36.715830758377294
training  [0.1338, -2.4896, -4.1741]  w:  [1.35697928 0.42696507 1.18696594]
-5.835922957535622  -  2.2644  =  -8.100322957535623
training  [-3.224, 3.9292, 2.1957]  w:  [1.35697928 0.42696507 1.18696594]
-0.0910489009823956  -  72.1211  =  -72.2121489009824
training  [-1.0141, 2.0322, 4.9616]  w:  [1.35697928 0.42696507 1.18696594]
5.38081595536445  -  92.3427  =  -86.96188404463554
training  [-3.6607, 0.5574, -1.4547]  w:  [1.35697928 0.42696507 1.18696594]
-6.456183059618881  -  5.8471  =  -12.303283059618881
training  [-4.6911, -3.1557, 4.7126]  w:  [1.35697928 0.42696507 1.18696594]
-2.1194034670355  -  11.2337  =  -13.3531034670355
training  [4.3914, -2.8797, -1.5355]  w:  [1.35697928 0.42696507 1.18696594]
2.906921267299423  -  37.475  =  -34.56807873270058
training  [-1.9869, -4.2265, 3.8654]  w:  [1.35697928 0.42696507 1.18696594]
0.08734814479749087  -  15.7889  =  -15.70155185520251
training  [-2.0447, 4.138, -0.4531]  w:  [1.35697928 0.42696507 1.18696594]
-1.5456483200354474  -  57.936  =  -59.48164832003545
training  [-1.6706, 2.0672, -0.8657]  w:  [1.35697928 0.42696507 1.18696594]
-2.411903794594436  -  32.4185  =  -34.83040379459444
training  [-0.3293, 0.5779, -2.8227]  w:  [1.35697928 0.42696507 1.18696594]
-3.5505589236355104  -  14.3434  =  -17.893958923635513
training  [1.482, -1.8657, -3.7435]  w:  [1.35697928 0.42696507 1.18696594]
-3.228952453613248  -  7.1519  =  -10.380852453613247
training  [-4.7477, -3.338, -1.9109]  w:  [1.35697928 0.42696507 1.18696594]
-10.13591314260792  -  0.4077  =  -10.54361314260792
training  [3.4221, 1.225, 2.261]  w:  [1.35697928 0.42696507 1.18696594]
7.850480990193752  -  95.0454  =  -87.19491900980626
training  [0.5903, 4.8793, 2.8287]  w:  [1.35697928 0.42696507 1.18696594]
6.241886109313773  -  97.4647  =  -91.22281389068623
training  [3.541, -3.2957, 1.9379]  w:  [1.35697928 0.42696507 1.18696594]
5.698136122662222  -  64.3732  =  -58.67506387733778
training  [-1.5212, -2.4221, -4.902]  w:  [1.35697928 0.42696507 1.18696594]
-8.916896026067384  -  0.7227  =  -9.639596026067384
training  [-0.5397, -1.032, 3.4321]  w:  [1.35697928 0.42696507 1.18696594]
2.9007961377883893  -  60.5921  =  -57.69130386221161
training  [-4.4576, -4.2601, 4.2233]  w:  [1.35697928 0.42696507 1.18696594]
-2.8548714685453866  -  6.0247  =  -8.879571468545386
training  [-3.2289, 1.841, 2.7095]  w:  [1.35697928 0.42696507 1.18696594]
-0.3794234649575432  -  54.0111  =  -54.39052346495754
training  [1.6281, -0.9761, -4.5734]  w:  [1.35697928 0.42696507 1.18696594]
-3.6359326871296327  -  7.8658  =  -11.501732687129632
training  [-1.6917, 4.8284, -1.2181]  w:  [1.35697928 0.42696507 1.18696594]
-1.6798868943394294  -  61.2837  =  -62.963586894339436
training  [3.9849, -0.9782, 2.0434]  w:  [1.35697928 0.42696507 1.18696594]
7.41521568796122  -  88.3402  =  -80.92498431203877
training  [-3.8184, 1.2067, 2.2951]  w:  [1.35697928 0.42696507 1.18696594]
-1.9420653806120751  -  34.1122  =  -36.05426538061208
training  [4.8842, -3.4563, -2.7572]  w:  [1.35697928 0.42696507 1.18696594]
1.8793363020716827  -  23.7819  =  -21.90256369792832
training  [0.3998, -1.1865, -2.3095]  w:  [1.35697928 0.42696507 1.18696594]
-2.705371587729748  -  11.4246  =  -14.129971587729749
training  [2.0692, -3.3887, 1.7303]  w:  [1.35697928 0.42696507 1.18696594]
3.4148121427480946  -  42.6881  =  -39.2732878572519
training  [4.9949, 2.5811, -0.2251]  w:  [1.35697928 0.42696507 1.18696594]
7.612829303816494  -  95.9901  =  -88.3772706961835
training  [-2.1215, 3.7111, 1.2372]  w:  [1.35697928 0.42696507 1.18696594]
0.1741928131538999  -  71.3692  =  -71.19500718684611
training  [-0.8548, -1.4922, -2.6356]  w:  [1.35697928 0.42696507 1.18696594]
-4.925430604109546  -  4.7821  =  -9.707530604109547
training  [-0.3516, 1.8554, -3.2288]  w:  [1.35697928 0.42696507 1.18696594]
-3.5173985491020145  -  20.3834  =  -23.900798549102017
training  [2.6396, -2.0585, 3.2964]  w:  [1.35697928 0.42696507 1.18696594]
6.615689424055388  -  80.826  =  -74.2103105759446
training  [3.182, 0.3063, 2.6692]  w:  [1.35697928 0.42696507 1.18696594]
7.616936950453059  -  92.9483  =  -85.33136304954695
training  [-3.9978, 3.3242, 4.3448]  w:  [1.35697928 0.42696507 1.18696594]
1.1515151712892289  -  79.1768  =  -78.02528482871077
training  [-3.2188, 0.9749, -3.9211]  w:  [1.35697928 0.42696507 1.18696594]
-8.605808798243247  -  2.7053  =  -11.311108798243247
training  [-1.4037, -1.6469, -3.1777]  w:  [1.35697928 0.42696507 1.18696594]
-6.379782262686622  -  2.6234  =  -9.003182262686622
training  [-4.433, -2.0077, -4.009]  w:  [1.35697928 0.42696507 1.18696594]
-11.63125336971142  -  0.3253  =  -11.95655336971142
training  [0.2189, -0.4741, -0.1024]  w:  [1.35697928 0.42696507 1.18696594]
-0.02692669023927513  -  33.6531  =  -33.68002669023928
training  [-1.6415, -0.7735, -3.0675]  w:  [1.35697928 0.42696507 1.18696594]
-6.198756992580922  -  3.7641  =  -9.962856992580921
training  [-3.2433, -1.4039, 3.9589]  w:  [1.35697928 0.42696507 1.18696594]
-0.3014276857403182  -  30.0658  =  -30.367227685740318
training  [-2.9105, 0.5832, -4.0091]  w:  [1.35697928 0.42696507 1.18696594]
-8.459147309582951  -  2.4887  =  -10.94784730958295
training  [4.0515, 2.4255, -4.5583]  w:  [1.35697928 0.42696507 1.18696594]
1.122858470215868  -  61.2853  =  -60.16244152978413
training  [1.7539, -0.7567, 0.573]  w:  [1.35697928 0.42696507 1.18696594]
2.7370529659108893  -  57.0797  =  -54.34264703408911
training  [-0.3153, -0.7064, 2.725]  w:  [1.35697928 0.42696507 1.18696594]
2.505018497806247  -  58.7004  =  -56.195381502193754
training  [4.1213, -3.7513, -1.8806]  w:  [1.35697928 0.42696507 1.18696594]
1.7586364602627858  -  22.1789  =  -20.420263539737213
training  [-3.9599, -4.7557, -3.2102]  w:  [1.35697928 0.42696507 1.18696594]
-11.214418101772042  -  0.1558  =  -11.370218101772041
training  [2.4555, -2.0981, -1.6104]  w:  [1.35697928 0.42696507 1.18696594]
0.5247572390894788  -  24.4796  =  -23.954842760910523
training  [2.3627, -1.8248, -2.8985]  w:  [1.35697928 0.42696507 1.18696594]
-1.0134117128111853  -  15.7052  =  -16.718611712811185
training  [0.6186, 1.5369, 0.1015]  w:  [1.35697928 0.42696507 1.18696594]
1.6161070447114376  -  65.2154  =  -63.59929295528856
training  [-3.1581, 4.5694, 4.0636]  w:  [1.35697928 0.42696507 1.18696594]
2.4888527560781837  -  90.3564  =  -87.8675472439218
training  [0.9721, 4.3573, 1.2892]  w:  [1.35697928 0.42696507 1.18696594]
4.709770961140339  -  94.3178  =  -89.60802903885967
training  [-2.0006, -0.4211, -3.9847]  w:  [1.35697928 0.42696507 1.18696594]
-7.624270920572877  -  2.4051  =  -10.029370920572877
training  [-3.6588, -2.5952, -1.0915]  w:  [1.35697928 0.42696507 1.18696594]
-7.3685488595612725  -  1.5176  =  -8.886148859561272
training  [-2.874, 2.639, -4.4538]  w:  [1.35697928 0.42696507 1.18696594]
-8.059706522283907  -  5.497  =  -13.556706522283907
training  [3.9494, 2.5933, 0.0128]  w:  [1.35697928 0.42696507 1.18696594]
6.481695642113103  -  94.1462  =  -87.66450435788688
training  [-4.2855, 2.4065, -0.6828]  w:  [1.35697928 0.42696507 1.18696594]
-5.598303583470386  -  14.4193  =  -20.017603583470386
training  [-2.5751, 2.4369, 4.9756]  w:  [1.35697928 0.42696507 1.18696594]
3.451981593798383  -  87.1991  =  -83.74711840620162
training  [-4.4625, -3.9408, 3.116]  w:  [1.35697928 0.42696507 1.18696594]
-4.039518106416101  -  4.1344  =  -8.173918106416101
training  [-0.5828, 1.8156, -0.1435]  w:  [1.35697928 0.42696507 1.18696594]
-0.1859793473597298  -  51.1166  =  -51.302579347359725
training  [-4.8672, -0.3674, 3.9445]  w:  [1.35697928 0.42696507 1.18696594]
-2.0795693430992612  -  24.1396  =  -26.219169343099264
training  [3.9719, -2.8784, -3.6245]  w:  [1.35697928 0.42696507 1.18696594]
-0.14134833689149495  -  14.6104  =  -14.751748336891495
training  [-3.0334, -4.0148, -1.1]  w:  [1.35697928 0.42696507 1.18696594]
-7.136102849100628  -  1.021  =  -8.157102849100628
training  [-4.0663, 3.2357, 4.2736]  w:  [1.35697928 0.42696507 1.18696594]
0.936263706816451  -  77.2328  =  -76.29653629318355
training  [-1.9263, -3.2499, 4.1749]  w:  [1.35697928 0.42696507 1.18696594]
0.9539211386779121  -  26.8814  =  -25.927478861322086
training  [-0.4394, -3.3643, 2.1357]  w:  [1.35697928 0.42696507 1.18696594]
0.5023078713391844  -  20.85  =  -20.347692128660817
training  [-3.9833, 1.6599, 1.1834]  w:  [1.35697928 0.42696507 1.18696594]
-3.291880729463993  -  25.5397  =  -28.831580729463994
training  [4.9539, 3.9439, -1.5671]  w:  [1.35697928 0.42696507 1.18696594]
6.5461528617041695  -  95.9509  =  -89.40474713829583
training  [-1.6791, 0.1656, 4.3603]  w:  [1.35697928 0.42696507 1.18696594]
2.967729109795423  -  71.5733  =  -68.60557089020458
training  [-2.0265, 2.027, -3.7523]  w:  [1.35697928 0.42696507 1.18696594]
-6.338312602571184  -  8.503  =  -14.841312602571184
training  [-4.3795, -3.4641, 2.3059]  w:  [1.35697928 0.42696507 1.18696594]
-4.684915685443829  -  3.6654  =  -8.350315685443828
training  [-2.0176, 4.5346, 1.4648]  w:  [1.35697928 0.42696507 1.18696594]
0.9369421463051932  -  81.6212  =  -80.6842578536948
training  [-4.5365, 0.4088, 3.3315]  w:  [1.35697928 0.42696507 1.18696594]
-2.0270161287992865  -  28.9449  =  -30.971916128799286
training  [0.0543, 1.7973, -1.0172]  w:  [1.35697928 0.42696507 1.18696594]
-0.3663134547721263  -  47.9317  =  -48.298013454772125
training  [2.6143, -4.6344, 2.4982]  w:  [1.35697928 0.42696507 1.18696594]
4.534102300845202  -  43.5132  =  -38.97909769915479
training  [1.3107, 3.092, 3.3522]  w:  [1.35697928 0.42696507 1.18696594]
7.07771597453568  -  96.6993  =  -89.62158402546432
training  [-4.1011, 2.4862, -1.7754]  w:  [1.35697928 0.42696507 1.18696594]
-6.610926476635788  -  10.0187  =  -16.62962647663579
training  [-4.1914, -3.7981, 0.5226]  w:  [1.35697928 0.42696507 1.18696594]
-6.68899058219987  -  1.4295  =  -8.11849058219987
training  [2.7724, 0.2505, 4.7913]  w:  [1.35697928 0.42696507 1.18696594]
9.5561540130022  -  96.7925  =  -87.2363459869978
training  [4.0513, -1.7417, 0.4931]  w:  [1.35697928 0.42696507 1.18696594]
5.339177978691116  -  71.1234  =  -65.78422202130889
training  [0.3377, 0.4645, -1.6958]  w:  [1.35697928 0.42696507 1.18696594]
-1.3562796659731142  -  27.9534  =  -29.309679665973114
training  [-3.9085, -1.0112, 1.1947]  w:  [1.35697928 0.42696507 1.18696594]
-4.317432372227661  -  8.608  =  -12.925432372227661
training  [3.2581, -0.8491, -1.3936]  w:  [1.35697928 0.42696507 1.18696594]
2.4044823990412763  -  50.1924  =  -47.78791760095872
training  [-1.619, -3.1926, 2.5651]  w:  [1.35697928 0.42696507 1.18696594]
-0.5153918042108359  -  16.4754  =  -16.990791804210836
training  [-2.0603, -2.4461, -0.861]  w:  [1.35697928 0.42696507 1.18696594]
-4.8621613446760765  -  3.9784  =  -8.840561344676077
training  [2.4631, -4.7946, -0.0765]  w:  [1.35697928 0.42696507 1.18696594]
1.204446019122408  -  15.394  =  -14.189553980877593
training  [-4.8966, 4.2368, 1.9474]  w:  [1.35697928 0.42696507 1.18696594]
-2.5241216249348652  -  53.5883  =  -56.11242162493486
training  [-4.5155, 1.537, 4.7273]  w:  [1.35697928 0.42696507 1.18696594]
0.13994949348654817  -  59.2523  =  -59.11235050651345
training  [1.6792, 4.3261, -1.7225]  w:  [1.35697928 0.42696507 1.18696594]
2.0811843699937356  -  83.7729  =  -81.69171563000627
training  [1.0347, -3.3649, 3.378]  w:  [1.35697928 0.42696507 1.18696594]
3.9769426327132167  -  50.5979  =  -46.620957367286785
training  [0.261, 4.211, 2.3907]  w:  [1.35697928 0.42696507 1.18696594]
4.989800992574459  -  94.9375  =  -89.94769900742554
training  [2.2971, 2.9466, 4.5417]  w:  [1.35697928 0.42696507 1.18696594]
9.766055598590125  -  98.7784  =  -89.01234440140988
training  [2.0725, 0.7739, -4.6808]  w:  [1.35697928 0.42696507 1.18696594]
-2.413182360403154  -  19.5109  =  -21.924082360403155
training  [2.8138, -0.5996, -1.4313]  w:  [1.35697928 0.42696507 1.18696594]
1.8633556764968517  -  47.2879  =  -45.42454432350315
training  [-2.1202, -2.4239, 1.6265]  w:  [1.35697928 0.42696507 1.18696594]
-1.9813879984035665  -  12.3599  =  -14.341287998403565
training  [1.9253, 2.5195, -2.185]  w:  [1.35697928 0.42696507 1.18696594]
1.094810120009535  -  65.2467  =  -64.15188987999046
training  [0.5667, -2.7133, -2.6962]  w:  [1.35697928 0.42696507 1.18696594]
-3.5897817504325515  -  5.1106  =  -8.700381750432552
training  [-1.0348, -4.3581, 2.1113]  w:  [1.35697928 0.42696507 1.18696594]
-0.7589174486483095  -  10.5192  =  -11.27811744864831
training  [-4.3841, 2.6733, 1.2457]  w:  [1.35697928 0.42696507 1.18696594]
-3.3291236396888015  -  32.4639  =  -35.793023639688805
training  [2.8018, 1.712, 0.9061]  w:  [1.35697928 0.42696507 1.18696594]
5.608458581440043  -  90.1138  =  -84.50534141855995
training  [-1.6242, 2.1521, 1.6044]  w:  [1.35697928 0.42696507 1.18696594]
0.6192339514463208  -  63.7879  =  -63.16866604855368
training  [1.0787, 1.4206, -4.5245]  w:  [1.35697928 0.42696507 1.18696594]
-3.3001072752652423  -  18.0555  =  -21.355607275265243
training  [2.4125, -0.8095, -1.5122]  w:  [1.35697928 0.42696507 1.18696594]
1.133154379383639  -  38.8276  =  -37.69444562061636
training  [-3.9519, -1.0924, -0.4866]  w:  [1.35697928 0.42696507 1.18696594]
-6.406640674759925  -  3.6777  =  -10.084340674759925
training  [-3.7211, 3.1614, -2.591]  w:  [1.35697928 0.42696507 1.18696594]
-6.775076956258118  -  11.1518  =  -17.92687695625812
training  [0.4954, -1.8257, 2.1505]  w:  [1.35697928 0.42696507 1.18696594]
2.445307656621396  -  47.7531  =  -45.30779234337861
training  [-0.1477, 3.1454, 3.5618]  w:  [1.35697928 0.42696507 1.18696594]
5.3702853946056335  -  94.1572  =  -88.78691460539437
training  [3.9048, 2.8907, -2.1849]  w:  [1.35697928 0.42696507 1.18696594]
3.939558728910719  -  85.8791  =  -81.93954127108927
training  [2.9896, 3.5226, 2.3105]  w:  [1.35697928 0.42696507 1.18696594]
8.303337220217584  -  98.038  =  -89.73466277978241
training  [2.3434, 0.0564, -3.6224]  w:  [1.35697928 0.42696507 1.18696594]
-1.095639361903415  -  24.7629  =  -25.858539361903414
training  [-4.4867, 1.3566, 3.3672]  w:  [1.35697928 0.42696507 1.18696594]
-1.5123863800873494  -  40.5785  =  -42.09088638008735
training  [-4.2711, 4.5089, -3.614]  w:  [1.35697928 0.42696507 1.18696594]
-8.160346280086891  -  10.0825  =  -18.24284628008689
training  [-4.1147, -0.5604, 0.8821]  w:  [1.35697928 0.42696507 1.18696594]
-4.775811197249605  -  8.344  =  -13.119811197249604
training  [2.9835, -4.3998, -1.3384]  w:  [1.35697928 0.42696507 1.18696594]
0.5813515234270539  -  13.2692  =  -12.687848476572945
training  [4.4301, 3.6675, 3.0676]  w:  [1.35697928 0.42696507 1.18696594]
11.218585021133826  -  99.3834  =  -88.16481497886616
training  [1.8372, 1.3119, 0.0378]  w:  [1.35697928 0.42696507 1.18696594]
3.0980451185369375  -  74.9026  =  -71.80455488146308
training  [-3.6792, -1.4493, -0.1041]  w:  [1.35697928 0.42696507 1.18696594]
-5.734961788145  -  4.2442  =  -9.979161788145
training  [2.2272, 4.97, 3.7705]  w:  [1.35697928 0.42696507 1.18696594]
9.619735742527382  -  99.3199  =  -89.70016425747262
training  [-3.8965, -2.7583, -1.4686]  w:  [1.35697928 0.42696507 1.18696594]
-8.208345693633827  -  1.0337  =  -9.242045693633827
training  [-3.8251, 1.5245, -0.5056]  w:  [1.35697928 0.42696507 1.18696594]
-5.1398031546695355  -  12.9762  =  -18.116003154669535
training  [1.4072, 1.0499, 4.6353]  w:  [1.35697928 0.42696507 1.18696594]
7.859755098086749  -  95.4618  =  -87.60204490191325
training  [-1.7119, -1.1275, -4.577]  w:  [1.35697928 0.42696507 1.18696594]
-8.237159058806856  -  1.4655  =  -9.702659058806857
training  [1.5381, -3.5781, 4.7296]  w:  [1.35697928 0.42696507 1.18696594]
6.173320213600597  -  69.9473  =  -63.7739797863994
training  [2.4913, -4.7487, -3.1079]  w:  [1.35697928 0.42696507 1.18696594]
-2.3358580244551397  -  3.9825  =  -6.31835802445514
training  [0.8319, -0.7889, 1.6712]  w:  [1.35697928 0.42696507 1.18696594]
2.7756957952916945  -  58.8336  =  -56.0579042047083
training  [2.4003, -3.159, 0.8644]  w:  [1.35697928 0.42696507 1.18696594]
2.9343880494180716  -  39.0041  =  -36.06971195058193
training  [-2.6517, 2.2578, 1.7511]  w:  [1.35697928 0.42696507 1.18696594]
-0.5558041428115157  -  54.4525  =  -55.00830414281152
training  [2.3496, -1.2964, -1.3898]  w:  [1.35697928 0.42696507 1.18696594]
0.9851957199212142  -  33.888  =  -32.90280428007878
training  [4.706, 3.4156, 1.2028]  w:  [1.35697928 0.42696507 1.18696594]
9.27196901309293  -  98.4665  =  -89.19453098690707
training  [3.6693, 2.3423, 3.1115]  w:  [1.35697928 0.42696507 1.18696594]
9.672488877356809  -  98.3069  =  -88.63441112264319
training  [-4.1377, 0.7103, -4.8074]  w:  [1.35697928 0.42696507 1.18696594]
-11.017719927725695  -  0.9782  =  -11.995919927725694
training  [-1.3356, -3.2314, -4.1613]  w:  [1.35697928 0.42696507 1.18696594]
-8.13139783328017  -  0.7659  =  -8.89729783328017
training  [-1.308, 4.5738, 4.748]  w:  [1.35697928 0.42696507 1.18696594]
5.81363825169001  -  97.0884  =  -91.27476174830998
training  [1.8503, -2.3468, 1.5135]  w:  [1.35697928 0.42696507 1.18696594]
3.305290073077064  -  50.2125  =  -46.90720992692293
training  [0.9794, 4.2458, -2.6876]  w:  [1.35697928 0.42696507 1.18696594]
-0.04825585327005122  -  68.3262  =  -68.37445585327005
training  [2.8936, -2.7623, -0.9651]  w:  [1.35697928 0.42696507 1.18696594]
1.6016087804025438  -  28.5596  =  -26.957991219597456
training  [-1.3235, -1.2644, -3.7798]  w:  [1.35697928 0.42696507 1.18696594]
-6.822310577709984  -  2.4511  =  -9.273410577709983
training  [-2.9397, -4.125, -2.3156]  w:  [1.35697928 0.42696507 1.18696594]
-8.49888124090481  -  0.554  =  -9.05288124090481
training  [-4.1333, 1.4012, -2.4215]  w:  [1.35697928 0.42696507 1.18696594]
-7.88477700905665  -  4.4072  =  -12.29197700905665
training  [2.7193, -3.1938, -1.6833]  w:  [1.35697928 0.42696507 1.18696594]
0.3283729239587856  -  17.0949  =  -16.766527076041214
training  [-2.9433, -4.5495, -3.4777]  w:  [1.35697928 0.42696507 1.18696594]
-10.064386160978867  -  0.2509  =  -10.315286160978866
training  [-1.1173, 2.2317, -1.5199]  w:  [1.35697928 0.42696507 1.18696594]
-2.367364525682858  -  33.1206  =  -35.48796452568286
training  [0.5178, -1.5256, -3.7834]  w:  [1.35697928 0.42696507 1.18696594]
-4.439500991215486  -  5.237  =  -9.676500991215487
training  [-2.7105, 1.6062, 3.8415]  w:  [1.35697928 0.42696507 1.18696594]
1.567428638660358  -  70.4458  =  -68.87837136133965
training  [1.4194, -1.1613, -4.0572]  w:  [1.35697928 0.42696507 1.18696594]
-3.3854963744905415  -  8.3206  =  -11.706096374490542
training  [-0.1552, 1.2735, 4.3004]  w:  [1.35697928 0.42696507 1.18696594]
5.437565173626556  -  90.1085  =  -84.67093482637345
training  [-3.4815, -4.7835, -1.0098]  w:  [1.35697928 0.42696507 1.18696594]
-7.965308986747261  -  0.5839  =  -8.549208986747262
training  [2.8193, 4.1057, -4.526]  w:  [1.35697928 0.42696507 1.18696594]
0.20651432258266045  -  66.8081  =  -66.60158567741733
training  [-3.9939, 3.0056, -1.5763]  w:  [1.35697928 0.42696507 1.18696594]
-6.007367720058928  -  14.4018  =  -20.409167720058928
training  [-2.0593, 2.4585, 2.3597]  w:  [1.35697928 0.42696507 1.18696594]
1.0561497427866906  -  70.6698  =  -69.61365025721331
training  [-2.6263, 3.1311, 2.9468]  w:  [1.35697928 0.42696507 1.18696594]
1.2707869061020758  -  77.309  =  -76.03821309389792
training  [0.3087, -1.1669, 0.4491]  w:  [1.35697928 0.42696507 1.18696594]
0.4537403627651684  -  33.0798  =  -32.62605963723483
training  [-4.085, 1.1728, 1.8622]  w:  [1.35697928 0.42696507 1.18696594]
-2.832147727824496  -  26.4056  =  -29.237747727824495
training  [-0.9468, 0.7549, 3.9363]  w:  [1.35697928 0.42696507 1.18696594]
3.70978199214752  -  79.7738  =  -76.06401800785247
training  [-3.9515, 0.3005, -4.4521]  w:  [1.35697928 0.42696507 1.18696594]
-10.518291674497465  -  1.0441  =  -11.562391674497466
training  [-3.8772, -2.2493, -1.9634]  w:  [1.35697928 0.42696507 1.18696594]
-8.552141519219536  -  1.0509  =  -9.603041519219536
training  [2.8443, -2.5137, -4.5381]  w:  [1.35697928 0.42696507 1.18696594]
-2.6001760907693825  -  6.8897  =  -9.489876090769382
training  [-2.0843, -0.4836, -3.0452]  w:  [1.35697928 0.42696507 1.18696594]
-6.6493809007335685  -  3.5346  =  -10.18398090073357
training  [1.0353, -2.7229, 2.2017]  w:  [1.35697928 0.42696507 1.18696594]
2.8556403600856743  -  43.9562  =  -41.10055963991433
training  [4.6442, 3.0445, 2.2175]  w:  [1.35697928 0.42696507 1.18696594]
10.234075296229395  -  98.8492  =  -88.6151247037706
training  [-0.6752, 4.861, 3.778]  w:  [1.35697928 0.42696507 1.18696594]
5.643602143139563  -  97.017  =  -91.37339785686044
training  [1.9475, -4.7001, 0.8243]  w:  [1.35697928 0.42696507 1.18696594]
1.6143546242026592  -  18.7839  =  -17.16954537579734
training  [2.581, 0.3566, -4.2932]  w:  [1.35697928 0.42696507 1.18696594]
-1.4412629246192394  -  23.5455  =  -24.98676292461924
training  [-0.6736, -4.1292, 4.2274]  w:  [1.35697928 0.42696507 1.18696594]
2.340694400683402  -  31.2667  =  -28.926005599316596
training  [1.555, 3.0209, 3.0037]  w:  [1.35697928 0.42696507 1.18696594]
6.965211164237431  -  96.4078  =  -89.44258883576256
training  [-3.9024, 4.8914, -2.1405]  w:  [1.35697928 0.42696507 1.18696594]
-5.74771956511287  -  25.4308  =  -31.17851956511287
training  [4.3376, -4.3305, 0.4366]  w:  [1.35697928 0.42696507 1.18696594]
4.555290387513385  -  43.0907  =  -38.53540961248661
training  [-3.1254, 4.394, 4.8478]  w:  [1.35697928 0.42696507 1.18696594]
3.389154996095052  -  92.8121  =  -89.42294500390494
training  [-2.3382, -4.8182, 2.1568]  w:  [1.35697928 0.42696507 1.18696594]
-2.670043917065457  -  4.7434  =  -7.413443917065457
training  [2.9783, 1.8384, 3.3897]  w:  [1.35697928 0.42696507 1.18696594]
8.849882422064749  -  97.3486  =  -88.49871757793525
training  [-0.124, 2.8374, -0.6674]  w:  [1.35697928 0.42696507 1.18696594]
0.2510241996698477  -  62.785  =  -62.53397580033015
training  [2.6896, 0.3414, -0.2938]  w:  [1.35697928 0.42696507 1.18696594]
3.4467667433666525  -  70.4455  =  -66.99873325663334
training  [-1.0399, 3.8536, 0.6071]  w:  [1.35697928 0.42696507 1.18696594]
0.954836881208746  -  77.0369  =  -76.08206311879125
training  [-2.2706, 3.99, -2.3091]  w:  [1.35697928 0.42696507 1.18696594]
-4.1183895573995635  -  31.1134  =  -35.231789557399566
training  [-4.6277, 1.2594, 2.4902]  w:  [1.35697928 0.42696507 1.18696594]
-2.786190594135663  -  28.1093  =  -30.895490594135666
training  [1.7329, -3.6213, 0.0389]  w:  [1.35697928 0.42696507 1.18696594]
0.8515137421106806  -  19.3919  =  -18.54038625788932
training  [-0.7044, -2.822, 1.4681]  w:  [1.35697928 0.42696507 1.18696594]
-0.41816694024073264  -  17.8122  =  -18.230366940240735
training  [-0.4826, -3.1786, -1.9225]  w:  [1.35697928 0.42696507 1.18696594]
-4.293971404341625  -  3.5851  =  -7.879071404341625
training  [1.0986, -4.5818, -3.6128]  w:  [1.35697928 0.42696507 1.18696594]
-4.753761695537315  -  1.7158  =  -6.4695616955373145
training  [-4.406, -3.9306, -0.2443]  w:  [1.35697928 0.42696507 1.18696594]
-7.947055387868065  -  0.8241  =  -8.771155387868065
training  [-1.8419, 1.1644, -1.3754]  w:  [1.35697928 0.42696507 1.18696594]
-3.634814953468867  -  17.8517  =  -21.48651495346887
training  [2.7272, 4.3966, 2.8811]  w:  [1.35697928 0.42696507 1.18696594]
8.997716098789748  -  98.904  =  -89.90628390121024
training  [1.9643, -1.4554, 2.803]  w:  [1.35697928 0.42696507 1.18696594]
5.371174959025508  -  76.0591  =  -70.68792504097449
training  [-3.7467, -0.8937, 1.6851]  w:  [1.35697928 0.42696507 1.18696594]
-3.465616631352974  -  12.1571  =  -15.622716631352974
training  [-3.6985, 4.8435, -3.665]  w:  [1.35697928 0.42696507 1.18696594]
-7.3010126960422195  -  14.6793  =  -21.98031269604222
254749.8405949142
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.32057108 0.43799227 1.14261395]
9.22101778418861  -  87.3174  =  -78.09638221581139
training  [-4.1793, -4.9218, 1.7664]  w:  [1.32057108 0.43799227 1.14261395]
-5.656459795519343  -  1.5257  =  -7.182159795519343
training  [-3.9429, -0.7689, 4.883]  w:  [1.32057108 0.43799227 1.14261395]
0.03573196622614816  -  39.7859  =  -39.750168033773846
training  [-3.5796, 1.5557, 2.6683]  w:  [1.32057108 0.43799227 1.14261395]
-0.9968948438519112  -  45.5674  =  -46.56429484385191
training  [-3.3354, 2.2292, -1.633]  w:  [1.32057108 0.43799227 1.14261395]
-5.294148986694445  -  13.3589  =  -18.653048986694444
training  [1.2096, 0.3121, 1.6238]  w:  [1.32057108 0.43799227 1.14261395]
3.589436702880259  -  74.5119  =  -70.92246329711973
training  [0.7371, -3.9118, -2.5583]  w:  [1.32057108 0.43799227 1.14261395]
-3.663094509095358  -  3.3358  =  -6.998894509095358
training  [-4.4792, 1.3177, -2.0449]  w:  [1.32057108 0.43799227 1.14261395]
-7.674490831494734  -  4.2974  =  -11.971890831494733
training  [4.312, -3.735, 1.8018]  w:  [1.32057108 0.43799227 1.14261395]
6.117163172476586  -  66.5833  =  -60.46613682752341
training  [2.2866, -3.657, 0.2785]  w:  [1.32057108 0.43799227 1.14261395]
1.7360980714266916  -  26.0005  =  -24.264401928573307
training  [2.3784, -4.0141, -0.8841]  w:  [1.32057108 0.43799227 1.14261395]
0.3725164737534321  -  14.6809  =  -14.308383526246567
training  [-4.366, -3.5797, 1.0264]  w:  [1.32057108 0.43799227 1.14261395]
-6.160715311103045  -  1.8713  =  -8.032015311103045
training  [3.6044, -3.3175, 2.5052]  w:  [1.32057108 0.43799227 1.14261395]
6.169303505688845  -  71.0139  =  -64.84459649431116
training  [4.3441, -3.0375, 0.8353]  w:  [1.32057108 0.43799227 1.14261395]
5.360716729158582  -  63.8979  =  -58.53718327084142
training  [4.844, -1.8252, 0.5179]  w:  [1.32057108 0.43799227 1.14261395]
6.189182575975147  -  78.0461  =  -71.85691742402484
training  [3.5894, -1.8357, 0.8357]  w:  [1.32057108 0.43799227 1.14261395]
4.890917895568195  -  68.8838  =  -63.9928821044318
training  [2.8556, -2.8244, 0.1182]  w:  [1.32057108 0.43799227 1.14261395]
2.669014365616794  -  39.5252  =  -36.8561856343832
training  [0.1338, -2.4896, -4.1741]  w:  [1.32057108 0.43799227 1.14261395]
-5.683118055263684  -  2.2644  =  -7.947518055263684
training  [-3.224, 3.9292, 2.1957]  w:  [1.32057108 0.43799227 1.14261395]
-0.02772446135104456  -  72.1211  =  -72.14882446135104
training  [-1.0141, 2.0322, 4.9616]  w:  [1.32057108 0.43799227 1.14261395]
5.2200901565381574  -  92.3427  =  -87.12260984346183
training  [-3.6607, 0.5574, -1.4547]  w:  [1.32057108 0.43799227 1.14261395]
-6.252238173625253  -  5.8471  =  -12.099338173625252
training  [-4.6911, -3.1557, 4.7126]  w:  [1.32057108 0.43799227 1.14261395]
-2.1924206910160056  -  11.2337  =  -13.426120691016006
training  [4.3914, -2.8797, -1.5355]  w:  [1.32057108 0.43799227 1.14261395]
2.7833857619107727  -  37.475  =  -34.69161423808923
training  [-1.9869, -4.2265, 3.8654]  w:  [1.32057108 0.43799227 1.14261395]
-0.058357046400845825  -  15.7889  =  -15.847257046400845
training  [-2.0447, 4.138, -0.4531]  w:  [1.32057108 0.43799227 1.14261395]
-1.4054780400809013  -  57.936  =  -59.3414780400809
training  [-1.6706, 2.0672, -0.8657]  w:  [1.32057108 0.43799227 1.14261395]
-2.2898893162887695  -  32.4185  =  -34.70838931628877
training  [-0.3293, 0.5779, -2.8227]  w:  [1.32057108 0.43799227 1.14261395]
-3.4070047269740105  -  14.3434  =  -17.75040472697401
training  [1.482, -1.8657, -3.7435]  w:  [1.32057108 0.43799227 1.14261395]
-3.137451178814761  -  7.1519  =  -10.289351178814762
training  [-4.7477, -3.338, -1.9109]  w:  [1.32057108 0.43799227 1.14261395]
-9.915114523979614  -  0.4077  =  -10.322814523979615
training  [3.4221, 1.225, 2.261]  w:  [1.32057108 0.43799227 1.14261395]
7.6391169727302835  -  95.0454  =  -87.40628302726972
training  [0.5903, 4.8793, 2.8287]  w:  [1.32057108 0.43799227 1.14261395]
6.1487408969652115  -  97.4647  =  -91.31595910303479
training  [3.541, -3.2957, 1.9379]  w:  [1.32057108 0.43799227 1.14261395]
5.44692263523463  -  64.3732  =  -58.92627736476537
training  [-1.5212, -2.4221, -4.902]  w:  [1.32057108 0.43799227 1.14261395]
-8.670807409181872  -  0.7227  =  -9.393507409181872
training  [-0.5397, -1.032, 3.4321]  w:  [1.32057108 0.43799227 1.14261395]
2.756845110895365  -  60.5921  =  -57.83525488910464
training  [-4.4576, -4.2601, 4.2233]  w:  [1.32057108 0.43799227 1.14261395]
-2.926867018094134  -  6.0247  =  -8.951567018094135
training  [-3.2289, 1.841, 2.7095]  w:  [1.32057108 0.43799227 1.14261395]
-0.36173567593140943  -  54.0111  =  -54.372835675931405
training  [1.6281, -0.9761, -4.5734]  w:  [1.32057108 0.43799227 1.14261395]
-3.503133137392383  -  7.8658  =  -11.368933137392382
training  [-1.6917, 4.8284, -1.2181]  w:  [1.32057108 0.43799227 1.14261395]
-1.5110262577060838  -  61.2837  =  -62.79472625770609
training  [3.9849, -0.9782, 2.0434]  w:  [1.32057108 0.43799227 1.14261395]
7.168717003001113  -  88.3402  =  -81.17148299699889
training  [-3.8184, 1.2067, 2.2951]  w:  [1.32057108 0.43799227 1.14261395]
-1.8915300482729713  -  34.1122  =  -36.00373004827297
training  [4.8842, -3.4563, -2.7572]  w:  [1.32057108 0.43799227 1.14261395]
1.7856853783058604  -  23.7819  =  -21.99621462169414
training  [0.3998, -1.1865, -2.3095]  w:  [1.32057108 0.43799227 1.14261395]
-2.6305804397286368  -  11.4246  =  -14.055180439728638
training  [2.0692, -3.3887, 1.7303]  w:  [1.32057108 0.43799227 1.14261395]
3.2253661829237634  -  42.6881  =  -39.462733817076234
training  [4.9949, 2.5811, -0.2251]  w:  [1.32057108 0.43799227 1.14261395]
7.4694199391164915  -  95.9901  =  -88.5206800608835
training  [-2.1215, 3.7111, 1.2372]  w:  [1.32057108 0.43799227 1.14261395]
0.23748356445747332  -  71.3692  =  -71.13171643554253
training  [-0.8548, -1.4922, -2.6356]  w:  [1.32057108 0.43799227 1.14261395]
-4.793869563664604  -  4.7821  =  -9.575969563664604
training  [-0.3516, 1.8554, -3.2288]  w:  [1.32057108 0.43799227 1.14261395]
-3.3409338590744166  -  20.3834  =  -23.72433385907442
training  [2.6396, -2.0585, 3.2964]  w:  [1.32057108 0.43799227 1.14261395]
6.350684960542186  -  80.826  =  -74.47531503945781
training  [3.182, 0.3063, 2.6692]  w:  [1.32057108 0.43799227 1.14261395]
7.386079370688252  -  92.9483  =  -85.56222062931175
training  [-3.9978, 3.3242, 4.3448]  w:  [1.32057108 0.43799227 1.14261395]
1.1410239588446691  -  79.1768  =  -78.03577604115533
training  [-3.2188, 0.9749, -3.9211]  w:  [1.32057108 0.43799227 1.14261395]
-8.303959093566071  -  2.7053  =  -11.00925909356607
training  [-1.4037, -1.6469, -3.1777]  w:  [1.32057108 0.43799227 1.14261395]
-6.205899457664421  -  2.6234  =  -8.82929945766442
training  [-4.433, -2.0077, -4.009]  w:  [1.32057108 0.43799227 1.14261395]
-11.314188019052391  -  0.3253  =  -11.639488019052392
training  [0.2189, -0.4741, -0.1024]  w:  [1.32057108 0.43799227 1.14261395]
-0.035582796423295746  -  33.6531  =  -33.6886827964233
training  [-1.6415, -0.7735, -3.0675]  w:  [1.32057108 0.43799227 1.14261395]
-6.0114727510163455  -  3.7641  =  -9.775572751016345
training  [-3.2433, -1.4039, 3.9589]  w:  [1.32057108 0.43799227 1.14261395]
-0.3744111545443918  -  30.0658  =  -30.440211154544393
training  [-2.9105, 0.5832, -4.0091]  w:  [1.32057108 0.43799227 1.14261395]
-8.168938631261668  -  2.4887  =  -10.657638631261667
training  [4.0515, 2.4255, -4.5583]  w:  [1.32057108 0.43799227 1.14261395]
1.2042668037234687  -  61.2853  =  -60.08103319627653
training  [1.7539, -0.7567, 0.573]  w:  [1.32057108 0.43799227 1.14261395]
2.6394386574474917  -  57.0797  =  -54.44026134255251
training  [-0.3153, -0.7064, 2.725]  w:  [1.32057108 0.43799227 1.14261395]
2.3878492190318457  -  58.7004  =  -56.31255078096816
training  [4.1213, -3.7513, -1.8806]  w:  [1.32057108 0.43799227 1.14261395]
1.6506293726955876  -  22.1789  =  -20.528270627304412
training  [-3.9599, -4.7557, -3.2102]  w:  [1.32057108 0.43799227 1.14261395]
-10.980308583204629  -  0.1558  =  -11.136108583204628
training  [2.4555, -2.0981, -1.6104]  w:  [1.32057108 0.43799227 1.14261395]
0.4836451857215269  -  24.4796  =  -23.995954814278473
training  [2.3627, -1.8248, -2.8985]  w:  [1.32057108 0.43799227 1.14261395]
-0.991001555090671  -  15.7052  =  -16.69620155509067
training  [0.6186, 1.5369, 0.1015]  w:  [1.32057108 0.43799227 1.14261395]
1.6060309108233366  -  65.2154  =  -63.60936908917667
training  [-3.1581, 4.5694, 4.0636]  w:  [1.32057108 0.43799227 1.14261395]
2.4739924292372306  -  90.3564  =  -87.88240757076277
training  [0.9721, 4.3573, 1.2892]  w:  [1.32057108 0.43799227 1.14261395]
4.665248787411457  -  94.3178  =  -89.65255121258855
training  [-2.0006, -0.4211, -3.9847]  w:  [1.32057108 0.43799227 1.14261395]
-7.379346866153461  -  2.4051  =  -9.784446866153461
training  [-3.6588, -2.5952, -1.0915]  w:  [1.32057108 0.43799227 1.14261395]
-7.215546142058227  -  1.5176  =  -8.733146142058228
training  [-2.874, 2.639, -4.4538]  w:  [1.32057108 0.43799227 1.14261395]
-7.7284336960813205  -  5.497  =  -13.225433696081321
training  [3.9494, 2.5933, 0.0128]  w:  [1.32057108 0.43799227 1.14261395]
6.365934241102156  -  94.1462  =  -87.78026575889784
training  [-4.2855, 2.4065, -0.6828]  w:  [1.32057108 0.43799227 1.14261395]
-5.385455760615878  -  14.4193  =  -19.804755760615876
training  [-2.5751, 2.4369, 4.9756]  w:  [1.32057108 0.43799227 1.14261395]
3.351930770473642  -  87.1991  =  -83.84716922952636
training  [-4.4625, -3.9408, 3.116]  w:  [1.32057108 0.43799227 1.14261395]
-4.058703313752712  -  4.1344  =  -8.193103313752712
training  [-0.5828, 1.8156, -0.1435]  w:  [1.32057108 0.43799227 1.14261395]
-0.13837515550771848  -  51.1166  =  -51.254975155507715
training  [-4.8672, -0.3674, 3.9445]  w:  [1.32057108 0.43799227 1.14261395]
-2.0813611793917595  -  24.1396  =  -26.22096117939176
training  [3.9719, -2.8784, -3.6245]  w:  [1.32057108 0.43799227 1.14261395]
-0.15694496386611245  -  14.6104  =  -14.767344963866112
training  [-3.0334, -4.0148, -1.1]  w:  [1.32057108 0.43799227 1.14261395]
-7.021147039170955  -  1.021  =  -8.042147039170956
training  [-4.0663, 3.2357, 4.2736]  w:  [1.32057108 0.43799227 1.14261395]
0.9304484102653281  -  77.2328  =  -76.30235158973467
training  [-1.9263, -3.2499, 4.1749]  w:  [1.32057108 0.43799227 1.14261395]
0.8030518337241879  -  26.8814  =  -26.078348166275813
training  [-0.4394, -3.3643, 2.1357]  w:  [1.32057108 0.43799227 1.14261395]
0.3864842819651759  -  20.85  =  -20.463515718034827
training  [-3.9833, 1.6599, 1.1834]  w:  [1.32057108 0.43799227 1.14261395]
-3.1810380525668323  -  25.5397  =  -28.720738052566833
training  [4.9539, 3.9439, -1.5671]  w:  [1.32057108 0.43799227 1.14261395]
6.478784470043937  -  95.9509  =  -89.47211552995607
training  [-1.6791, 0.1656, 4.3603]  w:  [1.32057108 0.43799227 1.14261395]
2.8373002413254205  -  71.5733  =  -68.73599975867458
training  [-2.0265, 2.027, -3.7523]  w:  [1.32057108 0.43799227 1.14261395]
-6.075757289785186  -  8.503  =  -14.578757289785187
training  [-4.3795, -3.4641, 2.3059]  w:  [1.32057108 0.43799227 1.14261395]
-4.665936560853966  -  3.6654  =  -8.331336560853966
training  [-2.0176, 4.5346, 1.4648]  w:  [1.32057108 0.43799227 1.14261395]
0.9954364724835281  -  81.6212  =  -80.62576352751647
training  [-4.5365, 0.4088, 3.3315]  w:  [1.32057108 0.43799227 1.14261395]
-2.005101074146423  -  28.9449  =  -30.950001074146424
training  [0.0543, 1.7973, -1.0172]  w:  [1.32057108 0.43799227 1.14261395]
-0.30335639045321083  -  47.9317  =  -48.23505639045321
training  [2.6143, -4.6344, 2.4982]  w:  [1.32057108 0.43799227 1.14261395]
4.277015757707407  -  43.5132  =  -39.236184242292595
training  [1.3107, 3.092, 3.3522]  w:  [1.32057108 0.43799227 1.14261395]
6.915415116477673  -  96.6993  =  -89.78388488352232
training  [-4.1011, 2.4862, -1.7754]  w:  [1.32057108 0.43799227 1.14261395]
-6.355454474607411  -  10.0187  =  -16.374154474607412
training  [-4.1914, -3.7981, 0.5226]  w:  [1.32057108 0.43799227 1.14261395]
-6.601450022790393  -  1.4295  =  -8.030950022790392
training  [2.7724, 0.2505, 4.7913]  w:  [1.32057108 0.43799227 1.14261395]
9.245474557731397  -  96.7925  =  -87.5470254422686
training  [4.0513, -1.7417, 0.4931]  w:  [1.32057108 0.43799227 1.14261395]
5.1506014103703475  -  71.1234  =  -65.97279858962966
training  [0.3377, 0.4645, -1.6958]  w:  [1.32057108 0.43799227 1.14261395]
-1.2882404772627125  -  27.9534  =  -29.24164047726271
training  [-3.9085, -1.0112, 1.1947]  w:  [1.32057108 0.43799227 1.14261395]
-4.239268959771436  -  8.608  =  -12.847268959771437
training  [3.2581, -0.8491, -1.3936]  w:  [1.32057108 0.43799227 1.14261395]
2.338306588368522  -  50.1924  =  -47.854093411631474
training  [-1.619, -3.1926, 2.5651]  w:  [1.32057108 0.43799227 1.14261395]
-0.6054196581210491  -  16.4754  =  -17.08081965812105
training  [-2.0603, -2.4461, -0.861]  w:  [1.32057108 0.43799227 1.14261395]
-4.775936107959425  -  3.9784  =  -8.754336107959425
training  [2.4631, -4.7946, -0.0765]  w:  [1.32057108 0.43799227 1.14261395]
1.0652909032647282  -  15.394  =  -14.328709096735272
training  [-4.8966, 4.2368, 1.9474]  w:  [1.32057108 0.43799227 1.14261395]
-2.3854962694953055  -  53.5883  =  -55.9737962694953
training  [-4.5155, 1.537, 4.7273]  w:  [1.32057108 0.43799227 1.14261395]
0.1116343571659133  -  59.2523  =  -59.14066564283409
training  [1.6792, 4.3261, -1.7225]  w:  [1.32057108 0.43799227 1.14261395]
2.1441487959215912  -  83.7729  =  -81.62875120407841
training  [1.0347, -3.3649, 3.378]  w:  [1.32057108 0.43799227 1.14261395]
3.752344628248912  -  50.5979  =  -46.84555537175109
training  [0.261, 4.211, 2.3907]  w:  [1.32057108 0.43799227 1.14261395]
4.920701692814159  -  94.9375  =  -90.01679830718584
training  [2.2971, 2.9466, 4.5417]  w:  [1.32057108 0.43799227 1.14261395]
9.513481649567161  -  98.7784  =  -89.26491835043285
training  [2.0725, 0.7739, -4.6808]  w:  [1.32057108 0.43799227 1.14261395]
-2.2725016098823207  -  19.5109  =  -21.78340160988232
training  [2.8138, -0.5996, -1.4313]  w:  [1.32057108 0.43799227 1.14261395]
1.8177793841172916  -  47.2879  =  -45.470120615882706
training  [-2.1202, -2.4239, 1.6265]  w:  [1.32057108 0.43799227 1.14261395]
-2.00306267876047  -  12.3599  =  -14.36296267876047
training  [1.9253, 2.5195, -2.185]  w:  [1.32057108 0.43799227 1.14261395]
1.1494055439724407  -  65.2467  =  -64.09729445602757
training  [0.5667, -2.7133, -2.6962]  w:  [1.32057108 0.43799227 1.14261395]
-3.5207525453872526  -  5.1106  =  -8.631352545387251
training  [-1.0348, -4.3581, 2.1113]  w:  [1.32057108 0.43799227 1.14261395]
-0.8629402403317612  -  10.5192  =  -11.382140240331761
training  [-4.3841, 2.6733, 1.2457]  w:  [1.32057108 0.43799227 1.14261395]
-3.1952767218837135  -  32.4639  =  -35.65917672188372
training  [2.8018, 1.712, 0.9061]  w:  [1.32057108 0.43799227 1.14261395]
5.48514132446121  -  90.1138  =  -84.62865867553879
training  [-1.6242, 2.1521, 1.6044]  w:  [1.32057108 0.43799227 1.14261395]
0.6309414513788445  -  63.7879  =  -63.156958548621155
training  [1.0787, 1.4206, -4.5245]  w:  [1.32057108 0.43799227 1.14261395]
-3.1230449841822843  -  18.0555  =  -21.17854498418228
training  [2.4125, -0.8095, -1.5122]  w:  [1.32057108 0.43799227 1.14261395]
1.1034621630734747  -  38.8276  =  -37.72413783692652
training  [-3.9519, -1.0924, -0.4866]  w:  [1.32057108 0.43799227 1.14261395]
-6.253223556575171  -  3.6777  =  -9.930923556575172
training  [-3.7211, 3.1614, -2.591]  w:  [1.32057108 0.43799227 1.14261395]
-6.4898210216807755  -  11.1518  =  -17.641621021680777
training  [0.4954, -1.8257, 2.1505]  w:  [1.32057108 0.43799227 1.14261395]
2.31175972512895  -  47.7531  =  -45.44134027487105
training  [-0.1477, 3.1454, 3.5618]  w:  [1.32057108 0.43799227 1.14261395]
5.252374926697011  -  94.1572  =  -88.90482507330299
training  [3.9048, 2.8907, -2.1849]  w:  [1.32057108 0.43799227 1.14261395]
3.9261729883415795  -  85.8791  =  -81.95292701165842
training  [2.9896, 3.5226, 2.3105]  w:  [1.32057108 0.43799227 1.14261395]
8.130860419160552  -  98.038  =  -89.90713958083944
training  [2.3434, 0.0564, -3.6224]  w:  [1.32057108 0.43799227 1.14261395]
-1.0196757527758233  -  24.7629  =  -25.78257575277582
training  [-4.4867, 1.3566, 3.3672]  w:  [1.32057108 0.43799227 1.14261395]
-1.483416239512871  -  40.5785  =  -42.06191623951287
training  [-4.2711, 4.5089, -3.614]  w:  [1.32057108 0.43799227 1.14261395]
-7.794834600754493  -  10.0825  =  -17.877334600754494
training  [-4.1147, -0.5604, 0.8821]  w:  [1.32057108 0.43799227 1.14261395]
-4.671304921156348  -  8.344  =  -13.015304921156346
training  [2.9835, -4.3998, -1.3384]  w:  [1.32057108 0.43799227 1.14261395]
0.48357089494944216  -  13.2692  =  -12.785629105050557
training  [4.4301, 3.6675, 3.0676]  w:  [1.32057108 0.43799227 1.14261395]
10.961681162922453  -  99.3834  =  -88.42171883707755
training  [1.8372, 1.3119, 0.0378]  w:  [1.32057108 0.43799227 1.14261395]
3.043946057472981  -  74.9026  =  -71.85865394252703
training  [-3.6792, -1.4493, -0.1041]  w:  [1.32057108 0.43799227 1.14261395]
-5.612373428631568  -  4.2442  =  -9.856573428631568
training  [2.2272, 4.97, 3.7705]  w:  [1.32057108 0.43799227 1.14261395]
9.426223416580974  -  99.3199  =  -89.89367658341902
training  [-3.8965, -2.7583, -1.4686]  w:  [1.32057108 0.43799227 1.14261395]
-8.031762149076531  -  1.0337  =  -9.06546214907653
training  [-3.8251, 1.5245, -0.5056]  w:  [1.32057108 0.43799227 1.14261395]
-4.961302828484178  -  12.9762  =  -17.937502828484178
training  [1.4072, 1.0499, 4.6353]  w:  [1.32057108 0.43799227 1.14261395]
7.614514167252571  -  95.4618  =  -87.84728583274743
training  [-1.7119, -1.1275, -4.577]  w:  [1.32057108 0.43799227 1.14261395]
-7.984265982006036  -  1.4655  =  -9.449765982006037
training  [1.5381, -3.5781, 4.7296]  w:  [1.32057108 0.43799227 1.14261395]
5.868097175794747  -  69.9473  =  -64.07920282420525
training  [2.4913, -4.7487, -3.1079]  w:  [1.32057108 0.43799227 1.14261395]
-2.341085084417879  -  3.9825  =  -6.3235850844178785
training  [0.8319, -0.7889, 1.6712]  w:  [1.32057108 0.43799227 1.14261395]
2.662587414623153  -  58.8336  =  -56.17101258537684
training  [2.4003, -3.159, 0.8644]  w:  [1.32057108 0.43799227 1.14261395]
2.7738246704225675  -  39.0041  =  -36.23027532957743
training  [-2.6517, 2.2578, 1.7511]  w:  [1.32057108 0.43799227 1.14261395]
-0.5120280821687371  -  54.4525  =  -54.96452808216874
training  [2.3496, -1.2964, -1.3898]  w:  [1.32057108 0.43799227 1.14261395]
0.9469957521202499  -  33.888  =  -32.94100424787975
training  [4.706, 3.4156, 1.2028]  w:  [1.32057108 0.43799227 1.14261395]
9.084949970201682  -  98.4665  =  -89.38155002979832
training  [3.6693, 2.3423, 3.1115]  w:  [1.32057108 0.43799227 1.14261395]
9.42672407772175  -  98.3069  =  -88.88017592227826
training  [-4.1377, 0.7103, -4.8074]  w:  [1.32057108 0.43799227 1.14261395]
-10.646023360344188  -  0.9782  =  -11.624223360344187
training  [-1.3356, -3.2314, -4.1613]  w:  [1.32057108 0.43799227 1.14261395]
-7.933842408728042  -  0.7659  =  -8.699742408728042
training  [-1.308, 4.5738, 4.748]  w:  [1.32057108 0.43799227 1.14261395]
5.701113138187315  -  97.0884  =  -91.38728686181268
training  [1.8503, -2.3468, 1.5135]  w:  [1.32057108 0.43799227 1.14261395]
3.1449186183740934  -  50.2125  =  -47.06758138162591
training  [0.9794, 4.2458, -2.6876]  w:  [1.32057108 0.43799227 1.14261395]
0.08210564906372575  -  68.3262  =  -68.24409435093628
training  [2.8936, -2.7623, -0.9651]  w:  [1.32057108 0.43799227 1.14261395]
1.5086016913968503  -  28.5596  =  -27.05099830860315
training  [-1.3235, -1.2644, -3.7798]  w:  [1.32057108 0.43799227 1.14261395]
-6.620425473698068  -  2.4511  =  -9.071525473698069
training  [-2.9397, -4.125, -2.3156]  w:  [1.32057108 0.43799227 1.14261395]
-8.334637798996019  -  0.554  =  -8.888637798996019
training  [-4.1333, 1.4012, -2.4215]  w:  [1.32057108 0.43799227 1.14261395]
-7.611441355144766  -  4.4072  =  -12.018641355144766
training  [2.7193, -3.1938, -1.6833]  w:  [1.32057108 0.43799227 1.14261395]
0.2688071451948726  -  17.0949  =  -16.826092854805125
training  [-2.9433, -4.5495, -3.4777]  w:  [1.32057108 0.43799227 1.14261395]
-9.853151249868553  -  0.2509  =  -10.104051249868553
training  [-1.1173, 2.2317, -1.5199]  w:  [1.32057108 0.43799227 1.14261395]
-2.2346656573692423  -  33.1206  =  -35.355265657369245
training  [0.5178, -1.5256, -3.7834]  w:  [1.32057108 0.43799227 1.14261395]
-4.30737493781141  -  5.237  =  -9.54437493781141
training  [-2.7105, 1.6062, 3.8415]  w:  [1.32057108 0.43799227 1.14261395]
1.5134467805911034  -  70.4458  =  -68.9323532194089
training  [1.4194, -1.1613, -4.0572]  w:  [1.32057108 0.43799227 1.14261395]
-3.2700351680448776  -  8.3206  =  -11.590635168044878
training  [-0.1552, 1.2735, 4.3004]  w:  [1.32057108 0.43799227 1.14261395]
5.26652757271613  -  90.1085  =  -84.84197242728388
training  [-3.4815, -4.7835, -1.0098]  w:  [1.32057108 0.43799227 1.14261395]
-7.846515821738465  -  0.5839  =  -8.430415821738466
training  [2.8193, 4.1057, -4.526]  w:  [1.32057108 0.43799227 1.14261395]
0.3498801685833399  -  66.8081  =  -66.45821983141666
training  [-3.9939, 3.0056, -1.5763]  w:  [1.32057108 0.43799227 1.14261395]
-5.758901630037779  -  14.4018  =  -20.160701630037778
training  [-2.0593, 2.4585, 2.3597]  w:  [1.32057108 0.43799227 1.14261395]
1.0535781262320847  -  70.6698  =  -69.61622187376791
training  [-2.6263, 3.1311, 2.9468]  w:  [1.32057108 0.43799227 1.14261395]
1.2702365793734942  -  77.309  =  -76.03876342062651
training  [0.3087, -1.1669, 0.4491]  w:  [1.32057108 0.43799227 1.14261395]
0.4097150345802487  -  33.0798  =  -32.67008496541975
training  [-4.085, 1.1728, 1.8622]  w:  [1.32057108 0.43799227 1.14261395]
-2.7530798163321095  -  26.4056  =  -29.15867981633211
training  [-0.9468, 0.7549, 3.9363]  w:  [1.32057108 0.43799227 1.14261395]
3.5779949731678973  -  79.7738  =  -76.19580502683209
training  [-3.9515, 0.3005, -4.4521]  w:  [1.32057108 0.43799227 1.14261395]
-10.173651521532197  -  1.0441  =  -11.217751521532197
training  [-3.8772, -2.2493, -1.9634]  w:  [1.32057108 0.43799227 1.14261395]
-8.348702444067815  -  1.0509  =  -9.399602444067815
training  [2.8443, -2.5137, -4.5381]  w:  [1.32057108 0.43799227 1.14261395]
-2.530177238094577  -  6.8897  =  -9.419877238094578
training  [-2.0843, -0.4836, -3.0452]  w:  [1.32057108 0.43799227 1.14261395]
-6.443767373615142  -  3.5346  =  -9.978367373615143
training  [1.0353, -2.7229, 2.2017]  w:  [1.32057108 0.43799227 1.14261395]
2.690271217400397  -  43.9562  =  -41.26592878259961
training  [4.6442, 3.0445, 2.2175]  w:  [1.32057108 0.43799227 1.14261395]
10.000210123062018  -  98.8492  =  -88.84898987693798
training  [-0.6752, 4.861, 3.778]  w:  [1.32057108 0.43799227 1.14261395]
5.55422636345357  -  97.017  =  -91.46277363654643
training  [1.9475, -4.7001, 0.8243]  w:  [1.32057108 0.43799227 1.14261395]
1.4550613736861089  -  18.7839  =  -17.32883862631389
training  [2.581, 0.3566, -4.2932]  w:  [1.32057108 0.43799227 1.14261395]
-1.340888223642724  -  23.5455  =  -24.886388223642726
training  [-0.6736, -4.1292, 4.2274]  w:  [1.32057108 0.43799227 1.14261395]
2.1321918510094933  -  31.2667  =  -29.134508148990506
training  [1.555, 3.0209, 3.0037]  w:  [1.32057108 0.43799227 1.14261395]
6.808688417799709  -  96.4078  =  -89.59911158220028
training  [-3.9024, 4.8914, -2.1405]  w:  [1.32057108 0.43799227 1.14261395]
-5.456766339389164  -  25.4308  =  -30.887566339389167
training  [4.3376, -4.3305, 0.4366]  w:  [1.32057108 0.43799227 1.14261395]
4.3302488244780015  -  43.0907  =  -38.76045117552199
training  [-3.1254, 4.394, 4.8478]  w:  [1.32057108 0.43799227 1.14261395]
3.3363891207924885  -  92.8121  =  -89.47571087920751
training  [-2.3382, -4.8182, 2.1568]  w:  [1.32057108 0.43799227 1.14261395]
-2.7337038949706423  -  4.7434  =  -7.477103894970643
training  [2.9783, 1.8384, 3.3897]  w:  [1.32057108 0.43799227 1.14261395]
8.611380357234179  -  97.3486  =  -88.73721964276582
training  [-0.124, 2.8374, -0.6674]  w:  [1.32057108 0.43799227 1.14261395]
0.3164279105495902  -  62.785  =  -62.468572089450404
training  [2.6896, 0.3414, -0.2938]  w:  [1.32057108 0.43799227 1.14261395]
3.3656385570675456  -  70.4455  =  -67.07986144293245
training  [-1.0399, 3.8536, 0.6071]  w:  [1.32057108 0.43799227 1.14261395]
1.0082660907181162  -  77.0369  =  -76.0286339092819
training  [-2.2706, 3.99, -2.3091]  w:  [1.32057108 0.43799227 1.14261395]
-3.889309400294425  -  31.1134  =  -35.00270940029442
training  [-4.6277, 1.2594, 2.4902]  w:  [1.32057108 0.43799227 1.14261395]
-2.714262047523435  -  28.1093  =  -30.823562047523435
training  [1.7329, -3.6213, 0.0389]  w:  [1.32057108 0.43799227 1.14261395]
0.746763885927008  -  19.3919  =  -18.64513611407299
training  [-0.7044, -2.822, 1.4681]  w:  [1.32057108 0.43799227 1.14261395]
-0.48875291920548425  -  17.8122  =  -18.300952919205486
training  [-0.4826, -3.1786, -1.9225]  w:  [1.32057108 0.43799227 1.14261395]
-4.226185167993278  -  3.5851  =  -7.811285167993278
training  [1.0986, -4.5818, -3.6128]  w:  [1.32057108 0.43799227 1.14261395]
-4.6840493007648245  -  1.7158  =  -6.399849300764824
training  [-4.406, -3.9306, -0.2443]  w:  [1.32057108 0.43799227 1.14261395]
-7.819149193237344  -  0.8241  =  -8.643249193237343
training  [-1.8419, 1.1644, -1.3754]  w:  [1.32057108 0.43799227 1.14261395]
-3.493912898502841  -  17.8517  =  -21.345612898502843
training  [2.7272, 4.3966, 2.8811]  w:  [1.32057108 0.43799227 1.14261395]
8.819123336639738  -  98.904  =  -90.08487666336026
training  [1.9643, -1.4554, 2.803]  w:  [1.32057108 0.43799227 1.14261395]
5.159290726475522  -  76.0591  =  -70.89980927352448
training  [-3.7467, -0.8937, 1.6851]  w:  [1.32057108 0.43799227 1.14261395]
-3.4137985844379353  -  12.1571  =  -15.570898584437934
training  [-3.6985, 4.8435, -3.665]  w:  [1.32057108 0.43799227 1.14261395]
-6.950396697778655  -  14.6793  =  -21.629696697778655
255294.41422391
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.23222004 0.61504284 1.57488149]
10.02961804665672  -  87.3174  =  -77.28778195334328
training  [-4.1793, -4.9218, 1.7664]  w:  [1.23222004 0.61504284 1.57488149]
-5.395064399523978  -  1.5257  =  -6.9207643995239785
training  [-3.9429, -0.7689, 4.883]  w:  [1.23222004 0.61504284 1.57488149]
2.358719497665481  -  39.7859  =  -37.427180502334515
training  [-3.5796, 1.5557, 2.6683]  w:  [1.23222004 0.61504284 1.57488149]
0.7482235819284342  -  45.5674  =  -44.819176418071564
training  [-3.3354, 2.2292, -1.633]  w:  [1.23222004 0.61504284 1.57488149]
-5.310674701288878  -  13.3589  =  -18.66957470128888
training  [1.2096, 0.3121, 1.6238]  w:  [1.23222004 0.61504284 1.57488149]
4.239740801799908  -  74.5119  =  -70.27215919820009
training  [0.7371, -3.9118, -2.5583]  w:  [1.23222004 0.61504284 1.57488149]
-5.5266745206394114  -  3.3358  =  -8.862474520639411
training  [-4.4792, 1.3177, -2.0449]  w:  [1.23222004 0.61504284 1.57488149]
-7.929393220708096  -  4.2974  =  -12.226793220708096
training  [4.312, -3.735, 1.8018]  w:  [1.23222004 0.61504284 1.57488149]
5.853769278775056  -  66.5833  =  -60.72953072122494
training  [2.2866, -3.657, 0.2785]  w:  [1.23222004 0.61504284 1.57488149]
1.006987170469382  -  26.0005  =  -24.993512829530616
training  [2.3784, -4.0141, -0.8841]  w:  [1.23222004 0.61504284 1.57488149]
-0.9304840534512444  -  14.6809  =  -15.611384053451244
training  [-4.366, -3.5797, 1.0264]  w:  [1.23222004 0.61504284 1.57488149]
-5.965083189590445  -  1.8713  =  -7.836383189590444
training  [3.6044, -3.3175, 2.5052]  w:  [1.23222004 0.61504284 1.57488149]
6.346402407294217  -  71.0139  =  -64.66749759270579
training  [4.3441, -3.0375, 0.8353]  w:  [1.23222004 0.61504284 1.57488149]
4.800192959728201  -  63.8979  =  -59.0977070402718
training  [4.844, -1.8252, 0.5179]  w:  [1.23222004 0.61504284 1.57488149]
5.661928808065982  -  78.0461  =  -72.38417119193402
training  [3.5894, -1.8357, 0.8357]  w:  [1.23222004 0.61504284 1.57488149]
4.610024934308085  -  68.8838  =  -64.27377506569191
training  [2.8556, -2.8244, 0.1182]  w:  [1.23222004 0.61504284 1.57488149]
1.967751539536756  -  39.5252  =  -37.55744846046324
training  [0.1338, -2.4896, -4.1741]  w:  [1.23222004 0.61504284 1.57488149]
-7.94005246052466  -  2.2644  =  -10.20445246052466
training  [-3.224, 3.9292, 2.1957]  w:  [1.23222004 0.61504284 1.57488149]
1.901916217704473  -  72.1211  =  -70.21918378229553
training  [-1.0141, 2.0322, 4.9616]  w:  [1.23222004 0.61504284 1.57488149]
7.814227739975971  -  92.3427  =  -84.52847226002402
training  [-3.6607, 0.5574, -1.4547]  w:  [1.23222004 0.61504284 1.57488149]
-6.4589431319099715  -  5.8471  =  -12.306043131909972
training  [-4.6911, -3.1557, 4.7126]  w:  [1.23222004 0.61504284 1.57488149]
-0.29957159649418585  -  11.2337  =  -11.533271596494187
training  [4.3914, -2.8797, -1.5355]  w:  [1.23222004 0.61504284 1.57488149]
1.221801681738253  -  37.475  =  -36.253198318261745
training  [-1.9869, -4.2265, 3.8654]  w:  [1.23222004 0.61504284 1.57488149]
1.0397703607712296  -  15.7889  =  -14.74912963922877
training  [-2.0447, 4.138, -0.4531]  w:  [1.23222004 0.61504284 1.57488149]
-0.6880518449544467  -  57.936  =  -58.624051844954444
training  [-1.6706, 2.0672, -0.8657]  w:  [1.23222004 0.61504284 1.57488149]
-2.150505147777319  -  32.4185  =  -34.56900514777732
training  [-0.3293, 0.5779, -2.8227]  w:  [1.23222004 0.61504284 1.57488149]
-4.4957547948402645  -  14.3434  =  -18.839154794840265
training  [1.482, -1.8657, -3.7435]  w:  [1.23222004 0.61504284 1.57488149]
-5.216904202015986  -  7.1519  =  -12.368804202015987
training  [-4.7477, -3.338, -1.9109]  w:  [1.23222004 0.61504284 1.57488149]
-10.912665136975706  -  0.4077  =  -11.320365136975706
training  [3.4221, 1.225, 2.261]  w:  [1.23222004 0.61504284 1.57488149]
8.531014739053845  -  95.0454  =  -86.51438526094616
training  [0.5903, 4.8793, 2.8287]  w:  [1.23222004 0.61504284 1.57488149]
8.18322530717461  -  97.4647  =  -89.28147469282538
training  [3.541, -3.2957, 1.9379]  w:  [1.23222004 0.61504284 1.57488149]
5.388257319057388  -  64.3732  =  -58.98494268094261
training  [-1.5212, -2.4221, -4.902]  w:  [1.23222004 0.61504284 1.57488149]
-11.084217475261958  -  0.7227  =  -11.806917475261958
training  [-0.5397, -1.032, 3.4321]  w:  [1.23222004 0.61504284 1.57488149]
4.105397408023309  -  60.5921  =  -56.486702591976695
training  [-4.4576, -4.2601, 4.2233]  w:  [1.23222004 0.61504284 1.57488149]
-1.4616910459005048  -  6.0247  =  -7.486391045900505
training  [-3.2289, 1.841, 2.7095]  w:  [1.23222004 0.61504284 1.57488149]
1.4207199902578922  -  54.0111  =  -52.590380009742105
training  [1.6281, -0.9761, -4.5734]  w:  [1.23222004 0.61504284 1.57488149]
-5.79672889456741  -  7.8658  =  -13.66252889456741
training  [-1.6917, 4.8284, -1.2181]  w:  [1.23222004 0.61504284 1.57488149]
-1.0332369361282563  -  61.2837  =  -62.31693693612826
training  [3.9849, -0.9782, 2.0434]  w:  [1.23222004 0.61504284 1.57488149]
7.5267515770461015  -  88.3402  =  -80.8134484229539
training  [-3.8184, 1.2067, 2.2951]  w:  [1.23222004 0.61504284 1.57488149]
-0.34842628890143645  -  34.1122  =  -34.46062628890144
training  [4.8842, -3.4563, -2.7572]  w:  [1.23222004 0.61504284 1.57488149]
-0.4496267058980217  -  23.7819  =  -24.231526705898023
training  [0.3998, -1.1865, -2.3095]  w:  [1.23222004 0.61504284 1.57488149]
-3.8742955695201275  -  11.4246  =  -15.298895569520127
training  [2.0692, -3.3887, 1.7303]  w:  [1.23222004 0.61504284 1.57488149]
3.190531481110411  -  42.6881  =  -39.49756851888959
training  [4.9949, 2.5811, -0.2251]  w:  [1.23222004 0.61504284 1.57488149]
7.387797133075462  -  95.9901  =  -88.60230286692453
training  [-2.1215, 3.7111, 1.2372]  w:  [1.23222004 0.61504284 1.57488149]
1.616774056541478  -  71.3692  =  -69.75242594345853
training  [-0.8548, -1.4922, -2.6356]  w:  [1.23222004 0.61504284 1.57488149]
-6.121826284048591  -  4.7821  =  -10.903926284048591
training  [-0.3516, 1.8554, -3.2288]  w:  [1.23222004 0.61504284 1.57488149]
-4.377075446911512  -  20.3834  =  -24.760475446911514
training  [2.6396, -2.0585, 3.2964]  w:  [1.23222004 0.61504284 1.57488149]
7.177941687432637  -  80.826  =  -73.64805831256736
training  [3.182, 0.3063, 2.6692]  w:  [1.23222004 0.61504284 1.57488149]
8.31298547505781  -  92.9483  =  -84.63531452494219
training  [-3.9978, 3.3242, 4.3448]  w:  [1.23222004 0.61504284 1.57488149]
3.960901250490254  -  79.1768  =  -75.21589874950975
training  [-3.2188, 0.9749, -3.9211]  w:  [1.23222004 0.61504284 1.57488149]
-9.541932426922802  -  2.7053  =  -12.247232426922801
training  [-1.4037, -1.6469, -3.1777]  w:  [1.23222004 0.61504284 1.57488149]
-7.7470822497402905  -  2.6234  =  -10.370482249740292
training  [-4.433, -2.0077, -4.009]  w:  [1.23222004 0.61504284 1.57488149]
-13.010952861436792  -  0.3253  =  -13.336252861436792
training  [0.2189, -0.4741, -0.1024]  w:  [1.23222004 0.61504284 1.57488149]
-0.18312670913830867  -  33.6531  =  -33.83622670913831
training  [-1.6415, -0.7735, -3.0675]  w:  [1.23222004 0.61504284 1.57488149]
-7.329373817234924  -  3.7641  =  -11.093473817234923
training  [-3.2433, -1.4039, 3.9589]  w:  [1.23222004 0.61504284 1.57488149]
1.3748804451186807  -  30.0658  =  -28.69091955488132
training  [-2.9105, 0.5832, -4.0091]  w:  [1.23222004 0.61504284 1.57488149]
-9.541540840817191  -  2.4887  =  -12.030240840817191
training  [4.0515, 2.4255, -4.5583]  w:  [1.23222004 0.61504284 1.57488149]
-0.694656409458549  -  61.2853  =  -61.97995640945855
training  [1.7539, -0.7567, 0.573]  w:  [1.23222004 0.61504284 1.57488149]
2.5981949071687893  -  57.0797  =  -54.48150509283121
training  [-0.3153, -0.7064, 2.725]  w:  [1.23222004 0.61504284 1.57488149]
3.4685668296987453  -  58.7004  =  -55.23183317030126
training  [4.1213, -3.7513, -1.8806]  w:  [1.23222004 0.61504284 1.57488149]
-0.19058389516666008  -  22.1789  =  -22.36948389516666
training  [-3.9599, -4.7557, -3.2102]  w:  [1.23222004 0.61504284 1.57488149]
-12.860111950325653  -  0.1558  =  -13.015911950325652
training  [2.4555, -2.0981, -1.6104]  w:  [1.23222004 0.61504284 1.57488149]
-0.8008942338313141  -  24.4796  =  -25.280494233831316
training  [2.3627, -1.8248, -2.8985]  w:  [1.23222004 0.61504284 1.57488149]
-2.7757578976597976  -  15.7052  =  -18.4809578976598
training  [0.6186, 1.5369, 0.1015]  w:  [1.23222004 0.61504284 1.57488149]
1.867361131265505  -  65.2154  =  -63.3480388687345
training  [-3.1581, 4.5694, 4.0636]  w:  [1.23222004 0.61504284 1.57488149]
5.318591088135685  -  90.3564  =  -85.0378089118643
training  [0.9721, 4.3573, 1.2892]  w:  [1.23222004 0.61504284 1.57488149]
5.908104495346921  -  94.3178  =  -88.40969550465309
training  [-2.0006, -0.4211, -3.9847]  w:  [1.23222004 0.61504284 1.57488149]
-8.999604242934286  -  2.4051  =  -11.404704242934287
training  [-3.6588, -2.5952, -1.0915]  w:  [1.23222004 0.61504284 1.57488149]
-7.823589016231725  -  1.5176  =  -9.341189016231725
training  [-2.874, 2.639, -4.4538]  w:  [1.23222004 0.61504284 1.57488149]
-8.932509536902923  -  5.497  =  -14.429509536902923
training  [3.9494, 2.5933, 0.0128]  w:  [1.23222004 0.61504284 1.57488149]
6.481678910891574  -  94.1462  =  -87.66452108910842
training  [-4.2855, 2.4065, -0.6828]  w:  [1.23222004 0.61504284 1.57488149]
-4.875907470281307  -  14.4193  =  -19.295207470281305
training  [-2.5751, 2.4369, 4.9756]  w:  [1.23222004 0.61504284 1.57488149]
6.16168843556386  -  87.1991  =  -81.03741156443614
training  [-4.4625, -3.9408, 3.116]  w:  [1.23222004 0.61504284 1.57488149]
-3.0152120233440485  -  4.1344  =  -7.149612023344049
training  [-0.5828, 1.8156, -0.1435]  w:  [1.23222004 0.61504284 1.57488149]
0.17253844843906743  -  51.1166  =  -50.94406155156093
training  [-4.8672, -0.3674, 3.9445]  w:  [1.23222004 0.61504284 1.57488149]
-0.011308067222113749  -  24.1396  =  -24.150908067222115
training  [3.9719, -2.8784, -3.6245]  w:  [1.23222004 0.61504284 1.57488149]
-2.584242510737745  -  14.6104  =  -17.194642510737744
training  [-3.0334, -4.0148, -1.1]  w:  [1.23222004 0.61504284 1.57488149]
-7.939459912950639  -  1.021  =  -8.96045991295064
training  [-4.0663, 3.2357, 4.2736]  w:  [1.23222004 0.61504284 1.57488149]
3.7099313238951903  -  77.2328  =  -73.5228686761048
training  [-1.9263, -3.2499, 4.1749]  w:  [1.23222004 0.61504284 1.57488149]
2.2025195563329767  -  26.8814  =  -24.678880443667023
training  [-0.4394, -3.3643, 2.1357]  w:  [1.23222004 0.61504284 1.57488149]
0.7528482906633704  -  20.85  =  -20.097151709336632
training  [-3.9833, 1.6599, 1.1834]  w:  [1.23222004 0.61504284 1.57488149]
-2.0236777149596707  -  25.5397  =  -27.56337771495967
training  [4.9539, 3.9439, -1.5671]  w:  [1.23222004 0.61504284 1.57488149]
6.061965530260261  -  95.9509  =  -89.88893446973974
training  [-1.6791, 0.1656, 4.3603]  w:  [1.23222004 0.61504284 1.57488149]
4.899786203344042  -  71.5733  =  -66.67351379665597
training  [-2.0265, 2.027, -3.7523]  w:  [1.23222004 0.61504284 1.57488149]
-7.159829903292095  -  8.503  =  -15.662829903292096
training  [-4.3795, -3.4641, 2.3059]  w:  [1.23222004 0.61504284 1.57488149]
-3.895558335982184  -  3.6654  =  -7.560958335982184
training  [-2.0176, 4.5346, 1.4648]  w:  [1.23222004 0.61504284 1.57488149]
2.609732526504666  -  81.6212  =  -79.01146747349533
training  [-4.5365, 0.4088, 3.3315]  w:  [1.23222004 0.61504284 1.57488149]
-0.09181900242107588  -  28.9449  =  -29.036719002421076
training  [0.0543, 1.7973, -1.0172]  w:  [1.23222004 0.61504284 1.57488149]
-0.4296434091858583  -  47.9317  =  -48.36134340918586
training  [2.6143, -4.6344, 2.4982]  w:  [1.23222004 0.61504284 1.57488149]
4.3054072572498985  -  43.5132  =  -39.2077927427501
training  [1.3107, 3.092, 3.3522]  w:  [1.23222004 0.61504284 1.57488149]
8.79610101646944  -  96.6993  =  -87.90319898353056
training  [-4.1011, 2.4862, -1.7754]  w:  [1.23222004 0.61504284 1.57488149]
-6.320382700846737  -  10.0187  =  -16.33908270084674
training  [-4.1914, -3.7981, 0.5226]  w:  [1.23222004 0.61504284 1.57488149]
-6.677688223771084  -  1.4295  =  -8.107188223771084
training  [2.7724, 0.2505, 4.7913]  w:  [1.23222004 0.61504284 1.57488149]
11.116004774604486  -  96.7925  =  -85.67649522539551
training  [4.0513, -1.7417, 0.4931]  w:  [1.23222004 0.61504284 1.57488149]
4.697446998181059  -  71.1234  =  -66.42595300181894
training  [0.3377, 0.4645, -1.6958]  w:  [1.23222004 0.61504284 1.57488149]
-1.9688759303311052  -  27.9534  =  -29.922275930331104
training  [-3.9085, -1.0112, 1.1947]  w:  [1.23222004 0.61504284 1.57488149]
-3.556552428088686  -  8.608  =  -12.164552428088687
training  [3.2581, -0.8491, -1.3936]  w:  [1.23222004 0.61504284 1.57488149]
1.2977083871771908  -  50.1924  =  -48.89469161282281
training  [-1.619, -3.1926, 2.5651]  w:  [1.23222004 0.61504284 1.57488149]
0.08117850034284757  -  16.4754  =  -16.394221499657153
training  [-2.0603, -2.4461, -0.861]  w:  [1.23222004 0.61504284 1.57488149]
-5.399172209554593  -  3.9784  =  -9.377572209554593
training  [2.4631, -4.7946, -0.0765]  w:  [1.23222004 0.61504284 1.57488149]
-0.03428165891038713  -  15.394  =  -15.428281658910388
training  [-4.8966, 4.2368, 1.9474]  w:  [1.23222004 0.61504284 1.57488149]
-0.36095091900501775  -  53.5883  =  -53.94925091900502
training  [-4.5155, 1.537, 4.7273]  w:  [1.23222004 0.61504284 1.57488149]
2.8261685413127084  -  59.2523  =  -56.42613145868729
training  [1.6792, 4.3261, -1.7225]  w:  [1.23222004 0.61504284 1.57488149]
2.0171473534924793  -  83.7729  =  -81.75575264650753
training  [1.0347, -3.3649, 3.378]  w:  [1.23222004 0.61504284 1.57488149]
4.52537010672738  -  50.5979  =  -46.07252989327262
training  [0.261, 4.211, 2.3907]  w:  [1.23222004 0.61504284 1.57488149]
6.676624022680878  -  94.9375  =  -88.26087597731912
training  [2.2971, 2.9466, 4.5417]  w:  [1.23222004 0.61504284 1.57488149]
11.795457172513846  -  98.7784  =  -86.98294282748616
training  [2.0725, 0.7739, -4.6808]  w:  [1.23222004 0.61504284 1.57488149]
-4.341947609016498  -  19.5109  =  -23.852847609016496
training  [2.8138, -0.5996, -1.4313]  w:  [1.23222004 0.61504284 1.57488149]
0.8443131797461478  -  47.2879  =  -46.443586820253856
training  [-2.1202, -2.4239, 1.6265]  w:  [1.23222004 0.61504284 1.57488149]
-1.541810522301688  -  12.3599  =  -13.901710522301688
training  [1.9253, 2.5195, -2.185]  w:  [1.23222004 0.61504284 1.57488149]
0.4808776175713172  -  65.2467  =  -64.76582238242868
training  [0.5667, -2.7133, -2.6962]  w:  [1.23222004 0.61504284 1.57488149]
-5.216692128433397  -  5.1106  =  -10.327292128433397
training  [-1.0348, -4.3581, 2.1113]  w:  [1.23222004 0.61504284 1.57488149]
-0.6304722054303467  -  10.5192  =  -11.149672205430345
training  [-4.3841, 2.6733, 1.2457]  w:  [1.23222004 0.61504284 1.57488149]
-1.796151974853096  -  32.4639  =  -34.2600519748531
training  [2.8018, 1.712, 0.9061]  w:  [1.23222004 0.61504284 1.57488149]
5.932387575236113  -  90.1138  =  -84.18141242476389
training  [-1.6242, 2.1521, 1.6044]  w:  [1.23222004 0.61504284 1.57488149]
1.8490017779194727  -  63.7879  =  -61.938898222080525
training  [1.0787, 1.4206, -4.5245]  w:  [1.23222004 0.61504284 1.57488149]
-4.92262570230856  -  18.0555  =  -22.97812570230856
training  [2.4125, -0.8095, -1.5122]  w:  [1.23222004 0.61504284 1.57488149]
0.09331787227738086  -  38.8276  =  -38.734282127722615
training  [-3.9519, -1.0924, -0.4866]  w:  [1.23222004 0.61504284 1.57488149]
-6.307820512596685  -  3.6777  =  -9.985520512596684
training  [-3.7211, 3.1614, -2.591]  w:  [1.23222004 0.61504284 1.57488149]
-6.721335505716036  -  11.1518  =  -17.873135505716036
training  [0.4954, -1.8257, 2.1505]  w:  [1.23222004 0.61504284 1.57488149]
2.874340746011122  -  47.7531  =  -44.87875925398888
training  [-0.1477, 3.1454, 3.5618]  w:  [1.23222004 0.61504284 1.57488149]
7.361969758354553  -  94.1572  =  -86.79523024164546
training  [3.9048, 2.8907, -2.1849]  w:  [1.23222004 0.61504284 1.57488149]
3.1485185784413185  -  85.8791  =  -82.73058142155868
training  [2.9896, 3.5226, 2.3105]  w:  [1.23222004 0.61504284 1.57488149]
9.489158637378747  -  98.038  =  -88.54884136262125
training  [2.3434, 0.0564, -3.6224]  w:  [1.23222004 0.61504284 1.57488149]
-2.782577865226393  -  24.7629  =  -27.545477865226392
training  [-4.4867, 1.3566, 3.3672]  w:  [1.23222004 0.61504284 1.57488149]
0.6087064297904634  -  40.5785  =  -39.96979357020953
training  [-4.2711, 4.5089, -3.614]  w:  [1.23222004 0.61504284 1.57488149]
-8.181390067970886  -  10.0825  =  -18.263890067970884
training  [-4.1147, -0.5604, 0.8821]  w:  [1.23222004 0.61504284 1.57488149]
-4.025682842692027  -  8.344  =  -12.369682842692026
training  [2.9835, -4.3998, -1.3384]  w:  [1.23222004 0.61504284 1.57488149]
-1.1375583935847557  -  13.2692  =  -14.406758393584756
training  [4.4301, 3.6675, 3.0676]  w:  [1.23222004 0.61504284 1.57488149]
12.545634092530257  -  99.3834  =  -86.83776590746973
training  [1.8372, 1.3119, 0.0378]  w:  [1.23222004 0.61504284 1.57488149]
3.1302398821261677  -  74.9026  =  -71.77236011787384
training  [-3.6792, -1.4493, -0.1041]  w:  [1.23222004 0.61504284 1.57488149]
-5.588910726079239  -  4.2442  =  -9.833110726079239
training  [2.2272, 4.97, 3.7705]  w:  [1.23222004 0.61504284 1.57488149]
11.73925406824258  -  99.3199  =  -87.58064593175743
training  [-3.8965, -2.7583, -1.4686]  w:  [1.23222004 0.61504284 1.57488149]
-8.810689018671374  -  1.0337  =  -9.844389018671373
training  [-3.8251, 1.5245, -0.5056]  w:  [1.23222004 0.61504284 1.57488149]
-4.571992148807887  -  12.9762  =  -17.548192148807885
training  [1.4072, 1.0499, 4.6353]  w:  [1.23222004 0.61504284 1.57488149]
9.679761709522644  -  95.4618  =  -85.78203829047735
training  [-1.7119, -1.1275, -4.577]  w:  [1.23222004 0.61504284 1.57488149]
-10.011130889216927  -  1.4655  =  -11.476630889216928
training  [1.5381, -3.5781, 4.7296]  w:  [1.23222004 0.61504284 1.57488149]
7.143152368796654  -  69.9473  =  -62.80414763120334
training  [2.4913, -4.7487, -3.1079]  w:  [1.23222004 0.61504284 1.57488149]
-4.74539834860952  -  3.9825  =  -8.72789834860952
training  [0.8319, -0.7889, 1.6712]  w:  [1.23222004 0.61504284 1.57488149]
3.1718185072173535  -  58.8336  =  -55.661781492782644
training  [2.4003, -3.159, 0.8644]  w:  [1.23222004 0.61504284 1.57488149]
2.3761049913696293  -  39.0041  =  -36.62799500863037
training  [-2.6517, 2.2578, 1.7511]  w:  [1.23222004 0.61504284 1.57488149]
0.8789408298498222  -  54.4525  =  -53.573559170150176
training  [2.3496, -1.2964, -1.3898]  w:  [1.23222004 0.61504284 1.57488149]
-0.09088763275168876  -  33.888  =  -33.978887632751686
training  [4.706, 3.4156, 1.2028]  w:  [1.23222004 0.61504284 1.57488149]
9.793835299782911  -  98.4665  =  -88.67266470021708
training  [3.6693, 2.3423, 3.1115]  w:  [1.23222004 0.61504284 1.57488149]
10.862243610230761  -  98.3069  =  -87.44465638976924
training  [-4.1377, 0.7103, -4.8074]  w:  [1.23222004 0.61504284 1.57488149]
-12.23277722609999  -  0.9782  =  -13.21097722609999
training  [-1.3356, -3.2314, -4.1613]  w:  [1.23222004 0.61504284 1.57488149]
-10.186756884420873  -  0.7659  =  -10.952656884420874
training  [-1.308, 4.5738, 4.748]  w:  [1.23222004 0.61504284 1.57488149]
8.678876468051651  -  97.0884  =  -88.40952353194834
training  [1.8503, -2.3468, 1.5135]  w:  [1.23222004 0.61504284 1.57488149]
3.2201773425423923  -  50.2125  =  -46.992322657457606
training  [0.9794, 4.2458, -2.6876]  w:  [1.23222004 0.61504284 1.57488149]
-0.4144663009302083  -  68.3262  =  -68.74066630093022
training  [2.8936, -2.7623, -0.9651]  w:  [1.23222004 0.61504284 1.57488149]
0.34670093893949594  -  28.5596  =  -28.212899061060504
training  [-1.3235, -1.2644, -3.7798]  w:  [1.23222004 0.61504284 1.57488149]
-8.361240463354353  -  2.4511  =  -10.812340463354353
training  [-2.9397, -4.125, -2.3156]  w:  [1.23222004 0.61504284 1.57488149]
-9.806204560498427  -  0.554  =  -10.360204560498428
training  [-4.1333, 1.4012, -2.4215]  w:  [1.23222004 0.61504284 1.57488149]
-8.044912602159883  -  4.4072  =  -12.452112602159882
training  [2.7193, -3.1938, -1.6833]  w:  [1.23222004 0.61504284 1.57488149]
-1.264545889145704  -  17.0949  =  -18.359445889145704
training  [-2.9433, -4.5495, -3.4777]  w:  [1.23222004 0.61504284 1.57488149]
-11.901896023025948  -  0.2509  =  -12.152796023025948
training  [-1.1173, 2.2317, -1.5199]  w:  [1.23222004 0.61504284 1.57488149]
-2.397830725469728  -  33.1206  =  -35.518430725469734
training  [0.5178, -1.5256, -3.7834]  w:  [1.23222004 0.61504284 1.57488149]
-6.258672466356753  -  5.237  =  -11.495672466356753
training  [-2.7105, 1.6062, 3.8415]  w:  [1.23222004 0.61504284 1.57488149]
3.697856651457924  -  70.4458  =  -66.74794334854208
training  [1.4194, -1.1613, -4.0572]  w:  [1.23222004 0.61504284 1.57488149]
-5.354845323933881  -  8.3206  =  -13.675445323933882
training  [-0.1552, 1.2735, 4.3004]  w:  [1.23222004 0.61504284 1.57488149]
7.364636885223248  -  90.1085  =  -82.74386311477676
training  [-3.4815, -4.7835, -1.0098]  w:  [1.23222004 0.61504284 1.57488149]
-8.822346834313764  -  0.5839  =  -9.406246834313764
training  [2.8193, 4.1057, -4.526]  w:  [1.23222004 0.61504284 1.57488149]
-1.1287342893197447  -  66.8081  =  -67.93683428931973
training  [-3.9939, 3.0056, -1.5763]  w:  [1.23222004 0.61504284 1.57488149]
-5.555276555330804  -  14.4018  =  -19.957076555330804
training  [-2.0593, 2.4585, 2.3597]  w:  [1.23222004 0.61504284 1.57488149]
2.6908199573533422  -  70.6698  =  -67.97898004264665
training  [-2.6263, 3.1311, 2.9468]  w:  [1.23222004 0.61504284 1.57488149]
3.3304419345766942  -  77.309  =  -73.9785580654233
training  [0.3087, -1.1669, 0.4491]  w:  [1.23222004 0.61504284 1.57488149]
0.36997211413718006  -  33.0798  =  -32.70982788586282
training  [-4.085, 1.1728, 1.8622]  w:  [1.23222004 0.61504284 1.57488149]
-1.3795523028029955  -  26.4056  =  -27.785152302802995
training  [-0.9468, 0.7549, 3.9363]  w:  [1.23222004 0.61504284 1.57488149]
5.4968359317647675  -  79.7738  =  -74.27696406823523
training  [-3.9515, 0.3005, -4.4521]  w:  [1.23222004 0.61504284 1.57488149]
-11.695827016019374  -  1.0441  =  -12.739927016019374
training  [-3.8772, -2.2493, -1.9634]  w:  [1.23222004 0.61504284 1.57488149]
-9.253101729023463  -  1.0509  =  -10.304001729023463
training  [2.8443, -2.5137, -4.5381]  w:  [1.23222004 0.61504284 1.57488149]
-5.188199437201281  -  6.8897  =  -12.077899437201282
training  [-2.0843, -0.4836, -3.0452]  w:  [1.23222004 0.61504284 1.57488149]
-7.6615800741754905  -  3.5346  =  -11.19618007417549
training  [1.0353, -2.7229, 2.2017]  w:  [1.23222004 0.61504284 1.57488149]
3.0684338412569123  -  43.9562  =  -40.88776615874309
training  [4.6442, 3.0445, 2.2175]  w:  [1.23222004 0.61504284 1.57488149]
11.087473955001014  -  98.8492  =  -87.76172604499898
training  [-0.6752, 4.861, 3.778]  w:  [1.23222004 0.61504284 1.57488149]
8.10763056434605  -  97.017  =  -88.90936943565394
training  [1.9475, -4.7001, 0.8243]  w:  [1.23222004 0.61504284 1.57488149]
0.8071604866170345  -  18.7839  =  -17.976739513382963
training  [2.581, 0.3566, -4.2932]  w:  [1.23222004 0.61504284 1.57488149]
-3.361597028946328  -  23.5455  =  -26.90709702894633
training  [-0.6736, -4.1292, 4.2274]  w:  [1.23222004 0.61504284 1.57488149]
3.287995709213984  -  31.2667  =  -27.978704290786016
training  [1.555, 3.0209, 3.0037]  w:  [1.23222004 0.61504284 1.57488149]
8.50455662564774  -  96.4078  =  -87.90324337435226
training  [-3.9024, 4.8914, -2.1405]  w:  [1.23222004 0.61504284 1.57488149]
-5.1712287707360725  -  25.4308  =  -30.602028770736073
training  [4.3376, -4.3305, 0.4366]  w:  [1.23222004 0.61504284 1.57488149]
3.369027884135384  -  43.0907  =  -39.721672115864614
training  [-3.1254, 4.394, 4.8478]  w:  [1.23222004 0.61504284 1.57488149]
6.486028236800238  -  92.8121  =  -86.32607176319976
training  [-2.3382, -4.8182, 2.1568]  w:  [1.23222004 0.61504284 1.57488149]
-2.447871909397204  -  4.7434  =  -7.191271909397204
training  [2.9783, 1.8384, 3.3897]  w:  [1.23222004 0.61504284 1.57488149]
10.138991506274934  -  97.3486  =  -87.20960849372507
training  [-0.124, 2.8374, -0.6674]  w:  [1.23222004 0.61504284 1.57488149]
0.5412513633380296  -  62.785  =  -62.24374863666197
training  [2.6896, 0.3414, -0.2938]  w:  [1.23222004 0.61504284 1.57488149]
3.0614544638106715  -  70.4455  =  -67.38404553618932
training  [-1.0399, 3.8536, 0.6071]  w:  [1.23222004 0.61504284 1.57488149]
2.0448540277236407  -  77.0369  =  -74.99204597227636
training  [-2.2706, 3.99, -2.3091]  w:  [1.23222004 0.61504284 1.57488149]
-3.980416745656558  -  31.1134  =  -35.093816745656554
training  [-4.6277, 1.2594, 2.4902]  w:  [1.23222004 0.61504284 1.57488149]
-1.0059898304107082  -  28.1093  =  -29.11528983041071
training  [1.7329, -3.6213, 0.0389]  w:  [1.23222004 0.61504284 1.57488149]
-0.03067764248977957  -  19.3919  =  -19.42257764248978
training  [-0.7044, -2.822, 1.4681]  w:  [1.23222004 0.61504284 1.57488149]
-0.2915431727615765  -  17.8122  =  -18.103743172761575
training  [-0.4826, -3.1786, -1.9225]  w:  [1.23222004 0.61504284 1.57488149]
-5.5773542388828545  -  3.5851  =  -9.162454238882855
training  [1.0986, -4.5818, -3.6128]  w:  [1.23222004 0.61504284 1.57488149]
-7.154018215136837  -  1.7158  =  -8.869818215136837
training  [-4.406, -3.9306, -0.2443]  w:  [1.23222004 0.61504284 1.57488149]
-8.2313924387412  -  0.8241  =  -9.055492438741199
training  [-1.8419, 1.1644, -1.3754]  w:  [1.23222004 0.61504284 1.57488149]
-3.719562215260448  -  17.8517  =  -21.57126221526045
training  [2.7272, 4.3966, 2.8811]  w:  [1.23222004 0.61504284 1.57488149]
10.601998922482547  -  98.904  =  -88.30200107751745
training  [1.9643, -1.4554, 2.803]  w:  [1.23222004 0.61504284 1.57488149]
5.939709302426296  -  76.0591  =  -70.1193906975737
training  [-3.7467, -0.8937, 1.6851]  w:  [1.23222004 0.61504284 1.57488149]
-2.51258980699388  -  12.1571  =  -14.66968980699388
training  [-3.6985, 4.8435, -3.665]  w:  [1.23222004 0.61504284 1.57488149]
-7.3503464943521575  -  14.6793  =  -22.029646494352157
249403.3406412963
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.1988487  0.58315007 1.60649877]
10.151028968586669  -  87.3174  =  -77.16637103141333
training  [-4.1793, -4.9218, 1.7664]  w:  [1.1988487  0.58315007 1.60649877]
-5.042776959339167  -  1.5257  =  -6.568476959339167
training  [-3.9429, -0.7689, 4.883]  w:  [1.1988487  0.58315007 1.60649877]
2.669208850862341  -  39.7859  =  -37.11669114913766
training  [-3.5796, 1.5557, 2.6683]  w:  [1.1988487  0.58315007 1.60649877]
0.9024284052863178  -  45.5674  =  -44.664971594713684
training  [-3.3354, 2.2292, -1.633]  w:  [1.1988487  0.58315007 1.60649877]
-5.322094328247424  -  13.3589  =  -18.680994328247422
training  [1.2096, 0.3121, 1.6238]  w:  [1.1988487  0.58315007 1.60649877]
4.240761229614993  -  74.5119  =  -70.27113877038501
training  [0.7371, -3.9118, -2.5583]  w:  [1.1988487  0.58315007 1.60649877]
-5.507400853082773  -  3.3358  =  -8.843200853082774
training  [-4.4792, 1.3177, -2.0449]  w:  [1.1988487  0.58315007 1.60649877]
-7.886595604465122  -  4.2974  =  -12.183995604465121
training  [4.312, -3.735, 1.8018]  w:  [1.1988487  0.58315007 1.60649877]
5.885959594192158  -  66.5833  =  -60.697340405807836
training  [2.2866, -3.657, 0.2785]  w:  [1.1988487  0.58315007 1.60649877]
1.0561175594103471  -  26.0005  =  -24.944382440589653
training  [2.3784, -4.0141, -0.8841]  w:  [1.1988487  0.58315007 1.60649877]
-0.9097864877183159  -  14.6809  =  -15.590686487718315
training  [-4.366, -3.5797, 1.0264]  w:  [1.1988487  0.58315007 1.60649877]
-5.672765397213181  -  1.8713  =  -7.54406539721318
training  [3.6044, -3.3175, 2.5052]  w:  [1.1988487  0.58315007 1.60649877]
6.4111306386762115  -  71.0139  =  -64.6027693613238
training  [4.3441, -3.0375, 0.8353]  w:  [1.1988487  0.58315007 1.60649877]
4.778508748444919  -  63.8979  =  -59.11939125155508
training  [4.844, -1.8252, 0.5179]  w:  [1.1988487  0.58315007 1.60649877]
5.574863331851879  -  78.0461  =  -72.47123666814812
training  [3.5894, -1.8357, 0.8357]  w:  [1.1988487  0.58315007 1.60649877]
4.575209981374533  -  68.8838  =  -64.30859001862547
training  [2.8556, -2.8244, 0.1182]  w:  [1.1988487  0.58315007 1.60649877]
1.966271464605016  -  39.5252  =  -37.55892853539498
training  [0.1338, -2.4896, -4.1741]  w:  [1.1988487  0.58315007 1.60649877]
-7.997090962843828  -  2.2644  =  -10.261490962843828
training  [-3.224, 3.9292, 2.1957]  w:  [1.1988487  0.58315007 1.60649877]
1.953614369150745  -  72.1211  =  -70.16748563084926
training  [-1.0141, 2.0322, 4.9616]  w:  [1.1988487  0.58315007 1.60649877]
7.940129389371085  -  92.3427  =  -84.40257061062891
training  [-3.6607, 0.5574, -1.4547]  w:  [1.1988487  0.58315007 1.60649877]
-6.400551362444611  -  5.8471  =  -12.24765136244461
training  [-4.6911, -3.1557, 4.7126]  w:  [1.1988487  0.58315007 1.60649877]
0.10662028129320156  -  11.2337  =  -11.1270797187068
training  [4.3914, -2.8797, -1.5355]  w:  [1.1988487  0.58315007 1.60649877]
1.1185480901214842  -  37.475  =  -36.356451909878515
training  [-1.9869, -4.2265, 3.8654]  w:  [1.1988487  0.58315007 1.60649877]
1.363084097074796  -  15.7889  =  -14.425815902925205
training  [-2.0447, 4.138, -0.4531]  w:  [1.1988487  0.58315007 1.60649877]
-0.7661155610495081  -  57.936  =  -58.70211556104951
training  [-1.6706, 2.0672, -0.8657]  w:  [1.1988487  0.58315007 1.60649877]
-2.1880548113086453  -  32.4185  =  -34.60655481130865
training  [-0.3293, 0.5779, -2.8227]  w:  [1.1988487  0.58315007 1.60649877]
-4.592442531037808  -  14.3434  =  -18.935842531037807
training  [1.482, -1.8657, -3.7435]  w:  [1.1988487  0.58315007 1.60649877]
-5.325217443770664  -  7.1519  =  -12.477117443770664
training  [-4.7477, -3.338, -1.9109]  w:  [1.1988487  0.58315007 1.60649877]
-10.70818741171629  -  0.4077  =  -11.11588741171629
training  [3.4221, 1.225, 2.261]  w:  [1.1988487  0.58315007 1.60649877]
8.449232698349846  -  95.0454  =  -86.59616730165015
training  [0.5903, 4.8793, 2.8287]  w:  [1.1988487  0.58315007 1.60649877]
8.097347579166282  -  97.4647  =  -89.36735242083371
training  [3.541, -3.2957, 1.9379]  w:  [1.1988487  0.58315007 1.60649877]
5.436469550423795  -  64.3732  =  -58.9367304495762
training  [-1.5212, -2.4221, -4.902]  w:  [1.1988487  0.58315007 1.60649877]
-11.111193392271538  -  0.7227  =  -11.833893392271538
training  [-0.5397, -1.032, 3.4321]  w:  [1.1988487  0.58315007 1.60649877]
4.264834912304291  -  60.5921  =  -56.32726508769571
training  [-4.4576, -4.2601, 4.2233]  w:  [1.1988487  0.58315007 1.60649877]
-1.0435393278931269  -  6.0247  =  -7.068239327893127
training  [-3.2289, 1.841, 2.7095]  w:  [1.1988487  0.58315007 1.60649877]
1.555425109005105  -  54.0111  =  -52.45567489099489
training  [1.6281, -0.9761, -4.5734]  w:  [1.1988487  0.58315007 1.60649877]
-5.964528677583135  -  7.8658  =  -13.830328677583136
training  [-1.6917, 4.8284, -1.2181]  w:  [1.1988487  0.58315007 1.60649877]
-1.1692867212064444  -  61.2837  =  -62.45298672120645
training  [3.9849, -0.9782, 2.0434]  w:  [1.1988487  0.58315007 1.60649877]
7.489574389693003  -  88.3402  =  -80.85062561030699
training  [-3.8184, 1.2067, 2.2951]  w:  [1.1988487  0.58315007 1.60649877]
-0.18692137917821539  -  34.1122  =  -34.29912137917822
training  [4.8842, -3.4563, -2.7572]  w:  [1.1988487  0.58315007 1.60649877]
-0.5895631437189377  -  23.7819  =  -24.371463143718938
training  [0.3998, -1.1865, -2.3095]  w:  [1.1988487  0.58315007 1.60649877]
-3.9228167503203117  -  11.4246  =  -15.347416750320312
training  [2.0692, -3.3887, 1.7303]  w:  [1.1988487  0.58315007 1.60649877]
3.284261927545308  -  42.6881  =  -39.40383807245469
training  [4.9949, 2.5811, -0.2251]  w:  [1.1988487  0.58315007 1.60649877]
7.131675154342653  -  95.9901  =  -88.85842484565734
training  [-2.1215, 3.7111, 1.2372]  w:  [1.1988487  0.58315007 1.60649877]
1.6083309649853592  -  71.3692  =  -69.76086903501465
training  [-0.8548, -1.4922, -2.6356]  w:  [1.1988487  0.58315007 1.60649877]
-6.129040558105749  -  4.7821  =  -10.91114055810575
training  [-0.3516, 1.8554, -3.2288]  w:  [1.1988487  0.58315007 1.60649877]
-4.52660179721798  -  20.3834  =  -24.91000179721798
training  [2.6396, -2.0585, 3.2964]  w:  [1.1988487  0.58315007 1.60649877]
7.259729169619966  -  80.826  =  -73.56627083038003
training  [3.182, 0.3063, 2.6692]  w:  [1.1988487  0.58315007 1.60649877]
8.281421956009154  -  92.9483  =  -84.66687804399085
training  [-3.9978, 3.3242, 4.3448]  w:  [1.1988487  0.58315007 1.60649877]
4.125665957220674  -  79.1768  =  -75.05113404277932
training  [-3.2188, 0.9749, -3.9211]  w:  [1.1988487  0.58315007 1.60649877]
-9.589583532318425  -  2.7053  =  -12.294883532318424
training  [-1.4037, -1.6469, -3.1777]  w:  [1.1988487  0.58315007 1.60649877]
-7.748184909796494  -  2.6234  =  -10.371584909796495
training  [-4.433, -2.0077, -4.009]  w:  [1.1988487  0.58315007 1.60649877]
-12.925740259070974  -  0.3253  =  -13.251040259070974
training  [0.2189, -0.4741, -0.1024]  w:  [1.1988487  0.58315007 1.60649877]
-0.17854893935091115  -  33.6531  =  -33.83164893935091
training  [-1.6415, -0.7735, -3.0675]  w:  [1.1988487  0.58315007 1.60649877]
-7.346911698922737  -  3.7641  =  -11.111011698922738
training  [-3.2433, -1.4039, 3.9589]  w:  [1.1988487  0.58315007 1.60649877]
1.6530575988374174  -  30.0658  =  -28.412742401162582
training  [-2.9105, 0.5832, -4.0091]  w:  [1.1988487  0.58315007 1.60649877]
-9.589770249782719  -  2.4887  =  -12.078470249782718
training  [4.0515, 2.4255, -4.5583]  w:  [1.1988487  0.58315007 1.60649877]
-1.0513373307604388  -  61.2853  =  -62.33663733076044
training  [1.7539, -0.7567, 0.573]  w:  [1.1988487  0.58315007 1.60649877]
2.5819148808940695  -  57.0797  =  -54.497785119105934
training  [-0.3153, -0.7064, 2.725]  w:  [1.1988487  0.58315007 1.60649877]
3.587774943275346  -  58.7004  =  -55.11262505672465
training  [4.1213, -3.7513, -1.8806]  w:  [1.1988487  0.58315007 1.60649877]
-0.26793726819161545  -  22.1789  =  -22.446837268191615
training  [-3.9599, -4.7557, -3.2102]  w:  [1.1988487  0.58315007 1.60649877]
-12.677790103540774  -  0.1558  =  -12.833590103540773
training  [2.4555, -2.0981, -1.6104]  w:  [1.1988487  0.58315007 1.60649877]
-0.866839781145113  -  24.4796  =  -25.346439781145115
training  [2.3627, -1.8248, -2.8985]  w:  [1.1988487  0.58315007 1.60649877]
-2.888049092514067  -  15.7052  =  -18.593249092514068
training  [0.6186, 1.5369, 0.1015]  w:  [1.1988487  0.58315007 1.60649877]
1.8009107706892318  -  65.2154  =  -63.41448922931077
training  [-3.1581, 4.5694, 4.0636]  w:  [1.1988487  0.58315007 1.60649877]
5.406730222800855  -  90.3564  =  -84.94966977719913
training  [0.9721, 4.3573, 1.2892]  w:  [1.1988487  0.58315007 1.60649877]
5.77745882393199  -  94.3178  =  -88.54034117606801
training  [-2.0006, -0.4211, -3.9847]  w:  [1.1988487  0.58315007 1.60649877]
-9.045396856244597  -  2.4051  =  -11.450496856244598
training  [-3.6588, -2.5952, -1.0915]  w:  [1.1988487  0.58315007 1.60649877]
-7.6532320970438725  -  1.5176  =  -9.170832097043872
training  [-2.874, 2.639, -4.4538]  w:  [1.1988487  0.58315007 1.60649877]
-9.061582367792797  -  5.497  =  -14.558582367792797
training  [3.9494, 2.5933, 0.0128]  w:  [1.1988487  0.58315007 1.60649877]
6.267579322652036  -  94.1462  =  -87.87862067734795
training  [-4.2855, 2.4065, -0.6828]  w:  [1.1988487  0.58315007 1.60649877]
-4.831232844140179  -  14.4193  =  -19.250532844140178
training  [-2.5751, 2.4369, 4.9756]  w:  [1.1988487  0.58315007 1.60649877]
6.3272183776048605  -  87.1991  =  -80.87188162239514
training  [-4.4625, -3.9408, 3.116]  w:  [1.1988487  0.58315007 1.60649877]
-2.642089957627137  -  4.1344  =  -6.776489957627137
training  [-0.5828, 1.8156, -0.1435]  w:  [1.1988487  0.58315007 1.60649877]
0.1295456631044848  -  51.1166  =  -50.98705433689551
training  [-4.8672, -0.3674, 3.9445]  w:  [1.1988487  0.58315007 1.60649877]
0.2875486506782341  -  24.1396  =  -23.85205134932177
training  [3.9719, -2.8784, -3.6245]  w:  [1.1988487  0.58315007 1.60649877]
-2.7395867753150864  -  14.6104  =  -17.349986775315088
training  [-3.0334, -4.0148, -1.1]  w:  [1.1988487  0.58315007 1.60649877]
-7.744967191918849  -  1.021  =  -8.765967191918849
training  [-4.0663, 3.2357, 4.2736]  w:  [1.1988487  0.58315007 1.60649877]
3.8775533277324765  -  77.2328  =  -73.35524667226753
training  [-1.9263, -3.2499, 4.1749]  w:  [1.1988487  0.58315007 1.60649877]
2.502450052766103  -  26.8814  =  -24.378949947233895
training  [-0.4394, -3.3643, 2.1357]  w:  [1.1988487  0.58315007 1.60649877]
0.9423335321202622  -  20.85  =  -19.90766646787974
training  [-3.9833, 1.6599, 1.1834]  w:  [1.1988487  0.58315007 1.60649877]
-1.9062726021668954  -  25.5397  =  -27.445972602166897
training  [4.9539, 3.9439, -1.5671]  w:  [1.1988487  0.58315007 1.60649877]
5.7213179197937585  -  95.9509  =  -90.22958208020624
training  [-1.6791, 0.1656, 4.3603]  w:  [1.1988487  0.58315007 1.60649877]
5.088399376893395  -  71.5733  =  -66.48490062310661
training  [-2.0265, 2.027, -3.7523]  w:  [1.1988487  0.58315007 1.60649877]
-7.275487045440843  -  8.503  =  -15.778487045440844
training  [-4.3795, -3.4641, 2.3059]  w:  [1.1988487  0.58315007 1.60649877]
-3.5660225315390366  -  3.6654  =  -7.231422531539037
training  [-2.0176, 4.5346, 1.4648]  w:  [1.1988487  0.58315007 1.60649877]
2.578754545125582  -  81.6212  =  -79.04244545487443
training  [-4.5365, 0.4088, 3.3315]  w:  [1.1988487  0.58315007 1.60649877]
0.15186525309972865  -  28.9449  =  -28.793034746900272
training  [0.0543, 1.7973, -1.0172]  w:  [1.1988487  0.58315007 1.60649877]
-0.5209374488086926  -  47.9317  =  -48.452637448808694
training  [2.6143, -4.6344, 2.4982]  w:  [1.1988487  0.58315007 1.60649877]
4.444954722929372  -  43.5132  =  -39.06824527707062
training  [1.3107, 3.092, 3.3522]  w:  [1.1988487  0.58315007 1.60649877]
8.759736176959548  -  96.6993  =  -87.93956382304044
training  [-4.1011, 2.4862, -1.7754]  w:  [1.1988487  0.58315007 1.60649877]
-6.318948638322459  -  10.0187  =  -16.33764863832246
training  [-4.1914, -3.7981, 0.5226]  w:  [1.1988487  0.58315007 1.60649877]
-6.400160468134819  -  1.4295  =  -7.829660468134819
training  [2.7724, 0.2505, 4.7913]  w:  [1.1988487  0.58315007 1.60649877]
11.166984791818626  -  96.7925  =  -85.62551520818138
training  [4.0513, -1.7417, 0.4931]  w:  [1.1988487  0.58315007 1.60649877]
4.633387825491973  -  71.1234  =  -66.49001217450802
training  [0.3377, 0.4645, -1.6958]  w:  [1.1988487  0.58315007 1.60649877]
-2.048576199957086  -  27.9534  =  -30.001976199957085
training  [-3.9085, -1.0112, 1.1947]  w:  [1.1988487  0.58315007 1.60649877]
-3.3560974261194594  -  8.608  =  -11.96409742611946
training  [3.2581, -0.8491, -1.3936]  w:  [1.1988487  0.58315007 1.60649877]
1.1719995549490725  -  50.1924  =  -49.020400445050925
training  [-1.619, -3.1926, 2.5651]  w:  [1.1988487  0.58315007 1.60649877]
0.31812903923684477  -  16.4754  =  -16.157270960763157
training  [-2.0603, -2.4461, -0.861]  w:  [1.1988487  0.58315007 1.60649877]
-5.279626802843125  -  3.9784  =  -9.258026802843125
training  [2.4631, -4.7946, -0.0765]  w:  [1.1988487  0.58315007 1.60649877]
0.0340157766305316  -  15.394  =  -15.359984223369468
training  [-4.8966, 4.2368, 1.9474]  w:  [1.1988487  0.58315007 1.60649877]
-0.27109665664306615  -  53.5883  =  -53.859396656643064
training  [-4.5155, 1.537, 4.7273]  w:  [1.1988487  0.58315007 1.60649877]
3.0773019634469456  -  59.2523  =  -56.17499803655305
training  [1.6792, 4.3261, -1.7225]  w:  [1.1988487  0.58315007 1.60649877]
1.7686781164091667  -  83.7729  =  -82.00422188359084
training  [1.0347, -3.3649, 3.378]  w:  [1.1988487  0.58315007 1.60649877]
4.704959937491216  -  50.5979  =  -45.892940062508785
training  [0.261, 4.211, 2.3907]  w:  [1.1988487  0.58315007 1.60649877]
6.609201050468041  -  94.9375  =  -88.32829894953196
training  [2.2971, 2.9466, 4.5417]  w:  [1.1988487  0.58315007 1.60649877]
11.768420804843034  -  98.7784  =  -87.00997919515697
training  [2.0725, 0.7739, -4.6808]  w:  [1.1988487  0.58315007 1.60649877]
-4.583785664806635  -  19.5109  =  -24.094685664806633
training  [2.8138, -0.5996, -1.4313]  w:  [1.1988487  0.58315007 1.60649877]
0.7242820139101034  -  47.2879  =  -46.563617986089895
training  [-2.1202, -2.4239, 1.6265]  w:  [1.1988487  0.58315007 1.60649877]
-1.3423262197950234  -  12.3599  =  -13.702226219795023
training  [1.9253, 2.5195, -2.185]  w:  [1.1988487  0.58315007 1.60649877]
0.26719019109353326  -  65.2467  =  -64.97950980890647
training  [0.5667, -2.7133, -2.6962]  w:  [1.1988487  0.58315007 1.60649877]
-5.234315497594883  -  5.1106  =  -10.344915497594883
training  [-1.0348, -4.3581, 2.1113]  w:  [1.1988487  0.58315007 1.60649877]
-0.3901940923113192  -  10.5192  =  -10.909394092311318
training  [-4.3841, 2.6733, 1.2457]  w:  [1.1988487  0.58315007 1.60649877]
-1.6957220117218772  -  32.4639  =  -34.15962201172188
training  [2.8018, 1.712, 0.9061]  w:  [1.1988487  0.58315007 1.60649877]
5.812935747214897  -  90.1138  =  -84.3008642527851
training  [-1.6242, 2.1521, 1.6044]  w:  [1.1988487  0.58315007 1.60649877]
1.885293819538241  -  63.7879  =  -61.90260618046176
training  [1.0787, 1.4206, -4.5245]  w:  [1.1988487  0.58315007 1.60649877]
-5.146982600795839  -  18.0555  =  -23.20248260079584
training  [2.4125, -0.8095, -1.5122]  w:  [1.1988487  0.58315007 1.60649877]
-0.009184920336118285  -  38.8276  =  -38.836784920336115
training  [-3.9519, -1.0924, -0.4866]  w:  [1.1988487  0.58315007 1.60649877]
-6.1564856262934455  -  3.6777  =  -9.834185626293445
training  [-3.7211, 3.1614, -2.591]  w:  [1.1988487  0.58315007 1.60649877]
-6.779903602224565  -  11.1518  =  -17.931703602224566
training  [0.4954, -1.8257, 2.1505]  w:  [1.1988487  0.58315007 1.60649877]
2.984028174733403  -  47.7531  =  -44.7690718252666
training  [-0.1477, 3.1454, 3.5618]  w:  [1.1988487  0.58315007 1.60649877]
7.379197583071898  -  94.1572  =  -86.7780024169281
training  [3.9048, 2.8907, -2.1849]  w:  [1.1988487  0.58315007 1.60649877]
2.85693715474913  -  85.8791  =  -83.02216284525086
training  [2.9896, 3.5226, 2.3105]  w:  [1.1988487  0.58315007 1.60649877]
9.350097916257504  -  98.038  =  -88.6879020837425
training  [2.3434, 0.0564, -3.6224]  w:  [1.1988487  0.58315007 1.60649877]
-2.977109426253842  -  24.7629  =  -27.74000942625384
training  [-4.4867, 1.3566, 3.3672]  w:  [1.1988487  0.58315007 1.60649877]
0.8216295578046422  -  40.5785  =  -39.75687044219536
training  [-4.2711, 4.5089, -3.614]  w:  [1.1988487  0.58315007 1.60649877]
-8.296923915547676  -  10.0825  =  -18.379423915547676
training  [-4.1147, -0.5604, 0.8821]  w:  [1.1988487  0.58315007 1.60649877]
-3.8426074940921184  -  8.344  =  -12.186607494092119
training  [2.9835, -4.3998, -1.3384]  w:  [1.1988487  0.58315007 1.60649877]
-1.1391165087529473  -  13.2692  =  -14.408316508752947
training  [4.4301, 3.6675, 3.0676]  w:  [1.1988487  0.58315007 1.60649877]
12.377818136963413  -  99.3834  =  -87.00558186303658
training  [1.8372, 1.3119, 0.0378]  w:  [1.1988487  0.58315007 1.60649877]
3.028285064439759  -  74.9026  =  -71.87431493556025
training  [-3.6792, -1.4493, -0.1041]  w:  [1.1988487  0.58315007 1.60649877]
-5.42320006428026  -  4.2442  =  -9.66740006428026
training  [2.2272, 4.97, 3.7705]  w:  [1.1988487  0.58315007 1.60649877]
11.625635274381914  -  99.3199  =  -87.6942647256181
training  [-3.8965, -2.7583, -1.4686]  w:  [1.1988487  0.58315007 1.60649877]
-8.639120895740824  -  1.0337  =  -9.672820895740823
training  [-3.8251, 1.5245, -0.5056]  w:  [1.1988487  0.58315007 1.60649877]
-4.508949677807335  -  12.9762  =  -17.485149677807335
training  [1.4072, 1.0499, 4.6353]  w:  [1.1988487  0.58315007 1.60649877]
9.745872896756937  -  95.4618  =  -85.71592710324306
training  [-1.7119, -1.1275, -4.577]  w:  [1.1988487  0.58315007 1.60649877]
-10.062755663699729  -  1.4655  =  -11.52825566369973
training  [1.5381, -3.5781, 4.7296]  w:  [1.1988487  0.58315007 1.60649877]
7.355476517475866  -  69.9473  =  -62.591823482524134
training  [2.4913, -4.7487, -3.1079]  w:  [1.1988487  0.58315007 1.60649877]
-4.775350471470589  -  3.9825  =  -8.75785047147059
training  [0.8319, -0.7889, 1.6712]  w:  [1.1988487  0.58315007 1.60649877]
3.222055892481943  -  58.8336  =  -55.61154410751806
training  [2.4003, -3.159, 0.8644]  w:  [1.1988487  0.58315007 1.60649877]
2.424083019227196  -  39.0041  =  -36.580016980772804
training  [-2.6517, 2.2578, 1.7511]  w:  [1.1988487  0.58315007 1.60649877]
0.9507891079778032  -  54.4525  =  -53.501710892022196
training  [2.3496, -1.2964, -1.3898]  w:  [1.1988487  0.58315007 1.60649877]
-0.17189282188643995  -  33.888  =  -34.059892821886436
training  [4.706, 3.4156, 1.2028]  w:  [1.1988487  0.58315007 1.60649877]
9.565886087321324  -  98.4665  =  -88.90061391267866
training  [3.6693, 2.3423, 3.1115]  w:  [1.1988487  0.58315007 1.60649877]
10.763468870791364  -  98.3069  =  -87.54343112920864
training  [-4.1377, 0.7103, -4.8074]  w:  [1.1988487  0.58315007 1.60649877]
-12.26934697314869  -  0.9782  =  -13.247546973148689
training  [-1.3356, -3.2314, -4.1613]  w:  [1.1988487  0.58315007 1.60649877]
-10.170696783310538  -  0.7659  =  -10.936596783310538
training  [-1.308, 4.5738, 4.748]  w:  [1.1988487  0.58315007 1.60649877]
8.726773827650053  -  97.0884  =  -88.36162617234994
training  [1.8503, -2.3468, 1.5135]  w:  [1.1988487  0.58315007 1.60649877]
3.2811290675547493  -  50.2125  =  -46.93137093244525
training  [0.9794, 4.2458, -2.6876]  w:  [1.1988487  0.58315007 1.60649877]
-0.6675351191766388  -  68.3262  =  -68.99373511917663
training  [2.8936, -2.7623, -0.9651]  w:  [1.1988487  0.58315007 1.60649877]
0.30772121757905535  -  28.5596  =  -28.251878782420945
training  [-1.3235, -1.2644, -3.7798]  w:  [1.1988487  0.58315007 1.60649877]
-8.396255252320827  -  2.4511  =  -10.847355252320828
training  [-2.9397, -4.125, -2.3156]  w:  [1.1988487  0.58315007 1.60649877]
-9.6497581098283  -  0.554  =  -10.2037581098283
training  [-4.1333, 1.4012, -2.4215]  w:  [1.1988487  0.58315007 1.60649877]
-8.028228243840351  -  4.4072  =  -12.43542824384035
training  [2.7193, -3.1938, -1.6833]  w:  [1.1988487  0.58315007 1.60649877]
-1.3066547814437712  -  17.0949  =  -18.40155478144377
training  [-2.9433, -4.5495, -3.4777]  w:  [1.1988487  0.58315007 1.60649877]
-11.768533388401586  -  0.2509  =  -12.019433388401586
training  [-1.1173, 2.2317, -1.5199]  w:  [1.1988487  0.58315007 1.60649877]
-2.479775132520008  -  33.1206  =  -35.600375132520014
training  [0.5178, -1.5256, -3.7834]  w:  [1.1988487  0.58315007 1.60649877]
-6.346917327130287  -  5.237  =  -11.583917327130287
training  [-2.7105, 1.6062, 3.8415]  w:  [1.1988487  0.58315007 1.60649877]
3.858541248341912  -  70.4458  =  -66.5872587516581
training  [1.4194, -1.1613, -4.0572]  w:  [1.1988487  0.58315007 1.60649877]
-5.493453129626436  -  8.3206  =  -13.814053129626437
training  [-0.1552, 1.2735, 4.3004]  w:  [1.1988487  0.58315007 1.60649877]
7.465167599082205  -  90.1085  =  -82.6433324009178
training  [-3.4815, -4.7835, -1.0098]  w:  [1.1988487  0.58315007 1.60649877]
-8.585532563308496  -  0.5839  =  -9.169432563308495
training  [2.8193, 4.1057, -4.526]  w:  [1.1988487  0.58315007 1.60649877]
-1.4968600512211747  -  66.8081  =  -68.30496005122117
training  [-3.9939, 3.0056, -1.5763]  w:  [1.1988487  0.58315007 1.60649877]
-5.567690007663036  -  14.4018  =  -19.969490007663037
training  [-2.0593, 2.4585, 2.3597]  w:  [1.1988487  0.58315007 1.60649877]
2.755740449513751  -  70.6698  =  -67.91405955048624
training  [-2.6263, 3.1311, 2.9468]  w:  [1.1988487  0.58315007 1.60649877]
3.4113953968668342  -  77.309  =  -73.89760460313316
training  [0.3087, -1.1669, 0.4491]  w:  [1.1988487  0.58315007 1.60649877]
0.41108537938669104  -  33.0798  =  -32.66871462061331
training  [-4.085, 1.1728, 1.8622]  w:  [1.1988487  0.58315007 1.60649877]
-1.2217565481323676  -  26.4056  =  -27.62735654813237
training  [-0.9468, 0.7549, 3.9363]  w:  [1.1988487  0.58315007 1.60649877]
5.6288111386908675  -  79.7738  =  -74.14498886130913
training  [-3.9515, 0.3005, -4.4521]  w:  [1.1988487  0.58315007 1.60649877]
-11.714307229063024  -  1.0441  =  -12.758407229063025
training  [-3.8772, -2.2493, -1.9634]  w:  [1.1988487  0.58315007 1.60649877]
-9.11405532292999  -  1.0509  =  -10.164955322929991
training  [2.8443, -2.5137, -4.5381]  w:  [1.1988487  0.58315007 1.60649877]
-5.346431020062223  -  6.8897  =  -12.236131020062224
training  [-2.0843, -0.4836, -3.0452]  w:  [1.1988487  0.58315007 1.60649877]
-7.672881778047653  -  3.5346  =  -11.207481778047654
training  [1.0353, -2.7229, 2.2017]  w:  [1.1988487  0.58315007 1.60649877]
3.1903370870528795  -  43.9562  =  -40.76586291294712
training  [4.6442, 3.0445, 2.2175]  w:  [1.1988487  0.58315007 1.60649877]
10.905504549015191  -  98.8492  =  -87.9436954509848
training  [-0.6752, 4.861, 3.778]  w:  [1.1988487  0.58315007 1.60649877]
8.094582180184219  -  97.017  =  -88.92241781981578
training  [1.9475, -4.7001, 0.8243]  w:  [1.1988487  0.58315007 1.60649877]
0.9181311577782216  -  18.7839  =  -17.865768842221776
training  [2.581, 0.3566, -4.2932]  w:  [1.1988487  0.58315007 1.60649877]
-3.5948406987572388  -  23.5455  =  -27.14034069875724
training  [-0.6736, -4.1292, 4.2274]  w:  [1.1988487  0.58315007 1.60649877]
3.5758251556967977  -  31.2667  =  -27.690874844303202
training  [1.555, 3.0209, 3.0037]  w:  [1.1988487  0.58315007 1.60649877]
8.451288124398708  -  96.4078  =  -87.95651187560128
training  [-3.9024, 4.8914, -2.1405]  w:  [1.1988487  0.58315007 1.60649877]
-5.264677561247348  -  25.4308  =  -30.69547756124735
training  [4.3376, -4.3305, 0.4366]  w:  [1.1988487  0.58315007 1.60649877]
3.3761921362986276  -  43.0907  =  -39.71450786370137
training  [-3.1254, 4.394, 4.8478]  w:  [1.1988487  0.58315007 1.60649877]
6.603464388694338  -  92.8121  =  -86.20863561130567
training  [-2.3382, -4.8182, 2.1568]  w:  [1.1988487  0.58315007 1.60649877]
-2.1479851444179157  -  4.7434  =  -6.8913851444179155
training  [2.9783, 1.8384, 3.3897]  w:  [1.1988487  0.58315007 1.60649877]
10.08814305557081  -  97.3486  =  -87.2604569444292
training  [-0.124, 2.8374, -0.6674]  w:  [1.1988487  0.58315007 1.60649877]
0.4337954812029945  -  62.785  =  -62.351204518797005
training  [2.6896, 0.3414, -0.2938]  w:  [1.1988487  0.58315007 1.60649877]
2.9515215678550373  -  70.4455  =  -67.49397843214496
training  [-1.0399, 3.8536, 0.6071]  w:  [1.1988487  0.58315007 1.60649877]
1.975849732829825  -  77.0369  =  -75.06105026717017
training  [-2.2706, 3.99, -2.3091]  w:  [1.1988487  0.58315007 1.60649877]
-4.104903409124468  -  31.1134  =  -35.218303409124466
training  [-4.6277, 1.2594, 2.4902]  w:  [1.1988487  0.58315007 1.60649877]
-0.8129897166789961  -  28.1093  =  -28.922289716678996
training  [1.7329, -3.6213, 0.0389]  w:  [1.1988487  0.58315007 1.60649877]
0.028216384384152367  -  19.3919  =  -19.363683615615848
training  [-0.7044, -2.822, 1.4681]  w:  [1.1988487  0.58315007 1.60649877]
-0.13161767167373561  -  17.8122  =  -17.943817671673735
training  [-0.4826, -3.1786, -1.9225]  w:  [1.1988487  0.58315007 1.60649877]
-5.5206590705423535  -  3.5851  =  -9.105759070542353
training  [1.0986, -4.5818, -3.6128]  w:  [1.1988487  0.58315007 1.60649877]
-7.158780543703541  -  1.7158  =  -8.87458054370354
training  [-4.406, -3.9306, -0.2443]  w:  [1.1988487  0.58315007 1.60649877]
-7.966724690053705  -  0.8241  =  -8.790824690053705
training  [-1.8419, 1.1644, -1.3754]  w:  [1.1988487  0.58315007 1.60649877]
-3.7387178972193387  -  17.8517  =  -21.59041789721934
training  [2.7272, 4.3966, 2.8811]  w:  [1.1988487  0.58315007 1.60649877]
10.461861372498491  -  98.904  =  -88.4421386275015
training  [1.9643, -1.4554, 2.803]  w:  [1.1988487  0.58315007 1.60649877]
6.0091979523720465  -  76.0591  =  -70.04990204762795
training  [-3.7467, -0.8937, 1.6851]  w:  [1.1988487  0.58315007 1.60649877]
-2.305776576500916  -  12.1571  =  -14.462876576500916
training  [-3.6985, 4.8435, -3.665]  w:  [1.1988487  0.58315007 1.60649877]
-7.497272572724792  -  14.6793  =  -22.17657257272479
249492.98337446424
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.17225802 0.54795646 1.59685621]
10.132422708645953  -  87.3174  =  -77.18497729135406
training  [-4.1793, -4.9218, 1.7664]  w:  [1.17225802 0.54795646 1.59685621]
-4.775463249419752  -  1.5257  =  -6.301163249419751
training  [-3.9429, -0.7689, 4.883]  w:  [1.17225802 0.54795646 1.59685621]
2.754028985645247  -  39.7859  =  -37.03187101435475
training  [-3.5796, 1.5557, 2.6683]  w:  [1.17225802 0.54795646 1.59685621]
0.9171324761723816  -  45.5674  =  -44.650267523827615
training  [-3.3354, 2.2292, -1.633]  w:  [1.17225802 0.54795646 1.59685621]
-5.296111035480991  -  13.3589  =  -18.655011035480992
training  [1.2096, 0.3121, 1.6238]  w:  [1.17225802 0.54795646 1.59685621]
4.181955617759195  -  74.5119  =  -70.3299443822408
training  [0.7371, -3.9118, -2.5583]  w:  [1.17225802 0.54795646 1.59685621]
-5.364661931293782  -  3.3358  =  -8.700461931293782
training  [-4.4792, 1.3177, -2.0449]  w:  [1.17225802 0.54795646 1.59685621]
-7.79414714322565  -  4.2974  =  -12.09154714322565
training  [4.312, -3.735, 1.8018]  w:  [1.17225802 0.54795646 1.59685621]
5.885374704316406  -  66.5833  =  -60.69792529568359
training  [2.2866, -3.657, 0.2785]  w:  [1.17225802 0.54795646 1.59685621]
1.1213328590998684  -  26.0005  =  -24.87916714090013
training  [2.3784, -4.0141, -0.8841]  w:  [1.17225802 0.54795646 1.59685621]
-0.8232341317228948  -  14.6809  =  -15.504134131722894
training  [-4.366, -3.5797, 1.0264]  w:  [1.17225802 0.54795646 1.59685621]
-5.440585046513162  -  1.8713  =  -7.3118850465131615
training  [3.6044, -3.3175, 2.5052]  w:  [1.17225802 0.54795646 1.59685621]
6.407885407844664  -  71.0139  =  -64.60601459215535
training  [4.3441, -3.0375, 0.8353]  w:  [1.17225802 0.54795646 1.59685621]
4.7618422960598314  -  63.8979  =  -59.13605770394017
training  [4.844, -1.8252, 0.5179]  w:  [1.17225802 0.54795646 1.59685621]
5.505299538439635  -  78.0461  =  -72.54080046156037
training  [3.5894, -1.8357, 0.8357]  w:  [1.17225802 0.54795646 1.59685621]
4.5363119872551065  -  68.8838  =  -64.34748801274489
training  [2.8556, -2.8244, 0.1182]  w:  [1.17225802 0.54795646 1.59685621]
1.9886001720014175  -  39.5252  =  -37.53659982799858
training  [0.1338, -2.4896, -4.1741]  w:  [1.17225802 0.54795646 1.59685621]
-7.872781771246966  -  2.2644  =  -10.137181771246965
training  [-3.224, 3.9292, 2.1957]  w:  [1.17225802 0.54795646 1.59685621]
1.8798878465354827  -  72.1211  =  -70.24121215346452
training  [-1.0141, 2.0322, 4.9616]  w:  [1.17225802 0.54795646 1.59685621]
7.847732013558618  -  92.3427  =  -84.49496798644138
training  [-3.6607, 0.5574, -1.4547]  w:  [1.17225802 0.54795646 1.59685621]
-6.308800720055796  -  5.8471  =  -12.155900720055797
training  [-4.6911, -3.1557, 4.7126]  w:  [1.17225802 0.54795646 1.59685621]
0.296978756003746  -  11.2337  =  -10.936721243996255
training  [4.3914, -2.8797, -1.5355]  w:  [1.17225802 0.54795646 1.59685621]
1.1179309379800775  -  37.475  =  -36.357069062019924
training  [-1.9869, -4.2265, 3.8654]  w:  [1.17225802 0.54795646 1.59685621]
1.5273905342003573  -  15.7889  =  -14.261509465799643
training  [-2.0447, 4.138, -0.4531]  w:  [1.17225802 0.54795646 1.59685621]
-0.8530076797971113  -  57.936  =  -58.78900767979711
training  [-1.6706, 2.0672, -0.8657]  w:  [1.17225802 0.54795646 1.59685621]
-2.208037065996074  -  32.4185  =  -34.626537065996075
training  [-0.3293, 0.5779, -2.8227]  w:  [1.17225802 0.54795646 1.59685621]
-4.576806537731897  -  14.3434  =  -18.920206537731897
training  [1.482, -1.8657, -3.7435]  w:  [1.17225802 0.54795646 1.59685621]
-5.262867191759828  -  7.1519  =  -12.414767191759829
training  [-4.7477, -3.338, -1.9109]  w:  [1.17225802 0.54795646 1.59685621]
-10.44604058796983  -  0.4077  =  -10.85374058796983
training  [3.4221, 1.225, 2.261]  w:  [1.17225802 0.54795646 1.59685621]
8.2933227123935  -  95.0454  =  -86.7520772876065
training  [0.5903, 4.8793, 2.8287]  w:  [1.17225802 0.54795646 1.59685621]
7.882655020069112  -  97.4647  =  -89.58204497993088
training  [3.541, -3.2957, 1.9379]  w:  [1.17225802 0.54795646 1.59685621]
5.439613174929621  -  64.3732  =  -58.93358682507038
training  [-1.5212, -2.4221, -4.902]  w:  [1.17225802 0.54795646 1.59685621]
-10.938233363270474  -  0.7227  =  -11.660933363270473
training  [-0.5397, -1.032, 3.4321]  w:  [1.17225802 0.54795646 1.59685621]
4.28241146177943  -  60.5921  =  -56.30968853822057
training  [-4.4576, -4.2601, 4.2233]  w:  [1.17225802 0.54795646 1.59685621]
-0.8158038541276591  -  6.0247  =  -6.840503854127659
training  [-3.2289, 1.841, 2.7095]  w:  [1.17225802 0.54795646 1.59685621]
1.5503658175406994  -  54.0111  =  -52.4607341824593
training  [1.6281, -0.9761, -4.5734]  w:  [1.17225802 0.54795646 1.59685621]
-5.929369191924482  -  7.8658  =  -13.795169191924483
training  [-1.6917, 4.8284, -1.2181]  w:  [1.17225802 0.54795646 1.59685621]
-1.2824864552733686  -  61.2837  =  -62.566186455273375
training  [3.9849, -0.9782, 2.0434]  w:  [1.17225802 0.54795646 1.59685621]
7.398335938910187  -  88.3402  =  -80.9418640610898
training  [-3.8184, 1.2067, 2.2951]  w:  [1.17225802 0.54795646 1.59685621]
-0.1499862797175302  -  34.1122  =  -34.26218627971753
training  [4.8842, -3.4563, -2.7572]  w:  [1.17225802 0.54795646 1.59685621]
-0.5712112323486407  -  23.7819  =  -24.353111232348642
training  [0.3998, -1.1865, -2.3095]  w:  [1.17225802 0.54795646 1.59685621]
-3.869420992352682  -  11.4246  =  -15.294020992352682
training  [2.0692, -3.3887, 1.7303]  w:  [1.17225802 0.54795646 1.59685621]
3.3318165235980524  -  42.6881  =  -39.35628347640195
training  [4.9949, 2.5811, -0.2251]  w:  [1.17225802 0.54795646 1.59685621]
6.91018966949465  -  95.9901  =  -89.07991033050534
training  [-2.1215, 3.7111, 1.2372]  w:  [1.17225802 0.54795646 1.59685621]
1.5222063350671422  -  71.3692  =  -69.84699366493287
training  [-0.8548, -1.4922, -2.6356]  w:  [1.17225802 0.54795646 1.59685621]
-6.028381001722698  -  4.7821  =  -10.810481001722698
training  [-0.3516, 1.8554, -3.2288]  w:  [1.17225802 0.54795646 1.59685621]
-4.551416816927347  -  20.3834  =  -24.93481681692735
training  [2.6396, -2.0585, 3.2964]  w:  [1.17225802 0.54795646 1.59685621]
7.230200686195757  -  80.826  =  -73.59579931380424
training  [3.182, 0.3063, 2.6692]  w:  [1.17225802 0.54795646 1.59685621]
8.160292663892912  -  92.9483  =  -84.78800733610709
training  [-3.9978, 3.3242, 4.3448]  w:  [1.17225802 0.54795646 1.59685621]
4.073084603538842  -  79.1768  =  -75.10371539646115
training  [-3.2188, 0.9749, -3.9211]  w:  [1.17225802 0.54795646 1.59685621]
-9.500494224069486  -  2.7053  =  -12.205794224069486
training  [-1.4037, -1.6469, -3.1777]  w:  [1.17225802 0.54795646 1.59685621]
-7.6222580418804124  -  2.6234  =  -10.245658041880413
training  [-4.433, -2.0077, -4.009]  w:  [1.17225802 0.54795646 1.59685621]
-12.698548513355075  -  0.3253  =  -13.023848513355075
training  [0.2189, -0.4741, -0.1024]  w:  [1.17225802 0.54795646 1.59685621]
-0.16669695355720698  -  33.6531  =  -33.81979695355721
training  [-1.6415, -0.7735, -3.0675]  w:  [1.17225802 0.54795646 1.59685621]
-7.246462271363923  -  3.7641  =  -11.010562271363924
training  [-3.2433, -1.4039, 3.9589]  w:  [1.17225802 0.54795646 1.59685621]
1.7505335230157  -  30.0658  =  -28.3152664769843
training  [-2.9105, 0.5832, -4.0091]  w:  [1.17225802 0.54795646 1.59685621]
-9.49424496894743  -  2.4887  =  -11.98294496894743
training  [4.0515, 2.4255, -4.5583]  w:  [1.17225802 0.54795646 1.59685621]
-1.2004778806022802  -  61.2853  =  -62.48577788060228
training  [1.7539, -0.7567, 0.573]  w:  [1.17225802 0.54795646 1.59685621]
2.5563832905276667  -  57.0797  =  -54.52331670947233
training  [-0.3153, -0.7064, 2.725]  w:  [1.17225802 0.54795646 1.59685621]
3.5947437621902294  -  58.7004  =  -55.105656237809775
training  [4.1213, -3.7513, -1.8806]  w:  [1.17225802 0.54795646 1.59685621]
-0.22736988135164582  -  22.1789  =  -22.406269881351644
training  [-3.9599, -4.7557, -3.2102]  w:  [1.17225802 0.54795646 1.59685621]
-12.37416886412813  -  0.1558  =  -12.52996886412813
training  [2.4555, -2.0981, -1.6104]  w:  [1.17225802 0.54795646 1.59685621]
-0.8427651201226316  -  24.4796  =  -25.322365120122633
training  [2.3627, -1.8248, -2.8985]  w:  [1.17225802 0.54795646 1.59685621]
-2.8587046416297657  -  15.7052  =  -18.563904641629765
training  [0.6186, 1.5369, 0.1015]  w:  [1.17225802 0.54795646 1.59685621]
1.7293940011348028  -  65.2154  =  -63.4860059988652
training  [-3.1581, 4.5694, 4.0636]  w:  [1.17225802 0.54795646 1.59685621]
5.290709082948869  -  90.3564  =  -85.06569091705113
training  [0.9721, 4.3573, 1.2892]  w:  [1.17225802 0.54795646 1.59685621]
5.585829730341668  -  94.3178  =  -88.73197026965833
training  [-2.0006, -0.4211, -3.9847]  w:  [1.17225802 0.54795646 1.59685621]
-8.938956780557053  -  2.4051  =  -11.344056780557054
training  [-3.6588, -2.5952, -1.0915]  w:  [1.17225802 0.54795646 1.59685621]
-7.454082796786967  -  1.5176  =  -8.971682796786967
training  [-2.874, 2.639, -4.4538]  w:  [1.17225802 0.54795646 1.59685621]
-9.035090612112171  -  5.497  =  -14.532090612112171
training  [3.9494, 2.5933, 0.0128]  w:  [1.17225802 0.54795646 1.59685621]
6.071171070909583  -  94.1462  =  -88.07502892909041
training  [-4.2855, 2.4065, -0.6828]  w:  [1.17225802 0.54795646 1.59685621]
-4.795387932078687  -  14.4193  =  -19.214687932078686
training  [-2.5751, 2.4369, 4.9756]  w:  [1.17225802 0.54795646 1.59685621]
6.261951213018532  -  87.1991  =  -80.93714878698147
training  [-4.4625, -3.9408, 3.116]  w:  [1.17225802 0.54795646 1.59685621]
-2.414784296589704  -  4.1344  =  -6.549184296589704
training  [-0.5828, 1.8156, -0.1435]  w:  [1.17225802 0.54795646 1.59685621]
0.08252891278668423  -  51.1166  =  -51.03407108721331
training  [-4.8672, -0.3674, 3.9445]  w:  [1.17225802 0.54795646 1.59685621]
0.3918658692858008  -  24.1396  =  -23.7477341307142
training  [3.9719, -2.8784, -3.6245]  w:  [1.17225802 0.54795646 1.59685621]
-2.7089515708256435  -  14.6104  =  -17.319351570825646
training  [-3.0334, -4.0148, -1.1]  w:  [1.17225802 0.54795646 1.59685621]
-7.512404902418058  -  1.021  =  -8.533404902418058
training  [-4.0663, 3.2357, 4.2736]  w:  [1.17225802 0.54795646 1.59685621]
3.83059462056516  -  77.2328  =  -73.40220537943483
training  [-1.9263, -3.2499, 4.1749]  w:  [1.17225802 0.54795646 1.59685621]
2.6277906461342555  -  26.8814  =  -24.253609353865745
training  [-0.4394, -3.3643, 2.1357]  w:  [1.17225802 0.54795646 1.59685621]
1.0518257008893221  -  20.85  =  -19.79817429911068
training  [-3.9833, 1.6599, 1.1834]  w:  [1.17225802 0.54795646 1.59685621]
-1.8701828022927371  -  25.5397  =  -27.40988280229274
training  [4.9539, 3.9439, -1.5671]  w:  [1.17225802 0.54795646 1.59685621]
5.465901128788638  -  95.9509  =  -90.48499887121136
training  [-1.6791, 0.1656, 4.3603]  w:  [1.17225802 0.54795646 1.59685621]
5.0851752634521326  -  71.5733  =  -66.48812473654787
training  [-2.0265, 2.027, -3.7523]  w:  [1.17225802 0.54795646 1.59685621]
-7.2567566674693795  -  8.503  =  -15.759756667469379
training  [-4.3795, -3.4641, 2.3059]  w:  [1.17225802 0.54795646 1.59685621]
-3.349889247864895  -  3.6654  =  -7.015289247864895
training  [-2.0176, 4.5346, 1.4648]  w:  [1.17225802 0.54795646 1.59685621]
2.458690561717046  -  81.6212  =  -79.16250943828295
training  [-4.5365, 0.4088, 3.3315]  w:  [1.17225802 0.54795646 1.59685621]
0.22598254763026393  -  28.9449  =  -28.718917452369737
training  [0.0543, 1.7973, -1.0172]  w:  [1.17225802 0.54795646 1.59685621]
-0.5758263734013795  -  47.9317  =  -48.507526373401376
training  [2.6143, -4.6344, 2.4982]  w:  [1.17225802 0.54795646 1.59685621]
4.514450885677498  -  43.5132  =  -38.9987491143225
training  [1.3107, 3.092, 3.3522]  w:  [1.17225802 0.54795646 1.59685621]
8.583741336630649  -  96.6993  =  -88.11555866336934
training  [-4.1011, 2.4862, -1.7754]  w:  [1.17225802 0.54795646 1.59685621]
-6.280276513548599  -  10.0187  =  -16.2989765135486
training  [-4.1914, -3.7981, 0.5226]  w:  [1.17225802 0.54795646 1.59685621]
-6.160078643966489  -  1.4295  =  -7.589578643966489
training  [2.7724, 0.2505, 4.7913]  w:  [1.17225802 0.54795646 1.59685621]
11.038248362517033  -  96.7925  =  -85.75425163748297
training  [4.0513, -1.7417, 0.4931]  w:  [1.17225802 0.54795646 1.59685621]
4.582202937544718  -  71.1234  =  -66.54119706245528
training  [0.3377, 0.4645, -1.6958]  w:  [1.17225802 0.54795646 1.59685621]
-2.0575514439212323  -  27.9534  =  -30.01095144392123
training  [-3.9085, -1.0112, 1.1947]  w:  [1.17225802 0.54795646 1.59685621]
-3.2280999319116774  -  8.608  =  -11.836099931911678
training  [3.2581, -0.8491, -1.3936]  w:  [1.17225802 0.54795646 1.59685621]
1.1286852116834014  -  50.1924  =  -49.063714788316595
training  [-1.619, -3.1926, 2.5651]  w:  [1.17225802 0.54795646 1.59685621]
0.4488043209542836  -  16.4754  =  -16.026595679045716
training  [-2.0603, -2.4461, -0.861]  w:  [1.17225802 0.54795646 1.59685621]
-5.130452689866099  -  3.9784  =  -9.108852689866099
training  [2.4631, -4.7946, -0.0765]  w:  [1.17225802 0.54795646 1.59685621]
0.13799717576859796  -  15.394  =  -15.256002824231402
training  [-4.8966, 4.2368, 1.9474]  w:  [1.17225802 0.54795646 1.59685621]
-0.30877890403222663  -  53.5883  =  -53.89707890403222
training  [-4.5155, 1.537, 4.7273]  w:  [1.17225802 0.54795646 1.59685621]
3.097696337634229  -  59.2523  =  -56.15460366236577
training  [1.6792, 4.3261, -1.7225]  w:  [1.17225802 0.54795646 1.59685621]
1.588385299749874  -  83.7729  =  -82.18451470025013
training  [1.0347, -3.3649, 3.378]  w:  [1.17225802 0.54795646 1.59685621]
4.763296936694995  -  50.5979  =  -45.83460306330501
training  [0.261, 4.211, 2.3907]  w:  [1.17225802 0.54795646 1.59685621]
6.4310081331712885  -  94.9375  =  -88.50649186682871
training  [2.2971, 2.9466, 4.5417]  w:  [1.17225802 0.54795646 1.59685621]
11.55984423335521  -  98.7784  =  -87.2185557666448
training  [2.0725, 0.7739, -4.6808]  w:  [1.17225802 0.54795646 1.59685621]
-4.620996277038289  -  19.5109  =  -24.131896277038287
training  [2.8138, -0.5996, -1.4313]  w:  [1.17225802 0.54795646 1.59685621]
0.6843646321280632  -  47.2879  =  -46.603535367871935
training  [-2.1202, -2.4239, 1.6265]  w:  [1.17225802 0.54795646 1.59685621]
-1.2163265005553994  -  12.3599  =  -13.5762265005554
training  [1.9253, 2.5195, -2.185]  w:  [1.17225802 0.54795646 1.59685621]
0.14839385963551965  -  65.2467  =  -65.09830614036449
training  [0.5667, -2.7133, -2.6962]  w:  [1.17225802 0.54795646 1.59685621]
-5.127895349229919  -  5.1106  =  -10.238495349229918
training  [-1.0348, -4.3581, 2.1113]  w:  [1.17225802 0.54795646 1.59685621]
-0.22965914647468866  -  10.5192  =  -10.748859146474688
training  [-4.3841, 2.6733, 1.2457]  w:  [1.17225802 0.54795646 1.59685621]
-1.6852405964697066  -  32.4639  =  -34.14914059646971
training  [2.8018, 1.712, 0.9061]  w:  [1.17225802 0.54795646 1.59685621]
5.669445387257766  -  90.1138  =  -84.44435461274223
training  [-1.6242, 2.1521, 1.6044]  w:  [1.17225802 0.54795646 1.59685621]
1.8372717228840758  -  63.7879  =  -61.950628277115925
training  [1.0787, 1.4206, -4.5245]  w:  [1.17225802 0.54795646 1.59685621]
-5.182034227539694  -  18.0555  =  -23.23753422753969
training  [2.4125, -0.8095, -1.5122]  w:  [1.17225802 0.54795646 1.59685621]
-0.030264239148683814  -  38.8276  =  -38.85786423914868
training  [-3.9519, -1.0924, -0.4866]  w:  [1.17225802 0.54795646 1.59685621]
-6.008264332925456  -  3.6777  =  -9.685964332925456
training  [-3.7211, 3.1614, -2.591]  w:  [1.17225802 0.54795646 1.59685621]
-6.7672341847306345  -  11.1518  =  -17.919034184730634
training  [0.4954, -1.8257, 2.1505]  w:  [1.17225802 0.54795646 1.59685621]
3.0143717805514436  -  47.7531  =  -44.73872821944856
training  [-0.1477, 3.1454, 3.5618]  w:  [1.17225802 0.54795646 1.59685621]
7.238082177664788  -  94.1572  =  -86.91911782233521
training  [3.9048, 2.8907, -2.1849]  w:  [1.17225802 0.54795646 1.59685621]
2.67243973210835  -  85.8791  =  -83.20666026789165
training  [2.9896, 3.5226, 2.3105]  w:  [1.17225802 0.54795646 1.59685621]
9.124350267561471  -  98.038  =  -88.91364973243853
training  [2.3434, 0.0564, -3.6224]  w:  [1.17225802 0.54795646 1.59685621]
-3.0064777330165797  -  24.7629  =  -27.76937773301658
training  [-4.4867, 1.3566, 3.3672]  w:  [1.17225802 0.54795646 1.59685621]
0.8607218977996993  -  40.5785  =  -39.7177781022003
training  [-4.2711, 4.5089, -3.614]  w:  [1.17225802 0.54795646 1.59685621]
-8.307188661336848  -  10.0825  =  -18.389688661336848
training  [-4.1147, -0.5604, 0.8821]  w:  [1.17225802 0.54795646 1.59685621]
-3.7219780123544934  -  8.344  =  -12.065978012354492
training  [2.9835, -4.3998, -1.3384]  w:  [1.17225802 0.54795646 1.59685621]
-1.0506993859134042  -  13.2692  =  -14.319899385913404
training  [4.4301, 3.6675, 3.0676]  w:  [1.17225802 0.54795646 1.59685621]
12.10136666818429  -  99.3834  =  -87.28203333181571
training  [1.8372, 1.3119, 0.0378]  w:  [1.17225802 0.54795646 1.59685621]
2.9328976787552175  -  74.9026  =  -71.9697023212448
training  [-3.6792, -1.4493, -0.1041]  w:  [1.17225802 0.54795646 1.59685621]
-5.27335773372123  -  4.2442  =  -9.51755773372123
training  [2.2272, 4.97, 3.7705]  w:  [1.17225802 0.54795646 1.59685621]
11.355142996532294  -  99.3199  =  -87.96475700346771
training  [-3.8965, -2.7583, -1.4686]  w:  [1.17225802 0.54795646 1.59685621]
-8.424274701848177  -  1.0337  =  -9.457974701848176
training  [-3.8251, 1.5245, -0.5056]  w:  [1.17225802 0.54795646 1.59685621]
-4.456015019707203  -  12.9762  =  -17.432215019707204
training  [1.4072, 1.0499, 4.6353]  w:  [1.17225802 0.54795646 1.59685621]
9.626808542520966  -  95.4618  =  -85.83499145747903
training  [-1.7119, -1.1275, -4.577]  w:  [1.17225802 0.54795646 1.59685621]
-9.933420265502477  -  1.4655  =  -11.398920265502477
training  [1.5381, -3.5781, 4.7296]  w:  [1.17225802 0.54795646 1.59685621]
7.394898153132319  -  69.9473  =  -62.55240184686768
training  [2.4913, -4.7487, -3.1079]  w:  [1.17225802 0.54795646 1.59685621]
-4.644503847879266  -  3.9825  =  -8.627003847879266
training  [0.8319, -0.7889, 1.6712]  w:  [1.17225802 0.54795646 1.59685621]
3.2115846839713322  -  58.8336  =  -55.622015316028666
training  [2.4003, -3.159, 0.8644]  w:  [1.17225802 0.54795646 1.59685621]
2.463098964519452  -  39.0041  =  -36.54100103548055
training  [-2.6517, 2.2578, 1.7511]  w:  [1.17225802 0.54795646 1.59685621]
0.9249544118548636  -  54.4525  =  -53.52754558814514
training  [2.3496, -1.2964, -1.3898]  w:  [1.17225802 0.54795646 1.59685621]
-0.17534407012829334  -  33.888  =  -34.063344070128295
training  [4.706, 3.4156, 1.2028]  w:  [1.17225802 0.54795646 1.59685621]
9.308944970885442  -  98.4665  =  -89.15755502911455
training  [3.6693, 2.3423, 3.1115]  w:  [1.17225802 0.54795646 1.59685621]
10.553462851968042  -  98.3069  =  -87.75343714803196
training  [-4.1377, 0.7103, -4.8074]  w:  [1.17225802 0.54795646 1.59685621]
-12.137965052264406  -  0.9782  =  -13.116165052264405
training  [-1.3356, -3.2314, -4.1613]  w:  [1.17225802 0.54795646 1.59685621]
-9.981332047919201  -  0.7659  =  -10.747232047919201
training  [-1.308, 4.5738, 4.748]  w:  [1.17225802 0.54795646 1.59685621]
8.554803039098516  -  97.0884  =  -88.53359696090148
training  [1.8503, -2.3468, 1.5135]  w:  [1.17225802 0.54795646 1.59685621]
3.2999266552485906  -  50.2125  =  -46.91257334475141
training  [0.9794, 4.2458, -2.6876]  w:  [1.17225802 0.54795646 1.59685621]
-0.8170876896382238  -  68.3262  =  -69.14328768963823
training  [2.8936, -2.7623, -0.9651]  w:  [1.17225802 0.54795646 1.59685621]
0.33729974555932496  -  28.5596  =  -28.222300254440675
training  [-1.3235, -1.2644, -3.7798]  w:  [1.17225802 0.54795646 1.59685621]
-8.280116723545149  -  2.4511  =  -10.731216723545149
training  [-2.9397, -4.125, -2.3156]  w:  [1.17225802 0.54795646 1.59685621]
-9.404087531530365  -  0.554  =  -9.958087531530365
training  [-4.1333, 1.4012, -2.4215]  w:  [1.17225802 0.54795646 1.59685621]
-7.94428477695629  -  4.4072  =  -12.35148477695629
training  [2.7193, -3.1938, -1.6833]  w:  [1.17225802 0.54795646 1.59685621]
-1.2503301670950306  -  17.0949  =  -18.34523016709503
training  [-2.9433, -4.5495, -3.4777]  w:  [1.17225802 0.54795646 1.59685621]
-11.496621774759625  -  0.2509  =  -11.747521774759624
training  [-1.1173, 2.2317, -1.5199]  w:  [1.17225802 0.54795646 1.59685621]
-2.5139511958768823  -  33.1206  =  -35.63455119587689
training  [0.5178, -1.5256, -3.7834]  w:  [1.17225802 0.54795646 1.59685621]
-6.270512943546562  -  5.237  =  -11.507512943546562
training  [-2.7105, 1.6062, 3.8415]  w:  [1.17225802 0.54795646 1.59685621]
3.8370454219616357  -  70.4458  =  -66.60875457803837
training  [1.4194, -1.1613, -4.0572]  w:  [1.17225802 0.54795646 1.59685621]
-5.451203803863042  -  8.3206  =  -13.771803803863044
training  [-0.1552, 1.2735, 4.3004]  w:  [1.17225802 0.54795646 1.59685621]
7.383008535460162  -  90.1085  =  -82.72549146453984
training  [-3.4815, -4.7835, -1.0098]  w:  [1.17225802 0.54795646 1.59685621]
-8.314871422951152  -  0.5839  =  -8.898771422951151
training  [2.8193, 4.1057, -4.526]  w:  [1.17225802 0.54795646 1.59685621]
-1.6726793092272203  -  66.8081  =  -68.48077930922722
training  [-3.9939, 3.0056, -1.5763]  w:  [1.17225802 0.54795646 1.59685621]
-5.55206779726266  -  14.4018  =  -19.95386779726266
training  [-2.0593, 2.4585, 2.3597]  w:  [1.17225802 0.54795646 1.59685621]
2.701221610731637  -  70.6698  =  -67.96857838926836
training  [-2.6263, 3.1311, 2.9468]  w:  [1.17225802 0.54795646 1.59685621]
3.342621108361217  -  77.309  =  -73.96637889163878
training  [0.3087, -1.1669, 0.4491]  w:  [1.17225802 0.54795646 1.59685621]
0.43961377728208656  -  33.0798  =  -32.640186222717915
training  [-4.085, 1.1728, 1.8622]  w:  [1.17225802 0.54795646 1.59685621]
-1.1723650429532788  -  26.4056  =  -27.577965042953277
training  [-0.9468, 0.7549, 3.9363]  w:  [1.17225802 0.54795646 1.59685621]
5.589463522335426  -  79.7738  =  -74.18433647766457
training  [-3.9515, 0.3005, -4.4521]  w:  [1.17225802 0.54795646 1.59685621]
-11.576880157298357  -  1.0441  =  -12.620980157298357
training  [-3.8772, -2.2493, -1.9634]  w:  [1.17225802 0.54795646 1.59685621]
-8.912864733619108  -  1.0509  =  -9.963764733619108
training  [2.8443, -2.5137, -4.5381]  w:  [1.17225802 0.54795646 1.59685621]
-5.289837820686386  -  6.8897  =  -12.179537820686386
training  [-2.0843, -0.4836, -3.0452]  w:  [1.17225802 0.54795646 1.59685621]
-7.571075650512514  -  3.5346  =  -11.105675650512513
training  [1.0353, -2.7229, 2.2017]  w:  [1.17225802 0.54795646 1.59685621]
3.237406385311651  -  43.9562  =  -40.71879361468835
training  [4.6442, 3.0445, 2.2175]  w:  [1.17225802 0.54795646 1.59685621]
10.653482774150259  -  98.8492  =  -88.19571722584973
training  [-0.6752, 4.861, 3.778]  w:  [1.17225802 0.54795646 1.59685621]
7.905030489854831  -  97.017  =  -89.11196951014516
training  [1.9475, -4.7001, 0.8243]  w:  [1.17225802 0.54795646 1.59685621]
1.0238108967890105  -  18.7839  =  -17.760089103210987
training  [2.581, 0.3566, -4.2932]  w:  [1.17225802 0.54795646 1.59685621]
-3.634623840621535  -  23.5455  =  -27.180123840621537
training  [-0.6736, -4.1292, 4.2274]  w:  [1.17225802 0.54795646 1.59685621]
3.698295100459187  -  31.2667  =  -27.568404899540813
training  [1.555, 3.0209, 3.0037]  w:  [1.17225802 0.54795646 1.59685621]
8.274659878597994  -  96.4078  =  -88.133140121402
training  [-3.9024, 4.8914, -2.1405]  w:  [1.17225802 0.54795646 1.59685621]
-5.3124161644186945  -  25.4308  =  -30.743216164418698
training  [4.3376, -4.3305, 0.4366]  w:  [1.17225802 0.54795646 1.59685621]
3.409048344967796  -  43.0907  =  -39.681651655032205
training  [-3.1254, 4.394, 4.8478]  w:  [1.17225802 0.54795646 1.59685621]
6.485184993159088  -  92.8121  =  -86.32691500684092
training  [-2.3382, -4.8182, 2.1568]  w:  [1.17225802 0.54795646 1.59685621]
-1.9370380588684109  -  4.7434  =  -6.680438058868411
training  [2.9783, 1.8384, 3.3897]  w:  [1.17225802 0.54795646 1.59685621]
9.911562696320352  -  97.3486  =  -87.43703730367966
training  [-0.124, 2.8374, -0.6674]  w:  [1.17225802 0.54795646 1.59685621]
0.3436698382223904  -  62.785  =  -62.44133016177761
training  [2.6896, 0.3414, -0.2938]  w:  [1.17225802 0.54795646 1.59685621]
2.8708211503039287  -  70.4455  =  -67.57467884969607
training  [-1.0399, 3.8536, 0.6071]  w:  [1.17225802 0.54795646 1.59685621]
1.8620253089416254  -  77.0369  =  -75.17487469105838
training  [-2.2706, 3.99, -2.3091]  w:  [1.17225802 0.54795646 1.59685621]
-4.1626834399865125  -  31.1134  =  -35.27608343998651
training  [-4.6277, 1.2594, 2.4902]  w:  [1.17225802 0.54795646 1.59685621]
-0.7582707431518387  -  28.1093  =  -28.86757074315184
training  [1.7329, -3.6213, 0.0389]  w:  [1.17225802 0.54795646 1.59685621]
0.10920889290338187  -  19.3919  =  -19.282691107096618
training  [-0.7044, -2.822, 1.4681]  w:  [1.17225802 0.54795646 1.59685621]
-0.02772708778045807  -  17.8122  =  -17.83992708778046
training  [-0.4826, -3.1786, -1.9225]  w:  [1.17225802 0.54795646 1.59685621]
-5.377422183786158  -  3.5851  =  -8.962522183786158
training  [1.0986, -4.5818, -3.6128]  w:  [1.17225802 0.54795646 1.59685621]
-6.991906355449374  -  1.7158  =  -8.707706355449375
training  [-4.406, -3.9306, -0.2443]  w:  [1.17225802 0.54795646 1.59685621]
-7.708878469973323  -  0.8241  =  -8.532978469973322
training  [-1.8419, 1.1644, -1.3754]  w:  [1.17225802 0.54795646 1.59685621]
-3.7174575660932025  -  17.8517  =  -21.569157566093203
training  [2.7272, 4.3966, 2.8811]  w:  [1.17225802 0.54795646 1.59685621]
10.206829861705515  -  98.904  =  -88.69717013829448
training  [1.9643, -1.4554, 2.803]  w:  [1.17225802 0.54795646 1.59685621]
5.981158536255997  -  76.0591  =  -70.077941463744
training  [-3.7467, -0.8937, 1.6851]  w:  [1.17225802 0.54795646 1.59685621]
-2.190945417045871  -  12.1571  =  -14.34804541704587
training  [-3.6985, 4.8435, -3.665]  w:  [1.17225802 0.54795646 1.59685621]
-7.534047154177244  -  14.6793  =  -22.213347154177242
250017.13255768348
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.13244353 0.62748209 1.54269525]
9.38856508763669  -  87.3174  =  -77.92883491236331
training  [-4.1793, -4.9218, 1.7664]  w:  [1.13244353 0.62748209 1.54269525]
-5.096145721428  -  1.5257  =  -6.621845721428
training  [-3.9429, -0.7689, 4.883]  w:  [1.13244353 0.62748209 1.54269525]
2.5853983193626373  -  39.7859  =  -37.20050168063736
training  [-3.5796, 1.5557, 2.6683]  w:  [1.13244353 0.62748209 1.54269525]
1.0388527480861294  -  45.5674  =  -44.52854725191387
training  [-3.3354, 2.2292, -1.633]  w:  [1.13244353 0.62748209 1.54269525]
-4.897590437179391  -  13.3589  =  -18.25649043717939
training  [1.2096, 0.3121, 1.6238]  w:  [1.13244353 0.62748209 1.54269525]
4.070669408625697  -  74.5119  =  -70.4412305913743
training  [0.7371, -3.9118, -2.5583]  w:  [1.13244353 0.62748209 1.54269525]
-5.566537569176249  -  3.3358  =  -8.902337569176249
training  [-4.4792, 1.3177, -2.0449]  w:  [1.13244353 0.62748209 1.54269525]
-7.400265450798729  -  4.2974  =  -11.697665450798729
training  [4.312, -3.735, 1.8018]  w:  [1.13244353 0.62748209 1.54269525]
5.31907922129644  -  66.5833  =  -61.26422077870355
training  [2.2866, -3.657, 0.2785]  w:  [1.13244353 0.62748209 1.54269525]
0.7243840128341764  -  26.0005  =  -25.276115987165824
training  [2.3784, -4.0141, -0.8841]  w:  [1.13244353 0.62748209 1.54269525]
-1.1892690238069688  -  14.6809  =  -15.870169023806968
training  [-4.366, -3.5797, 1.0264]  w:  [1.13244353 0.62748209 1.54269525]
-5.607023702910983  -  1.8713  =  -7.478323702910982
training  [3.6044, -3.3175, 2.5052]  w:  [1.13244353 0.62748209 1.54269525]
5.864867788090485  -  71.0139  =  -65.14903221190953
training  [4.3441, -3.0375, 0.8353]  w:  [1.13244353 0.62748209 1.54269525]
4.3020844559562175  -  63.8979  =  -59.59581554404378
training  [4.844, -1.8252, 0.5179]  w:  [1.13244353 0.62748209 1.54269525]
5.139238043381365  -  78.0461  =  -72.90686195661863
training  [3.5894, -1.8357, 0.8357]  w:  [1.13244353 0.62748209 1.54269525]
4.202154373497985  -  68.8838  =  -64.681645626502
training  [2.8556, -2.8244, 0.1182]  w:  [1.13244353 0.62748209 1.54269525]
1.6438919230876827  -  39.5252  =  -37.88130807691232
training  [0.1338, -2.4896, -4.1741]  w:  [1.13244353 0.62748209 1.54269525]
-7.850022712837422  -  2.2644  =  -10.114422712837422
training  [-3.224, 3.9292, 2.1957]  w:  [1.13244353 0.62748209 1.54269525]
2.2018006327821724  -  72.1211  =  -69.91929936721783
training  [-1.0141, 2.0322, 4.9616]  w:  [1.13244353 0.62748209 1.54269525]
7.780994871695531  -  92.3427  =  -84.56170512830447
training  [-3.6607, 0.5574, -1.4547]  w:  [1.13244353 0.62748209 1.54269525]
-6.039936312984846  -  5.8471  =  -11.887036312984847
training  [-4.6911, -3.1557, 4.7126]  w:  [1.13244353 0.62748209 1.54269525]
-0.022445455369283884  -  11.2337  =  -11.256145455369285
training  [4.3914, -2.8797, -1.5355]  w:  [1.13244353 0.62748209 1.54269525]
0.7972438074669532  -  37.475  =  -36.677756192533046
training  [-1.9869, -4.2265, 3.8654]  w:  [1.13244353 0.62748209 1.54269525]
1.0610291132327738  -  15.7889  =  -14.727870886767226
training  [-2.0447, 4.138, -0.4531]  w:  [1.13244353 0.62748209 1.54269525]
-0.41798162756993473  -  57.936  =  -58.35398162756994
training  [-1.6706, 2.0672, -0.8657]  w:  [1.13244353 0.62748209 1.54269525]
-1.930240472745688  -  32.4185  =  -34.34874047274569
training  [-0.3293, 0.5779, -2.8227]  w:  [1.13244353 0.62748209 1.54269525]
-4.364857641888875  -  14.3434  =  -18.708257641888878
training  [1.482, -1.8657, -3.7435]  w:  [1.13244353 0.62748209 1.54269525]
-5.267491688447386  -  7.1519  =  -12.419391688447387
training  [-4.7477, -3.338, -1.9109]  w:  [1.13244353 0.62748209 1.54269525]
-10.418973740291664  -  0.4077  =  -10.826673740291664
training  [3.4221, 1.225, 2.261]  w:  [1.13244353 0.62748209 1.54269525]
8.13203454289038  -  95.0454  =  -86.91336545710962
training  [0.5903, 4.8793, 2.8287]  w:  [1.13244353 0.62748209 1.54269525]
8.093976834759392  -  97.4647  =  -89.3707231652406
training  [3.541, -3.2957, 1.9379]  w:  [1.13244353 0.62748209 1.54269525]
4.931578961562499  -  64.3732  =  -59.441621038437496
training  [-1.5212, -2.4221, -4.902]  w:  [1.13244353 0.62748209 1.54269525]
-10.804789595192217  -  0.7227  =  -11.527489595192216
training  [-0.5397, -1.032, 3.4321]  w:  [1.13244353 0.62748209 1.54269525]
4.035943079357151  -  60.5921  =  -56.55615692064285
training  [-4.4576, -4.2601, 4.2233]  w:  [1.13244353 0.62748209 1.54269525]
-1.205851896014006  -  6.0247  =  -7.230551896014006
training  [-3.2289, 1.841, 2.7095]  w:  [1.13244353 0.62748209 1.54269525]
1.6785803802189343  -  54.0111  =  -52.33251961978107
training  [1.6281, -0.9761, -4.5734]  w:  [1.13244353 0.62748209 1.54269525]
-5.824116410123125  -  7.8658  =  -13.689916410123125
training  [-1.6917, 4.8284, -1.2181]  w:  [1.13244353 0.62748209 1.54269525]
-0.7651772923240401  -  61.2837  =  -62.04887729232404
training  [3.9849, -0.9782, 2.0434]  w:  [1.13244353 0.62748209 1.54269525]
7.051214738054648  -  88.3402  =  -81.28898526194534
training  [-3.8184, 1.2067, 2.2951]  w:  [1.13244353 0.62748209 1.54269525]
-0.026299884982679878  -  34.1122  =  -34.13849988498268
training  [4.8842, -3.4563, -2.7572]  w:  [1.13244353 0.62748209 1.54269525]
-0.8912049797067221  -  23.7819  =  -24.67310497970672
training  [0.3998, -1.1865, -2.3095]  w:  [1.13244353 0.62748209 1.54269525]
-3.854611256483782  -  11.4246  =  -15.279211256483782
training  [2.0692, -3.3887, 1.7303]  w:  [1.13244353 0.62748209 1.54269525]
2.886229198588039  -  42.6881  =  -39.80187080141196
training  [4.9949, 2.5811, -0.2251]  w:  [1.13244353 0.62748209 1.54269525]
6.928775532117166  -  95.9901  =  -89.06132446788283
training  [-2.1215, 3.7111, 1.2372]  w:  [1.13244353 0.62748209 1.54269525]
1.8347923879581733  -  71.3692  =  -69.53440761204183
training  [-0.8548, -1.4922, -2.6356]  w:  [1.13244353 0.62748209 1.54269525]
-5.970269111395776  -  4.7821  =  -10.752369111395776
training  [-0.3516, 1.8554, -3.2288]  w:  [1.13244353 0.62748209 1.54269525]
-4.214991304876174  -  20.3834  =  -24.598391304876174
training  [2.6396, -2.0585, 3.2964]  w:  [1.13244353 0.62748209 1.54269525]
6.782866699093363  -  80.826  =  -74.04313330090663
training  [3.182, 0.3063, 2.6692]  w:  [1.13244353 0.62748209 1.54269525]
7.913395256084401  -  92.9483  =  -85.0349047439156
training  [-3.9978, 3.3242, 4.3448]  w:  [1.13244353 0.62748209 1.54269525]
4.261295525641799  -  79.1768  =  -74.9155044743582
training  [-3.2188, 0.9749, -3.9211]  w:  [1.13244353 0.62748209 1.54269525]
-9.08243931001094  -  2.7053  =  -11.78773931001094
training  [-1.4037, -1.6469, -3.1777]  w:  [1.13244353 0.62748209 1.54269525]
-7.525233942534563  -  2.6234  =  -10.148633942534563
training  [-4.433, -2.0077, -4.009]  w:  [1.13244353 0.62748209 1.54269525]
-12.464583242659131  -  0.3253  =  -12.789883242659132
training  [0.2189, -0.4741, -0.1024]  w:  [1.13244353 0.62748209 1.54269525]
-0.2075693625784826  -  33.6531  =  -33.860669362578484
training  [-1.6415, -0.7735, -3.0675]  w:  [1.13244353 0.62748209 1.54269525]
-7.076481141470257  -  3.7641  =  -10.840581141470256
training  [-3.2433, -1.4039, 3.9589]  w:  [1.13244353 0.62748209 1.54269525]
1.5536000078984564  -  30.0658  =  -28.512199992101543
training  [-2.9105, 0.5832, -4.0091]  w:  [1.13244353 0.62748209 1.54269525]
-9.114848884787879  -  2.4887  =  -11.603548884787878
training  [4.0515, 2.4255, -4.5583]  w:  [1.13244353 0.62748209 1.54269525]
-0.922014973983666  -  61.2853  =  -62.207314973983664
training  [1.7539, -0.7567, 0.573]  w:  [1.13244353 0.62748209 1.54269525]
2.3953413974657374  -  57.0797  =  -54.68435860253427
training  [-0.3153, -0.7064, 2.725]  w:  [1.13244353 0.62748209 1.54269525]
3.403531764822165  -  58.7004  =  -55.29686823517784
training  [4.1213, -3.7513, -1.8806]  w:  [1.13244353 0.62748209 1.54269525]
-0.5879267116530018  -  22.1789  =  -22.766826711653
training  [-3.9599, -4.7557, -3.2102]  w:  [1.13244353 0.62748209 1.54269525]
-12.420840021661391  -  0.1558  =  -12.57664002166139
training  [2.4555, -2.0981, -1.6104]  w:  [1.13244353 0.62748209 1.54269525]
-1.0201615047097286  -  24.4796  =  -25.49976150470973
training  [2.3627, -1.8248, -2.8985]  w:  [1.13244353 0.62748209 1.54269525]
-2.9409071626763152  -  15.7052  =  -18.646107162676316
training  [0.6186, 1.5369, 0.1015]  w:  [1.13244353 0.62748209 1.54269525]
1.8214903619583638  -  65.2154  =  -63.39390963804164
training  [-3.1581, 4.5694, 4.0636]  w:  [1.13244353 0.62748209 1.54269525]
5.559743155026698  -  90.3564  =  -84.7966568449733
training  [0.9721, 4.3573, 1.2892]  w:  [1.13244353 0.62748209 1.54269525]
5.8238187864966555  -  94.3178  =  -88.49398121350335
training  [-2.0006, -0.4211, -3.9847]  w:  [1.13244353 0.62748209 1.54269525]
-8.676977010825919  -  2.4051  =  -11.08207701082592
training  [-3.6588, -2.5952, -1.0915]  w:  [1.13244353 0.62748209 1.54269525]
-7.455677790389856  -  1.5176  =  -8.973277790389856
training  [-2.874, 2.639, -4.4538]  w:  [1.13244353 0.62748209 1.54269525]
-8.46957359437072  -  5.497  =  -13.96657359437072
training  [3.9494, 2.5933, 0.0128]  w:  [1.13244353 0.62748209 1.54269525]
6.119468298225142  -  94.1462  =  -88.02673170177485
training  [-4.2855, 2.4065, -0.6828]  w:  [1.13244353 0.62748209 1.54269525]
-4.3964034374880905  -  14.4193  =  -18.81570343748809
training  [-2.5751, 2.4369, 4.9756]  w:  [1.13244353 0.62748209 1.54269525]
6.288790249010902  -  87.1991  =  -80.9103097509891
training  [-4.4625, -3.9408, 3.116]  w:  [1.13244353 0.62748209 1.54269525]
-2.7192722897487833  -  4.1344  =  -6.853672289748784
training  [-0.5828, 1.8156, -0.1435]  w:  [1.13244353 0.62748209 1.54269525]
0.25789162106494035  -  51.1166  =  -50.858708378935056
training  [-4.8672, -0.3674, 3.9445]  w:  [1.13244353 0.62748209 1.54269525]
0.3427953258843752  -  24.1396  =  -23.796804674115627
training  [3.9719, -2.8784, -3.6245]  w:  [1.13244353 0.62748209 1.54269525]
-2.8996909082995352  -  14.6104  =  -17.510090908299535
training  [-3.0334, -4.0148, -1.1]  w:  [1.13244353 0.62748209 1.54269525]
-7.651334087606745  -  1.021  =  -8.672334087606746
training  [-4.0663, 3.2357, 4.2736]  w:  [1.13244353 0.62748209 1.54269525]
4.018351076706749  -  77.2328  =  -73.21444892329325
training  [-1.9263, -3.2499, 4.1749]  w:  [1.13244353 0.62748209 1.54269525]
2.2199183802688323  -  26.8814  =  -24.661481619731166
training  [-0.4394, -3.3643, 2.1357]  w:  [1.13244353 0.62748209 1.54269525]
0.686100564992282  -  20.85  =  -20.16389943500772
training  [-3.9833, 1.6599, 1.1834]  w:  [1.13244353 0.62748209 1.54269525]
-1.6436792516069134  -  25.5397  =  -27.18337925160691
training  [4.9539, 3.9439, -1.5671]  w:  [1.13244353 0.62748209 1.54269525]
5.66718091171923  -  95.9509  =  -90.28371908828078
training  [-1.6791, 0.1656, 4.3603]  w:  [1.13244353 0.62748209 1.54269525]
4.929039198295996  -  71.5733  =  -66.64426080170401
training  [-2.0265, 2.027, -3.7523]  w:  [1.13244353 0.62748209 1.54269525]
-6.811646018723803  -  8.503  =  -15.314646018723803
training  [-4.3795, -3.4641, 2.3059]  w:  [1.13244353 0.62748209 1.54269525]
-3.5758961872493065  -  3.6654  =  -7.241296187249306
training  [-2.0176, 4.5346, 1.4648]  w:  [1.13244353 0.62748209 1.54269525]
2.8203022110810427  -  81.6212  =  -78.80089778891896
training  [-4.5365, 0.4088, 3.3315]  w:  [1.13244353 0.62748209 1.54269525]
0.2586738117563634  -  28.9449  =  -28.686226188243637
training  [0.0543, 1.7973, -1.0172]  w:  [1.13244353 0.62748209 1.54269525]
-0.37996436607613804  -  47.9317  =  -48.31166436607614
training  [2.6143, -4.6344, 2.4982]  w:  [1.13244353 0.62748209 1.54269525]
3.9065054138763378  -  43.5132  =  -39.60669458612366
training  [1.3107, 3.092, 3.3522]  w:  [1.13244353 0.62748209 1.54269525]
8.595891382649118  -  96.6993  =  -88.10340861735088
training  [-4.1011, 2.4862, -1.7754]  w:  [1.13244353 0.62748209 1.54269525]
-5.823119358536507  -  10.0187  =  -15.841819358536508
training  [-4.1914, -3.7981, 0.5226]  w:  [1.13244353 0.62748209 1.54269525]
-6.323551017605956  -  1.4295  =  -7.753051017605956
training  [2.7724, 0.2505, 4.7913]  w:  [1.13244353 0.62748209 1.54269525]
10.688286476085938  -  96.7925  =  -86.10421352391407
training  [4.0513, -1.7417, 0.4931]  w:  [1.13244353 0.62748209 1.54269525]
4.25568596559196  -  71.1234  =  -66.86771403440804
training  [0.3377, 0.4645, -1.6958]  w:  [1.13244353 0.62748209 1.54269525]
-1.942210994615854  -  27.9534  =  -29.89561099461585
training  [-3.9085, -1.0112, 1.1947]  w:  [1.13244353 0.62748209 1.54269525]
-3.2176074281111218  -  8.608  =  -11.825607428111123
training  [3.2581, -0.8491, -1.3936]  w:  [1.13244353 0.62748209 1.54269525]
1.006919136542928  -  50.1924  =  -49.18548086345707
training  [-1.619, -3.1926, 2.5651]  w:  [1.13244353 0.62748209 1.54269525]
0.12044218695176623  -  16.4754  =  -16.354957813048234
training  [-2.0603, -2.4461, -0.861]  w:  [1.13244353 0.62748209 1.54269525]
-5.196317965084878  -  3.9784  =  -9.174717965084879
training  [2.4631, -4.7946, -0.0765]  w:  [1.13244353 0.62748209 1.54269525]
-0.33722014243680154  -  15.394  =  -15.731220142436802
training  [-4.8966, 4.2368, 1.9474]  w:  [1.13244353 0.62748209 1.54269525]
0.11763783634988023  -  53.5883  =  -53.47066216365012
training  [-4.5155, 1.537, 4.7273]  w:  [1.13244353 0.62748209 1.54269525]
3.143674450897029  -  59.2523  =  -56.10862554910297
training  [1.6792, 4.3261, -1.7225]  w:  [1.13244353 0.62748209 1.54269525]
1.958856880895575  -  83.7729  =  -81.81404311910443
training  [1.0347, -3.3649, 3.378]  w:  [1.13244353 0.62748209 1.54269525]
4.271549400876732  -  50.5979  =  -46.32635059912327
training  [0.261, 4.211, 2.3907]  w:  [1.13244353 0.62748209 1.54269525]
6.626016378342301  -  94.9375  =  -88.3114836216577
training  [2.2971, 2.9466, 4.5417]  w:  [1.13244353 0.62748209 1.54269525]
11.456733790794075  -  98.7784  =  -87.32166620920593
training  [2.0725, 0.7739, -4.6808]  w:  [1.13244353 0.62748209 1.54269525]
-4.388450316619004  -  19.5109  =  -23.899350316619003
training  [2.8138, -0.5996, -1.4313]  w:  [1.13244353 0.62748209 1.54269525]
0.6021716443929948  -  47.2879  =  -46.685728355607004
training  [-2.1202, -2.4239, 1.6265]  w:  [1.13244353 0.62748209 1.54269525]
-1.412766793217049  -  12.3599  =  -13.772666793217049
training  [1.9253, 2.5195, -2.185]  w:  [1.13244353 0.62748209 1.54269525]
0.390445538277866  -  65.2467  =  -64.85625446172214
training  [0.5667, -2.7133, -2.6962]  w:  [1.13244353 0.62748209 1.54269525]
-5.220206338380714  -  5.1106  =  -10.330806338380714
training  [-1.0348, -4.3581, 2.1113]  w:  [1.13244353 0.62748209 1.54269525]
-0.6493897802920592  -  10.5192  =  -11.16858978029206
training  [-4.3841, 2.6733, 1.2457]  w:  [1.13244353 0.62748209 1.54269525]
-1.3655623567152217  -  32.4639  =  -33.829462356715226
training  [2.8018, 1.712, 0.9061]  w:  [1.13244353 0.62748209 1.54269525]
5.644965800066653  -  90.1138  =  -84.46883419993334
training  [-1.6242, 2.1521, 1.6044]  w:  [1.13244353 0.62748209 1.54269525]
1.9861896765124325  -  63.7879  =  -61.80171032348757
training  [1.0787, 1.4206, -4.5245]  w:  [1.13244353 0.62748209 1.54269525]
-4.866956766471835  -  18.0555  =  -22.922456766471832
training  [2.4125, -0.8095, -1.5122]  w:  [1.13244353 0.62748209 1.54269525]
-0.10879048252310364  -  38.8276  =  -38.9363904825231
training  [-3.9519, -1.0924, -0.4866]  w:  [1.13244353 0.62748209 1.54269525]
-5.911440548933008  -  3.6777  =  -9.589140548933008
training  [-3.7211, 3.1614, -2.591]  w:  [1.13244353 0.62748209 1.54269525]
-6.227337155319164  -  11.1518  =  -17.379137155319164
training  [0.4954, -1.8257, 2.1505]  w:  [1.13244353 0.62748209 1.54269525]
2.732984613931664  -  47.7531  =  -45.02011538606834
training  [-0.1477, 3.1454, 3.5618]  w:  [1.13244353 0.62748209 1.54269525]
7.30119219971912  -  94.1572  =  -86.85600780028088
training  [3.9048, 2.8907, -2.1849]  w:  [1.13244353 0.62748209 1.54269525]
2.865193136553907  -  85.8791  =  -83.01390686344608
training  [2.9896, 3.5226, 2.3105]  w:  [1.13244353 0.62748209 1.54269525]
9.160318977841388  -  98.038  =  -88.87768102215861
training  [2.3434, 0.0564, -3.6224]  w:  [1.13244353 0.62748209 1.54269525]
-2.899101108445145  -  24.7629  =  -27.662001108445143
training  [-4.4867, 1.3566, 3.3672]  w:  [1.13244353 0.62748209 1.54269525]
0.964871244676563  -  40.5785  =  -39.61362875532343
training  [-4.2711, 4.5089, -3.614]  w:  [1.13244353 0.62748209 1.54269525]
-7.582826225783867  -  10.0825  =  -17.665326225783865
training  [-4.1147, -0.5604, 0.8821]  w:  [1.13244353 0.62748209 1.54269525]
-3.6504948945497846  -  8.344  =  -11.994494894549785
training  [2.9835, -4.3998, -1.3384]  w:  [1.13244353 0.62748209 1.54269525]
-1.4468937354124063  -  13.2692  =  -14.716093735412406
training  [4.4301, 3.6675, 3.0676]  w:  [1.13244353 0.62748209 1.54269525]
12.050500619123852  -  99.3834  =  -87.33289938087614
training  [1.8372, 1.3119, 0.0378]  w:  [1.13244353 0.62748209 1.54269525]
2.9620328958285773  -  74.9026  =  -71.94056710417144
training  [-3.6792, -1.4493, -0.1041]  w:  [1.13244353 0.62748209 1.54269525]
-5.236490621172112  -  4.2442  =  -9.480690621172112
training  [2.2272, 4.97, 3.7705]  w:  [1.13244353 0.62748209 1.54269525]
11.45749666991141  -  99.3199  =  -87.8624033300886
training  [-3.8965, -2.7583, -1.4686]  w:  [1.13244353 0.62748209 1.54269525]
-8.408952326613079  -  1.0337  =  -9.442652326613079
training  [-3.8251, 1.5245, -0.5056]  w:  [1.13244353 0.62748209 1.54269525]
-4.155100038497998  -  12.9762  =  -17.131300038497997
training  [1.4072, 1.0499, 4.6353]  w:  [1.13244353 0.62748209 1.54269525]
9.403223285543401  -  95.4618  =  -86.05857671445659
training  [-1.7119, -1.1275, -4.577]  w:  [1.13244353 0.62748209 1.54269525]
-9.707032307599203  -  1.4655  =  -11.172532307599203
training  [1.5381, -3.5781, 4.7296]  w:  [1.13244353 0.62748209 1.54269525]
6.7929491962571005  -  69.9473  =  -63.1543508037429
training  [2.4913, -4.7487, -3.1079]  w:  [1.13244353 0.62748209 1.54269525]
-4.953010191159295  -  3.9825  =  -8.935510191159295
training  [0.8319, -0.7889, 1.6712]  w:  [1.13244353 0.62748209 1.54269525]
3.0252114599050404  -  58.8336  =  -55.80838854009496
training  [2.4003, -3.159, 0.8644]  w:  [1.13244353 0.62748209 1.54269525]
2.0694940709522003  -  39.0041  =  -36.9346059290478
training  [-2.6517, 2.2578, 1.7511]  w:  [1.13244353 0.62748209 1.54269525]
1.1152421947102207  -  54.4525  =  -53.33725780528978
training  [2.3496, -1.2964, -1.3898]  w:  [1.13244353 0.62748209 1.54269525]
-0.29671631149625877  -  33.888  =  -34.18471631149626
training  [4.706, 3.4156, 1.2028]  w:  [1.13244353 0.62748209 1.54269525]
9.328060947701715  -  98.4665  =  -89.13843905229828
training  [3.6693, 2.3423, 3.1115]  w:  [1.13244353 0.62748209 1.54269525]
10.425122634379036  -  98.3069  =  -87.88177736562096
training  [-4.1377, 0.7103, -4.8074]  w:  [1.13244353 0.62748209 1.54269525]
-11.656364236103027  -  0.9782  =  -12.634564236103026
training  [-1.3356, -3.2314, -4.1613]  w:  [1.13244353 0.62748209 1.54269525]
-9.9597549576398  -  0.7659  =  -10.7256549576398
training  [-1.308, 4.5738, 4.748]  w:  [1.13244353 0.62748209 1.54269525]
8.713458489830312  -  97.0884  =  -88.37494151016968
training  [1.8503, -2.3468, 1.5135]  w:  [1.13244353 0.62748209 1.54269525]
2.9576545674161983  -  50.2125  =  -47.2548454325838
training  [0.9794, 4.2458, -2.6876]  w:  [1.13244353 0.62748209 1.54269525]
-0.37286910341884694  -  68.3262  =  -68.69906910341885
training  [2.8936, -2.7623, -0.9651]  w:  [1.13244353 0.62748209 1.54269525]
0.05468964960549361  -  28.5596  =  -28.504910350394507
training  [-1.3235, -1.2644, -3.7798]  w:  [1.13244353 0.62748209 1.54269525]
-8.123256882525254  -  2.4511  =  -10.574356882525255
training  [-2.9397, -4.125, -2.3156]  w:  [1.13244353 0.62748209 1.54269525]
-9.489673001946457  -  0.554  =  -10.043673001946457
training  [-4.1333, 1.4012, -2.4215]  w:  [1.13244353 0.62748209 1.54269525]
-7.537137509219733  -  4.4072  =  -11.944337509219732
training  [2.7193, -3.1938, -1.6833]  w:  [1.13244353 0.62748209 1.54269525]
-1.5214175094960236  -  17.0949  =  -18.61631750949602
training  [-2.9433, -4.5495, -3.4777]  w:  [1.13244353 0.62748209 1.54269525]
-11.55288209701352  -  0.2509  =  -11.803782097013519
training  [-1.1173, 2.2317, -1.5199]  w:  [1.13244353 0.62748209 1.54269525]
-2.209669894517796  -  33.1206  =  -35.3302698945178
training  [0.5178, -1.5256, -3.7834]  w:  [1.13244353 0.62748209 1.54269525]
-6.2075406265828335  -  5.237  =  -11.444540626582834
training  [-2.7105, 1.6062, 3.8415]  w:  [1.13244353 0.62748209 1.54269525]
3.8646373383374533  -  70.4458  =  -66.58116266166255
training  [1.4194, -1.1613, -4.0572]  w:  [1.13244353 0.62748209 1.54269525]
-5.380327770169981  -  8.3206  =  -13.700927770169983
training  [-0.1552, 1.2735, 4.3004]  w:  [1.13244353 0.62748209 1.54269525]
7.257549862379456  -  90.1085  =  -82.85095013762054
training  [-3.4815, -4.7835, -1.0098]  w:  [1.13244353 0.62748209 1.54269525]
-8.501976406089707  -  0.5839  =  -9.085876406089707
training  [2.8193, 4.1057, -4.526]  w:  [1.13244353 0.62748209 1.54269525]
-1.2132874341826598  -  66.8081  =  -68.02138743418266
training  [-3.9939, 3.0056, -1.5763]  w:  [1.13244353 0.62748209 1.54269525]
-5.068656589821195  -  14.4018  =  -19.470456589821197
training  [-2.0593, 2.4585, 2.3597]  w:  [1.13244353 0.62748209 1.54269525]
2.8509217299303042  -  70.6698  =  -67.81887827006969
training  [-2.6263, 3.1311, 2.9468]  w:  [1.13244353 0.62748209 1.54269525]
3.5365870810387205  -  77.309  =  -73.77241291896128
training  [0.3087, -1.1669, 0.4491]  w:  [1.13244353 0.62748209 1.54269525]
0.31020090625025687  -  33.0798  =  -32.76959909374974
training  [-4.085, 1.1728, 1.8622]  w:  [1.13244353 0.62748209 1.54269525]
-1.017313748412755  -  26.4056  =  -27.422913748412753
training  [-0.9468, 0.7549, 3.9363]  w:  [1.13244353 0.62748209 1.54269525]
5.474000007682109  -  79.7738  =  -74.29979999231789
training  [-3.9515, 0.3005, -4.4521]  w:  [1.13244353 0.62748209 1.54269525]
-11.154525787467332  -  1.0441  =  -12.198625787467332
training  [-3.8772, -2.2493, -1.9634]  w:  [1.13244353 0.62748209 1.54269525]
-8.831033393104526  -  1.0509  =  -9.881933393104527
training  [2.8443, -2.5137, -4.5381]  w:  [1.13244353 0.62748209 1.54269525]
-5.3571979015419835  -  6.8897  =  -12.246897901541985
training  [-2.0843, -0.4836, -3.0452]  w:  [1.13244353 0.62748209 1.54269525]
-7.361617976833962  -  3.5346  =  -10.896217976833963
training  [1.0353, -2.7229, 2.2017]  w:  [1.13244353 0.62748209 1.54269525]
2.860399944533965  -  43.9562  =  -41.095800055466036
training  [4.6442, 3.0445, 2.2175]  w:  [1.13244353 0.62748209 1.54269525]
10.590590205174035  -  98.8492  =  -88.25860979482596
training  [-0.6752, 4.861, 3.778]  w:  [1.13244353 0.62748209 1.54269525]
8.113867221144776  -  97.017  =  -88.90313277885522
training  [1.9475, -4.7001, 0.8243]  w:  [1.13244353 0.62748209 1.54269525]
0.5278489107074564  -  18.7839  =  -18.256051089292544
training  [2.581, 0.3566, -4.2932]  w:  [1.13244353 0.62748209 1.54269525]
-3.4765023757774807  -  23.5455  =  -27.022002375777483
training  [-0.6736, -4.1292, 4.2274]  w:  [1.13244353 0.62748209 1.54269525]
3.167776895703002  -  31.2667  =  -28.098923104296997
training  [1.555, 3.0209, 3.0037]  w:  [1.13244353 0.62748209 1.54269525]
8.290304066614176  -  96.4078  =  -88.11749593338581
training  [-3.9024, 4.8914, -2.1405]  w:  [1.13244353 0.62748209 1.54269525]
-4.652120942715466  -  25.4308  =  -30.082920942715468
training  [4.3376, -4.3305, 0.4366]  w:  [1.13244353 0.62748209 1.54269525]
2.868316634635224  -  43.0907  =  -40.22238336536478
training  [-3.1254, 4.394, 4.8478]  w:  [1.13244353 0.62748209 1.54269525]
6.696495316062951  -  92.8121  =  -86.11560468393705
training  [-2.3382, -4.8182, 2.1568]  w:  [1.13244353 0.62748209 1.54269525]
-2.343928558995563  -  4.7434  =  -7.087328558995564
training  [2.9783, 1.8384, 3.3897]  w:  [1.13244353 0.62748209 1.54269525]
9.75559374580627  -  97.3486  =  -87.59300625419374
training  [-0.124, 2.8374, -0.6674]  w:  [1.13244353 0.62748209 1.54269525]
0.6103998718006929  -  62.785  =  -62.1746001281993
training  [2.6896, 0.3414, -0.2938]  w:  [1.13244353 0.62748209 1.54269525]
2.806798651758054  -  70.4455  =  -67.63870134824194
training  [-1.0399, 3.8536, 0.6071]  w:  [1.13244353 0.62748209 1.54269525]
2.177007235203109  -  77.0369  =  -74.8598927647969
training  [-2.2706, 3.99, -2.3091]  w:  [1.13244353 0.62748209 1.54269525]
-3.6299103574449374  -  31.1134  =  -34.74331035744493
training  [-4.6277, 1.2594, 2.4902]  w:  [1.13244353 0.62748209 1.54269525]
-0.6087382880800032  -  28.1093  =  -28.718038288080002
training  [1.7329, -3.6213, 0.0389]  w:  [1.13244353 0.62748209 1.54269525]
-0.24987864396173726  -  19.3919  =  -19.641778643961736
training  [-0.7044, -2.822, 1.4681]  w:  [1.13244353 0.62748209 1.54269525]
-0.3036167842592108  -  17.8122  =  -18.115816784259213
training  [-0.4826, -3.1786, -1.9225]  w:  [1.13244353 0.62748209 1.54269525]
-5.5068634398760885  -  3.5851  =  -9.09196343987609
training  [1.0986, -4.5818, -3.6128]  w:  [1.13244353 0.62748209 1.54269525]
-7.204344373636529  -  1.7158  =  -8.920144373636528
training  [-4.406, -3.9306, -0.2443]  w:  [1.13244353 0.62748209 1.54269525]
-7.832807765131983  -  0.8241  =  -8.656907765131983
training  [-1.8419, 1.1644, -1.3754]  w:  [1.13244353 0.62748209 1.54269525]
-3.477030650157815  -  17.8517  =  -21.328730650157816
training  [2.7272, 4.3966, 2.8811]  w:  [1.13244353 0.62748209 1.54269525]
10.2918470508291  -  98.904  =  -88.61215294917089
training  [1.9643, -1.4554, 2.803]  w:  [1.13244353 0.62748209 1.54269525]
5.635396191304665  -  76.0591  =  -70.42370380869534
training  [-3.7467, -0.8937, 1.6851]  w:  [1.13244353 0.62748209 1.54269525]
-2.204111167505516  -  12.1571  =  -14.361211167505516
training  [-3.6985, 4.8435, -3.665]  w:  [1.13244353 0.62748209 1.54269525]
-6.8031110084228335  -  14.6793  =  -21.482411008422833
250073.2649643499
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.20218732 0.63711814 1.42668439]
9.14476590344432  -  87.3174  =  -78.17263409655568
training  [-4.1793, -4.9218, 1.7664]  w:  [1.20218732 0.63711814 1.42668439]
-5.639974210765981  -  1.5257  =  -7.165674210765982
training  [-3.9429, -0.7689, 4.883]  w:  [1.20218732 0.63711814 1.42668439]
1.7365153490234704  -  39.7859  =  -38.04938465097653
training  [-3.5796, 1.5557, 2.6683]  w:  [1.20218732 0.63711814 1.42668439]
0.49463690158673135  -  45.5674  =  -45.07276309841327
training  [-3.3354, 2.2292, -1.633]  w:  [1.20218732 0.63711814 1.42668439]
-4.919287458906755  -  13.3589  =  -18.278187458906757
training  [1.2096, 0.3121, 1.6238]  w:  [1.20218732 0.63711814 1.42668439]
3.96966046927958  -  74.5119  =  -70.54223953072042
training  [0.7371, -3.9118, -2.5583]  w:  [1.20218732 0.63711814 1.42668439]
-5.2560331231995026  -  3.3358  =  -8.591833123199503
training  [-4.4792, 1.3177, -2.0449]  w:  [1.20218732 0.63711814 1.42668439]
-7.462733799882352  -  4.2974  =  -11.760133799882352
training  [4.312, -3.735, 1.8018]  w:  [1.20218732 0.63711814 1.42668439]
5.374795435106295  -  66.5833  =  -61.2085045648937
training  [2.2866, -3.657, 0.2785]  w:  [1.20218732 0.63711814 1.42668439]
0.8163121137049052  -  26.0005  =  -25.184187886295092
training  [2.3784, -4.0141, -0.8841]  w:  [1.20218732 0.63711814 1.42668439]
-0.9595052486959923  -  14.6809  =  -15.640405248695991
training  [-4.366, -3.5797, 1.0264]  w:  [1.20218732 0.63711814 1.42668439]
-6.065092783249469  -  1.8713  =  -7.9363927832494685
training  [3.6044, -3.3175, 2.5052]  w:  [1.20218732 0.63711814 1.42668439]
5.793654307297108  -  71.0139  =  -65.2202456927029
training  [4.3441, -3.0375, 0.8353]  w:  [1.20218732 0.63711814 1.42668439]
4.478885084252628  -  63.8979  =  -59.41901491574737
training  [4.844, -1.8252, 0.5179]  w:  [1.20218732 0.63711814 1.42668439]
5.399407217142268  -  78.0461  =  -72.64669278285773
training  [3.5894, -1.8357, 0.8357]  w:  [1.20218732 0.63711814 1.42668439]
4.337853560686551  -  68.8838  =  -64.54594643931344
training  [2.8556, -2.8244, 0.1182]  w:  [1.20218732 0.63711814 1.42668439]
1.8021237522984825  -  39.5252  =  -37.72307624770151
training  [0.1338, -2.4896, -4.1741]  w:  [1.20218732 0.63711814 1.42668439]
-7.380439960995333  -  2.2644  =  -9.644839960995334
training  [-3.224, 3.9292, 2.1957]  w:  [1.20218732 0.63711814 1.42668439]
1.7600835653549183  -  72.1211  =  -70.36101643464508
training  [-1.0141, 2.0322, 4.9616]  w:  [1.20218732 0.63711814 1.42668439]
7.154250582976702  -  92.3427  =  -85.18844941702329
training  [-3.6607, 0.5574, -1.4547]  w:  [1.20218732 0.63711814 1.42668439]
-6.1211152672181495  -  5.8471  =  -11.968215267218149
training  [-4.6911, -3.1557, 4.7126]  w:  [1.20218732 0.63711814 1.42668439]
-0.9267417920479986  -  11.2337  =  -12.160441792048
training  [4.3914, -2.8797, -1.5355]  w:  [1.20218732 0.63711814 1.42668439]
1.253902433317991  -  37.475  =  -36.22109756668201
training  [-1.9869, -4.2265, 3.8654]  w:  [1.20218732 0.63711814 1.42668439]
0.4333000514130054  -  15.7889  =  -15.355599948586995
training  [-2.0447, 4.138, -0.4531]  w:  [1.20218732 0.63711814 1.42668439]
-0.46814827168215156  -  57.936  =  -58.40414827168215
training  [-1.6706, 2.0672, -0.8657]  w:  [1.20218732 0.63711814 1.42668439]
-1.9264042087888835  -  32.4185  =  -34.34490420878888
training  [-0.3293, 0.5779, -2.8227]  w:  [1.20218732 0.63711814 1.42668439]
-4.0547917440952865  -  14.3434  =  -18.398191744095286
training  [1.482, -1.8657, -3.7435]  w:  [1.20218732 0.63711814 1.42668439]
-4.747822708891271  -  7.1519  =  -11.899722708891272
training  [-4.7477, -3.338, -1.9109]  w:  [1.20218732 0.63711814 1.42668439]
-10.560576291391016  -  0.4077  =  -10.968276291391016
training  [3.4221, 1.225, 2.261]  w:  [1.20218732 0.63711814 1.42668439]
8.120208360848421  -  95.0454  =  -86.92519163915158
training  [0.5903, 4.8793, 2.8287]  w:  [1.20218732 0.63711814 1.42668439]
7.854003830993418  -  97.4647  =  -89.61069616900657
training  [3.541, -3.2957, 1.9379]  w:  [1.20218732 0.63711814 1.42668439]
4.921966751623593  -  64.3732  =  -59.451233248376404
training  [-1.5212, -2.4221, -4.902]  w:  [1.20218732 0.63711814 1.42668439]
-10.365538074169693  -  0.7227  =  -11.088238074169693
training  [-0.5397, -1.032, 3.4321]  w:  [1.20218732 0.63711814 1.42668439]
3.5901970827174727  -  60.5921  =  -57.00190291728253
training  [-4.4576, -4.2601, 4.2233]  w:  [1.20218732 0.63711814 1.42668439]
-2.0477409933270305  -  6.0247  =  -8.072440993327032
training  [-3.2289, 1.841, 2.7095]  w:  [1.20218732 0.63711814 1.42668439]
1.1567931966979463  -  54.0111  =  -52.85430680330205
training  [1.6281, -0.9761, -4.5734]  w:  [1.20218732 0.63711814 1.42668439]
-5.189408223345671  -  7.8658  =  -13.055208223345671
training  [-1.6917, 4.8284, -1.2181]  w:  [1.20218732 0.63711814 1.42668439]
-0.6953233446759528  -  61.2837  =  -61.97902334467596
training  [3.9849, -0.9782, 2.0434]  w:  [1.20218732 0.63711814 1.42668439]
7.0826541865886075  -  88.3402  =  -81.25754581341138
training  [-3.8184, 1.2067, 2.2951]  w:  [1.20218732 0.63711814 1.42668439]
-0.5472382749826408  -  34.1122  =  -34.65943827498264
training  [4.8842, -3.4563, -2.7572]  w:  [1.20218732 0.63711814 1.42668439]
-0.26400229082047133  -  23.7819  =  -24.04590229082047
training  [0.3998, -1.1865, -2.3095]  w:  [1.20218732 0.63711814 1.42668439]
-3.570233776068682  -  11.4246  =  -14.994833776068681
training  [2.0692, -3.3887, 1.7303]  w:  [1.20218732 0.63711814 1.42668439]
2.797155783654734  -  42.6881  =  -39.89094421634526
training  [4.9949, 2.5811, -0.2251]  w:  [1.20218732 0.63711814 1.42668439]
7.328124422630526  -  95.9901  =  -88.66197557736947
training  [-2.1215, 3.7111, 1.2372]  w:  [1.20218732 0.63711814 1.42668439]
1.5790626351882247  -  71.3692  =  -69.79013736481178
training  [-0.8548, -1.4922, -2.6356]  w:  [1.20218732 0.63711814 1.42668439]
-5.738506785206006  -  4.7821  =  -10.520606785206006
training  [-0.3516, 1.8554, -3.2288]  w:  [1.20218732 0.63711814 1.42668439]
-3.847058634243092  -  20.3834  =  -24.230458634243092
training  [2.6396, -2.0585, 3.2964]  w:  [1.20218732 0.63711814 1.42668439]
6.564708400577301  -  80.826  =  -74.26129159942269
training  [3.182, 0.3063, 2.6692]  w:  [1.20218732 0.63711814 1.42668439]
7.82861532171162  -  92.9483  =  -85.11968467828838
training  [-3.9978, 3.3242, 4.3448]  w:  [1.20218732 0.63711814 1.42668439]
3.510461966584747  -  79.1768  =  -75.66633803341526
training  [-3.2188, 0.9749, -3.9211]  w:  [1.20218732 0.63711814 1.42668439]
-8.842646248460987  -  2.7053  =  -11.547946248460986
training  [-1.4037, -1.6469, -3.1777]  w:  [1.20218732 0.63711814 1.42668439]
-7.270355190442795  -  2.6234  =  -9.893755190442796
training  [-4.433, -2.0077, -4.009]  w:  [1.20218732 0.63711814 1.42668439]
-12.328016204952583  -  0.3253  =  -12.653316204952583
training  [0.2189, -0.4741, -0.1024]  w:  [1.20218732 0.63711814 1.42668439]
-0.18499138466198425  -  33.6531  =  -33.838091384661986
training  [-1.6415, -0.7735, -3.0675]  w:  [1.20218732 0.63711814 1.42668439]
-6.84255573641671  -  3.7641  =  -10.606655736416709
training  [-3.2433, -1.4039, 3.9589]  w:  [1.20218732 0.63711814 1.42668439]
0.8545965387765531  -  30.0658  =  -29.211203461223448
training  [-2.9105, 0.5832, -4.0091]  w:  [1.20218732 0.63711814 1.42668439]
-8.847119296860782  -  2.4887  =  -11.335819296860782
training  [4.0515, 2.4255, -4.5583]  w:  [1.20218732 0.63711814 1.42668439]
-0.08726348080830082  -  61.2853  =  -61.3725634808083
training  [1.7539, -0.7567, 0.573]  w:  [1.20218732 0.63711814 1.42668439]
2.443899208302706  -  57.0797  =  -54.6358007916973
training  [-0.3153, -0.7064, 2.725]  w:  [1.20218732 0.63711814 1.42668439]
3.0586050503622895  -  58.7004  =  -55.64179494963771
training  [4.1213, -3.7513, -1.8806]  w:  [1.20218732 0.63711814 1.42668439]
-0.11846931271817462  -  22.1789  =  -22.297369312718175
training  [-3.9599, -4.7557, -3.2102]  w:  [1.20218732 0.63711814 1.42668439]
-12.370426527774391  -  0.1558  =  -12.52622652777439
training  [2.4555, -2.0981, -1.6104]  w:  [1.20218732 0.63711814 1.42668439]
-0.6822991312537909  -  24.4796  =  -25.161899131253794
training  [2.3627, -1.8248, -2.8985]  w:  [1.20218732 0.63711814 1.42668439]
-2.4574498918358576  -  15.7052  =  -18.16264989183586
training  [0.6186, 1.5369, 0.1015]  w:  [1.20218732 0.63711814 1.42668439]
1.8676684061158224  -  65.2154  =  -63.34773159388418
training  [-3.1581, 4.5694, 4.0636]  w:  [1.20218732 0.63711814 1.42668439]
4.9120945134025975  -  90.3564  =  -85.4443054865974
training  [0.9721, 4.3573, 1.2892]  w:  [1.20218732 0.63711814 1.42668439]
5.784042664896015  -  94.3178  =  -88.53375733510399
training  [-2.0006, -0.4211, -3.9847]  w:  [1.20218732 0.63711814 1.42668439]
-8.358295696121461  -  2.4051  =  -10.76339569612146
training  [-3.6588, -2.5952, -1.0915]  w:  [1.20218732 0.63711814 1.42668439]
-7.609237974763925  -  1.5176  =  -9.126837974763925
training  [-2.874, 2.639, -4.4538]  w:  [1.20218732 0.63711814 1.42668439]
-8.12789854500429  -  5.497  =  -13.62489854500429
training  [3.9494, 2.5933, 0.0128]  w:  [1.20218732 0.63711814 1.42668439]
6.418418634271729  -  94.1462  =  -87.72778136572826
training  [-4.2855, 2.4065, -0.6828]  w:  [1.20218732 0.63711814 1.42668439]
-4.592889081097209  -  14.4193  =  -19.01218908109721
training  [-2.5751, 2.4369, 4.9756]  w:  [1.20218732 0.63711814 1.42668439]
5.555451462805114  -  87.1991  =  -81.64364853719489
training  [-4.4625, -3.9408, 3.116]  w:  [1.20218732 0.63711814 1.42668439]
-3.4299675161787464  -  4.1344  =  -7.564367516178747
training  [-0.5828, 1.8156, -0.1435]  w:  [1.20218732 0.63711814 1.42668439]
0.2513877050410353  -  51.1166  =  -50.865212294958965
training  [-4.8672, -0.3674, 3.9445]  w:  [1.20218732 0.63711814 1.42668439]
-0.4578067626643296  -  24.1396  =  -24.59740676266433
training  [3.9719, -2.8784, -3.6245]  w:  [1.20218732 0.63711814 1.42668439]
-2.229930586917212  -  14.6104  =  -16.84033058691721
training  [-3.0334, -4.0148, -1.1]  w:  [1.20218732 0.63711814 1.42668439]
-7.773969745536646  -  1.021  =  -8.794969745536646
training  [-4.0663, 3.2357, 4.2736]  w:  [1.20218732 0.63711814 1.42668439]
3.2701472513621854  -  77.2328  =  -73.96265274863781
training  [-1.9263, -3.2499, 4.1749]  w:  [1.20218732 0.63711814 1.42668439]
1.569920993223949  -  26.8814  =  -25.31147900677605
training  [-0.4394, -3.3643, 2.1357]  w:  [1.20218732 0.63711814 1.42668439]
0.37527219978777726  -  20.85  =  -20.474727800212225
training  [-3.9833, 1.6599, 1.1834]  w:  [1.20218732 0.63711814 1.42668439]
-2.042782062472557  -  25.5397  =  -27.582482062472558
training  [4.9539, 3.9439, -1.5671]  w:  [1.20218732 0.63711814 1.42668439]
6.23248888539709  -  95.9509  =  -89.71841111460292
training  [-1.6791, 0.1656, 4.3603]  w:  [1.20218732 0.63711814 1.42668439]
4.307685977396351  -  71.5733  =  -67.26561402260366
training  [-2.0265, 2.027, -3.7523]  w:  [1.20218732 0.63711814 1.42668439]
-6.498141987807173  -  8.503  =  -15.001141987807173
training  [-4.3795, -3.4641, 2.3059]  w:  [1.20218732 0.63711814 1.42668439]
-4.182228777941816  -  3.6654  =  -7.847628777941816
training  [-2.0176, 4.5346, 1.4648]  w:  [1.20218732 0.63711814 1.42668439]
2.553350049945379  -  81.6212  =  -79.06784995005462
training  [-4.5365, 0.4088, 3.3315]  w:  [1.20218732 0.63711814 1.42668439]
-0.4402698495676809  -  28.9449  =  -29.38516984956768
training  [0.0543, 1.7973, -1.0172]  w:  [1.20218732 0.63711814 1.42668439]
-0.24085216541793764  -  47.9317  =  -48.17255216541794
training  [2.6143, -4.6344, 2.4982]  w:  [1.20218732 0.63711814 1.42668439]
3.7543609754382214  -  43.5132  =  -39.75883902456177
training  [1.3107, 3.092, 3.3522]  w:  [1.20218732 0.63711814 1.42668439]
8.32820761322925  -  96.6993  =  -88.37109238677074
training  [-4.1011, 2.4862, -1.7754]  w:  [1.20218732 0.63711814 1.42668439]
-5.8792227884529265  -  10.0187  =  -15.897922788452927
training  [-4.1914, -3.7981, 0.5226]  w:  [1.20218732 0.63711814 1.42668439]
-6.713101073423202  -  1.4295  =  -8.1426010734232
training  [2.7724, 0.2505, 4.7913]  w:  [1.20218732 0.63711814 1.42668439]
10.328215147446306  -  96.7925  =  -86.4642848525537
training  [4.0513, -1.7417, 0.4931]  w:  [1.20218732 0.63711814 1.42668439]
4.464250917688535  -  71.1234  =  -66.65914908231147
training  [0.3377, 0.4645, -1.6958]  w:  [1.20218732 0.63711814 1.42668439]
-1.7174513565698413  -  27.9534  =  -29.67085135656984
training  [-3.9085, -1.0112, 1.1947]  w:  [1.20218732 0.63711814 1.42668439]
-3.6385431689459593  -  8.608  =  -12.24654316894596
training  [3.2581, -0.8491, -1.3936]  w:  [1.20218732 0.63711814 1.42668439]
1.3876421412884574  -  50.1924  =  -48.80475785871154
training  [-1.619, -3.1926, 2.5651]  w:  [1.20218732 0.63711814 1.42668439]
-0.3208165051683074  -  16.4754  =  -16.796216505168307
training  [-2.0603, -2.4461, -0.861]  w:  [1.20218732 0.63711814 1.42668439]
-5.263696473032724  -  3.9784  =  -9.242096473032724
training  [2.4631, -4.7946, -0.0765]  w:  [1.20218732 0.63711814 1.42668439]
-0.20276037343120357  -  15.394  =  -15.596760373431204
training  [-4.8966, 4.2368, 1.9474]  w:  [1.20218732 0.63711814 1.42668439]
-0.4089631466557373  -  53.5883  =  -53.99726314665573
training  [-4.5155, 1.537, 4.7273]  w:  [1.20218732 0.63711814 1.42668439]
2.295138837049163  -  59.2523  =  -56.95716116295083
training  [1.6792, 4.3261, -1.7225]  w:  [1.20218732 0.63711814 1.42668439]
2.3174858561143945  -  83.7729  =  -81.45541414388562
training  [1.0347, -3.3649, 3.378]  w:  [1.20218732 0.63711814 1.42668439]
3.9194042800068134  -  50.5979  =  -46.67849571999319
training  [0.261, 4.211, 2.3907]  w:  [1.20218732 0.63711814 1.42668439]
6.407449732513818  -  94.9375  =  -88.53005026748619
training  [2.2971, 2.9466, 4.5417]  w:  [1.20218732 0.63711814 1.42668439]
11.118449294208904  -  98.7784  =  -87.6599507057911
training  [2.0725, 0.7739, -4.6808]  w:  [1.20218732 0.63711814 1.42668439]
-3.6934253433847295  -  19.5109  =  -23.204325343384728
training  [2.8138, -0.5996, -1.4313]  w:  [1.20218732 0.63711814 1.42668439]
0.9586852870049145  -  47.2879  =  -46.32921471299509
training  [-2.1202, -2.4239, 1.6265]  w:  [1.20218732 0.63711814 1.42668439]
-1.7726860495934704  -  12.3599  =  -14.13258604959347
training  [1.9253, 2.5195, -2.185]  w:  [1.20218732 0.63711814 1.42668439]
0.8024850019944219  -  65.2467  =  -64.44421499800558
training  [0.5667, -2.7133, -2.6962]  w:  [1.20218732 0.63711814 1.42668439]
-4.894039535037372  -  5.1106  =  -10.004639535037372
training  [-1.0348, -4.3581, 2.1113]  w:  [1.20218732 0.63711814 1.42668439]
-1.0084892345133634  -  10.5192  =  -11.527689234513364
training  [-4.3841, 2.6733, 1.2457]  w:  [1.20218732 0.63711814 1.42668439]
-1.790080785415249  -  32.4639  =  -34.25398078541525
training  [2.8018, 1.712, 0.9061]  w:  [1.20218732 0.63711814 1.42668439]
5.7517534156979915  -  90.1138  =  -84.362046584302
training  [-1.6242, 2.1521, 1.6044]  w:  [1.20218732 0.63711814 1.42668439]
1.707521725780675  -  63.7879  =  -62.08037827421933
training  [1.0787, 1.4206, -4.5245]  w:  [1.20218732 0.63711814 1.42668439]
-4.25314403641603  -  18.0555  =  -22.308644036416027
training  [2.4125, -0.8095, -1.5122]  w:  [1.20218732 0.63711814 1.42668439]
0.227097650468699  -  38.8276  =  -38.6005023495313
training  [-3.9519, -1.0924, -0.4866]  w:  [1.20218732 0.63711814 1.42668439]
-6.141136557185546  -  3.6777  =  -9.818836557185547
training  [-3.7211, 3.1614, -2.591]  w:  [1.20218732 0.63711814 1.42668439]
-6.155813229549292  -  11.1518  =  -17.30761322954929
training  [0.4954, -1.8257, 2.1505]  w:  [1.20218732 0.63711814 1.42668439]
2.5004618015841924  -  47.7531  =  -45.25263819841581
training  [-0.1477, 3.1454, 3.5618]  w:  [1.20218732 0.63711814 1.42668439]
6.907992778164943  -  94.1572  =  -87.24920722183506
training  [3.9048, 2.8907, -2.1849]  w:  [1.20218732 0.63711814 1.42668439]
3.418855728084183  -  85.8791  =  -82.46024427191581
training  [2.9896, 3.5226, 2.3105]  w:  [1.20218732 0.63711814 1.42668439]
9.134725849230756  -  98.038  =  -88.90327415076924
training  [2.3434, 0.0564, -3.6224]  w:  [1.20218732 0.63711814 1.42668439]
-2.314882300903521  -  24.7629  =  -27.077782300903518
training  [-4.4867, 1.3566, 3.3672]  w:  [1.20218732 0.63711814 1.42668439]
0.27439228072161637  -  40.5785  =  -40.304107719278385
training  [-4.2711, 4.5089, -3.614]  w:  [1.20218732 0.63711814 1.42668439]
-7.4179977010444444  -  10.0825  =  -17.500497701044445
training  [-4.1147, -0.5604, 0.8821]  w:  [1.20218732 0.63711814 1.42668439]
-4.045202879915875  -  8.344  =  -12.389202879915874
training  [2.9835, -4.3998, -1.3384]  w:  [1.20218732 0.63711814 1.42668439]
-1.125940883092796  -  13.2692  =  -14.395140883092795
training  [4.4301, 3.6675, 3.0676]  w:  [1.20218732 0.63711814 1.42668439]
12.038937857829414  -  99.3834  =  -87.34446214217058
training  [1.8372, 1.3119, 0.0378]  w:  [1.20218732 0.63711814 1.42668439]
3.098422501663127  -  74.9026  =  -71.80417749833688
training  [-3.6792, -1.4493, -0.1041]  w:  [1.20218732 0.63711814 1.42668439]
-5.494980757414714  -  4.2442  =  -9.739180757414715
training  [2.2272, 4.97, 3.7705]  w:  [1.20218732 0.63711814 1.42668439]
11.223302233802208  -  99.3199  =  -88.09659776619779
training  [-3.8965, -2.7583, -1.4686]  w:  [1.20218732 0.63711814 1.42668439]
-8.536914553004253  -  1.0337  =  -9.570614553004253
training  [-3.8251, 1.5245, -0.5056]  w:  [1.20218732 0.63711814 1.42668439]
-4.348531759163096  -  12.9762  =  -17.324731759163097
training  [1.4072, 1.0499, 4.6353]  w:  [1.20218732 0.63711814 1.42668439]
8.973738486809808  -  95.4618  =  -86.48806151319019
training  [-1.7119, -1.1275, -4.577]  w:  [1.20218732 0.63711814 1.42668439]
-9.30630963145562  -  1.4655  =  -10.771809631455621
training  [1.5381, -3.5781, 4.7296]  w:  [1.20218732 0.63711814 1.42668439]
6.317058414128969  -  69.9473  =  -63.63024158587103
training  [2.4913, -4.7487, -3.1079]  w:  [1.20218732 0.63711814 1.42668439]
-4.464466029992918  -  3.9825  =  -8.446966029992918
training  [0.8319, -0.7889, 1.6712]  w:  [1.20218732 0.63711814 1.42668439]
2.8817520902911165  -  58.8336  =  -55.95184790970888
training  [2.4003, -3.159, 0.8644]  w:  [1.20218732 0.63711814 1.42668439]
2.106180028239674  -  39.0041  =  -36.89791997176033
training  [-2.6517, 2.2578, 1.7511]  w:  [1.20218732 0.63711814 1.42668439]
0.7489122384901699  -  54.4525  =  -53.70358776150983
training  [2.3496, -1.2964, -1.3898]  w:  [1.20218732 0.63711814 1.42668439]
0.01589341706426395  -  33.888  =  -33.872106582935736
training  [4.706, 3.4156, 1.2028]  w:  [1.20218732 0.63711814 1.42668439]
9.549650230399868  -  98.4665  =  -88.91684976960013
training  [3.6693, 2.3423, 3.1115]  w:  [1.20218732 0.63711814 1.42668439]
10.342636234071783  -  98.3069  =  -87.96426376592822
training  [-4.1377, 0.7103, -4.8074]  w:  [1.20218732 0.63711814 1.42668439]
-11.380388013502042  -  0.9782  =  -12.358588013502041
training  [-1.3356, -3.2314, -4.1613]  w:  [1.20218732 0.63711814 1.42668439]
-9.601286686052191  -  0.7659  =  -10.367186686052191
training  [-1.308, 4.5738, 4.748]  w:  [1.20218732 0.63711814 1.42668439]
8.115487396237187  -  97.0884  =  -88.97291260376281
training  [1.8503, -2.3468, 1.5135]  w:  [1.20218732 0.63711814 1.42668439]
2.888505188215417  -  50.2125  =  -47.32399481178458
training  [0.9794, 4.2458, -2.6876]  w:  [1.20218732 0.63711814 1.42668439]
0.048141475932450994  -  68.3262  =  -68.27805852406755
training  [2.8936, -2.7623, -0.9651]  w:  [1.20218732 0.63711814 1.42668439]
0.34184470651247834  -  28.5596  =  -28.21775529348752
training  [-1.3235, -1.2644, -3.7798]  w:  [1.20218732 0.63711814 1.42668439]
-7.789248751845182  -  2.4511  =  -10.240348751845183
training  [-2.9397, -4.125, -2.3156]  w:  [1.20218732 0.63711814 1.42668439]
-9.46581275705782  -  0.554  =  -10.01981275705782
training  [-4.1333, 1.4012, -2.4215]  w:  [1.20218732 0.63711814 1.42668439]
-7.5309871820417555  -  4.4072  =  -11.938187182041755
training  [2.7193, -3.1938, -1.6833]  w:  [1.20218732 0.63711814 1.42668439]
-1.1672577486470974  -  17.0949  =  -18.2621577486471
training  [-2.9433, -4.5495, -3.4777]  w:  [1.20218732 0.63711814 1.42668439]
-11.398547210206297  -  0.2509  =  -11.649447210206297
training  [-1.1173, 2.2317, -1.5199]  w:  [1.20218732 0.63711814 1.42668439]
-2.0897649580085407  -  33.1206  =  -35.21036495800854
training  [0.5178, -1.5256, -3.7834]  w:  [1.20218732 0.63711814 1.42668439]
-5.747212554944897  -  5.237  =  -10.984212554944897
training  [-2.7105, 1.6062, 3.8415]  w:  [1.20218732 0.63711814 1.42668439]
3.2454184967733024  -  70.4458  =  -67.20038150322671
training  [1.4194, -1.1613, -4.0572]  w:  [1.20218732 0.63711814 1.42668439]
-4.82184451394515  -  8.3206  =  -13.14244451394515
training  [-0.1552, 1.2735, 4.3004]  w:  [1.20218732 0.63711814 1.42668439]
6.760104026179603  -  90.1085  =  -83.3483959738204
training  [-3.4815, -4.7835, -1.0098]  w:  [1.20218732 0.63711814 1.42668439]
-8.673735663704079  -  0.5839  =  -9.257635663704079
training  [2.8193, 4.1057, -4.526]  w:  [1.20218732 0.63711814 1.42668439]
-0.45203090297225845  -  66.8081  =  -67.26013090297225
training  [-3.9939, 3.0056, -1.5763]  w:  [1.20218732 0.63711814 1.42668439]
-5.135376285678358  -  14.4018  =  -19.537176285678356
training  [-2.0593, 2.4585, 2.3597]  w:  [1.20218732 0.63711814 1.42668439]
2.4572377384802837  -  70.6698  =  -68.21256226151971
training  [-2.6263, 3.1311, 2.9468]  w:  [1.20218732 0.63711814 1.42668439]
3.0417295900311947  -  77.309  =  -74.2672704099688
training  [0.3087, -1.1669, 0.4491]  w:  [1.20218732 0.63711814 1.42668439]
0.2683860340187685  -  33.0798  =  -32.81141396598123
training  [-4.085, 1.1728, 1.8622]  w:  [1.20218732 0.63711814 1.42668439]
-1.5069513927360711  -  26.4056  =  -27.91255139273607
training  [-0.9468, 0.7549, 3.9363]  w:  [1.20218732 0.63711814 1.42668439]
4.958587289661327  -  79.7738  =  -74.81521271033867
training  [-3.9515, 0.3005, -4.4521]  w:  [1.20218732 0.63711814 1.42668439]
-10.910730781957408  -  1.0441  =  -11.954830781957408
training  [-3.8772, -2.2493, -1.9634]  w:  [1.20218732 0.63711814 1.42668439]
-8.895342643122001  -  1.0509  =  -9.946242643122002
training  [2.8443, -2.5137, -4.5381]  w:  [1.20218732 0.63711814 1.42668439]
-4.656578887419881  -  6.8897  =  -11.54627888741988
training  [-2.0843, -0.4836, -3.0452]  w:  [1.20218732 0.63711814 1.42668439]
-7.1583686736075  -  3.5346  =  -10.6929686736075
training  [1.0353, -2.7229, 2.2017]  w:  [1.20218732 0.63711814 1.42668439]
2.6509465868226414  -  43.9562  =  -41.30525341317736
training  [4.6442, 3.0445, 2.2175]  w:  [1.20218732 0.63711814 1.42668439]
10.68657716482702  -  98.8492  =  -88.16262283517298
training  [-0.6752, 4.861, 3.778]  w:  [1.20218732 0.63711814 1.42668439]
7.675328003887959  -  97.017  =  -89.34167199611204
training  [1.9475, -4.7001, 0.8243]  w:  [1.20218732 0.63711814 1.42668439]
0.5227568056755181  -  18.7839  =  -18.261143194324482
training  [2.581, 0.3566, -4.2932]  w:  [1.20218732 0.63711814 1.42668439]
-2.7949996178620817  -  23.5455  =  -26.340499617862083
training  [-0.6736, -4.1292, 4.2274]  w:  [1.20218732 0.63711814 1.42668439]
2.590584006580139  -  31.2667  =  -28.676115993419863
training  [1.555, 3.0209, 3.0037]  w:  [1.20218732 0.63711814 1.42668439]
8.079403366679962  -  96.4078  =  -88.32839663332004
training  [-3.9024, 4.8914, -2.1405]  w:  [1.20218732 0.63711814 1.42668439]
-4.628834098772404  -  25.4308  =  -30.059634098772406
training  [4.3376, -4.3305, 0.4366]  w:  [1.20218732 0.63711814 1.42668439]
3.0784580508908412  -  43.0907  =  -40.01224194910915
training  [-3.1254, 4.394, 4.8478]  w:  [1.20218732 0.63711814 1.42668439]
5.958461416951806  -  92.8121  =  -86.8536385830482
training  [-2.3382, -4.8182, 2.1568]  w:  [1.20218732 0.63711814 1.42668439]
-2.8036441056115664  -  4.7434  =  -7.547044105611567
training  [2.9783, 1.8384, 3.3897]  w:  [1.20218732 0.63711814 1.42668439]
9.587784562877868  -  97.3486  =  -87.76081543712213
training  [-0.124, 2.8374, -0.6674]  w:  [1.20218732 0.63711814 1.42668439]
0.7065186074909026  -  62.785  =  -62.0784813925091
training  [2.6896, 0.3414, -0.2938]  w:  [1.20218732 0.63711814 1.42668439]
3.031755281282266  -  70.4455  =  -67.41374471871772
training  [-1.0399, 3.8536, 0.6071]  w:  [1.20218732 0.63711814 1.42668439]
2.071183943502193  -  77.0369  =  -74.96571605649781
training  [-2.2706, 3.99, -2.3091]  w:  [1.20218732 0.63711814 1.42668439]
-3.481942100838112  -  31.1134  =  -34.59534210083811
training  [-4.6277, 1.2594, 2.4902]  w:  [1.20218732 0.63711814 1.42668439]
-1.2082462250914077  -  28.1093  =  -29.31754622509141
training  [1.7329, -3.6213, 0.0389]  w:  [1.20218732 0.63711814 1.42668439]
-0.16842746953606097  -  19.3919  =  -19.56032746953606
training  [-0.7044, -2.822, 1.4681]  w:  [1.20218732 0.63711814 1.42668439]
-0.5502527750109145  -  17.8122  =  -18.362452775010915
training  [-0.4826, -3.1786, -1.9225]  w:  [1.20218732 0.63711814 1.42668439]
-5.348120048491271  -  3.5851  =  -8.933220048491272
training  [1.0986, -4.5818, -3.6128]  w:  [1.20218732 0.63711814 1.42668439]
-6.752750246599362  -  1.7158  =  -8.468550246599362
training  [-4.406, -3.9306, -0.2443]  w:  [1.20218732 0.63711814 1.42668439]
-8.149632884989682  -  0.8241  =  -8.973732884989682
training  [-1.8419, 1.1644, -1.3754]  w:  [1.20218732 0.63711814 1.42668439]
-3.434710183831755  -  17.8517  =  -21.286410183831755
training  [2.7272, 4.3966, 2.8811]  w:  [1.20218732 0.63711814 1.42668439]
10.190179259399738  -  98.904  =  -88.71382074060026
training  [1.9643, -1.4554, 2.803]  w:  [1.20218732 0.63711814 1.42668439]
5.433191170654097  -  76.0591  =  -70.6259088293459
training  [-3.7467, -0.8937, 1.6851]  w:  [1.20218732 0.63711814 1.42668439]
-2.6695218540481553  -  12.1571  =  -14.826621854048156
training  [-3.6985, 4.8435, -3.665]  w:  [1.20218732 0.63711814 1.42668439]
-6.589206415701117  -  14.6793  =  -21.26850641570112
250916.59072027155
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.30612886 0.45285977 1.52600992]
10.804055134639157  -  87.3174  =  -76.51334486536085
training  [-4.1793, -4.9218, 1.7664]  w:  [1.30612886 0.45285977 1.52600992]
-4.992045626101613  -  1.5257  =  -6.517745626101613
training  [-3.9429, -0.7689, 4.883]  w:  [1.30612886 0.45285977 1.52600992]
1.9533671059080016  -  39.7859  =  -37.832532894092
training  [-3.5796, 1.5557, 2.6683]  w:  [1.30612886 0.45285977 1.52600992]
0.1009473704447279  -  45.5674  =  -45.46645262955527
training  [-3.3354, 2.2292, -1.633]  w:  [1.30612886 0.45285977 1.52600992]
-5.838921384883067  -  13.3589  =  -19.197821384883067
training  [1.2096, 0.3121, 1.6238]  w:  [1.30612886 0.45285977 1.52600992]
4.19916591045261  -  74.5119  =  -70.31273408954739
training  [0.7371, -3.9118, -2.5583]  w:  [1.30612886 0.45285977 1.52600992]
-4.712740460315787  -  3.3358  =  -8.048540460315788
training  [-4.4792, 1.3177, -2.0449]  w:  [1.30612886 0.45285977 1.52600992]
-8.374216739234228  -  4.2974  =  -12.671616739234228
training  [4.312, -3.735, 1.8018]  w:  [1.30612886 0.45285977 1.52600992]
6.690161055690147  -  66.5833  =  -59.89313894430985
training  [2.2866, -3.657, 0.2785]  w:  [1.30612886 0.45285977 1.52600992]
1.7554798189071452  -  26.0005  =  -24.245020181092855
training  [2.3784, -4.0141, -0.8841]  w:  [1.30612886 0.45285977 1.52600992]
-0.06047291224188167  -  14.6809  =  -14.74137291224188
training  [-4.366, -3.5797, 1.0264]  w:  [1.30612886 0.45285977 1.52600992]
-5.757364125946861  -  1.8713  =  -7.628664125946861
training  [3.6044, -3.3175, 2.5052]  w:  [1.30612886 0.45285977 1.52600992]
7.0284086113985555  -  71.0139  =  -63.98549138860145
training  [4.3441, -3.0375, 0.8353]  w:  [1.30612886 0.45285977 1.52600992]
5.5730688931066386  -  63.8979  =  -58.32483110689336
training  [4.844, -1.8252, 0.5179]  w:  [1.30612886 0.45285977 1.52600992]
6.290649060365377  -  78.0461  =  -71.75545093963461
training  [3.5894, -1.8357, 0.8357]  w:  [1.30612886 0.45285977 1.52600992]
5.132190723557388  -  68.8838  =  -63.75160927644261
training  [2.8556, -2.8244, 0.1182]  w:  [1.30612886 0.45285977 1.52600992]
2.6310987934625674  -  39.5252  =  -36.89410120653743
training  [0.1338, -2.4896, -4.1741]  w:  [1.30612886 0.45285977 1.52600992]
-7.322397663606129  -  2.2644  =  -9.586797663606129
training  [-3.224, 3.9292, 2.1957]  w:  [1.30612886 0.45285977 1.52600992]
0.919077171093992  -  72.1211  =  -71.20202282890601
training  [-1.0141, 2.0322, 4.9616]  w:  [1.30612886 0.45285977 1.52600992]
7.167207185883847  -  92.3427  =  -85.17549281411614
training  [-3.6607, 0.5574, -1.4547]  w:  [1.30612886 0.45285977 1.52600992]
-6.748808499315636  -  5.8471  =  -12.595908499315637
training  [-4.6911, -3.1557, 4.7126]  w:  [1.30612886 0.45285977 1.52600992]
-0.3647962984622737  -  11.2337  =  -11.598496298462274
training  [4.3914, -2.8797, -1.5355]  w:  [1.30612886 0.45285977 1.52600992]
2.088445736465596  -  37.475  =  -35.38655426353441
training  [-1.9869, -4.2265, 3.8654]  w:  [1.30612886 0.45285977 1.52600992]
1.3894795034656182  -  15.7889  =  -14.399420496534383
training  [-2.0447, 4.138, -0.4531]  w:  [1.30612886 0.45285977 1.52600992]
-1.4881430307911692  -  57.936  =  -59.42414303079117
training  [-1.6706, 2.0672, -0.8657]  w:  [1.30612886 0.45285977 1.52600992]
-2.5669339355215297  -  32.4185  =  -34.985433935521534
training  [-0.3293, 0.5779, -2.8227]  w:  [1.30612886 0.45285977 1.52600992]
-4.475868777368684  -  14.3434  =  -18.819268777368684
training  [1.482, -1.8657, -3.7435]  w:  [1.30612886 0.45285977 1.52600992]
-4.621835656003357  -  7.1519  =  -11.773735656003357
training  [-4.7477, -3.338, -1.9109]  w:  [1.30612886 0.45285977 1.52600992]
-10.628806247776934  -  0.4077  =  -11.036506247776934
training  [3.4221, 1.225, 2.261]  w:  [1.30612886 0.45285977 1.52600992]
8.474765212138543  -  95.0454  =  -86.57063478786145
training  [0.5903, 4.8793, 2.8287]  w:  [1.30612886 0.45285977 1.52600992]
7.29727081582985  -  97.4647  =  -90.16742918417015
training  [3.541, -3.2957, 1.9379]  w:  [1.30612886 0.45285977 1.52600992]
6.089766956109947  -  64.3732  =  -58.28343304389005
training  [-1.5212, -2.4221, -4.902]  w:  [1.30612886 0.45285977 1.52600992]
-10.564255507697174  -  0.7227  =  -11.286955507697174
training  [-0.5397, -1.032, 3.4321]  w:  [1.30612886 0.45285977 1.52600992]
4.0651496258216895  -  60.5921  =  -56.52695037417831
training  [-4.4576, -4.2601, 4.2233]  w:  [1.30612886 0.45285977 1.52600992]
-1.3066301977222574  -  6.0247  =  -7.331330197722258
training  [-3.2289, 1.841, 2.7095]  w:  [1.30612886 0.45285977 1.52600992]
0.7510792619065736  -  54.0111  =  -53.260020738093424
training  [1.6281, -0.9761, -4.5734]  w:  [1.30612886 0.45285977 1.52600992]
-5.294581811460633  -  7.8658  =  -13.160381811460633
training  [-1.6917, 4.8284, -1.2181]  w:  [1.30612886 0.45285977 1.52600992]
-1.8818227486103296  -  61.2837  =  -63.165522748610336
training  [3.9849, -0.9782, 2.0434]  w:  [1.30612886 0.45285977 1.52600992]
7.880054123515507  -  88.3402  =  -80.46014587648449
training  [-3.8184, 1.2067, 2.2951]  w:  [1.30612886 0.45285977 1.52600992]
-0.9385111636964574  -  34.1122  =  -35.05071116369646
training  [4.8842, -3.4563, -2.7572]  w:  [1.30612886 0.45285977 1.52600992]
0.6066607701408548  -  23.7819  =  -23.175239229859145
training  [0.3998, -1.1865, -2.3095]  w:  [1.30612886 0.45285977 1.52600992]
-3.5394477181965978  -  11.4246  =  -14.964047718196598
training  [2.0692, -3.3887, 1.7303]  w:  [1.30612886 0.45285977 1.52600992]
3.808490887516662  -  42.6881  =  -38.87960911248334
training  [4.9949, 2.5811, -0.2251]  w:  [1.30612886 0.45285977 1.52600992]
7.349354545723273  -  95.9901  =  -88.64074545427673
training  [-2.1215, 3.7111, 1.2372]  w:  [1.30612886 0.45285977 1.52600992]
0.7976350079157195  -  71.3692  =  -70.57156499208429
training  [-0.8548, -1.4922, -2.6356]  w:  [1.30612886 0.45285977 1.52600992]
-5.81418804858891  -  4.7821  =  -10.59628804858891
training  [-0.3516, 1.8554, -3.2288]  w:  [1.30612886 0.45285977 1.52600992]
-4.546179721570458  -  20.3834  =  -24.92957972157046
training  [2.6396, -2.0585, 3.2964]  w:  [1.30612886 0.45285977 1.52600992]
7.545784994674508  -  80.826  =  -73.28021500532549
training  [3.182, 0.3063, 2.6692]  w:  [1.30612886 0.45285977 1.52600992]
8.368038651598347  -  92.9483  =  -84.58026134840165
training  [-3.9978, 3.3242, 4.3448]  w:  [1.30612886 0.45285977 1.52600992]
2.9139624242299167  -  79.1768  =  -76.26283757577008
training  [-3.2188, 0.9749, -3.9211]  w:  [1.30612886 0.45285977 1.52600992]
-9.74631207524396  -  2.7053  =  -12.45161207524396
training  [-1.4037, -1.6469, -3.1777]  w:  [1.30612886 0.45285977 1.52600992]
-7.428429563076579  -  2.6234  =  -10.051829563076579
training  [-4.433, -2.0077, -4.009]  w:  [1.30612886 0.45285977 1.52600992]
-12.81704955996855  -  0.3253  =  -13.142349559968551
training  [0.2189, -0.4741, -0.1024]  w:  [1.30612886 0.45285977 1.52600992]
-0.08505262738847966  -  33.6531  =  -33.73815262738848
training  [-1.6415, -0.7735, -3.0675]  w:  [1.30612886 0.45285977 1.52600992]
-7.175332986723878  -  3.7641  =  -10.939432986723878
training  [-3.2433, -1.4039, 3.9589]  w:  [1.30612886 0.45285977 1.52600992]
1.1693831291228376  -  30.0658  =  -28.89641687087716
training  [-2.9105, 0.5832, -4.0091]  w:  [1.30612886 0.45285977 1.52600992]
-9.655306594835235  -  2.4887  =  -12.144006594835234
training  [4.0515, 2.4255, -4.5583]  w:  [1.30612886 0.45285977 1.52600992]
-0.5658185921959538  -  61.2853  =  -61.85111859219595
training  [1.7539, -0.7567, 0.573]  w:  [1.30612886 0.45285977 1.52600992]
2.8225440961428547  -  57.0797  =  -54.25715590385715
training  [-0.3153, -0.7064, 2.725]  w:  [1.30612886 0.45285977 1.52600992]
3.4266544668300236  -  58.7004  =  -55.27374553316998
training  [4.1213, -3.7513, -1.8806]  w:  [1.30612886 0.45285977 1.52600992]
0.8143217311229578  -  22.1789  =  -21.36457826887704
training  [-3.9599, -4.7557, -3.2102]  w:  [1.30612886 0.45285977 1.52600992]
-12.224601925805162  -  0.1558  =  -12.380401925805161
training  [2.4555, -2.0981, -1.6104]  w:  [1.30612886 0.45285977 1.52600992]
-0.20043206086478715  -  24.4796  =  -24.68003206086479
training  [2.3627, -1.8248, -2.8985]  w:  [1.30612886 0.45285977 1.52600992]
-2.163527623781464  -  15.7052  =  -17.868727623781464
training  [0.6186, 1.5369, 0.1015]  w:  [1.30612886 0.45285977 1.52600992]
1.6588615008277168  -  65.2154  =  -63.556538499172284
training  [-3.1581, 4.5694, 4.0636]  w:  [1.30612886 0.45285977 1.52600992]
4.145505822367484  -  90.3564  =  -86.21089417763251
training  [0.9721, 4.3573, 1.2892]  w:  [1.30612886 0.45285977 1.52600992]
5.210265736788537  -  94.3178  =  -89.10753426321146
training  [-2.0006, -0.4211, -3.9847]  w:  [1.30612886 0.45285977 1.52600992]
-8.884432375833766  -  2.4051  =  -11.289532375833765
training  [-3.6588, -2.5952, -1.0915]  w:  [1.30612886 0.45285977 1.52600992]
-7.619765767845375  -  1.5176  =  -9.137365767845376
training  [-2.874, 2.639, -4.4538]  w:  [1.30612886 0.45285977 1.52600992]
-9.35526038479292  -  5.497  =  -14.85226038479292
training  [3.9494, 2.5933, 0.0128]  w:  [1.30612886 0.45285977 1.52600992]
6.352359476701538  -  94.1462  =  -87.79384052329846
training  [-4.2855, 2.4065, -0.6828]  w:  [1.30612886 0.45285977 1.52600992]
-5.549567745132616  -  14.4193  =  -19.968867745132616
training  [-2.5751, 2.4369, 4.9756]  w:  [1.30612886 0.45285977 1.52600992]
5.332976530618955  -  87.1991  =  -81.86612346938105
training  [-4.4625, -3.9408, 3.116]  w:  [1.30612886 0.45285977 1.52600992]
-2.8581828907719613  -  4.1344  =  -6.992582890771962
training  [-0.5828, 1.8156, -0.1435]  w:  [1.30612886 0.45285977 1.52600992]
-0.1579821190103774  -  51.1166  =  -51.274582119010375
training  [-4.8672, -0.3674, 3.9445]  w:  [1.30612886 0.45285977 1.52600992]
-0.504224909034213  -  24.1396  =  -24.643824909034215
training  [3.9719, -2.8784, -3.6245]  w:  [1.30612886 0.45285977 1.52600992]
-1.6467213282971  -  14.6104  =  -16.2571213282971
training  [-3.0334, -4.0148, -1.1]  w:  [1.30612886 0.45285977 1.52600992]
-7.458763598053612  -  1.021  =  -8.479763598053612
training  [-4.0663, 3.2357, 4.2736]  w:  [1.30612886 0.45285977 1.52600992]
2.6757626013291764  -  77.2328  =  -74.55703739867081
training  [-1.9263, -3.2499, 4.1749]  w:  [1.30612886 0.45285977 1.52600992]
2.3831938363462655  -  26.8814  =  -24.498206163653734
training  [-0.4394, -3.3643, 2.1357]  w:  [1.30612886 0.45285977 1.52600992]
1.1616302407724528  -  20.85  =  -19.688369759227548
training  [-3.9833, 1.6599, 1.1834]  w:  [1.30612886 0.45285977 1.52600992]
-2.645120993864282  -  25.5397  =  -28.18482099386428
training  [4.9539, 3.9439, -1.5671]  w:  [1.30612886 0.45285977 1.52600992]
5.865055244286047  -  95.9509  =  -90.08584475571396
training  [-1.6791, 0.1656, 4.3603]  w:  [1.30612886 0.45285977 1.52600992]
4.535733680218378  -  71.5733  =  -67.03756631978163
training  [-2.0265, 2.027, -3.7523]  w:  [1.30612886 0.45285977 1.52600992]
-7.454970399533881  -  8.503  =  -15.957970399533881
training  [-4.3795, -3.4641, 2.3059]  w:  [1.30612886 0.45285977 1.52600992]
-3.7701165804145034  -  3.6654  =  -7.435516580414504
training  [-2.0176, 4.5346, 1.4648]  w:  [1.30612886 0.45285977 1.52600992]
1.6535916765366645  -  81.6212  =  -79.96760832346334
training  [-4.5365, 0.4088, 3.3315]  w:  [1.30612886 0.45285977 1.52600992]
-0.6562224237295391  -  28.9449  =  -29.60112242372954
training  [0.0543, 1.7973, -1.0172]  w:  [1.30612886 0.45285977 1.52600992]
-0.667409627833215  -  47.9317  =  -48.599109627833215
training  [2.6143, -4.6344, 2.4982]  w:  [1.30612886 0.45285977 1.52600992]
5.128157328124015  -  43.5132  =  -38.38504267187598
training  [1.3107, 3.092, 3.3522]  w:  [1.30612886 0.45285977 1.52600992]
8.227675967377152  -  96.6993  =  -88.47162403262284
training  [-4.1011, 2.4862, -1.7754]  w:  [1.30612886 0.45285977 1.52600992]
-6.939943101287615  -  10.0187  =  -16.958643101287617
training  [-4.1914, -3.7981, 0.5226]  w:  [1.30612886 0.45285977 1.52600992]
-6.397022400723885  -  1.4295  =  -7.826522400723885
training  [2.7724, 0.2505, 4.7913]  w:  [1.30612886 0.45285977 1.52600992]
11.046124352877229  -  96.7925  =  -85.74637564712278
training  [4.0513, -1.7417, 0.4931]  w:  [1.30612886 0.45285977 1.52600992]
5.25524946126851  -  71.1234  =  -65.8681505387315
training  [0.3377, 0.4645, -1.6958]  w:  [1.30612886 0.45285977 1.52600992]
-1.936374547377198  -  27.9534  =  -29.889774547377197
training  [-3.9085, -1.0112, 1.1947]  w:  [1.30612886 0.45285977 1.52600992]
-3.7398123802256262  -  8.608  =  -12.347812380225626
training  [3.2581, -0.8491, -1.3936]  w:  [1.30612886 0.45285977 1.52600992]
1.7443277651086913  -  50.1924  =  -48.448072234891306
training  [-1.619, -3.1926, 2.5651]  w:  [1.30612886 0.45285977 1.52600992]
0.353945325917564  -  16.4754  =  -16.121454674082436
training  [-2.0603, -2.4461, -0.861]  w:  [1.30612886 0.45285977 1.52600992]
-5.112652112797912  -  3.9784  =  -9.091052112797913
training  [2.4631, -4.7946, -0.0765]  w:  [1.30612886 0.45285977 1.52600992]
0.9291047629884098  -  15.394  =  -14.464895237011591
training  [-4.8966, 4.2368, 1.9474]  w:  [1.30612886 0.45285977 1.52600992]
-1.5051625509262836  -  53.5883  =  -55.09346255092628
training  [-4.5155, 1.537, 4.7273]  w:  [1.30612886 0.45285977 1.52600992]
2.0121273263702957  -  59.2523  =  -57.2401726736297
training  [1.6792, 4.3261, -1.7225]  w:  [1.30612886 0.45285977 1.52600992]
1.5238161431633297  -  83.7729  =  -82.24908385683668
training  [1.0347, -3.3649, 3.378]  w:  [1.30612886 0.45285977 1.52600992]
4.982485197571615  -  50.5979  =  -45.61541480242839
training  [0.261, 4.211, 2.3907]  w:  [1.30612886 0.45285977 1.52600992]
5.896124052093073  -  94.9375  =  -89.04137594790693
training  [2.2971, 2.9466, 4.5417]  w:  [1.30612886 0.45285977 1.52600992]
11.265384462334715  -  98.7784  =  -87.5130155376653
training  [2.0725, 0.7739, -4.6808]  w:  [1.30612886 0.45285977 1.52600992]
-4.085527012652193  -  19.5109  =  -23.596427012652192
training  [2.8138, -0.5996, -1.4313]  w:  [1.30612886 0.45285977 1.52600992]
1.2194726535192832  -  47.2879  =  -46.06842734648072
training  [-2.1202, -2.4239, 1.6265]  w:  [1.30612886 0.45285977 1.52600992]
-1.384886062866201  -  12.3599  =  -13.7447860628662
training  [1.9253, 2.5195, -2.185]  w:  [1.30612886 0.45285977 1.52600992]
0.321338401527381  -  65.2467  =  -64.92536159847262
training  [0.5667, -2.7133, -2.6962]  w:  [1.30612886 0.45285977 1.52600992]
-4.602989148913173  -  5.1106  =  -9.713589148913172
training  [-1.0348, -4.3581, 2.1113]  w:  [1.30612886 0.45285977 1.52600992]
-0.10332556344569754  -  10.5192  =  -10.622525563445697
training  [-4.3841, 2.6733, 1.2457]  w:  [1.30612886 0.45285977 1.52600992]
-2.614618928203501  -  32.4639  =  -35.0785189282035
training  [2.8018, 1.712, 0.9061]  w:  [1.30612886 0.45285977 1.52600992]
5.817525348258478  -  90.1138  =  -84.29627465174153
training  [-1.6242, 2.1521, 1.6044]  w:  [1.30612886 0.45285977 1.52600992]
1.3015153468367981  -  63.7879  =  -62.4863846531632
training  [1.0787, 1.4206, -4.5245]  w:  [1.30612886 0.45285977 1.52600992]
-4.852178104168816  -  18.0555  =  -22.907678104168816
training  [2.4125, -0.8095, -1.5122]  w:  [1.30612886 0.45285977 1.52600992]
0.476813674849486  -  38.8276  =  -38.35078632515051
training  [-3.9519, -1.0924, -0.4866]  w:  [1.30612886 0.45285977 1.52600992]
-6.398951068234192  -  3.6777  =  -10.076651068234192
training  [-3.7211, 3.1614, -2.591]  w:  [1.30612886 0.45285977 1.52600992]
-7.382456910597269  -  11.1518  =  -18.534256910597268
training  [0.4954, -1.8257, 2.1505]  w:  [1.30612886 0.45285977 1.52600992]
3.101954487159465  -  47.7531  =  -44.651145512840536
training  [-0.1477, 3.1454, 3.5618]  w:  [1.30612886 0.45285977 1.52600992]
6.666852035606187  -  94.1572  =  -87.49034796439382
training  [3.9048, 2.8907, -2.1849]  w:  [1.30612886 0.45285977 1.52600992]
3.075074619911263  -  85.8791  =  -82.80402538008873
training  [2.9896, 3.5226, 2.3105]  w:  [1.30612886 0.45285977 1.52600992]
9.025892585223929  -  98.038  =  -89.01210741477607
training  [2.3434, 0.0564, -3.6224]  w:  [1.30612886 0.45285977 1.52600992]
-2.4414946903537347  -  24.7629  =  -27.204394690353734
training  [-4.4867, 1.3566, 3.3672]  w:  [1.30612886 0.45285977 1.52600992]
-0.10747816062056437  -  40.5785  =  -40.685978160620564
training  [-4.2711, 4.5089, -3.614]  w:  [1.30612886 0.45285977 1.52600992]
-9.051707388963502  -  10.0825  =  -19.134207388963503
training  [-4.1147, -0.5604, 0.8821]  w:  [1.30612886 0.45285977 1.52600992]
-4.282017666765625  -  8.344  =  -12.626017666765623
training  [2.9835, -4.3998, -1.3384]  w:  [1.30612886 0.45285977 1.52600992]
-0.13806866330202228  -  13.2692  =  -13.407268663302021
training  [4.4301, 3.6675, 3.0676]  w:  [1.30612886 0.45285977 1.52600992]
12.12833269504118  -  99.3834  =  -87.25506730495881
training  [1.8372, 1.3119, 0.0378]  w:  [1.30612886 0.45285977 1.52600992]
3.0514098437588397  -  74.9026  =  -71.85119015624117
training  [-3.6792, -1.4493, -0.1041]  w:  [1.30612886 0.45285977 1.52600992]
-5.620696586635277  -  4.2442  =  -9.864896586635277
training  [2.2272, 4.97, 3.7705]  w:  [1.30612886 0.45285977 1.52600992]
10.913543665913075  -  99.3199  =  -88.40635633408692
training  [-3.8965, -2.7583, -1.4686]  w:  [1.30612886 0.45285977 1.52600992]
-8.57955236733348  -  1.0337  =  -9.61325236733348
training  [-3.8251, 1.5245, -0.5056]  w:  [1.30612886 0.45285977 1.52600992]
-5.077239380586763  -  12.9762  =  -18.053439380586763
training  [1.4072, 1.0499, 4.6353]  w:  [1.30612886 0.45285977 1.52600992]
9.38695579279787  -  95.4618  =  -86.07484420720212
training  [-1.7119, -1.1275, -4.577]  w:  [1.30612886 0.45285977 1.52600992]
-9.731108794997992  -  1.4655  =  -11.196608794997992
training  [1.5381, -3.5781, 4.7296]  w:  [1.30612886 0.45285977 1.52600992]
7.605995771030447  -  69.9473  =  -62.34130422896955
training  [2.4913, -4.7487, -3.1079]  w:  [1.30612886 0.45285977 1.52600992]
-3.6392226178820377  -  3.9825  =  -7.621722617882037
training  [0.8319, -0.7889, 1.6712]  w:  [1.30612886 0.45285977 1.52600992]
3.279575302999016  -  58.8336  =  -55.55402469700098
training  [2.4003, -3.159, 0.8644]  w:  [1.30612886 0.45285977 1.52600992]
3.0236000496621642  -  39.0041  =  -35.98049995033784
training  [-2.6517, 2.2578, 1.7511]  w:  [1.30612886 0.45285977 1.52600992]
0.23120088099398162  -  54.4525  =  -54.22129911900602
training  [2.3496, -1.2964, -1.3898]  w:  [1.30612886 0.45285977 1.52600992]
0.36094436132701535  -  33.888  =  -33.527055638672984
training  [4.706, 3.4156, 1.2028]  w:  [1.30612886 0.45285977 1.52600992]
9.528914966889806  -  98.4665  =  -88.9375850331102
training  [3.6693, 2.3423, 3.1115]  w:  [1.30612886 0.45285977 1.52600992]
10.601491927331852  -  98.3069  =  -87.70540807266815
training  [-4.1377, 0.7103, -4.8074]  w:  [1.30612886 0.45285977 1.52600992]
-12.418843170532192  -  0.9782  =  -13.397043170532191
training  [-1.3356, -3.2314, -4.1613]  w:  [1.30612886 0.45285977 1.52600992]
-9.558021856144892  -  0.7659  =  -10.323921856144892
training  [-1.308, 4.5738, 4.748]  w:  [1.30612886 0.45285977 1.52600992]
7.6083685922122175  -  97.0884  =  -89.48003140778778
training  [1.8503, -2.3468, 1.5135]  w:  [1.30612886 0.45285977 1.52600992]
3.663574926262661  -  50.2125  =  -46.54892507373734
training  [0.9794, 4.2458, -2.6876]  w:  [1.30612886 0.45285977 1.52600992]
-0.8993296457168087  -  68.3262  =  -69.2255296457168
training  [2.8936, -2.7623, -0.9651]  w:  [1.30612886 0.45285977 1.52600992]
1.0557277331095793  -  28.5596  =  -27.50387226689042
training  [-1.3235, -1.2644, -3.7798]  w:  [1.30612886 0.45285977 1.52600992]
-8.069269740218205  -  2.4511  =  -10.520369740218205
training  [-2.9397, -4.125, -2.3156]  w:  [1.30612886 0.45285977 1.52600992]
-9.241302132554765  -  0.554  =  -9.795302132554765
training  [-4.1333, 1.4012, -2.4215]  w:  [1.30612886 0.45285977 1.52600992]
-8.45930831375507  -  4.4072  =  -12.86650831375507
training  [2.7193, -3.1938, -1.6833]  w:  [1.30612886 0.45285977 1.52600992]
-0.463319844176894  -  17.0949  =  -17.558219844176893
training  [-2.9433, -4.5495, -3.4777]  w:  [1.30612886 0.45285977 1.52600992]
-11.211619300215588  -  0.2509  =  -11.462519300215588
training  [-1.1173, 2.2317, -1.5199]  w:  [1.30612886 0.45285977 1.52600992]
-2.7680730982230384  -  33.1206  =  -35.888673098223045
training  [0.5178, -1.5256, -3.7834]  w:  [1.30612886 0.45285977 1.52600992]
-5.788075286207325  -  5.237  =  -11.025075286207326
training  [-2.7105, 1.6062, 3.8415]  w:  [1.30612886 0.45285977 1.52600992]
3.0492882182141687  -  70.4458  =  -67.39651178178583
training  [1.4194, -1.1613, -4.0572]  w:  [1.30612886 0.45285977 1.52600992]
-4.8633142115958945  -  8.3206  =  -13.183914211595894
training  [-0.1552, 1.2735, 4.3004]  w:  [1.30612886 0.45285977 1.52600992]
6.936458790578774  -  90.1085  =  -83.17204120942124
training  [-3.4815, -4.7835, -1.0098]  w:  [1.30612886 0.45285977 1.52600992]
-8.254507150061102  -  0.5839  =  -8.838407150061101
training  [2.8193, 4.1057, -4.526]  w:  [1.30612886 0.45285977 1.52600992]
-1.3650454589594627  -  66.8081  =  -68.17314545895945
training  [-3.9939, 3.0056, -1.5763]  w:  [1.30612886 0.45285977 1.52600992]
-6.260882146879582  -  14.4018  =  -20.662682146879582
training  [-2.0593, 2.4585, 2.3597]  w:  [1.30612886 0.45285977 1.52600992]
2.0245702100447995  -  70.6698  =  -68.6452297899552
training  [-2.6263, 3.1311, 2.9468]  w:  [1.30612886 0.45285977 1.52600992]
2.4845090567545682  -  77.309  =  -74.82449094324542
training  [0.3087, -1.1669, 0.4491]  w:  [1.30612886 0.45285977 1.52600992]
0.560090965933945  -  33.0798  =  -32.519709034066054
training  [-4.085, 1.1728, 1.8622]  w:  [1.30612886 0.45285977 1.52600992]
-1.962686758237453  -  26.4056  =  -28.368286758237453
training  [-0.9468, 0.7549, 3.9363]  w:  [1.30612886 0.45285977 1.52600992]
5.1120538979230385  -  79.7738  =  -74.66174610207696
training  [-3.9515, 0.3005, -4.4521]  w:  [1.30612886 0.45285977 1.52600992]
-11.819032586779798  -  1.0441  =  -12.863132586779798
training  [-3.8772, -2.2493, -1.9634]  w:  [1.30612886 0.45285977 1.52600992]
-9.078908165987881  -  1.0509  =  -10.129808165987882
training  [2.8443, -2.5137, -4.5381]  w:  [1.30612886 0.45285977 1.52600992]
-4.34851693216732  -  6.8897  =  -11.23821693216732
training  [-2.0843, -0.4836, -3.0452]  w:  [1.30612886 0.45285977 1.52600992]
-7.588372774910618  -  3.5346  =  -11.122972774910618
training  [1.0353, -2.7229, 2.2017]  w:  [1.30612886 0.45285977 1.52600992]
3.478959377010474  -  43.9562  =  -40.47724062298953
training  [4.6442, 3.0445, 2.2175]  w:  [1.30612886 0.45285977 1.52600992]
10.828582210275364  -  98.8492  =  -88.02061778972464
training  [-0.6752, 4.861, 3.778]  w:  [1.30612886 0.45285977 1.52600992]
7.084718634137518  -  97.017  =  -89.93228136586248
training  [1.9475, -4.7001, 0.8243]  w:  [1.30612886 0.45285977 1.52600992]
1.6730897113050174  -  18.7839  =  -17.11081028869498
training  [2.581, 0.3566, -4.2932]  w:  [1.30612886 0.45285977 1.52600992]
-3.018857426481247  -  23.5455  =  -26.564357426481248
training  [-0.6736, -4.1292, 4.2274]  w:  [1.30612886 0.45285977 1.52600992]
3.7012973774221316  -  31.2667  =  -27.565402622577867
training  [1.555, 3.0209, 3.0037]  w:  [1.30612886 0.45285977 1.52600992]
7.982750459175811  -  96.4078  =  -88.42504954082418
training  [-3.9024, 4.8914, -2.1405]  w:  [1.30612886 0.45285977 1.52600992]
-6.148343196704891  -  25.4308  =  -31.57914319670489
training  [4.3376, -4.3305, 0.4366]  w:  [1.30612886 0.45285977 1.52600992]
4.3706112144149625  -  43.0907  =  -38.720088785585034
training  [-3.1254, 4.394, 4.8478]  w:  [1.30612886 0.45285977 1.52600992]
5.305481612933247  -  92.8121  =  -87.50661838706675
training  [-2.3382, -4.8182, 2.1568]  w:  [1.30612886 0.45285977 1.52600992]
-1.9446612437049322  -  4.7434  =  -6.688061243704933
training  [2.9783, 1.8384, 3.3897]  w:  [1.30612886 0.45285977 1.52600992]
9.895296809241367  -  97.3486  =  -87.45330319075863
training  [-0.124, 2.8374, -0.6674]  w:  [1.30612886 0.45285977 1.52600992]
0.1045253167831186  -  62.785  =  -62.68047468321688
training  [2.6896, 0.3414, -0.2938]  w:  [1.30612886 0.45285977 1.52600992]
3.219228781543901  -  70.4455  =  -67.22627121845609
training  [-1.0399, 3.8536, 0.6071]  w:  [1.30612886 0.45285977 1.52600992]
1.3133376438702369  -  77.0369  =  -75.72356235612976
training  [-2.2706, 3.99, -2.3091]  w:  [1.30612886 0.45285977 1.52600992]
-4.6824952011560255  -  31.1134  =  -35.79589520115602
training  [-4.6277, 1.2594, 2.4902]  w:  [1.30612886 0.45285977 1.52600992]
-1.6739710008856532  -  28.1093  =  -29.783271000885655
training  [1.7329, -3.6213, 0.0389]  w:  [1.30612886 0.45285977 1.52600992]
0.6828113879572775  -  19.3919  =  -18.709088612042724
training  [-0.7044, -2.822, 1.4681]  w:  [1.30612886 0.45285977 1.52600992]
0.04232772426808484  -  17.8122  =  -17.769872275731917
training  [-0.4826, -3.1786, -1.9225]  w:  [1.30612886 0.45285977 1.52600992]
-5.003551932388927  -  3.5851  =  -8.588651932388927
training  [1.0986, -4.5818, -3.6128]  w:  [1.30612886 0.45285977 1.52600992]
-6.153168389116676  -  1.7158  =  -7.8689683891166755
training  [-4.406, -3.9306, -0.2443]  w:  [1.30612886 0.45285977 1.52600992]
-7.907618582292063  -  0.8241  =  -8.731718582292062
training  [-1.8419, 1.1644, -1.3754]  w:  [1.30612886 0.45285977 1.52600992]
-3.9773228679903463  -  17.8517  =  -21.829022867990346
training  [2.7272, 4.3966, 2.8811]  w:  [1.30612886 0.45285977 1.52600992]
9.94970507576517  -  98.904  =  -88.95429492423483
training  [1.9643, -1.4554, 2.803]  w:  [1.30612886 0.45285977 1.52600992]
6.1839426112206315  -  76.0591  =  -69.87515738877937
training  [-3.7467, -0.8937, 1.6851]  w:  [1.30612886 0.45285977 1.52600992]
-2.7269144423091487  -  12.1571  =  -14.884014442309148
training  [-3.6985, 4.8435, -3.665]  w:  [1.30612886 0.45285977 1.52600992]
-8.230117632469991  -  14.6793  =  -22.90941763246999
251032.51873357815
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.46152537 0.35095711 1.47167387]
11.67341834659144  -  87.3174  =  -75.64398165340856
training  [-4.1793, -4.9218, 1.7664]  w:  [1.46152537 0.35095711 1.47167387]
-5.235928971088925  -  1.5257  =  -6.761628971088925
training  [-3.9429, -0.7689, 4.883]  w:  [1.46152537 0.35095711 1.47167387]
1.1536841927908297  -  39.7859  =  -38.63221580720917
training  [-3.5796, 1.5557, 2.6683]  w:  [1.46152537 0.35095711 1.47167387]
-0.758824854203914  -  45.5674  =  -46.326224854203915
training  [-3.3354, 2.2292, -1.633]  w:  [1.46152537 0.35095711 1.47167387]
-6.495661553059151  -  13.3589  =  -19.85456155305915
training  [1.2096, 0.3121, 1.6238]  w:  [1.46152537 0.35095711 1.47167387]
4.267098829377094  -  74.5119  =  -70.2448011706229
training  [0.7371, -3.9118, -2.5583]  w:  [1.46152537 0.35095711 1.47167387]
-4.060566935814052  -  3.3358  =  -7.396366935814052
training  [-4.4792, 1.3177, -2.0449]  w:  [1.46152537 0.35095711 1.47167387]
-9.093434145025752  -  4.2974  =  -13.390834145025751
training  [4.312, -3.735, 1.8018]  w:  [1.46152537 0.35095711 1.47167387]
7.642934559793892  -  66.5833  =  -58.9403654402061
training  [2.2866, -3.657, 0.2785]  w:  [1.46152537 0.35095711 1.47167387]
2.468334926422504  -  26.0005  =  -23.532165073577495
training  [2.3784, -4.0141, -0.8841]  w:  [1.46152537 0.35095711 1.47167387]
0.7662081317561173  -  14.6809  =  -13.914691868243882
training  [-4.366, -3.5797, 1.0264]  w:  [1.46152537 0.35095711 1.47167387]
-6.126814880563973  -  1.8713  =  -7.998114880563973
training  [3.6044, -3.3175, 2.5052]  w:  [1.46152537 0.35095711 1.47167387]
7.790459200803337  -  71.0139  =  -63.223440799196666
training  [4.3441, -3.0375, 0.8353]  w:  [1.46152537 0.35095711 1.47167387]
6.512269316014542  -  63.8979  =  -57.385630683985454
training  [4.844, -1.8252, 0.5179]  w:  [1.46152537 0.35095711 1.47167387]
7.201241869283541  -  78.0461  =  -70.84485813071646
training  [3.5894, -1.8357, 0.8357]  w:  [1.46152537 0.35095711 1.47167387]
5.83162504546755  -  68.8838  =  -63.05217495453245
training  [2.8556, -2.8244, 0.1182]  w:  [1.46152537 0.35095711 1.47167387]
3.3562404321588097  -  39.5252  =  -36.168959567841185
training  [0.1338, -2.4896, -4.1741]  w:  [1.46152537 0.35095711 1.47167387]
-6.821104623565359  -  2.2644  =  -9.08550462356536
training  [-3.224, 3.9292, 2.1957]  w:  [1.46152537 0.35095711 1.47167387]
-0.10162279813446862  -  72.1211  =  -72.22272279813447
training  [-1.0141, 2.0322, 4.9616]  w:  [1.46152537 0.35095711 1.47167387]
6.53293922846862  -  92.3427  =  -85.80976077153137
training  [-3.6607, 0.5574, -1.4547]  w:  [1.46152537 0.35095711 1.47167387]
-7.295426404553929  -  5.8471  =  -13.14252640455393
training  [-4.6911, -3.1557, 4.7126]  w:  [1.46152537 0.35095711 1.47167387]
-1.0282667504000402  -  11.2337  =  -12.261966750400042
training  [4.3914, -2.8797, -1.5355]  w:  [1.46152537 0.35095711 1.47167387]
3.1477360917000237  -  37.475  =  -34.327263908299976
training  [-1.9869, -4.2265, 3.8654]  w:  [1.46152537 0.35095711 1.47167387]
1.301383179421439  -  15.7889  =  -14.487516820578561
training  [-2.0447, 4.138, -0.4531]  w:  [1.46152537 0.35095711 1.47167387]
-2.202935826044386  -  57.936  =  -60.13893582604439
training  [-1.6706, 2.0672, -0.8657]  w:  [1.46152537 0.35095711 1.47167387]
-2.9901538098548635  -  32.4185  =  -35.40865380985487
training  [-0.3293, 0.5779, -2.8227]  w:  [1.46152537 0.35095711 1.47167387]
-4.432556017124905  -  14.3434  =  -18.775956017124905
training  [1.482, -1.8657, -3.7435]  w:  [1.46152537 0.35095711 1.47167387]
-3.99801120991045  -  7.1519  =  -11.14991120991045
training  [-4.7477, -3.338, -1.9109]  w:  [1.46152537 0.35095711 1.47167387]
-10.922600433310713  -  0.4077  =  -11.330300433310713
training  [3.4221, 1.225, 2.261]  w:  [1.46152537 0.35095711 1.47167387]
8.758863046903361  -  95.0454  =  -86.28653695309664
training  [0.5903, 4.8793, 2.8287]  w:  [1.46152537 0.35095711 1.47167387]
6.738087331659717  -  97.4647  =  -90.72661266834028
training  [3.541, -3.2957, 1.9379]  w:  [1.46152537 0.35095711 1.47167387]
6.870568771982255  -  64.3732  =  -57.50263122801774
training  [-1.5212, -2.4221, -4.902]  w:  [1.46152537 0.35095711 1.47167387]
-10.287470914788978  -  0.7227  =  -11.010170914788977
training  [-0.5397, -1.032, 3.4321]  w:  [1.46152537 0.35095711 1.47167387]
3.8999589012672207  -  60.5921  =  -56.69214109873278
training  [-4.4576, -4.2601, 4.2233]  w:  [1.46152537 0.35095711 1.47167387]
-1.7946876342426767  -  6.0247  =  -7.819387634242677
training  [-3.2289, 1.841, 2.7095]  w:  [1.46152537 0.35095711 1.47167387]
-0.08550687955944936  -  54.0111  =  -54.096606879559445
training  [1.6281, -0.9761, -4.5734]  w:  [1.46152537 0.35095711 1.47167387]
-4.693613049955033  -  7.8658  =  -12.559413049955033
training  [-1.6917, 4.8284, -1.2181]  w:  [1.46152537 0.35095711 1.47167387]
-2.5705470895979285  -  61.2837  =  -63.85424708959793
training  [3.9849, -0.9782, 2.0434]  w:  [1.46152537 0.35095711 1.47167387]
8.487944583147573  -  88.3402  =  -79.85225541685242
training  [-3.8184, 1.2067, 2.2951]  w:  [1.46152537 0.35095711 1.47167387]
-1.779549832153445  -  34.1122  =  -35.891749832153444
training  [4.8842, -3.4563, -2.7572]  w:  [1.46152537 0.35095711 1.47167387]
1.8676699588637424  -  23.7819  =  -21.914230041136257
training  [0.3998, -1.1865, -2.3095]  w:  [1.46152537 0.35095711 1.47167387]
-3.2309235684028117  -  11.4246  =  -14.655523568402812
training  [2.0692, -3.3887, 1.7303]  w:  [1.46152537 0.35095711 1.47167387]
4.381337225739878  -  42.6881  =  -38.30676277426012
training  [4.9949, 2.5811, -0.2251]  w:  [1.46152537 0.35095711 1.47167387]
7.874754684702714  -  95.9901  =  -88.11534531529729
training  [-2.1215, 3.7111, 1.2372]  w:  [1.46152537 0.35095711 1.47167387]
0.022565773847298853  -  71.3692  =  -71.3466342261527
training  [-0.8548, -1.4922, -2.6356]  w:  [1.46152537 0.35095711 1.47167387]
-5.651753735262078  -  4.7821  =  -10.433853735262078
training  [-0.3516, 1.8554, -3.2288]  w:  [1.46152537 0.35095711 1.47167387]
-4.614447080588613  -  20.3834  =  -24.997847080588613
training  [2.6396, -2.0585, 3.2964]  w:  [1.46152537 0.35095711 1.47167387]
7.98662289167785  -  80.826  =  -72.83937710832214
training  [3.182, 0.3063, 2.6692]  w:  [1.46152537 0.35095711 1.47167387]
8.68626378001466  -  92.9483  =  -84.26203621998535
training  [-3.9978, 3.3242, 4.3448]  w:  [1.46152537 0.35095711 1.47167387]
1.7178941278480275  -  79.1768  =  -77.45890587215197
training  [-3.2188, 0.9749, -3.9211]  w:  [1.46152537 0.35095711 1.47167387]
-10.132790177690254  -  2.7053  =  -12.838090177690253
training  [-1.4037, -1.6469, -3.1777]  w:  [1.46152537 0.35095711 1.47167387]
-7.306072480037381  -  2.6234  =  -9.929472480037381
training  [-4.433, -2.0077, -4.009]  w:  [1.46152537 0.35095711 1.47167387]
-13.08349909638913  -  0.3253  =  -13.40879909638913
training  [0.2189, -0.4741, -0.1024]  w:  [1.46152537 0.35095711 1.47167387]
0.0028397328033117064  -  33.6531  =  -33.65026026719669
training  [-1.6415, -0.7735, -3.0675]  w:  [1.46152537 0.35095711 1.47167387]
-7.184918811483117  -  3.7641  =  -10.949018811483118
training  [-3.2433, -1.4039, 3.9589]  w:  [1.46152537 0.35095711 1.47167387]
0.5933357543411093  -  30.0658  =  -29.47246424565889
training  [-2.9105, 0.5832, -4.0091]  w:  [1.46152537 0.35095711 1.47167387]
-9.949179107091414  -  2.4887  =  -12.437879107091414
training  [4.0515, 2.4255, -4.5583]  w:  [1.46152537 0.35095711 1.47167387]
0.06428551855320119  -  61.2853  =  -61.2210144814468
training  [1.7539, -0.7567, 0.573]  w:  [1.46152537 0.35095711 1.47167387]
3.141069226812096  -  57.0797  =  -53.93863077318791
training  [-0.3153, -0.7064, 2.725]  w:  [1.46152537 0.35095711 1.47167387]
3.301576237741573  -  58.7004  =  -55.39882376225843
training  [4.1213, -3.7513, -1.8806]  w:  [1.46152537 0.35095711 1.47167387]
1.9392092188085446  -  22.1789  =  -20.239690781191456
training  [-3.9599, -4.7557, -3.2102]  w:  [1.46152537 0.35095711 1.47167387]
-12.180908500719607  -  0.1558  =  -12.336708500719606
training  [2.4555, -2.0981, -1.6104]  w:  [1.46152537 0.35095711 1.47167387]
0.4824488333060142  -  24.4796  =  -23.99715116669399
training  [2.3627, -1.8248, -2.8985]  w:  [1.46152537 0.35095711 1.47167387]
-1.4529272519600807  -  15.7052  =  -17.15812725196008
training  [0.6186, 1.5369, 0.1015]  w:  [1.46152537 0.35095711 1.47167387]
1.5928604765082937  -  65.2154  =  -63.62253952349171
training  [-3.1581, 4.5694, 4.0636]  w:  [1.46152537 0.35095711 1.47167387]
2.9683140849048755  -  90.3564  =  -87.38808591509512
training  [0.9721, 4.3573, 1.2892]  w:  [1.46152537 0.35095711 1.47167387]
4.847256185740153  -  94.3178  =  -89.47054381425986
training  [-2.0006, -0.4211, -3.9847]  w:  [1.46152537 0.35095711 1.47167387]
-8.935894557611164  -  2.4051  =  -11.340994557611165
training  [-3.6588, -2.5952, -1.0915]  w:  [1.46152537 0.35095711 1.47167387]
-7.864564947643331  -  1.5176  =  -9.38216494764333
training  [-2.874, 2.639, -4.4538]  w:  [1.46152537 0.35095711 1.47167387]
-9.828789170098942  -  5.497  =  -15.325789170098941
training  [3.9494, 2.5933, 0.0128]  w:  [1.46152537 0.35095711 1.47167387]
6.7011228001637555  -  94.1462  =  -87.44507719983623
training  [-4.2855, 2.4065, -0.6828]  w:  [1.46152537 0.35095711 1.47167387]
-6.42364760188571  -  14.4193  =  -20.84294760188571
training  [-2.5751, 2.4369, 4.9756]  w:  [1.46152537 0.35095711 1.47167387]
4.41413390285088  -  87.1991  =  -82.78496609714912
training  [-4.4625, -3.9408, 3.116]  w:  [1.46152537 0.35095711 1.47167387]
-3.3193729769772062  -  4.1344  =  -7.4537729769772065
training  [-0.5828, 1.8156, -0.1435]  w:  [1.46152537 0.35095711 1.47167387]
-0.4257644539030063  -  51.1166  =  -51.542364453903005
training  [-4.8672, -0.3674, 3.9445]  w:  [1.46152537 0.35095711 1.47167387]
-1.4374603517740283  -  24.1396  =  -25.57706035177403
training  [3.9719, -2.8784, -3.6245]  w:  [1.46152537 0.35095711 1.47167387]
-0.5392442673532045  -  14.6104  =  -15.149644267353205
training  [-3.0334, -4.0148, -1.1]  w:  [1.46152537 0.35095711 1.47167387]
-7.461254924710739  -  1.021  =  -8.48225492471074
training  [-4.0663, 3.2357, 4.2736]  w:  [1.46152537 0.35095711 1.47167387]
1.4819367561989507  -  77.2328  =  -75.75086324380105
training  [-1.9263, -3.2499, 4.1749]  w:  [1.46152537 0.35095711 1.47167387]
2.188179394277733  -  26.8814  =  -24.693220605722267
training  [-0.4394, -3.3643, 2.1357]  w:  [1.46152537 0.35095711 1.47167387]
1.3201346217573975  -  20.85  =  -19.529865378242604
training  [-3.9833, 1.6599, 1.1834]  w:  [1.46152537 0.35095711 1.47167387]
-3.497561441886911  -  25.5397  =  -29.037261441886912
training  [4.9539, 3.9439, -1.5671]  w:  [1.46152537 0.35095711 1.47167387]
6.318130165265394  -  95.9509  =  -89.6327698347346
training  [-1.6791, 0.1656, 4.3603]  w:  [1.46152537 0.35095711 1.47167387]
4.021010815784855  -  71.5733  =  -67.55228918421514
training  [-2.0265, 2.027, -3.7523]  w:  [1.46152537 0.35095711 1.47167387]
-7.772552952711827  -  8.503  =  -16.275552952711827
training  [-4.3795, -3.4641, 2.3059]  w:  [1.46152537 0.35095711 1.47167387]
-4.222968116692754  -  3.6654  =  -7.888368116692754
training  [-2.0176, 4.5346, 1.4648]  w:  [1.46152537 0.35095711 1.47167387]
0.7983844136394458  -  81.6212  =  -80.82281558636056
training  [-4.5365, 0.4088, 3.3315]  w:  [1.46152537 0.35095711 1.47167387]
-1.5838570829484198  -  28.9449  =  -30.52875708294842
training  [0.0543, 1.7973, -1.0172]  w:  [1.46152537 0.35095711 1.47167387]
-0.7868506142800076  -  47.9317  =  -48.718550614280005
training  [2.6143, -4.6344, 2.4982]  w:  [1.46152537 0.35095711 1.47167387]
5.870925794372697  -  43.5132  =  -37.6422742056273
training  [1.3107, 3.092, 3.3522]  w:  [1.46152537 0.35095711 1.47167387]
7.934125832646028  -  96.6993  =  -88.76517416735396
training  [-4.1011, 2.4862, -1.7754]  w:  [1.46152537 0.35095711 1.47167387]
-7.734121910134891  -  10.0187  =  -17.75282191013489
training  [-4.1914, -3.7981, 0.5226]  w:  [1.46152537 0.35095711 1.47167387]
-6.689710878874405  -  1.4295  =  -8.119210878874405
training  [2.7724, 0.2505, 4.7913]  w:  [1.46152537 0.35095711 1.47167387]
11.191078697098202  -  96.7925  =  -85.6014213029018
training  [4.0513, -1.7417, 0.4931]  w:  [1.46152537 0.35095711 1.47167387]
6.0354981152323  -  71.1234  =  -65.0879018847677
training  [0.3377, 0.4645, -1.6958]  w:  [1.46152537 0.35095711 1.47167387]
-1.839087849687254  -  27.9534  =  -29.79248784968725
training  [-3.9085, -1.0112, 1.1947]  w:  [1.46152537 0.35095711 1.47167387]
-4.309050970421423  -  8.608  =  -12.917050970421425
training  [3.2581, -0.8491, -1.3936]  w:  [1.46152537 0.35095711 1.47167387]
2.4128734224779254  -  50.1924  =  -47.77952657752208
training  [-1.619, -3.1926, 2.5651]  w:  [1.46152537 0.35095711 1.47167387]
0.2883153901306019  -  16.4754  =  -16.187084609869398
training  [-2.0603, -2.4461, -0.861]  w:  [1.46152537 0.35095711 1.47167387]
-5.136768111454981  -  3.9784  =  -9.115168111454981
training  [2.4631, -4.7946, -0.0765]  w:  [1.46152537 0.35095711 1.47167387]
1.8046011208612789  -  15.394  =  -13.589398879138722
training  [-4.8966, 4.2368, 1.9474]  w:  [1.46152537 0.35095711 1.47167387]
-2.8036323462144765  -  53.5883  =  -56.391932346214475
training  [-4.5155, 1.537, 4.7273]  w:  [1.46152537 0.35095711 1.47167387]
0.8969471483156592  -  59.2523  =  -58.35535285168434
training  [1.6792, 4.3261, -1.7225]  w:  [1.46152537 0.35095711 1.47167387]
1.4375107244915193  -  83.7729  =  -82.33538927550849
training  [1.0347, -3.3649, 3.378]  w:  [1.46152537 0.35095711 1.47167387]
5.3026190420460795  -  50.5979  =  -45.29528095795392
training  [0.261, 4.211, 2.3907]  w:  [1.46152537 0.35095711 1.47167387]
5.377669235303726  -  94.9375  =  -89.55983076469627
training  [2.2971, 2.9466, 4.5417]  w:  [1.46152537 0.35095711 1.47167387]
11.075301359891967  -  98.7784  =  -87.70309864010804
training  [2.0725, 0.7739, -4.6808]  w:  [1.46152537 0.35095711 1.47167387]
-3.5879940034903246  -  19.5109  =  -23.098894003490322
training  [2.8138, -0.5996, -1.4313]  w:  [1.46152537 0.35095711 1.47167387]
1.795599395034241  -  47.2879  =  -45.49230060496576
training  [-2.1202, -2.4239, 1.6265]  w:  [1.46152537 0.35095711 1.47167387]
-1.5557334862975924  -  12.3599  =  -13.915633486297592
training  [1.9253, 2.5195, -2.185]  w:  [1.46152537 0.35095711 1.47167387]
0.48250383617672554  -  65.2467  =  -64.76419616382327
training  [0.5667, -2.7133, -2.6962]  w:  [1.46152537 0.35095711 1.47167387]
-4.091932586992275  -  5.1106  =  -9.202532586992275
training  [-1.0348, -4.3581, 2.1113]  w:  [1.46152537 0.35095711 1.47167387]
0.06525239640783331  -  10.5192  =  -10.453947603592166
training  [-4.3841, 2.6733, 1.2457]  w:  [1.46152537 0.35095711 1.47167387]
-3.6359955913243525  -  32.4639  =  -36.099895591324355
training  [2.8018, 1.712, 0.9061]  w:  [1.46152537 0.35095711 1.47167387]
6.029224049234792  -  90.1138  =  -84.0845759507652
training  [-1.6242, 2.1521, 1.6044]  w:  [1.46152537 0.35095711 1.47167387]
0.7426388477483459  -  63.7879  =  -63.045261152251655
training  [1.0787, 1.4206, -4.5245]  w:  [1.46152537 0.35095711 1.47167387]
-4.58347132668622  -  18.0555  =  -22.638971326686217
training  [2.4125, -0.8095, -1.5122]  w:  [1.46152537 0.35095711 1.47167387]
1.0163649503126115  -  38.8276  =  -37.81123504968738
training  [-3.9519, -1.0924, -0.4866]  w:  [1.46152537 0.35095711 1.47167387]
-6.875304163426573  -  3.6777  =  -10.553004163426573
training  [-3.7211, 3.1614, -2.591]  w:  [1.46152537 0.35095711 1.47167387]
-8.14207323451754  -  11.1518  =  -19.29387323451754
training  [0.4954, -1.8257, 2.1505]  w:  [1.46152537 0.35095711 1.47167387]
3.248131923041498  -  47.7531  =  -44.504968076958505
training  [-0.1477, 3.1454, 3.5618]  w:  [1.46152537 0.35095711 1.47167387]
6.1298411852903625  -  94.1572  =  -88.02735881470964
training  [3.9048, 2.8907, -2.1849]  w:  [1.46152537 0.35095711 1.47167387]
3.506015753687843  -  85.8791  =  -82.37308424631215
training  [2.9896, 3.5226, 2.3105]  w:  [1.46152537 0.35095711 1.47167387]
9.005960240502816  -  98.038  =  -89.03203975949718
training  [2.3434, 0.0564, -3.6224]  w:  [1.46152537 0.35095711 1.47167387]
-1.8862588862979144  -  24.7629  =  -26.64915888629791
training  [-4.4867, 1.3566, 3.3672]  w:  [1.46152537 0.35095711 1.47167387]
-1.1258972119974135  -  40.5785  =  -41.70439721199741
training  [-4.2711, 4.5089, -3.614]  w:  [1.46152537 0.35095711 1.47167387]
-9.978519847255917  -  10.0825  =  -20.061019847255917
training  [-4.1147, -0.5604, 0.8821]  w:  [1.46152537 0.35095711 1.47167387]
-4.9122512869954  -  8.344  =  -13.2562512869954
training  [2.9835, -4.3998, -1.3384]  w:  [1.46152537 0.35095711 1.47167387]
0.8466315370024735  -  13.2692  =  -12.422568462997527
training  [4.4301, 3.6675, 3.0676]  w:  [1.46152537 0.35095711 1.47167387]
12.276345507286058  -  99.3834  =  -87.10705449271394
training  [1.8372, 1.3119, 0.0378]  w:  [1.46152537 0.35095711 1.47167387]
3.201164317093308  -  74.9026  =  -71.7014356829067
training  [-3.6792, -1.4493, -0.1041]  w:  [1.46152537 0.35095711 1.47167387]
-6.039087533569522  -  4.2442  =  -10.283287533569522
training  [2.2272, 4.97, 3.7705]  w:  [1.46152537 0.35095711 1.47167387]
10.548312469137606  -  99.3199  =  -88.7715875308624
training  [-3.8965, -2.7583, -1.4686]  w:  [1.46152537 0.35095711 1.47167387]
-8.824178848715201  -  1.0337  =  -9.8578788487152
training  [-3.8251, 1.5245, -0.5056]  w:  [1.46152537 0.35095711 1.47167387]
-5.799524884499069  -  12.9762  =  -18.77572488449907
training  [1.4072, 1.0499, 4.6353]  w:  [1.46152537 0.35095711 1.47167387]
9.246778253350882  -  95.4618  =  -86.21502174664911
training  [-1.7119, -1.1275, -4.577]  w:  [1.46152537 0.35095711 1.47167387]
-9.633540718998628  -  1.4655  =  -11.099040718998628
training  [1.5381, -3.5781, 4.7296]  w:  [1.46152537 0.35095711 1.47167387]
7.9526412573457055  -  69.9473  =  -61.994658742654295
training  [2.4913, -4.7487, -3.1079]  w:  [1.46152537 0.35095711 1.47167387]
-2.599307096098821  -  3.9825  =  -6.581807096098821
training  [0.8319, -0.7889, 1.6712]  w:  [1.46152537 0.35095711 1.47167387]
3.3984342584785923  -  58.8336  =  -55.4351657415214
training  [2.4003, -3.159, 0.8644]  w:  [1.46152537 0.35095711 1.47167387]
3.671540721947685  -  39.0041  =  -35.332559278052315
training  [-2.6517, 2.2578, 1.7511]  w:  [1.46152537 0.35095711 1.47167387]
-0.5060877469605245  -  54.4525  =  -54.958587746960525
training  [2.3496, -1.2964, -1.3898]  w:  [1.46152537 0.35095711 1.47167387]
0.9336868683227113  -  33.888  =  -32.95431313167729
training  [4.706, 3.4156, 1.2028]  w:  [1.46152537 0.35095711 1.47167387]
9.846796831221276  -  98.4665  =  -88.61970316877873
training  [3.6693, 2.3423, 3.1115]  w:  [1.46152537 0.35095711 1.47167387]
10.763935124099266  -  98.3069  =  -87.54296487590074
training  [-4.1377, 0.7103, -4.8074]  w:  [1.46152537 0.35095711 1.47167387]
-12.872993641411657  -  0.9782  =  -13.851193641411657
training  [-1.3356, -3.2314, -4.1613]  w:  [1.46152537 0.35095711 1.47167387]
-9.210172562425182  -  0.7659  =  -9.976072562425182
training  [-1.308, 4.5738, 4.748]  w:  [1.46152537 0.35095711 1.47167387]
6.681039978915869  -  97.0884  =  -90.40736002108412
training  [1.8503, -2.3468, 1.5135]  w:  [1.46152537 0.35095711 1.47167387]
4.108012642228207  -  50.2125  =  -46.10448735777179
training  [0.9794, 4.2458, -2.6876]  w:  [1.46152537 0.35095711 1.47167387]
-1.0337590357530932  -  68.3262  =  -69.35995903575309
training  [2.8936, -2.7623, -0.9651]  w:  [1.46152537 0.35095711 1.47167387]
1.8393085315231592  -  28.5596  =  -26.72029146847684
training  [-1.3235, -1.2644, -3.7798]  w:  [1.46152537 0.35095711 1.47167387]
-7.940711886137762  -  2.4511  =  -10.391811886137761
training  [-2.9397, -4.125, -2.3156]  w:  [1.46152537 0.35095711 1.47167387]
-9.151952225317313  -  0.554  =  -9.705952225317313
training  [-4.1333, 1.4012, -2.4215]  w:  [1.46152537 0.35095711 1.47167387]
-9.112819979390821  -  4.4072  =  -13.52001997939082
training  [2.7193, -3.1938, -1.6833]  w:  [1.46152537 0.35095711 1.47167387]
0.3761704937372006  -  17.0949  =  -16.718729506262797
training  [-2.9433, -4.5495, -3.4777]  w:  [1.46152537 0.35095711 1.47167387]
-11.016427212690536  -  0.2509  =  -11.267327212690535
training  [-1.1173, 2.2317, -1.5199]  w:  [1.46152537 0.35095711 1.47167387]
-3.08652842219055  -  33.1206  =  -36.20712842219055
training  [0.5178, -1.5256, -3.7834]  w:  [1.46152537 0.35095711 1.47167387]
-5.346573245506926  -  5.237  =  -10.583573245506926
training  [-2.7105, 1.6062, 3.8415]  w:  [1.46152537 0.35095711 1.47167387]
2.2556779612417244  -  70.4458  =  -68.19012203875828
training  [1.4194, -1.1613, -4.0572]  w:  [1.46152537 0.35095711 1.47167387]
-4.303952601065968  -  8.3206  =  -12.624552601065968
training  [-0.1552, 1.2735, 4.3004]  w:  [1.46152537 0.35095711 1.47167387]
6.5489014467070215  -  90.1085  =  -83.55959855329299
training  [-3.4815, -4.7835, -1.0098]  w:  [1.46152537 0.35095711 1.47167387]
-8.25320019191257  -  0.5839  =  -8.83710019191257
training  [2.8193, 4.1057, -4.526]  w:  [1.46152537 0.35095711 1.47167387]
-1.099392837649134  -  66.8081  =  -67.90749283764913
training  [-3.9939, 3.0056, -1.5763]  w:  [1.46152537 0.35095711 1.47167387]
-7.102148999516023  -  14.4018  =  -21.503948999516023
training  [-2.0593, 2.4585, 2.3597]  w:  [1.46152537 0.35095711 1.47167387]
1.325817690783869  -  70.6698  =  -69.34398230921613
training  [-2.6263, 3.1311, 2.9468]  w:  [1.46152537 0.35095711 1.47167387]
1.5972062871610797  -  77.309  =  -75.71179371283891
training  [0.3087, -1.1669, 0.4491]  w:  [1.46152537 0.35095711 1.47167387]
0.7025697623623373  -  33.0798  =  -32.37723023763766
training  [-4.085, 1.1728, 1.8622]  w:  [1.46152537 0.35095711 1.47167387]
-2.8181775594393637  -  26.4056  =  -29.223777559439363
training  [-0.9468, 0.7549, 3.9363]  w:  [1.46152537 0.35095711 1.47167387]
4.674115150183534  -  79.7738  =  -75.09968484981646
training  [-3.9515, 0.3005, -4.4521]  w:  [1.46152537 0.35095711 1.47167387]
-12.221794116494825  -  1.0441  =  -13.265894116494826
training  [-3.8772, -2.2493, -1.9634]  w:  [1.46152537 0.35095711 1.47167387]
-9.345518469186327  -  1.0509  =  -10.396418469186328
training  [2.8443, -2.5137, -4.5381]  w:  [1.46152537 0.35095711 1.47167387]
-3.4037874620690167  -  6.8897  =  -10.293487462069017
training  [-2.0843, -0.4836, -3.0452]  w:  [1.46152537 0.35095711 1.47167387]
-7.697521451473476  -  3.5346  =  -11.232121451473477
training  [1.0353, -2.7229, 2.2017]  w:  [1.46152537 0.35095711 1.47167387]
3.797680451877312  -  43.9562  =  -40.15851954812269
training  [4.6442, 3.0445, 2.2175]  w:  [1.46152537 0.35095711 1.47167387]
11.119541853192885  -  98.8492  =  -87.72965814680711
training  [-0.6752, 4.861, 3.778]  w:  [1.46152537 0.35095711 1.47167387]
6.279164463556687  -  97.017  =  -90.73783553644331
training  [1.9475, -4.7001, 0.8243]  w:  [1.46152537 0.35095711 1.47167387]
2.4098879074496153  -  18.7839  =  -16.374012092550384
training  [2.581, 0.3566, -4.2932]  w:  [1.46152537 0.35095711 1.47167387]
-2.4208419641602816  -  23.5455  =  -25.966341964160282
training  [-0.6736, -4.1292, 4.2274]  w:  [1.46152537 0.35095711 1.47167387]
3.787698515307762  -  31.2667  =  -27.479001484692237
training  [1.555, 3.0209, 3.0037]  w:  [1.46152537 0.35095711 1.47167387]
7.753345086903075  -  96.4078  =  -88.65445491309691
training  [-3.9024, 4.8914, -2.1405]  w:  [1.46152537 0.35095711 1.47167387]
-7.136902903384844  -  25.4308  =  -32.56770290338485
training  [4.3376, -4.3305, 0.4366]  w:  [1.46152537 0.35095711 1.47167387]
5.462225484522002  -  43.0907  =  -37.628474515478
training  [-3.1254, 4.394, 4.8478]  w:  [1.46152537 0.35095711 1.47167387]
4.10863473450714  -  92.8121  =  -88.70346526549287
training  [-2.3382, -4.8182, 2.1568]  w:  [1.46152537 0.35095711 1.47167387]
-1.9342139771614755  -  4.7434  =  -6.677613977161476
training  [2.9783, 1.8384, 3.3897]  w:  [1.46152537 0.35095711 1.47167387]
9.986593474852134  -  97.3486  =  -87.36200652514788
training  [-0.124, 2.8374, -0.6674]  w:  [1.46152537 0.35095711 1.47167387]
-0.16761857688543036  -  62.785  =  -62.95261857688543
training  [2.6896, 0.3414, -0.2938]  w:  [1.46152537 0.35095711 1.47167387]
3.6183576111105014  -  70.4455  =  -66.8271423888895
training  [-1.0399, 3.8536, 0.6071]  w:  [1.46152537 0.35095711 1.47167387]
0.7260612983451518  -  77.0369  =  -76.31083870165484
training  [-2.2706, 3.99, -2.3091]  w:  [1.46152537 0.35095711 1.47167387]
-5.31646275892732  -  31.1134  =  -36.42986275892732
training  [-4.6277, 1.2594, 2.4902]  w:  [1.46152537 0.35095711 1.47167387]
-2.656743302788662  -  28.1093  =  -30.766043302788663
training  [1.7329, -3.6213, 0.0389]  w:  [1.46152537 0.35095711 1.47167387]
1.3190044390357014  -  19.3919  =  -18.072895560964298
training  [-0.7044, -2.822, 1.4681]  w:  [1.46152537 0.35095711 1.47167387]
0.140664965949576  -  17.8122  =  -17.671535034050425
training  [-0.4826, -3.1786, -1.9225]  w:  [1.46152537 0.35095711 1.47167387]
-4.650177430212224  -  3.5851  =  -8.235277430212225
training  [1.0986, -4.5818, -3.6128]  w:  [1.46152537 0.35095711 1.47167387]
-5.3192468732338405  -  1.7158  =  -7.03504687323384
training  [-4.406, -3.9306, -0.2443]  w:  [1.46152537 0.35095711 1.47167387]
-8.178482730072309  -  0.8241  =  -9.002582730072309
training  [-1.8419, 1.1644, -1.3754]  w:  [1.46152537 0.35095711 1.47167387]
-4.307469356748552  -  17.8517  =  -22.159169356748553
training  [2.7272, 4.3966, 2.8811]  w:  [1.46152537 0.35095711 1.47167387]
9.768929608100777  -  98.904  =  -89.13507039189922
training  [1.9643, -1.4554, 2.803]  w:  [1.46152537 0.35095711 1.47167387]
6.485193156698824  -  76.0591  =  -69.57390684330117
training  [-3.7467, -0.8937, 1.6851]  w:  [1.46152537 0.35095711 1.47167387]
-3.3096298399796606  -  12.1571  =  -15.46672983997966
training  [-3.6985, 4.8435, -3.665]  w:  [1.46152537 0.35095711 1.47167387]
-9.099275538004017  -  14.6793  =  -23.778575538004016
251912.17068801788
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.59325525 0.44502223 1.47438418]
11.892096170737943  -  87.3174  =  -75.42530382926206
training  [-4.1793, -4.9218, 1.7664]  w:  [1.59325525 0.44502223 1.47438418]
-6.244649825059771  -  1.5257  =  -7.770349825059771
training  [-3.9429, -0.7689, 4.883]  w:  [1.59325525 0.44502223 1.47438418]
0.5751942570830213  -  39.7859  =  -39.21070574291698
training  [-3.5796, 1.5557, 2.6683]  w:  [1.59325525 0.44502223 1.47438418]
-1.0767960955995197  -  45.5674  =  -46.64419609559952
training  [-3.3354, 2.2292, -1.633]  w:  [1.59325525 0.44502223 1.47438418]
-6.729769379176675  -  13.3589  =  -20.088669379176675
training  [1.2096, 0.3121, 1.6238]  w:  [1.59325525 0.44502223 1.47438418]
4.460198019590807  -  74.5119  =  -70.05170198040919
training  [0.7371, -3.9118, -2.5583]  w:  [1.59325525 0.44502223 1.47438418]
-4.338366550883348  -  3.3358  =  -7.674166550883348
training  [-4.4792, 1.3177, -2.0449]  w:  [1.59325525 0.44502223 1.47438418]
-9.565071334561482  -  4.2974  =  -13.862471334561482
training  [4.312, -3.735, 1.8018]  w:  [1.59325525 0.44502223 1.47438418]
7.864504037593181  -  66.5833  =  -58.718795962406816
training  [2.2866, -3.657, 0.2785]  w:  [1.59325525 0.44502223 1.47438418]
2.4263071671817147  -  26.0005  =  -23.574192832818284
training  [2.3784, -4.0141, -0.8841]  w:  [1.59325525 0.44502223 1.47438418]
0.6995315118924523  -  14.6809  =  -13.981368488107547
training  [-4.366, -3.5797, 1.0264]  w:  [1.59325525 0.44502223 1.47438418]
-7.035890546457186  -  1.8713  =  -8.907190546457187
training  [3.6044, -3.3175, 2.5052]  w:  [1.59325525 0.44502223 1.47438418]
7.959995237118356  -  71.0139  =  -63.05390476288165
training  [4.3441, -3.0375, 0.8353]  w:  [1.59325525 0.44502223 1.47438418]
6.801058220792163  -  63.8979  =  -57.096841779207836
training  [4.844, -1.8252, 0.5179]  w:  [1.59325525 0.44502223 1.47438418]
7.669057423205392  -  78.0461  =  -70.37704257679461
training  [3.5894, -1.8357, 0.8357]  w:  [1.59325525 0.44502223 1.47438418]
6.134045949089645  -  68.8838  =  -62.74975405091035
training  [2.8556, -2.8244, 0.1182]  w:  [1.59325525 0.44502223 1.47438418]
3.4670511233931003  -  39.5252  =  -36.0581488766069
training  [0.1338, -2.4896, -4.1741]  w:  [1.59325525 0.44502223 1.47438418]
-7.048976795227933  -  2.2644  =  -9.313376795227933
training  [-3.224, 3.9292, 2.1957]  w:  [1.59325525 0.44502223 1.47438418]
-0.15076824273917389  -  72.1211  =  -72.27186824273917
training  [-1.0141, 2.0322, 4.9616]  w:  [1.59325525 0.44502223 1.47438418]
6.603958578432076  -  92.3427  =  -85.73874142156792
training  [-3.6607, 0.5574, -1.4547]  w:  [1.59325525 0.44502223 1.47438418]
-7.729160767535689  -  5.8471  =  -13.57626076753569
training  [-4.6911, -3.1557, 4.7126]  w:  [1.59325525 0.44502223 1.47438418]
-1.930293430942923  -  11.2337  =  -13.163993430942924
training  [4.3914, -2.8797, -1.5355]  w:  [1.59325525 0.44502223 1.47438418]
3.4511736815272984  -  37.475  =  -34.0238263184727
training  [-1.9869, -4.2265, 3.8654]  w:  [1.59325525 0.44502223 1.47438418]
0.6525593322287584  -  15.7889  =  -15.136340667771242
training  [-2.0447, 4.138, -0.4531]  w:  [1.59325525 0.44502223 1.47438418]
-2.084270510694403  -  57.936  =  -60.0202705106944
training  [-1.6706, 2.0672, -0.8657]  w:  [1.59325525 0.44502223 1.47438418]
-3.0181166599269837  -  32.4185  =  -35.43661665992698
training  [-0.3293, 0.5779, -2.8227]  w:  [1.59325525 0.44502223 1.47438418]
-4.429224840841527  -  14.3434  =  -18.772624840841527
training  [1.482, -1.8657, -3.7435]  w:  [1.59325525 0.44502223 1.47438418]
-3.9884308749237265  -  7.1519  =  -11.140330874923727
training  [-4.7477, -3.338, -1.9109]  w:  [1.59325525 0.44502223 1.47438418]
-11.867182861673335  -  0.4077  =  -12.274882861673335
training  [3.4221, 1.225, 2.261]  w:  [1.59325525 0.44502223 1.47438418]
9.331013645729179  -  95.0454  =  -85.71438635427083
training  [0.5903, 4.8793, 2.8287]  w:  [1.59325525 0.44502223 1.47438418]
7.282486052566724  -  97.4647  =  -90.18221394743327
training  [3.541, -3.2957, 1.9379]  w:  [1.59325525 0.44502223 1.47438418]
7.032266192244112  -  64.3732  =  -57.34093380775589
training  [-1.5212, -2.4221, -4.902]  w:  [1.59325525 0.44502223 1.47438418]
-10.728979476537067  -  0.7227  =  -11.451679476537066
training  [-0.5397, -1.032, 3.4321]  w:  [1.59325525 0.44502223 1.47438418]
3.7410911588052023  -  60.5921  =  -56.8510088411948
training  [-4.4576, -4.2601, 4.2233]  w:  [1.59325525 0.44502223 1.47438418]
-2.7711670564480597  -  6.0247  =  -8.79586705644806
training  [-3.2289, 1.841, 2.7095]  w:  [1.59325525 0.44502223 1.47438418]
-0.33033201104633436  -  54.0111  =  -54.34143201104634
training  [1.6281, -0.9761, -4.5734]  w:  [1.59325525 0.44502223 1.47438418]
-4.583355944712233  -  7.8658  =  -12.449155944712233
training  [-1.6917, 4.8284, -1.2181]  w:  [1.59325525 0.44502223 1.47438418]
-2.3425119635165066  -  61.2837  =  -63.62621196351651
training  [3.9849, -0.9782, 2.0434]  w:  [1.59325525 0.44502223 1.47438418]
8.926398734719992  -  88.3402  =  -79.41380126528
training  [-3.8184, 1.2067, 2.2951]  w:  [1.59325525 0.44502223 1.47438418]
-2.162818382215671  -  34.1122  =  -36.27501838221567
training  [4.8842, -3.4563, -2.7572]  w:  [1.59325525 0.44502223 1.47438418]
2.178474897019953  -  23.7819  =  -21.603425102980047
training  [0.3998, -1.1865, -2.3095]  w:  [1.59325525 0.44502223 1.47438418]
-3.296125691262519  -  11.4246  =  -14.720725691262519
training  [2.0692, -3.3887, 1.7303]  w:  [1.59325525 0.44502223 1.47438418]
4.339843895300994  -  42.6881  =  -38.348256104699004
training  [4.9949, 2.5811, -0.2251]  w:  [1.59325525 0.44502223 1.47438418]
8.774913623151665  -  95.9901  =  -87.21518637684834
training  [-2.1215, 3.7111, 1.2372]  w:  [1.59325525 0.44502223 1.47438418]
0.09553908186199433  -  71.3692  =  -71.273660918138
training  [-0.8548, -1.4922, -2.6356]  w:  [1.59325525 0.44502223 1.47438418]
-5.911863701276284  -  4.7821  =  -10.693963701276283
training  [-0.3516, 1.8554, -3.2288]  w:  [1.59325525 0.44502223 1.47438418]
-4.494985956740099  -  20.3834  =  -24.8783859567401
training  [2.6396, -2.0585, 3.2964]  w:  [1.59325525 0.44502223 1.47438418]
8.149638320560287  -  80.826  =  -72.67636167943971
training  [3.182, 0.3063, 2.6692]  w:  [1.59325525 0.44502223 1.47438418]
9.141474765757351  -  92.9483  =  -83.80682523424265
training  [-3.9978, 3.3242, 4.3448]  w:  [1.59325525 0.44502223 1.47438418]
1.5157314466723957  -  79.1768  =  -77.66106855332761
training  [-3.2188, 0.9749, -3.9211]  w:  [1.59325525 0.44502223 1.47438418]
-10.475725641982258  -  2.7053  =  -13.181025641982258
training  [-1.4037, -1.6469, -3.1777]  w:  [1.59325525 0.44502223 1.47438418]
-7.654510110305642  -  2.6234  =  -10.277910110305642
training  [-4.433, -2.0077, -4.009]  w:  [1.59325525 0.44502223 1.47438418]
-13.867177822174561  -  0.3253  =  -14.192477822174562
training  [0.2189, -0.4741, -0.1024]  w:  [1.59325525 0.44502223 1.47438418]
-0.013198403460422559  -  33.6531  =  -33.666298403460424
training  [-1.6415, -0.7735, -3.0675]  w:  [1.59325525 0.44502223 1.47438418]
-7.482226659914147  -  3.7641  =  -11.246326659914146
training  [-3.2433, -1.4039, 3.9589]  w:  [1.59325525 0.44502223 1.47438418]
0.044768092557104566  -  30.0658  =  -30.021031907442897
training  [-2.9105, 0.5832, -4.0091]  w:  [1.59325525 0.44502223 1.47438418]
-10.288586062710838  -  2.4887  =  -12.777286062710838
training  [4.0515, 2.4255, -4.5583]  w:  [1.59325525 0.44502223 1.47438418]
0.8137896249938175  -  61.2853  =  -60.47151037500618
training  [1.7539, -0.7567, 0.573]  w:  [1.59325525 0.44502223 1.47438418]
3.302484197910454  -  57.0797  =  -53.77721580208955
training  [-0.3153, -0.7064, 2.725]  w:  [1.59325525 0.44502223 1.47438418]
3.200979817548352  -  58.7004  =  -55.49942018245165
training  [4.1213, -3.7513, -1.8806]  w:  [1.59325525 0.44502223 1.47438418]
2.1241440863294483  -  22.1789  =  -20.05475591367055
training  [-3.9599, -4.7557, -3.2102]  w:  [1.59325525 0.44502223 1.47438418]
-13.158591754179387  -  0.1558  =  -13.314391754179386
training  [2.4555, -2.0981, -1.6104]  w:  [1.59325525 0.44502223 1.47438418]
0.6041888431678228  -  24.4796  =  -23.87541115683218
training  [2.3627, -1.8248, -2.8985]  w:  [1.59325525 0.44502223 1.47438418]
-1.3211949350406025  -  15.7052  =  -17.026394935040603
training  [0.6186, 1.5369, 0.1015]  w:  [1.59325525 0.44502223 1.47438418]
1.8191923486083412  -  65.2154  =  -63.39620765139166
training  [-3.1581, 4.5694, 4.0636]  w:  [1.59325525 0.44502223 1.47438418]
2.9931327209041765  -  90.3564  =  -87.36326727909582
training  [0.9721, 4.3573, 1.2892]  w:  [1.59325525 0.44502223 1.47438418]
5.388674855879394  -  94.3178  =  -88.9291251441206
training  [-2.0006, -0.4211, -3.9847]  w:  [1.59325525 0.44502223 1.47438418]
-9.24984395936119  -  2.4051  =  -11.65494395936119
training  [-3.6588, -2.5952, -1.0915]  w:  [1.59325525 0.44502223 1.47438418]
-8.593614314448251  -  1.5176  =  -10.111214314448251
training  [-2.874, 2.639, -4.4538]  w:  [1.59325525 0.44502223 1.47438418]
-9.9712142016634  -  5.497  =  -15.4682142016634
training  [3.9494, 2.5933, 0.0128]  w:  [1.59325525 0.44502223 1.47438418]
7.4653505296925164  -  94.1462  =  -86.68084947030748
training  [-4.2855, 2.4065, -0.6828]  w:  [1.59325525 0.44502223 1.47438418]
-6.763658899508917  -  14.4193  =  -21.182958899508918
training  [-2.5751, 2.4369, 4.9756]  w:  [1.59325525 0.44502223 1.47438418]
4.317629009645593  -  87.1991  =  -82.88147099035442
training  [-4.4625, -3.9408, 3.116]  w:  [1.59325525 0.44502223 1.47438418]
-4.269464015841128  -  4.1344  =  -8.403864015841128
training  [-0.5828, 1.8156, -0.1435]  w:  [1.59325525 0.44502223 1.47438418]
-0.3321409366667135  -  51.1166  =  -51.44874093666671
training  [-4.8672, -0.3674, 3.9445]  w:  [1.59325525 0.44502223 1.47438418]
-2.1024847002634903  -  24.1396  =  -26.24208470026349
training  [3.9719, -2.8784, -3.6245]  w:  [1.59325525 0.44502223 1.47438418]
-0.2966069230545356  -  14.6104  =  -14.907006923054535
training  [-3.0334, -4.0148, -1.1]  w:  [1.59325525 0.44502223 1.47438418]
-8.24147829879842  -  1.021  =  -9.26247829879842
training  [-4.0663, 3.2357, 4.2736]  w:  [1.59325525 0.44502223 1.47438418]
1.262232841486961  -  77.2328  =  -75.97056715851303
training  [-1.9263, -3.2499, 4.1749]  w:  [1.59325525 0.44502223 1.47438418]
1.640041209753182  -  26.8814  =  -25.241358790246817
training  [-0.4394, -3.3643, 2.1357]  w:  [1.59325525 0.44502223 1.47438418]
0.9515776704525525  -  20.85  =  -19.89842232954745
training  [-3.9833, 1.6599, 1.1834]  w:  [1.59325525 0.44502223 1.47438418]
-3.8629349957183647  -  25.5397  =  -29.402634995718365
training  [4.9539, 3.9439, -1.5671]  w:  [1.59325525 0.44502223 1.47438418]
7.337442873622689  -  95.9509  =  -88.61345712637731
training  [-1.6791, 0.1656, 4.3603]  w:  [1.59325525 0.44502223 1.47438418]
3.8272181443425195  -  71.5733  =  -67.74608185565748
training  [-2.0265, 2.027, -3.7523]  w:  [1.59325525 0.44502223 1.47438418]
-7.859003476964775  -  8.503  =  -16.362003476964773
training  [-4.3795, -3.4641, 2.3059]  w:  [1.59325525 0.44502223 1.47438418]
-5.119480361709703  -  3.6654  =  -8.784880361709703
training  [-2.0176, 4.5346, 1.4648]  w:  [1.59325525 0.44502223 1.47438418]
0.9631239444126964  -  81.6212  =  -80.6580760555873
training  [-4.5365, 0.4088, 3.3315]  w:  [1.59325525 0.44502223 1.47438418]
-2.133966442472947  -  28.9449  =  -31.078866442472947
training  [0.0543, 1.7973, -1.0172]  w:  [1.59325525 0.44502223 1.47438418]
-0.6133913851546214  -  47.9317  =  -48.54509138515462
training  [2.6143, -4.6344, 2.4982]  w:  [1.59325525 0.44502223 1.47438418]
5.786142758707991  -  43.5132  =  -37.72705724129201
training  [1.3107, 3.092, 3.3522]  w:  [1.59325525 0.44502223 1.47438418]
8.406719029612962  -  96.6993  =  -88.29258097038704
training  [-4.1011, 2.4862, -1.7754]  w:  [1.59325525 0.44502223 1.47438418]
-8.045306518148259  -  10.0187  =  -18.06400651814826
training  [-4.1914, -3.7981, 0.5226]  w:  [1.59325525 0.44502223 1.47438418]
-7.597695785243262  -  1.4295  =  -9.027195785243261
training  [2.7724, 0.2505, 4.7913]  w:  [1.59325525 0.44502223 1.47438418]
11.592835849539018  -  96.7925  =  -85.19966415046099
training  [4.0513, -1.7417, 0.4931]  w:  [1.59325525 0.44502223 1.47438418]
6.406678616332669  -  71.1234  =  -64.71672138366733
training  [0.3377, 0.4645, -1.6958]  w:  [1.59325525 0.44502223 1.47438418]
-1.7555055757384839  -  27.9534  =  -29.708905575738484
training  [-3.9085, -1.0112, 1.1947]  w:  [1.59325525 0.44502223 1.47438418]
-4.915797827450561  -  8.608  =  -13.523797827450561
training  [3.2581, -0.8491, -1.3936]  w:  [1.59325525 0.44502223 1.47438418]
2.758414754991412  -  50.1924  =  -47.433985245008586
training  [-1.619, -3.1926, 2.5651]  w:  [1.59325525 0.44502223 1.47438418]
-0.21831533590417918  -  16.4754  =  -16.69371533590418
training  [-2.0603, -2.4461, -0.861]  w:  [1.59325525 0.44502223 1.47438418]
-5.640597433000043  -  3.9784  =  -9.618997433000043
training  [2.4631, -4.7946, -0.0765]  w:  [1.59325525 0.44502223 1.47438418]
1.6778530503717182  -  15.394  =  -13.716146949628282
training  [-4.8966, 4.2368, 1.9474]  w:  [1.59325525 0.44502223 1.47438418]
-3.044847726283055  -  53.5883  =  -56.63314772628305
training  [-4.5155, 1.537, 4.7273]  w:  [1.59325525 0.44502223 1.47438418]
0.45951143389747795  -  59.2523  =  -58.79278856610252
training  [1.6792, 4.3261, -1.7225]  w:  [1.59325525 0.44502223 1.47438418]
2.0609781060838994  -  83.7729  =  -81.71192189391611
training  [1.0347, -3.3649, 3.378]  w:  [1.59325525 0.44502223 1.47438418]
5.131555687713464  -  50.5979  =  -45.46634431228654
training  [0.261, 4.211, 2.3907]  w:  [1.59325525 0.44502223 1.47438418]
5.81463847452164  -  94.9375  =  -89.12286152547836
training  [2.2971, 2.9466, 4.5417]  w:  [1.59325525 0.44502223 1.47438418]
11.667379759483545  -  98.7784  =  -87.11102024051647
training  [2.0725, 0.7739, -4.6808]  w:  [1.59325525 0.44502223 1.47438418]
-3.254873279801566  -  19.5109  =  -22.765773279801564
training  [2.8138, -0.5996, -1.4313]  w:  [1.59325525 0.44502223 1.47438418]
2.1059802098772002  -  47.2879  =  -45.1819197901228
training  [-2.1202, -2.4239, 1.6265]  w:  [1.59325525 0.44502223 1.47438418]
-2.0586232752503264  -  12.3599  =  -14.418523275250326
training  [1.9253, 2.5195, -2.185]  w:  [1.59325525 0.44502223 1.47438418]
0.9671983863069085  -  65.2467  =  -64.2795016136931
training  [0.5667, -2.7133, -2.6962]  w:  [1.59325525 0.44502223 1.47438418]
-4.279815687051846  -  5.1106  =  -9.390415687051846
training  [-1.0348, -4.3581, 2.1113]  w:  [1.59325525 0.44502223 1.47438418]
-0.4752845654789004  -  10.5192  =  -10.9944845654789
training  [-4.3841, 2.6733, 1.2457]  w:  [1.59325525 0.44502223 1.47438418]
-3.9586720415406864  -  32.4639  =  -36.42257204154069
training  [2.8018, 1.712, 0.9061]  w:  [1.59325525 0.44502223 1.47438418]
6.561800110420849  -  90.1138  =  -83.55199988957915
training  [-1.6242, 2.1521, 1.6044]  w:  [1.59325525 0.44502223 1.47438418]
0.7354691394077699  -  63.7879  =  -63.05243086059223
training  [1.0787, 1.4206, -4.5245]  w:  [1.59325525 0.44502223 1.47438418]
-4.320008224389929  -  18.0555  =  -22.37550822438993
training  [2.4125, -0.8095, -1.5122]  w:  [1.59325525 0.44502223 1.47438418]
1.2539190335177843  -  38.8276  =  -37.573680966482215
training  [-3.9519, -1.0924, -0.4866]  w:  [1.59325525 0.44502223 1.47438418]
-7.499963035739256  -  3.6777  =  -11.177663035739256
training  [-3.7211, 3.1614, -2.591]  w:  [1.59325525 0.44502223 1.47438418]
-8.341898256730062  -  11.1518  =  -19.493698256730063
training  [0.4954, -1.8257, 2.1505]  w:  [1.59325525 0.44502223 1.47438418]
3.147484757591201  -  47.7531  =  -44.6056152424088
training  [-0.1477, 3.1454, 3.5618]  w:  [1.59325525 0.44502223 1.47438418]
6.415910687642197  -  94.1572  =  -87.74128931235781
training  [3.9048, 2.8907, -2.1849]  w:  [1.59325525 0.44502223 1.47438418]
4.286386837752129  -  85.8791  =  -81.59271316224786
training  [2.9896, 3.5226, 2.3105]  w:  [1.59325525 0.44502223 1.47438418]
9.737395832521294  -  98.038  =  -88.3006041674787
training  [2.3434, 0.0564, -3.6224]  w:  [1.59325525 0.44502223 1.47438418]
-1.5820756610517281  -  24.7629  =  -26.344975661051727
training  [-4.4867, 1.3566, 3.3672]  w:  [1.59325525 0.44502223 1.47438418]
-1.5801947508470944  -  40.5785  =  -42.15869475084709
training  [-4.2711, 4.5089, -3.614]  w:  [1.59325525 0.44502223 1.47438418]
-10.12681621326152  -  10.0825  =  -20.20931621326152
training  [-4.1147, -0.5604, 0.8821]  w:  [1.59325525 0.44502223 1.47438418]
-5.504603535880283  -  8.344  =  -13.848603535880283
training  [2.9835, -4.3998, -1.3384]  w:  [1.59325525 0.44502223 1.47438418]
0.8221524560581093  -  13.2692  =  -12.44704754394189
training  [4.4301, 3.6675, 3.0676]  w:  [1.59325525 0.44502223 1.47438418]
13.213220001915179  -  99.3834  =  -86.17017999808482
training  [1.8372, 1.3119, 0.0378]  w:  [1.59325525 0.44502223 1.47438418]
3.566684920531146  -  74.9026  =  -71.33591507946886
training  [-3.6792, -1.4493, -0.1041]  w:  [1.59325525 0.44502223 1.47438418]
-6.660358812041176  -  4.2442  =  -10.904558812041177
training  [2.2272, 4.97, 3.7705]  w:  [1.59325525 0.44502223 1.47438418]
11.31942410651834  -  99.3199  =  -88.00047589348166
training  [-3.8965, -2.7583, -1.4686]  w:  [1.59325525 0.44502223 1.47438418]
-9.60090448695247  -  1.0337  =  -10.634604486952469
training  [-3.8251, 1.5245, -0.5056]  w:  [1.59325525 0.44502223 1.47438418]
-6.161372908852597  -  12.9762  =  -19.137572908852597
training  [1.4072, 1.0499, 4.6353]  w:  [1.59325525 0.44502223 1.47438418]
9.543470619526069  -  95.4618  =  -85.91832938047392
training  [-1.7119, -1.1275, -4.577]  w:  [1.59325525 0.44502223 1.47438418]
-9.977512620373284  -  1.4655  =  -11.443012620373285
training  [1.5381, -3.5781, 4.7296]  w:  [1.59325525 0.44502223 1.47438418]
7.831499301988783  -  69.9473  =  -62.11580069801121
training  [2.4913, -4.7487, -3.1079]  w:  [1.59325525 0.44502223 1.47438418]
-2.7262388420051273  -  3.9825  =  -6.708738842005127
training  [0.8319, -0.7889, 1.6712]  w:  [1.59325525 0.44502223 1.47438418]
3.438341852872172  -  58.8336  =  -55.39525814712783
training  [2.4003, -3.159, 0.8644]  w:  [1.59325525 0.44502223 1.47438418]
3.692923049433537  -  39.0041  =  -35.31117695056646
training  [-2.6517, 2.2578, 1.7511]  w:  [1.59325525 0.44502223 1.47438418]
-0.6382696189754768  -  54.4525  =  -55.09076961897548
training  [2.3496, -1.2964, -1.3898]  w:  [1.59325525 0.44502223 1.47438418]
1.1174865809413284  -  33.888  =  -32.77051341905867
training  [4.706, 3.4156, 1.2028]  w:  [1.59325525 0.44502223 1.47438418]
10.791266402958163  -  98.4665  =  -87.67523359704184
training  [3.6693, 2.3423, 3.1115]  w:  [1.59325525 0.44502223 1.47438418]
11.476053422245204  -  98.3069  =  -86.8308465777548
training  [-4.1377, 0.7103, -4.8074]  w:  [1.59325525 0.44502223 1.47438418]
-13.364267470825215  -  0.9782  =  -14.342467470825214
training  [-1.3356, -3.2314, -4.1613]  w:  [1.59325525 0.44502223 1.47438418]
-9.70135142543822  -  0.7659  =  -10.46725142543822
training  [-1.308, 4.5738, 4.748]  w:  [1.59325525 0.44502223 1.47438418]
6.951840887115564  -  97.0884  =  -90.13655911288443
training  [1.8503, -2.3468, 1.5135]  w:  [1.59325525 0.44502223 1.47438418]
4.135102487168084  -  50.2125  =  -46.077397512831915
training  [0.9794, 4.2458, -2.6876]  w:  [1.59325525 0.44502223 1.47438418]
-0.5126453754434972  -  68.3262  =  -68.8388453754435
training  [2.8936, -2.7623, -0.9651]  w:  [1.59325525 0.44502223 1.47438418]
1.9580303182068728  -  28.5596  =  -26.601569681793126
training  [-1.3235, -1.2644, -3.7798]  w:  [1.59325525 0.44502223 1.47438418]
-8.24423675453762  -  2.4511  =  -10.695336754537621
training  [-2.9397, -4.125, -2.3156]  w:  [1.59325525 0.44502223 1.47438418]
-9.93349314340027  -  0.554  =  -10.48749314340027
training  [-4.1333, 1.4012, -2.4215]  w:  [1.59325525 0.44502223 1.47438418]
-9.532058071630727  -  4.4072  =  -13.939258071630727
training  [2.7193, -3.1938, -1.6833]  w:  [1.59325525 0.44502223 1.47438418]
0.4293961185776429  -  17.0949  =  -16.665503881422357
training  [-2.9433, -4.5495, -3.4777]  w:  [1.59325525 0.44502223 1.47438418]
-11.84152265521381  -  0.2509  =  -12.09242265521381
training  [-1.1173, 2.2317, -1.5199]  w:  [1.59325525 0.44502223 1.47438418]
-3.027904507394767  -  33.1206  =  -36.14850450739477
training  [0.5178, -1.5256, -3.7834]  w:  [1.59325525 0.44502223 1.47438418]
-5.432123454984808  -  5.237  =  -10.669123454984808
training  [-2.7105, 1.6062, 3.8415]  w:  [1.59325525 0.44502223 1.47438418]
2.0601231854306485  -  70.4458  =  -68.38567681456935
training  [1.4194, -1.1613, -4.0572]  w:  [1.59325525 0.44502223 1.47438418]
-4.237209316075463  -  8.3206  =  -12.557809316075463
training  [-0.1552, 1.2735, 4.3004]  w:  [1.59325525 0.44502223 1.47438418]
6.65990432718653  -  90.1085  =  -83.44859567281348
training  [-3.4815, -4.7835, -1.0098]  w:  [1.59325525 0.44502223 1.47438418]
-9.16451510654842  -  0.5839  =  -9.74841510654842
training  [2.8193, 4.1057, -4.526]  w:  [1.59325525 0.44502223 1.47438418]
-0.35407053962516244  -  66.8081  =  -67.16217053962515
training  [-3.9939, 3.0056, -1.5763]  w:  [1.59325525 0.44502223 1.47438418]
-7.3498151211382545  -  14.4018  =  -21.751615121138254
training  [-2.0593, 2.4585, 2.3597]  w:  [1.59325525 0.44502223 1.47438418]
1.2922009638187726  -  70.6698  =  -69.37759903618122
training  [-2.6263, 3.1311, 2.9468]  w:  [1.59325525 0.44502223 1.47438418]
1.5537581404047711  -  77.309  =  -75.75524185959523
training  [0.3087, -1.1669, 0.4491]  w:  [1.59325525 0.44502223 1.47438418]
0.6346873968159413  -  33.0798  =  -32.44511260318406
training  [-4.085, 1.1728, 1.8622]  w:  [1.59325525 0.44502223 1.47438418]
-3.2409273972732  -  26.4056  =  -29.6465273972732
training  [-0.9468, 0.7549, 3.9363]  w:  [1.59325525 0.44502223 1.47438418]
4.631071666253817  -  79.7738  =  -75.14272833374618
training  [-3.9515, 0.3005, -4.4521]  w:  [1.59325525 0.44502223 1.47438418]
-12.726124751533721  -  1.0441  =  -13.770224751533721
training  [-3.8772, -2.2493, -1.9634]  w:  [1.59325525 0.44502223 1.47438418]
-10.073163641527964  -  1.0509  =  -11.124063641527965
training  [2.8443, -2.5137, -4.5381]  w:  [1.59325525 0.44502223 1.47438418]
-3.2778593240260205  -  6.8897  =  -10.167559324026021
training  [-2.0843, -0.4836, -3.0452]  w:  [1.59325525 0.44502223 1.47438418]
-8.025829373318164  -  3.5346  =  -11.560429373318165
training  [1.0353, -2.7229, 2.2017]  w:  [1.59325525 0.44502223 1.47438418]
3.6838977956461565  -  43.9562  =  -40.27230220435385
training  [4.6442, 3.0445, 2.2175]  w:  [1.59325525 0.44502223 1.47438418]
12.023713110770785  -  98.8492  =  -86.82548688922921
training  [-0.6752, 4.861, 3.778]  w:  [1.59325525 0.44502223 1.47438418]
6.657710534073371  -  97.017  =  -90.35928946592662
training  [1.9475, -4.7001, 0.8243]  w:  [1.59325525 0.44502223 1.47438418]
2.2265505163670953  -  18.7839  =  -16.557349483632905
training  [2.581, 0.3566, -4.2932]  w:  [1.59325525 0.44502223 1.47438418]
-2.0589394517347346  -  23.5455  =  -25.604439451734734
training  [-0.6736, -4.1292, 4.2274]  w:  [1.59325525 0.44502223 1.47438418]
3.322009185721452  -  31.2667  =  -27.944690814278548
training  [1.555, 3.0209, 3.0037]  w:  [1.59325525 0.44502223 1.47438418]
8.25048731888607  -  96.4078  =  -88.15731268111392
training  [-3.9024, 4.8914, -2.1405]  w:  [1.59325525 0.44502223 1.47438418]
-7.196656909527526  -  25.4308  =  -32.627456909527524
training  [4.3376, -4.3305, 0.4366]  w:  [1.59325525 0.44502223 1.47438418]
5.627451351076188  -  43.0907  =  -37.46324864892381
training  [-3.1254, 4.394, 4.8478]  w:  [1.59325525 0.44502223 1.47438418]
4.123387345051703  -  92.8121  =  -88.6887126549483
training  [-2.3382, -4.8182, 2.1568]  w:  [1.59325525 0.44502223 1.47438418]
-2.6896037009692226  -  4.7434  =  -7.433003700969223
training  [2.9783, 1.8384, 3.3897]  w:  [1.59325525 0.44502223 1.47438418]
10.561041026301996  -  97.3486  =  -86.78755897369801
training  [-0.124, 2.8374, -0.6674]  w:  [1.59325525 0.44502223 1.47438418]
0.08113840751122325  -  62.785  =  -62.70386159248877
training  [2.6896, 0.3414, -0.2938]  w:  [1.59325525 0.44502223 1.47438418]
4.0039758294093  -  70.4455  =  -66.4415241705907
training  [-1.0399, 3.8536, 0.6071]  w:  [1.59325525 0.44502223 1.47438418]
0.9532101516606717  -  77.0369  =  -76.08368984833933
training  [-2.2706, 3.99, -2.3091]  w:  [1.59325525 0.44502223 1.47438418]
-5.246507203012287  -  31.1134  =  -36.359907203012284
training  [-4.6277, 1.2594, 2.4902]  w:  [1.59325525 0.44502223 1.47438418]
-3.1411348290283767  -  28.1093  =  -31.25043482902838
training  [1.7329, -3.6213, 0.0389]  w:  [1.59325525 0.44502223 1.47438418]
1.2067465797996637  -  19.3919  =  -18.185153420200336
training  [-0.7044, -2.822, 1.4681]  w:  [1.59325525 0.44502223 1.47438418]
-0.21359829769875294  -  17.8122  =  -18.025798297698753
training  [-0.4826, -3.1786, -1.9225]  w:  [1.59325525 0.44502223 1.47438418]
-5.017956218024846  -  3.5851  =  -8.603056218024847
training  [1.0986, -4.5818, -3.6128]  w:  [1.59325525 0.44502223 1.47438418]
-5.61530778996047  -  1.7158  =  -7.33110778996047
training  [-4.406, -3.9306, -0.2443]  w:  [1.59325525 0.44502223 1.47438418]
-9.129279035729835  -  0.8241  =  -9.953379035729835
training  [-1.8419, 1.1644, -1.3754]  w:  [1.59325525 0.44502223 1.47438418]
-4.44430096648553  -  17.8517  =  -22.29600096648553
training  [2.7272, 4.3966, 2.8811]  w:  [1.59325525 0.44502223 1.47438418]
10.549558694724068  -  98.904  =  -88.35444130527593
training  [1.9643, -1.4554, 2.803]  w:  [1.59325525 0.44502223 1.47438418]
6.614644800088216  -  76.0591  =  -69.44445519991179
training  [-3.7467, -0.8937, 1.6851]  w:  [1.59325525 0.44502223 1.47438418]
-3.8826810138567556  -  12.1571  =  -16.039781013856754
training  [-3.6985, 4.8435, -3.665]  w:  [1.59325525 0.44502223 1.47438418]
-9.140807415134724  -  14.6793  =  -23.82010741513472
250536.85189801882
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.57882815 0.42809553 1.44172407]
11.750947563072044  -  87.3174  =  -75.56645243692796
training  [-4.1793, -4.9218, 1.7664]  w:  [1.57882815 0.42809553 1.44172407]
-6.158735679336403  -  1.5257  =  -7.684435679336403
training  [-3.9429, -0.7689, 4.883]  w:  [1.57882815 0.42809553 1.44172407]
0.48561446994905033  -  39.7859  =  -39.30028553005095
training  [-3.5796, 1.5557, 2.6683]  w:  [1.57882815 0.42809553 1.44172407]
-1.1386326763944035  -  45.5674  =  -46.7060326763944
training  [-3.3354, 2.2292, -1.633]  w:  [1.57882815 0.42809553 1.44172407]
-6.666048231739404  -  13.3589  =  -20.024948231739405
training  [1.2096, 0.3121, 1.6238]  w:  [1.57882815 0.42809553 1.44172407]
4.384430681834193  -  74.5119  =  -70.12746931816581
training  [0.7371, -3.9118, -2.5583]  w:  [1.57882815 0.42809553 1.44172407]
-4.199232569412185  -  3.3358  =  -7.535032569412185
training  [-4.4792, 1.3177, -2.0449]  w:  [1.57882815 0.42809553 1.44172407]
-9.45596708794167  -  4.2974  =  -13.753367087941669
training  [4.312, -3.735, 1.8018]  w:  [1.57882815 0.42809553 1.44172407]
7.806668564569842  -  66.5833  =  -58.776631435430154
training  [2.2866, -3.657, 0.2785]  w:  [1.57882815 0.42809553 1.44172407]
2.4461232186858175  -  26.0005  =  -23.554376781314183
training  [2.3784, -4.0141, -0.8841]  w:  [1.57882815 0.42809553 1.44172407]
0.7620383261002144  -  14.6809  =  -13.918861673899785
training  [-4.366, -3.5797, 1.0264]  w:  [1.57882815 0.42809553 1.44172407]
-6.945831686507723  -  1.8713  =  -8.817131686507723
training  [3.6044, -3.3175, 2.5052]  w:  [1.57882815 0.42809553 1.44172407]
7.882328363765513  -  71.0139  =  -63.1315716362345
training  [4.3441, -3.0375, 0.8353]  w:  [1.57882815 0.42809553 1.44172407]
6.762519272500461  -  63.8979  =  -57.13538072749954
training  [4.844, -1.8252, 0.5179]  w:  [1.57882815 0.42809553 1.44172407]
7.6131524604187595  -  78.0461  =  -70.43294753958124
training  [3.5894, -1.8357, 0.8357]  w:  [1.57882815 0.42809553 1.44172407]
6.086039574714636  -  68.8838  =  -62.79776042528536
training  [2.8556, -2.8244, 0.1182]  w:  [1.57882815 0.42809553 1.44172407]
3.4698004078191014  -  39.5252  =  -36.0553995921809
training  [0.1338, -2.4896, -4.1741]  w:  [1.57882815 0.42809553 1.44172407]
-6.872439867863813  -  2.2644  =  -9.136839867863813
training  [-3.224, 3.9292, 2.1957]  w:  [1.57882815 0.42809553 1.44172407]
-0.2424754299226728  -  72.1211  =  -72.36357542992268
training  [-1.0141, 2.0322, 4.9616]  w:  [1.57882815 0.42809553 1.44172407]
6.422144256880339  -  92.3427  =  -85.92055574311965
training  [-3.6607, 0.5574, -1.4547]  w:  [1.57882815 0.42809553 1.44172407]
-7.638271741566925  -  5.8471  =  -13.485371741566926
training  [-4.6911, -3.1557, 4.7126]  w:  [1.57882815 0.42809553 1.44172407]
-1.9631129523806452  -  11.2337  =  -13.196812952380647
training  [4.3914, -2.8797, -1.5355]  w:  [1.57882815 0.42809553 1.44172407]
3.486711900124977  -  37.475  =  -33.98828809987502
training  [-1.9869, -4.2265, 3.8654]  w:  [1.57882815 0.42809553 1.44172407]
0.6265207896379517  -  15.7889  =  -15.162379210362047
training  [-2.0447, 4.138, -0.4531]  w:  [1.57882815 0.42809553 1.44172407]
-2.1100157601700436  -  57.936  =  -60.04601576017004
training  [-1.6706, 2.0672, -0.8657]  w:  [1.57882815 0.42809553 1.44172407]
-3.0007317350024625  -  32.4185  =  -35.41923173500246
training  [-0.3293, 0.5779, -2.8227]  w:  [1.57882815 0.42809553 1.44172407]
-4.342066223767276  -  14.3434  =  -18.68546622376728
training  [1.482, -1.8657, -3.7435]  w:  [1.57882815 0.42809553 1.44172407]
-3.8559685745366696  -  7.1519  =  -11.00786857453667
training  [-4.7477, -3.338, -1.9109]  w:  [1.57882815 0.42809553 1.44172407]
-11.679775802076572  -  0.4077  =  -12.087475802076572
training  [3.4221, 1.225, 2.261]  w:  [1.57882815 0.42809553 1.44172407]
9.187062943165653  -  95.0454  =  -85.85833705683434
training  [0.5903, 4.8793, 2.8287]  w:  [1.57882815 0.42809553 1.44172407]
7.098993667525861  -  97.4647  =  -90.36570633247413
training  [3.541, -3.2957, 1.9379]  w:  [1.57882815 0.42809553 1.44172407]
6.973673078554709  -  64.3732  =  -57.399526921445286
training  [-1.5212, -2.4221, -4.902]  w:  [1.57882815 0.42809553 1.44172407]
-10.505934948573076  -  0.7227  =  -11.228634948573076
training  [-0.5397, -1.032, 3.4321]  w:  [1.57882815 0.42809553 1.44172407]
3.654253029682372  -  60.5921  =  -56.93784697031763
training  [-4.4576, -4.2601, 4.2233]  w:  [1.57882815 0.42809553 1.44172407]
-2.772680875439131  -  6.0247  =  -8.797380875439131
training  [-3.2289, 1.841, 2.7095]  w:  [1.57882815 0.42809553 1.44172407]
-0.40340295809964255  -  54.0111  =  -54.41450295809964
training  [1.6281, -0.9761, -4.5734]  w:  [1.57882815 0.42809553 1.44172407]
-4.4409547981526885  -  7.8658  =  -12.306754798152689
training  [-1.6917, 4.8284, -1.2181]  w:  [1.57882815 0.42809553 1.44172407]
-2.3600511790914758  -  61.2837  =  -63.64375117909148
training  [3.9849, -0.9782, 2.0434]  w:  [1.57882815 0.42809553 1.44172407]
8.818728183690183  -  88.3402  =  -79.52147181630981
training  [-3.8184, 1.2067, 2.2951]  w:  [1.57882815 0.42809553 1.44172407]
-2.2031136011840027  -  34.1122  =  -36.315313601184
training  [4.8842, -3.4563, -2.7572]  w:  [1.57882815 0.42809553 1.44172407]
2.256564231534388  -  23.7819  =  -21.525335768465613
training  [0.3998, -1.1865, -2.3095]  w:  [1.57882815 0.42809553 1.44172407]
-3.2063815934407542  -  11.4246  =  -14.630981593440755
training  [2.0692, -3.3887, 1.7303]  w:  [1.57882815 0.42809553 1.44172407]
4.310839013006174  -  42.6881  =  -38.377260986993825
training  [4.9949, 2.5811, -0.2251]  w:  [1.57882815 0.42809553 1.44172407]
8.666514001168087  -  95.9901  =  -87.32358599883192
training  [-2.1215, 3.7111, 1.2372]  w:  [1.57882815 0.42809553 1.44172407]
0.0229224455692445  -  71.3692  =  -71.34627755443076
training  [-0.8548, -1.4922, -2.6356]  w:  [1.57882815 0.42809553 1.44172407]
-5.788194408086323  -  4.7821  =  -10.570294408086323
training  [-0.3516, 1.8554, -3.2288]  w:  [1.57882815 0.42809553 1.44172407]
-4.415866189277839  -  20.3834  =  -24.79926618927784
training  [2.6396, -2.0585, 3.2964]  w:  [1.57882815 0.42809553 1.44172407]
8.03873932975737  -  80.826  =  -72.78726067024263
training  [3.182, 0.3063, 2.6692]  w:  [1.57882815 0.42809553 1.44172407]
9.00320670181025  -  92.9483  =  -83.94509329818976
training  [-3.9978, 3.3242, 4.3448]  w:  [1.57882815 0.42809553 1.44172407]
1.3752387458349133  -  79.1768  =  -77.80156125416508
training  [-3.2188, 0.9749, -3.9211]  w:  [1.57882815 0.42809553 1.44172407]
-10.317725938184555  -  2.7053  =  -13.023025938184555
training  [-1.4037, -1.6469, -3.1777]  w:  [1.57882815 0.42809553 1.44172407]
-7.502598173310009  -  2.6234  =  -10.125998173310009
training  [-4.433, -2.0077, -4.009]  w:  [1.57882815 0.42809553 1.44172407]
-13.638304360438308  -  0.3253  =  -13.963604360438309
training  [0.2189, -0.4741, -0.1024]  w:  [1.57882815 0.42809553 1.44172407]
-0.0049871566037425485  -  33.6531  =  -33.65808715660374
training  [-1.6415, -0.7735, -3.0675]  w:  [1.57882815 0.42809553 1.44172407]
-7.345266873817243  -  3.7641  =  -11.109366873817244
training  [-3.2433, -1.4039, 3.9589]  w:  [1.57882815 0.42809553 1.44172407]
-0.013975234946919102  -  30.0658  =  -30.07977523494692
training  [-2.9105, 0.5832, -4.0091]  w:  [1.57882815 0.42809553 1.44172407]
-10.125529959937595  -  2.4887  =  -12.614229959937594
training  [4.0515, 2.4255, -4.5583]  w:  [1.57882815 0.42809553 1.44172407]
0.8631571345579188  -  61.2853  =  -60.42214286544208
training  [1.7539, -0.7567, 0.573]  w:  [1.57882815 0.42809553 1.44172407]
3.271274683546711  -  57.0797  =  -53.808425316453295
training  [-0.3153, -0.7064, 2.725]  w:  [1.57882815 0.42809553 1.44172407]
3.128486883612211  -  58.7004  =  -55.57191311638779
training  [4.1213, -3.7513, -1.8806]  w:  [1.57882815 0.42809553 1.44172407]
2.1896033741071363  -  22.1789  =  -19.989296625892862
training  [-3.9599, -4.7557, -3.2102]  w:  [1.57882815 0.42809553 1.44172407]
-12.91611810986547  -  0.1558  =  -13.07191810986547
training  [2.4555, -2.0981, -1.6104]  w:  [1.57882815 0.42809553 1.44172407]
0.6568728309246779  -  24.4796  =  -23.822727169075325
training  [2.3627, -1.8248, -2.8985]  w:  [1.57882815 0.42809553 1.44172407]
-1.229728682523132  -  15.7052  =  -16.934928682523132
training  [0.6186, 1.5369, 0.1015]  w:  [1.57882815 0.42809553 1.44172407]
1.7809381112740834  -  65.2154  =  -63.43446188872592
training  [-3.1581, 4.5694, 4.0636]  w:  [1.57882815 0.42809553 1.44172407]
2.8286324919010744  -  90.3564  =  -87.52776750809892
training  [0.9721, 4.3573, 1.2892]  w:  [1.57882815 0.42809553 1.44172407]
5.25879018237484  -  94.3178  =  -89.05900981762517
training  [-2.0006, -0.4211, -3.9847]  w:  [1.57882815 0.42809553 1.44172407]
-9.083712508958186  -  2.4051  =  -11.488812508958187
training  [-3.6588, -2.5952, -1.0915]  w:  [1.57882815 0.42809553 1.44172407]
-8.461251770326156  -  1.5176  =  -9.978851770326155
training  [-2.874, 2.639, -4.4538]  w:  [1.57882815 0.42809553 1.44172407]
-9.828958624639236  -  5.497  =  -15.325958624639236
training  [3.9494, 2.5933, 0.0128]  w:  [1.57882815 0.42809553 1.44172407]
7.364058096322614  -  94.1462  =  -86.78214190367738
training  [-4.2855, 2.4065, -0.6828]  w:  [1.57882815 0.42809553 1.44172407]
-6.720265305458779  -  14.4193  =  -21.139565305458778
training  [-2.5751, 2.4369, 4.9756]  w:  [1.57882815 0.42809553 1.44172407]
4.151027921856917  -  87.1991  =  -83.04807207814308
training  [-4.4625, -3.9408, 3.116]  w:  [1.57882815 0.42809553 1.44172407]
-4.240147288906171  -  4.1344  =  -8.374547288906172
training  [-0.5828, 1.8156, -0.1435]  w:  [1.57882815 0.42809553 1.44172407]
-0.34977819353456224  -  51.1166  =  -51.46637819353456
training  [-4.8672, -0.3674, 3.9445]  w:  [1.57882815 0.42809553 1.44172407]
-2.1548740648408327  -  24.1396  =  -26.294474064840834
training  [3.9719, -2.8784, -3.6245]  w:  [1.57882815 0.42809553 1.44172407]
-0.1868115595418507  -  14.6104  =  -14.79721155954185
training  [-3.0334, -4.0148, -1.1]  w:  [1.57882815 0.42809553 1.44172407]
-8.093831724201724  -  1.021  =  -9.114831724201725
training  [-4.0663, 3.2357, 4.2736]  w:  [1.57882815 0.42809553 1.44172407]
1.126551809429568  -  77.2328  =  -76.10624819057043
training  [-1.9263, -3.2499, 4.1749]  w:  [1.57882815 0.42809553 1.44172407]
1.5864894735653587  -  26.8814  =  -25.29491052643464
training  [-0.4394, -3.3643, 2.1357]  w:  [1.57882815 0.42809553 1.44172407]
0.945111195449452  -  20.85  =  -19.90488880455055
training  [-3.9833, 1.6599, 1.1834]  w:  [1.57882815 0.42809553 1.44172407]
-3.8722141116798747  -  25.5397  =  -29.411914111679874
training  [4.9539, 3.9439, -1.5671]  w:  [1.57882815 0.42809553 1.44172407]
7.250396943760446  -  95.9509  =  -88.70050305623955
training  [-1.6791, 0.1656, 4.3603]  w:  [1.57882815 0.42809553 1.44172407]
3.7062317328791514  -  71.5733  =  -67.86706826712086
training  [-2.0265, 2.027, -3.7523]  w:  [1.57882815 0.42809553 1.44172407]
-7.74152680550749  -  8.503  =  -16.24452680550749
training  [-4.3795, -3.4641, 2.3059]  w:  [1.57882815 0.42809553 1.44172407]
-5.072972078348264  -  3.6654  =  -8.738372078348263
training  [-2.0176, 4.5346, 1.4648]  w:  [1.57882815 0.42809553 1.44172407]
0.8676357606666811  -  81.6212  =  -80.75356423933331
training  [-4.5365, 0.4088, 3.3315]  w:  [1.57882815 0.42809553 1.44172407]
-2.1842446962549396  -  28.9449  =  -31.12914469625494
training  [0.0543, 1.7973, -1.0172]  w:  [1.57882815 0.42809553 1.44172407]
-0.611375248107098  -  47.9317  =  -48.543075248107094
training  [2.6143, -4.6344, 2.4982]  w:  [1.57882815 0.42809553 1.44172407]
5.745279538540288  -  43.5132  =  -37.76792046145971
training  [1.3107, 3.092, 3.3522]  w:  [1.57882815 0.42809553 1.44172407]
8.2259888631313  -  96.6993  =  -88.47331113686869
training  [-4.1011, 2.4862, -1.7754]  w:  [1.57882815 0.42809553 1.44172407]
-7.970237897387927  -  10.0187  =  -17.988937897387927
training  [-4.1914, -3.7981, 0.5226]  w:  [1.57882815 0.42809553 1.44172407]
-7.490004942329967  -  1.4295  =  -8.919504942329967
training  [2.7724, 0.2505, 4.7913]  w:  [1.57882815 0.42809553 1.44172407]
11.392113606103516  -  96.7925  =  -85.40038639389648
training  [4.0513, -1.7417, 0.4931]  w:  [1.57882815 0.42809553 1.44172407]
6.361606609858358  -  71.1234  =  -64.76179339014165
training  [0.3377, 0.4645, -1.6958]  w:  [1.57882815 0.42809553 1.44172407]
-1.7128550328610062  -  27.9534  =  -29.666255032861006
training  [-3.9085, -1.0112, 1.1947]  w:  [1.57882815 0.42809553 1.44172407]
-4.8813122678841  -  8.608  =  -13.4893122678841
training  [3.2581, -0.8491, -1.3936]  w:  [1.57882815 0.42809553 1.44172407]
2.771297401411043  -  50.1924  =  -47.42110259858896
training  [-1.619, -3.1926, 2.5651]  w:  [1.57882815 0.42809553 1.44172407]
-0.22469416695382582  -  16.4754  =  -16.700094166953825
training  [-2.0603, -2.4461, -0.861]  w:  [1.57882815 0.42809553 1.44172407]
-5.541348538099914  -  3.9784  =  -9.519748538099915
training  [2.4631, -4.7946, -0.0765]  w:  [1.57882815 0.42809553 1.44172407]
1.7259728618350556  -  15.394  =  -13.668027138164945
training  [-4.8966, 4.2368, 1.9474]  w:  [1.57882815 0.42809553 1.44172407]
-3.109521285305257  -  53.5883  =  -56.69782128530525
training  [-4.5155, 1.537, 4.7273]  w:  [1.57882815 0.42809553 1.44172407]
0.34424653066766453  -  59.2523  =  -58.90805346933233
training  [1.6792, 4.3261, -1.7225]  w:  [1.57882815 0.42809553 1.44172407]
2.0197826094074367  -  83.7729  =  -81.75311739059256
training  [1.0347, -3.3649, 3.378]  w:  [1.57882815 0.42809553 1.44172407]
5.063258716232706  -  50.5979  =  -45.5346412837673
training  [0.261, 4.211, 2.3907]  w:  [1.57882815 0.42809553 1.44172407]
5.661514171694052  -  94.9375  =  -89.27598582830595
training  [2.2971, 2.9466, 4.5417]  w:  [1.57882815 0.42809553 1.44172407]
11.436030633180376  -  98.7784  =  -87.34236936681963
training  [2.0725, 0.7739, -4.6808]  w:  [1.57882815 0.42809553 1.44172407]
-3.1449975489930058  -  19.5109  =  -22.655897548993003
training  [2.8138, -0.5996, -1.4313]  w:  [1.57882815 0.42809553 1.44172407]
2.1222808950416674  -  47.2879  =  -45.16561910495833
training  [-2.1202, -2.4239, 1.6265]  w:  [1.57882815 0.42809553 1.44172407]
-2.0401280053935236  -  12.3599  =  -14.400028005393523
training  [1.9253, 2.5195, -2.185]  w:  [1.57882815 0.42809553 1.44172407]
0.9681374413365367  -  65.2467  =  -64.27856255866347
training  [0.5667, -2.7133, -2.6962]  w:  [1.57882815 0.42809553 1.44172407]
-4.1540061356329145  -  5.1106  =  -9.264606135632913
training  [-1.0348, -4.3581, 2.1113]  w:  [1.57882815 0.42809553 1.44172407]
-0.45554249221341037  -  10.5192  =  -10.97474249221341
training  [-4.3841, 2.6733, 1.2457]  w:  [1.57882815 0.42809553 1.44172407]
-3.981357007822194  -  32.4639  =  -36.4452570078222
training  [2.8018, 1.712, 0.9061]  w:  [1.57882815 0.42809553 1.44172407]
6.462806431137287  -  90.1138  =  -83.65099356886272
training  [-1.6242, 2.1521, 1.6044]  w:  [1.57882815 0.42809553 1.44172407]
0.6700738208287125  -  63.7879  =  -63.11782617917129
training  [1.0787, 1.4206, -4.5245]  w:  [1.57882815 0.42809553 1.44172407]
-4.211846105689309  -  18.0555  =  -22.267346105689306
training  [2.4125, -0.8095, -1.5122]  w:  [1.57882815 0.42809553 1.44172407]
1.2822044304489202  -  38.8276  =  -37.545395569551076
training  [-3.9519, -1.0924, -0.4866]  w:  [1.57882815 0.42809553 1.44172407]
-7.408565441408565  -  3.6777  =  -11.086265441408566
training  [-3.7211, 3.1614, -2.591]  w:  [1.57882815 0.42809553 1.44172407]
-8.257103246327155  -  11.1518  =  -19.408903246327156
training  [0.4954, -1.8257, 2.1505]  w:  [1.57882815 0.42809553 1.44172407]
3.1010050520616015  -  47.7531  =  -44.6520949479384
training  [-0.1477, 3.1454, 3.5618]  w:  [1.57882815 0.42809553 1.44172407]
6.248471561982865  -  94.1572  =  -87.90872843801714
training  [3.9048, 2.8907, -2.1849]  w:  [1.57882815 0.42809553 1.44172407]
4.2524809901386  -  85.8791  =  -81.6266190098614
training  [2.9896, 3.5226, 2.3105]  w:  [1.57882815 0.42809553 1.44172407]
9.559177412751676  -  98.038  =  -88.47882258724832
training  [2.3434, 0.0564, -3.6224]  w:  [1.57882815 0.42809553 1.44172407]
-1.4985307977700053  -  24.7629  =  -26.261430797770004
training  [-4.4867, 1.3566, 3.3672]  w:  [1.57882815 0.42809553 1.44172407]
-1.6484005573679532  -  40.5785  =  -42.226900557367955
training  [-4.2711, 4.5089, -3.614]  w:  [1.57882815 0.42809553 1.44172407]
-10.023483713916555  -  10.0825  =  -20.105983713916554
training  [-4.1147, -0.5604, 0.8821]  w:  [1.57882815 0.42809553 1.44172407]
-5.464564107783146  -  8.344  =  -13.808564107783145
training  [2.9835, -4.3998, -1.3384]  w:  [1.57882815 0.42809553 1.44172407]
0.8972955452105851  -  13.2692  =  -12.371904454789414
training  [4.4301, 3.6675, 3.0676]  w:  [1.57882815 0.42809553 1.44172407]
12.98703969066829  -  99.3834  =  -86.3963603093317
training  [1.8372, 1.3119, 0.0378]  w:  [1.57882815 0.42809553 1.44172407]
3.5167387707945816  -  74.9026  =  -71.38586122920543
training  [-3.6792, -1.4493, -0.1041]  w:  [1.57882815 0.42809553 1.44172407]
-6.579346846793831  -  4.2442  =  -10.823546846793832
training  [2.2272, 4.97, 3.7705]  w:  [1.57882815 0.42809553 1.44172407]
11.080021450458613  -  99.3199  =  -88.23987854954139
training  [-3.8965, -2.7583, -1.4686]  w:  [1.57882815 0.42809553 1.44172407]
-9.45003574806902  -  1.0337  =  -10.48373574806902
training  [-3.8251, 1.5245, -0.5056]  w:  [1.57882815 0.42809553 1.44172407]
-6.1154795844062395  -  12.9762  =  -19.09167958440624
training  [1.4072, 1.0499, 4.6353]  w:  [1.57882815 0.42809553 1.44172407]
9.354008038135797  -  95.4618  =  -86.1077919618642
training  [-1.7119, -1.1275, -4.577]  w:  [1.57882815 0.42809553 1.44172407]
-9.784244674420634  -  1.4655  =  -11.249744674420635
training  [1.5381, -3.5781, 4.7296]  w:  [1.57882815 0.42809553 1.44172407]
7.715405086114545  -  69.9473  =  -62.231894913885455
training  [2.4913, -4.7487, -3.1079]  w:  [1.57882815 0.42809553 1.44172407]
-2.5802969374262394  -  3.9825  =  -6.562796937426239
training  [0.8319, -0.7889, 1.6712]  w:  [1.57882815 0.42809553 1.44172407]
3.385111828118188  -  58.8336  =  -55.448488171881806
training  [2.4003, -3.159, 0.8644]  w:  [1.57882815 0.42809553 1.44172407]
3.6835336863386576  -  39.0041  =  -35.320566313661345
training  [-2.6517, 2.2578, 1.7511]  w:  [1.57882815 0.42809553 1.44172407]
-0.6954214798303471  -  54.4525  =  -55.147921479830345
training  [2.3496, -1.2964, -1.3898]  w:  [1.57882815 0.42809553 1.44172407]
1.1509234499832237  -  33.888  =  -32.73707655001677
training  [4.706, 3.4156, 1.2028]  w:  [1.57882815 0.42809553 1.44172407]
10.62627406977734  -  98.4665  =  -87.84022593022266
training  [3.6693, 2.3423, 3.1115]  w:  [1.57882815 0.42809553 1.44172407]
11.281846721275123  -  98.3069  =  -87.02505327872487
training  [-4.1377, 0.7103, -4.8074]  w:  [1.57882815 0.42809553 1.44172407]
-13.159585240508727  -  0.9782  =  -14.137785240508727
training  [-1.3356, -3.2314, -4.1613]  w:  [1.57882815 0.42809553 1.44172407]
-9.491477144485732  -  0.7659  =  -10.257377144485732
training  [-1.308, 4.5738, 4.748]  w:  [1.57882815 0.42809553 1.44172407]
6.738222015808192  -  97.0884  =  -90.3501779841918
training  [1.8503, -2.3468, 1.5135]  w:  [1.57882815 0.42809553 1.44172407]
4.0987004920378  -  50.2125  =  -46.1137995079622
training  [0.9794, 4.2458, -2.6876]  w:  [1.57882815 0.42809553 1.44172407]
-0.5108652956797575  -  68.3262  =  -68.83706529567976
training  [2.8936, -2.7623, -0.9651]  w:  [1.57882815 0.42809553 1.44172407]
1.994560927815346  -  28.5596  =  -26.565039072184653
training  [-1.3235, -1.2644, -3.7798]  w:  [1.57882815 0.42809553 1.44172407]
-8.080291674926752  -  2.4511  =  -10.531391674926752
training  [-2.9397, -4.125, -2.3156]  w:  [1.57882815 0.42809553 1.44172407]
-9.745631431302435  -  0.554  =  -10.299631431302435
training  [-4.1333, 1.4012, -2.4215]  w:  [1.57882815 0.42809553 1.44172407]
-9.417057739074043  -  4.4072  =  -13.824257739074042
training  [2.7193, -3.1938, -1.6833]  w:  [1.57882815 0.42809553 1.44172407]
0.49920173350505825  -  17.0949  =  -16.595698266494942
training  [-2.9433, -4.5495, -3.4777]  w:  [1.57882815 0.42809553 1.44172407]
-11.608469305981924  -  0.2509  =  -11.859369305981923
training  [-1.1173, 2.2317, -1.5199]  w:  [1.57882815 0.42809553 1.44172407]
-2.999920291566468  -  33.1206  =  -36.12052029156647
training  [0.5178, -1.5256, -3.7834]  w:  [1.57882815 0.42809553 1.44172407]
-5.290204171179454  -  5.237  =  -10.527204171179454
training  [-2.7105, 1.6062, 3.8415]  w:  [1.57882815 0.42809553 1.44172407]
1.9465763651996721  -  70.4458  =  -68.49922363480033
training  [1.4194, -1.1613, -4.0572]  w:  [1.57882815 0.42809553 1.44172407]
-4.105521561563796  -  8.3206  =  -12.426121561563797
training  [-0.1552, 1.2735, 4.3004]  w:  [1.57882815 0.42809553 1.44172407]
6.500135715199484  -  90.1085  =  -83.60836428480053
training  [-3.4815, -4.7835, -1.0098]  w:  [1.57882815 0.42809553 1.44172407]
-9.000338142999166  -  0.5839  =  -9.584238142999165
training  [2.8193, 4.1057, -4.526]  w:  [1.57882815 0.42809553 1.44172407]
-0.3164211009779496  -  66.8081  =  -67.12452110097794
training  [-3.9939, 3.0056, -1.5763]  w:  [1.57882815 0.42809553 1.44172407]
-7.291587437515034  -  14.4018  =  -21.693387437515035
training  [-2.0593, 2.4585, 2.3597]  w:  [1.57882815 0.42809553 1.44172407]
1.2032283548108151  -  70.6698  =  -69.46657164518918
training  [-2.6263, 3.1311, 2.9468]  w:  [1.57882815 0.42809553 1.44172407]
1.4424060531763736  -  77.309  =  -75.86659394682363
training  [0.3087, -1.1669, 0.4491]  w:  [1.57882815 0.42809553 1.44172407]
0.6353178474193759  -  33.0798  =  -32.444482152580626
training  [-4.085, 1.1728, 1.8622]  w:  [1.57882815 0.42809553 1.44172407]
-3.2626639721743156  -  26.4056  =  -29.668263972174316
training  [-0.9468, 0.7549, 3.9363]  w:  [1.57882815 0.42809553 1.44172407]
4.503393277917249  -  79.7738  =  -75.27040672208274
training  [-3.9515, 0.3005, -4.4521]  w:  [1.57882815 0.42809553 1.44172407]
-12.528796428904748  -  1.0441  =  -13.572896428904748
training  [-3.8772, -2.2493, -1.9634]  w:  [1.57882815 0.42809553 1.44172407]
-9.915028806132053  -  1.0509  =  -10.965928806132053
training  [2.8443, -2.5137, -4.5381]  w:  [1.57882815 0.42809553 1.44172407]
-3.1281308426988788  -  6.8897  =  -10.01783084269888
training  [-2.0843, -0.4836, -3.0452]  w:  [1.57882815 0.42809553 1.44172407]
-7.88811663431  -  3.5346  =  -11.42271663431
training  [1.0353, -2.7229, 2.2017]  w:  [1.57882815 0.42809553 1.44172407]
3.643143326045329  -  43.9562  =  -40.31305667395468
training  [4.6442, 3.0445, 2.2175]  w:  [1.57882815 0.42809553 1.44172407]
11.83275364859086  -  98.8492  =  -87.01644635140914
training  [-0.6752, 4.861, 3.778]  w:  [1.57882815 0.42809553 1.44172407]
6.461781158448112  -  97.017  =  -90.55521884155189
training  [1.9475, -4.7001, 0.8243]  w:  [1.57882815 0.42809553 1.44172407]
2.2510891380652165  -  18.7839  =  -16.532810861934784
training  [2.581, 0.3566, -4.2932]  w:  [1.57882815 0.42809553 1.44172407]
-1.9619954552611691  -  23.5455  =  -25.50749545526117
training  [-0.6736, -4.1292, 4.2274]  w:  [1.57882815 0.42809553 1.44172407]
3.263553600952795  -  31.2667  =  -28.003146399047203
training  [1.555, 3.0209, 3.0037]  w:  [1.57882815 0.42809553 1.44172407]
8.078818149015872  -  96.4078  =  -88.32898185098412
training  [-3.9024, 4.8914, -2.1405]  w:  [1.57882815 0.42809553 1.44172407]
-7.153242821221848  -  25.4308  =  -32.58404282122185
training  [4.3376, -4.3305, 0.4366]  w:  [1.57882815 0.42809553 1.44172407]
5.623913977161528  -  43.0907  =  -37.46678602283847
training  [-3.1254, 4.394, 4.8478]  w:  [1.57882815 0.42809553 1.44172407]
3.935772229103902  -  92.8121  =  -88.8763277708961
training  [-2.3382, -4.8182, 2.1568]  w:  [1.57882815 0.42809553 1.44172407]
-2.6447554074947583  -  4.7434  =  -7.388155407494759
training  [2.9783, 1.8384, 3.3897]  w:  [1.57882815 0.42809553 1.44172407]
10.37624676829618  -  97.3486  =  -86.97235323170382
training  [-0.124, 2.8374, -0.6674]  w:  [1.57882815 0.42809553 1.44172407]
0.056696938272315256  -  62.785  =  -62.72830306172768
training  [2.6896, 0.3414, -0.2938]  w:  [1.57882815 0.42809553 1.44172407]
3.9689894644891988  -  70.4455  =  -66.4765105355108
training  [-1.0399, 3.8536, 0.6071]  w:  [1.57882815 0.42809553 1.44172407]
0.8831562464753012  -  77.0369  =  -76.15374375352471
training  [-2.2706, 3.99, -2.3091]  w:  [1.57882815 0.42809553 1.44172407]
-5.205871046545903  -  31.1134  =  -36.3192710465459
training  [-4.6277, 1.2594, 2.4902]  w:  [1.57882815 0.42809553 1.44172407]
-3.177018219006396  -  28.1093  =  -31.286318219006397
training  [1.7329, -3.6213, 0.0389]  w:  [1.57882815 0.42809553 1.44172407]
1.241771998619823  -  19.3919  =  -18.15012800138018
training  [-0.7044, -2.822, 1.4681]  w:  [1.57882815 0.42809553 1.44172407]
-0.20361704188855523  -  17.8122  =  -18.015817041888557
training  [-0.4826, -3.1786, -1.9225]  w:  [1.57882815 0.42809553 1.44172407]
-4.894401450045558  -  3.5851  =  -8.479501450045559
training  [1.0986, -4.5818, -3.6128]  w:  [1.57882815 0.42809553 1.44172407]
-5.435608232384453  -  1.7158  =  -7.151408232384453
training  [-4.406, -3.9306, -0.2443]  w:  [1.57882815 0.42809553 1.44172407]
-8.991202308029605  -  0.8241  =  -9.815302308029604
training  [-1.8419, 1.1644, -1.3754]  w:  [1.57882815 0.42809553 1.44172407]
-4.3925164024452545  -  17.8517  =  -22.244216402445254
training  [2.7272, 4.3966, 2.8811]  w:  [1.57882815 0.42809553 1.44172407]
10.341696157834763  -  98.904  =  -88.56230384216524
training  [1.9643, -1.4554, 2.803]  w:  [1.57882815 0.42809553 1.44172407]
6.519394445434907  -  76.0591  =  -69.53970555456509
training  [-3.7467, -0.8937, 1.6851]  w:  [1.57882815 0.42809553 1.44172407]
-3.8685351659311933  -  12.1571  =  -16.02563516593119
training  [-3.6985, 4.8435, -3.665]  w:  [1.57882815 0.42809553 1.44172407]
-9.049733879301424  -  14.6793  =  -23.729033879301426
251093.236923258
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.54829721 0.39319131 1.46514571]
11.86083957952771  -  87.3174  =  -75.4565604204723
training  [-4.1793, -4.9218, 1.7664]  w:  [1.54829721 0.39319131 1.46514571]
-5.817974100906103  -  1.5257  =  -7.343674100906103
training  [-3.9429, -0.7689, 4.883]  w:  [1.54829721 0.39319131 1.46514571]
0.7472006668618647  -  39.7859  =  -39.03869933313813
training  [-3.5796, 1.5557, 2.6683]  w:  [1.54829721 0.39319131 1.46514571]
-1.0211486562936938  -  45.5674  =  -46.588548656293696
training  [-3.3354, 2.2292, -1.633]  w:  [1.54829721 0.39319131 1.46514571]
-6.680271388520815  -  13.3589  =  -20.039171388520813
training  [1.2096, 0.3121, 1.6238]  w:  [1.54829721 0.39319131 1.46514571]
4.374638916087018  -  74.5119  =  -70.13726108391297
training  [0.7371, -3.9118, -2.5583]  w:  [1.54829721 0.39319131 1.46514571]
-4.145118162009663  -  3.3358  =  -7.4809181620096625
training  [-4.4792, 1.3177, -2.0449]  w:  [1.54829721 0.39319131 1.46514571]
-9.413101128351299  -  4.2974  =  -13.710501128351298
training  [4.312, -3.735, 1.8018]  w:  [1.54829721 0.39319131 1.46514571]
7.847587566069738  -  66.5833  =  -58.73571243393026
training  [2.2866, -3.657, 0.2785]  w:  [1.54829721 0.39319131 1.46514571]
2.5104788623576524  -  26.0005  =  -23.490021137642348
training  [2.3784, -4.0141, -0.8841]  w:  [1.54829721 0.39319131 1.46514571]
0.8088255241966684  -  14.6809  =  -13.87207447580333
training  [-4.366, -3.5797, 1.0264]  w:  [1.54829721 0.39319131 1.46514571]
-6.663546963644099  -  1.8713  =  -8.5348469636441
training  [3.6044, -3.3175, 2.5052]  w:  [1.54829721 0.39319131 1.46514571]
7.946753328308164  -  71.0139  =  -63.067146671691845
training  [4.3441, -3.0375, 0.8353]  w:  [1.54829721 0.39319131 1.46514571]
6.755475511473647  -  63.8979  =  -57.14242448852635
training  [4.844, -1.8252, 0.5179]  w:  [1.54829721 0.39319131 1.46514571]
7.541097857037871  -  78.0461  =  -70.50500214296213
training  [3.5894, -1.8357, 0.8357]  w:  [1.54829721 0.39319131 1.46514571]
6.060098981224975  -  68.8838  =  -62.82370101877502
training  [2.8556, -2.8244, 0.1182]  w:  [1.54829721 0.39319131 1.46514571]
3.483968197068833  -  39.5252  =  -36.041231802931165
training  [0.1338, -2.4896, -4.1741]  w:  [1.54829721 0.39319131 1.46514571]
-6.887391632510232  -  2.2644  =  -9.151791632510232
training  [-3.224, 3.9292, 2.1957]  w:  [1.54829721 0.39319131 1.46514571]
-0.2297624664303073  -  72.1211  =  -72.3508624664303
training  [-1.0141, 2.0322, 4.9616]  w:  [1.54829721 0.39319131 1.46514571]
6.498382147164948  -  92.3427  =  -85.84431785283505
training  [-3.6607, 0.5574, -1.4547]  w:  [1.54829721 0.39319131 1.46514571]
-7.5800342161937  -  5.8471  =  -13.4271342161937
training  [-4.6911, -3.1557, 4.7126]  w:  [1.54829721 0.39319131 1.46514571]
-1.599365143918373  -  11.2337  =  -12.833065143918374
training  [4.3914, -2.8797, -1.5355]  w:  [1.54829721 0.39319131 1.46514571]
3.4171881012340344  -  37.475  =  -34.05781189876597
training  [-1.9869, -4.2265, 3.8654]  w:  [1.54829721 0.39319131 1.46514571]
0.925239460942568  -  15.7889  =  -14.863660539057431
training  [-2.0447, 4.138, -0.4531]  w:  [1.54829721 0.39319131 1.46514571]
-2.202635191001722  -  57.936  =  -60.138635191001725
training  [-1.6706, 2.0672, -0.8657]  w:  [1.54829721 0.39319131 1.46514571]
-3.0421568861107264  -  32.4185  =  -35.460656886110726
training  [-0.3293, 0.5779, -2.8227]  w:  [1.54829721 0.39319131 1.46514571]
-4.41829581761975  -  14.3434  =  -18.761695817619753
training  [1.482, -1.8657, -3.7435]  w:  [1.54829721 0.39319131 1.46514571]
-3.9237735388527955  -  7.1519  =  -11.075673538852795
training  [-4.7477, -3.338, -1.9109]  w:  [1.54829721 0.39319131 1.46514571]
-11.463070171008162  -  0.4077  =  -11.870770171008163
training  [3.4221, 1.225, 2.261]  w:  [1.54829721 0.39319131 1.46514571]
9.092781676958012  -  95.0454  =  -85.95261832304199
training  [0.5903, 4.8793, 2.8287]  w:  [1.54829721 0.39319131 1.46514571]
6.976915863675091  -  97.4647  =  -90.4877841363249
training  [3.541, -3.2957, 1.9379]  w:  [1.54829721 0.39319131 1.46514571]
7.0259856929650795  -  64.3732  =  -57.34721430703492
training  [-1.5212, -2.4221, -4.902]  w:  [1.54829721 0.39319131 1.46514571]
-10.48976265972896  -  0.7227  =  -11.21246265972896
training  [-0.5397, -1.032, 3.4321]  w:  [1.54829721 0.39319131 1.46514571]
3.7871371705334704  -  60.5921  =  -56.80496282946653
training  [-4.4576, -4.2601, 4.2233]  w:  [1.54829721 0.39319131 1.46514571]
-2.3889740232162078  -  6.0247  =  -8.413674023216208
training  [-3.2289, 1.841, 2.7095]  w:  [1.54829721 0.39319131 1.46514571]
-0.30561934285657966  -  54.0111  =  -54.31671934285658
training  [1.6281, -0.9761, -4.5734]  w:  [1.54829721 0.39319131 1.46514571]
-4.563708757478456  -  7.8658  =  -12.429508757478455
training  [-1.6917, 4.8284, -1.2181]  w:  [1.54829721 0.39319131 1.46514571]
-2.5054634692995092  -  61.2837  =  -63.78916346929951
training  [3.9849, -0.9782, 2.0434]  w:  [1.54829721 0.39319131 1.46514571]
8.779068549599522  -  88.3402  =  -79.56113145040047
training  [-3.8184, 1.2067, 2.2951]  w:  [1.54829721 0.39319131 1.46514571]
-2.0748981753486917  -  34.1122  =  -36.187098175348694
training  [4.8842, -3.4563, -2.7572]  w:  [1.54829721 0.39319131 1.46514571]
2.1635063391459832  -  23.7819  =  -21.618393660854018
training  [0.3998, -1.1865, -2.3095]  w:  [1.54829721 0.39319131 1.46514571]
-3.231266287020885  -  11.4246  =  -14.655866287020885
training  [2.0692, -3.3887, 1.7303]  w:  [1.54829721 0.39319131 1.46514571]
4.406470823568373  -  42.6881  =  -38.28162917643162
training  [4.9949, 2.5811, -0.2251]  w:  [1.54829721 0.39319131 1.46514571]
8.418651497073316  -  95.9901  =  -87.57144850292669
training  [-2.1215, 3.7111, 1.2372]  w:  [1.54829721 0.39319131 1.46514571]
-0.012861986760864141  -  71.3692  =  -71.38206198676087
training  [-0.8548, -1.4922, -2.6356]  w:  [1.54829721 0.39319131 1.46514571]
-5.771742561274521  -  4.7821  =  -10.553842561274521
training  [-0.3516, 1.8554, -3.2288]  w:  [1.54829721 0.39319131 1.46514571]
-4.545516624559979  -  20.3834  =  -24.92891662455998
training  [2.6396, -2.0585, 3.2964]  w:  [1.54829721 0.39319131 1.46514571]
8.107207327666972  -  80.826  =  -72.71879267233302
training  [3.182, 0.3063, 2.6692]  w:  [1.54829721 0.39319131 1.46514571]
8.957883144016304  -  92.9483  =  -83.9904168559837
training  [-3.9978, 3.3242, 4.3448]  w:  [1.54829721 0.39319131 1.46514571]
1.483029066539168  -  79.1768  =  -77.69377093346083
training  [-3.2188, 0.9749, -3.9211]  w:  [1.54829721 0.39319131 1.46514571]
-10.345319696649316  -  2.7053  =  -13.050619696649315
training  [-1.4037, -1.6469, -3.1777]  w:  [1.54829721 0.39319131 1.46514571]
-7.476685083873838  -  2.6234  =  -10.10008508387384
training  [-4.433, -2.0077, -4.009]  w:  [1.54829721 0.39319131 1.46514571]
-13.526780864873716  -  0.3253  =  -13.852080864873717
training  [0.2189, -0.4741, -0.1024]  w:  [1.54829721 0.39319131 1.46514571]
0.002479338701211087  -  33.6531  =  -33.65062066129879
training  [-1.6415, -0.7735, -3.0675]  w:  [1.54829721 0.39319131 1.46514571]
-7.339997814289896  -  3.7641  =  -11.104097814289897
training  [-3.2433, -1.4039, 3.9589]  w:  [1.54829721 0.39319131 1.46514571]
0.2267717588294973  -  30.0658  =  -29.839028241170503
training  [-2.9105, 0.5832, -4.0091]  w:  [1.54829721 0.39319131 1.46514571]
-10.150925525759277  -  2.4887  =  -12.639625525759277
training  [4.0515, 2.4255, -4.5583]  w:  [1.54829721 0.39319131 1.46514571]
0.5480379420293184  -  61.2853  =  -60.73726205797068
training  [1.7539, -0.7567, 0.573]  w:  [1.54829721 0.39319131 1.46514571]
3.257559101112437  -  57.0797  =  -53.82214089888757
training  [-0.3153, -0.7064, 2.725]  w:  [1.54829721 0.39319131 1.46514571]
3.226593619499684  -  58.7004  =  -55.47380638050032
training  [4.1213, -3.7513, -1.8806]  w:  [1.54829721 0.39319131 1.46514571]
2.15066569708455  -  22.1789  =  -20.02823430291545
training  [-3.9599, -4.7557, -3.2102]  w:  [1.54829721 0.39319131 1.46514571]
-12.70441277303371  -  0.1558  =  -12.860212773033709
training  [2.4555, -2.0981, -1.6104]  w:  [1.54829721 0.39319131 1.46514571]
0.617418451809201  -  24.4796  =  -23.8621815481908
training  [2.3627, -1.8248, -2.8985]  w:  [1.54829721 0.39319131 1.46514571]
-1.3060585375785951  -  15.7052  =  -17.011258537578595
training  [0.6186, 1.5369, 0.1015]  w:  [1.54829721 0.39319131 1.46514571]
1.7107846613665865  -  65.2154  =  -63.504615338633414
training  [-3.1581, 4.5694, 4.0636]  w:  [1.54829721 0.39319131 1.46514571]
2.860737071522549  -  90.3564  =  -87.49566292847744
training  [0.9721, 4.3573, 1.2892]  w:  [1.54829721 0.39319131 1.46514571]
5.10721804949905  -  94.3178  =  -89.21058195050095
training  [-2.0006, -0.4211, -3.9847]  w:  [1.54829721 0.39319131 1.46514571]
-9.101262372305428  -  2.4051  =  -11.506362372305428
training  [-3.6588, -2.5952, -1.0915]  w:  [1.54829721 0.39319131 1.46514571]
-8.284526443252052  -  1.5176  =  -9.802126443252051
training  [-2.874, 2.639, -4.4538]  w:  [1.54829721 0.39319131 1.46514571]
-9.937640287204985  -  5.497  =  -15.434640287204985
training  [3.9494, 2.5933, 0.0128]  w:  [1.54829721 0.39319131 1.46514571]
7.153261867242901  -  94.1462  =  -86.99293813275709
training  [-4.2855, 2.4065, -0.6828]  w:  [1.54829721 0.39319131 1.46514571]
-6.689414288739252  -  14.4193  =  -21.10871428873925
training  [-2.5751, 2.4369, 4.9756]  w:  [1.54829721 0.39319131 1.46514571]
4.261126770522833  -  87.1991  =  -82.93797322947717
training  [-4.4625, -3.9408, 3.116]  w:  [1.54829721 0.39319131 1.46514571]
-3.893370543161482  -  4.1344  =  -8.027770543161482
training  [-0.5828, 1.8156, -0.1435]  w:  [1.54829721 0.39319131 1.46514571]
-0.39871788434521727  -  51.1166  =  -51.515317884345215
training  [-4.8672, -0.3674, 3.9445]  w:  [1.54829721 0.39319131 1.46514571]
-1.9010633825059564  -  24.1396  =  -26.040663382505958
training  [3.9719, -2.8784, -3.6245]  w:  [1.54829721 0.39319131 1.46514571]
-0.29250082241593756  -  14.6104  =  -14.902900822415937
training  [-3.0334, -4.0148, -1.1]  w:  [1.54829721 0.39319131 1.46514571]
-7.886849488699523  -  1.021  =  -8.907849488699522
training  [-4.0663, 3.2357, 4.2736]  w:  [1.54829721 0.39319131 1.46514571]
1.237854902485517  -  77.2328  =  -75.99494509751447
training  [-1.9263, -3.2499, 4.1749]  w:  [1.54829721 0.39319131 1.46514571]
1.8565195002918626  -  26.8814  =  -25.024880499708136
training  [-0.4394, -3.3643, 2.1357]  w:  [1.54829721 0.39319131 1.46514571]
1.125976392478838  -  20.85  =  -19.724023607521165
training  [-3.9833, 1.6599, 1.1834]  w:  [1.54829721 0.39319131 1.46514571]
-3.7808205733763316  -  25.5397  =  -29.32052057337633
training  [4.9539, 3.9439, -1.5671]  w:  [1.54829721 0.39319131 1.46514571]
6.924786878093037  -  95.9509  =  -89.02611312190697
training  [-1.6791, 0.1656, 4.3603]  w:  [1.54829721 0.39319131 1.46514571]
3.8538414941448607  -  71.5733  =  -67.71945850585514
training  [-2.0265, 2.027, -3.7523]  w:  [1.54829721 0.39319131 1.46514571]
-7.83829176737746  -  8.503  =  -16.34129176737746
training  [-4.3795, -3.4641, 2.3059]  w:  [1.54829721 0.39319131 1.46514571]
-4.764342121064028  -  3.6654  =  -8.429742121064027
training  [-2.0176, 4.5346, 1.4648]  w:  [1.54829721 0.39319131 1.46514571]
0.8052662986016024  -  81.6212  =  -80.8159337013984
training  [-4.5365, 0.4088, 3.3315]  w:  [1.54829721 0.39319131 1.46514571]
-1.981980725976893  -  28.9449  =  -30.926880725976893
training  [0.0543, 1.7973, -1.0172]  w:  [1.54829721 0.39319131 1.46514571]
-0.6995909447423267  -  47.9317  =  -48.631290944742325
training  [2.6143, -4.6344, 2.4982]  w:  [1.54829721 0.39319131 1.46514571]
5.885734612339451  -  43.5132  =  -37.62746538766055
training  [1.3107, 3.092, 3.3522]  w:  [1.54829721 0.39319131 1.46514571]
8.156562128493132  -  96.6993  =  -88.54273787150686
training  [-4.1011, 2.4862, -1.7754]  w:  [1.54829721 0.39319131 1.46514571]
-7.973389142780517  -  10.0187  =  -17.992089142780518
training  [-4.1914, -3.7981, 0.5226]  w:  [1.54829721 0.39319131 1.46514571]
-7.217227663140563  -  1.4295  =  -8.646727663140563
training  [2.7724, 0.2505, 4.7913]  w:  [1.54829721 0.39319131 1.46514571]
11.410946251017531  -  96.7925  =  -85.38155374898247
training  [4.0513, -1.7417, 0.4931]  w:  [1.54829721 0.39319131 1.46514571]
6.3102585222838155  -  71.1234  =  -64.81314147771619
training  [0.3377, 0.4645, -1.6958]  w:  [1.54829721 0.39319131 1.46514571]
-1.7790967714649475  -  27.9534  =  -29.732496771464945
training  [-3.9085, -1.0112, 1.1947]  w:  [1.54829721 0.39319131 1.46514571]
-4.698705096154894  -  8.608  =  -13.306705096154895
training  [3.2581, -0.8491, -1.3936]  w:  [1.54829721 0.39319131 1.46514571]
2.6688213224820063  -  50.1924  =  -47.523578677517996
training  [-1.619, -3.1926, 2.5651]  w:  [1.54829721 0.39319131 1.46514571]
-0.0037504751631729505  -  16.4754  =  -16.479150475163173
training  [-2.0603, -2.4461, -0.861]  w:  [1.54829721 0.39319131 1.46514571]
-5.413232448697794  -  3.9784  =  -9.391632448697795
training  [2.4631, -4.7946, -0.0765]  w:  [1.54829721 0.39319131 1.46514571]
1.816332160175194  -  15.394  =  -13.577667839824805
training  [-4.8966, 4.2368, 1.9474]  w:  [1.54829721 0.39319131 1.46514571]
-3.0622944076977077  -  53.5883  =  -56.6505944076977
training  [-4.5155, 1.537, 4.7273]  w:  [1.54829721 0.39319131 1.46514571]
0.5391823341817821  -  59.2523  =  -58.71311766581822
training  [1.6792, 4.3261, -1.7225]  w:  [1.54829721 0.39319131 1.46514571]
1.7771720913028095  -  83.7729  =  -81.99572790869719
training  [1.0347, -3.3649, 3.378]  w:  [1.54829721 0.39319131 1.46514571]
5.228235908330857  -  50.5979  =  -45.369664091669144
training  [0.261, 4.211, 2.3907]  w:  [1.54829721 0.39319131 1.46514571]
5.562558020922625  -  94.9375  =  -89.37494197907738
training  [2.2971, 2.9466, 4.5417]  w:  [1.54829721 0.39319131 1.46514571]
11.369423302057424  -  98.7784  =  -87.40897669794258
training  [2.0725, 0.7739, -4.6808]  w:  [1.54829721 0.39319131 1.46514571]
-3.3449173413040594  -  19.5109  =  -22.85581734130406
training  [2.8138, -0.5996, -1.4313]  w:  [1.54829721 0.39319131 1.46514571]
2.0237781115839555  -  47.2879  =  -45.26412188841604
training  [-2.1202, -2.4239, 1.6265]  w:  [1.54829721 0.39319131 1.46514571]
-1.8526966432741587  -  12.3599  =  -14.212596643274159
training  [1.9253, 2.5195, -2.185]  w:  [1.54829721 0.39319131 1.46514571]
0.7702387260761041  -  65.2467  =  -64.4764612739239
training  [0.5667, -2.7133, -2.6962]  w:  [1.54829721 0.39319131 1.46514571]
-4.139751818198901  -  5.1106  =  -9.2503518181989
training  [-1.0348, -4.3581, 2.1113]  w:  [1.54829721 0.39319131 1.46514571]
-0.22238284036097244  -  10.5192  =  -10.741582840360973
training  [-4.3841, 2.6733, 1.2457]  w:  [1.54829721 0.39319131 1.46514571]
-3.9116394450344174  -  32.4639  =  -36.37553944503442
training  [2.8018, 1.712, 0.9061]  w:  [1.54829721 0.39319131 1.46514571]
6.3387311600898135  -  90.1138  =  -83.77506883991019
training  [-1.6242, 2.1521, 1.6044]  w:  [1.54829721 0.39319131 1.46514571]
0.6821224718611125  -  63.7879  =  -63.10577752813889
training  [1.0787, 1.4206, -4.5245]  w:  [1.54829721 0.39319131 1.46514571]
-4.400336011419346  -  18.0555  =  -22.455836011419343
training  [2.4125, -0.8095, -1.5122]  w:  [1.54829721 0.39319131 1.46514571]
1.201385299270644  -  38.8276  =  -37.62621470072935
training  [-3.9519, -1.0924, -0.4866]  w:  [1.54829721 0.39319131 1.46514571]
-7.2611778162708704  -  3.6777  =  -10.938877816270871
training  [-3.7211, 3.1614, -2.591]  w:  [1.54829721 0.39319131 1.46514571]
-8.31452627746034  -  11.1518  =  -19.46632627746034
training  [0.4954, -1.8257, 2.1505]  w:  [1.54829721 0.39319131 1.46514571]
3.1999729222958213  -  47.7531  =  -44.55312707770418
training  [-0.1477, 3.1454, 3.5618]  w:  [1.54829721 0.39319131 1.46514571]
6.226616440470693  -  94.1572  =  -87.93058355952931
training  [3.9048, 2.8907, -2.1849]  w:  [1.54829721 0.39319131 1.46514571]
3.9811921731559816  -  85.8791  =  -81.89790782684402
training  [2.9896, 3.5226, 2.3105]  w:  [1.54829721 0.39319131 1.46514571]
9.399064195297056  -  98.038  =  -88.63893580470294
training  [2.3434, 0.0564, -3.6224]  w:  [1.54829721 0.39319131 1.46514571]
-1.6568881684018288  -  24.7629  =  -26.419788168401826
training  [-4.4867, 1.3566, 3.3672]  w:  [1.54829721 0.39319131 1.46514571]
-1.479903102311538  -  40.5785  =  -42.05840310231154
training  [-4.2711, 4.5089, -3.614]  w:  [1.54829721 0.39319131 1.46514571]
-10.135108518862172  -  10.0825  =  -20.21760851886217
training  [-4.1147, -0.5604, 0.8821]  w:  [1.54829721 0.39319131 1.46514571]
-5.298717888682895  -  8.344  =  -13.642717888682895
training  [2.9835, -4.3998, -1.3384]  w:  [1.54829721 0.39319131 1.46514571]
0.9284305790104723  -  13.2692  =  -12.340769420989528
training  [4.4301, 3.6675, 3.0676]  w:  [1.54829721 0.39319131 1.46514571]
12.7956215602674  -  99.3834  =  -86.5877784397326
training  [1.8372, 1.3119, 0.0378]  w:  [1.54829721 0.39319131 1.46514571]
3.415741810614157  -  74.9026  =  -71.48685818938586
training  [-3.6792, -1.4493, -0.1041]  w:  [1.54829721 0.39319131 1.46514571]
-6.418868910469898  -  4.2442  =  -10.6630689104699
training  [2.2272, 4.97, 3.7705]  w:  [1.54829721 0.39319131 1.46514571]
10.926860244252367  -  99.3199  =  -88.39303975574764
training  [-3.8965, -2.7583, -1.4686]  w:  [1.54829721 0.39319131 1.46514571]
-9.269192639674591  -  1.0337  =  -10.30289263967459
training  [-3.8251, 1.5245, -0.5056]  w:  [1.54829721 0.39319131 1.46514571]
-6.063749167592138  -  12.9762  =  -19.039949167592138
training  [1.4072, 1.0499, 4.6353]  w:  [1.54829721 0.39319131 1.46514571]
9.382965305012329  -  95.4618  =  -86.07883469498766
training  [-1.7119, -1.1275, -4.577]  w:  [1.54829721 0.39319131 1.46514571]
-9.79982511404971  -  1.4655  =  -11.26532511404971
training  [1.5381, -3.5781, 4.7296]  w:  [1.54829721 0.39319131 1.46514571]
7.9041112808412235  -  69.9473  =  -62.04318871915878
training  [2.4913, -4.7487, -3.1079]  w:  [1.54829721 0.39319131 1.46514571]
-2.5634010919589416  -  3.9825  =  -6.5459010919589415
training  [0.8319, -0.7889, 1.6712]  w:  [1.54829721 0.39319131 1.46514571]
3.4263913390712086  -  58.8336  =  -55.40720866092879
training  [2.4003, -3.159, 0.8644]  w:  [1.54829721 0.39319131 1.46514571]
3.740758398846149  -  39.0041  =  -35.263341601153854
training  [-2.6517, 2.2578, 1.7511]  w:  [1.54829721 0.39319131 1.46514571]
-0.6522557100729016  -  54.4525  =  -55.1047557100729
training  [2.3496, -1.2964, -1.3898]  w:  [1.54829721 0.39319131 1.46514571]
1.0918863928630564  -  33.888  =  -32.796113607136945
training  [4.706, 3.4156, 1.2028]  w:  [1.54829721 0.39319131 1.46514571]
10.391548143582787  -  98.4665  =  -88.07495185641721
training  [3.6693, 2.3423, 3.1115]  w:  [1.54829721 0.39319131 1.46514571]
11.160939822581547  -  98.3069  =  -87.14596017741846
training  [-4.1377, 0.7103, -4.8074]  w:  [1.54829721 0.39319131 1.46514571]
-13.17064706453393  -  0.9782  =  -14.14884706453393
training  [-1.3356, -3.2314, -4.1613]  w:  [1.54829721 0.39319131 1.46514571]
-9.435374993505413  -  0.7659  =  -10.201274993505413
training  [-1.308, 4.5738, 4.748]  w:  [1.54829721 0.39319131 1.46514571]
6.729717500100479  -  97.0884  =  -90.35868249989952
training  [1.8503, -2.3468, 1.5135]  w:  [1.54829721 0.39319131 1.46514571]
4.159570997443684  -  50.2125  =  -46.05292900255631
training  [0.9794, 4.2458, -2.6876]  w:  [1.54829721 0.39319131 1.46514571]
-0.7519116830304382  -  68.3262  =  -69.07811168303044
training  [2.8936, -2.7623, -0.9651]  w:  [1.54829721 0.39319131 1.46514571]
1.9800283201921098  -  28.5596  =  -26.57957167980789
training  [-1.3235, -1.2644, -3.7798]  w:  [1.54829721 0.39319131 1.46514571]
-8.08428020677971  -  2.4511  =  -10.53538020677971
training  [-2.9397, -4.125, -2.3156]  w:  [1.54829721 0.39319131 1.46514571]
-9.566134851238756  -  0.554  =  -10.120134851238756
training  [-4.1333, 1.4012, -2.4215]  w:  [1.54829721 0.39319131 1.46514571]
-9.396487526156779  -  4.4072  =  -13.803687526156779
training  [2.7193, -3.1938, -1.6833]  w:  [1.54829721 0.39319131 1.46514571]
0.4882304171118754  -  17.0949  =  -16.606669582888124
training  [-2.9433, -4.5495, -3.4777]  w:  [1.54829721 0.39319131 1.46514571]
-11.441264264095015  -  0.2509  =  -11.692164264095014
training  [-1.1173, 2.2317, -1.5199]  w:  [1.54829721 0.39319131 1.46514571]
-3.0793023974379947  -  33.1206  =  -36.199902397437995
training  [0.5178, -1.5256, -3.7834]  w:  [1.54829721 0.39319131 1.46514571]
-5.341376655308479  -  5.237  =  -10.578376655308478
training  [-2.7105, 1.6062, 3.8415]  w:  [1.54829721 0.39319131 1.46514571]
2.063241556939912  -  70.4458  =  -68.38255844306009
training  [1.4194, -1.1613, -4.0572]  w:  [1.54829721 0.39319131 1.46514571]
-4.20334919740447  -  8.3206  =  -12.52394919740447
training  [-0.1552, 1.2735, 4.3004]  w:  [1.54829721 0.39319131 1.46514571]
6.561146027309267  -  90.1085  =  -83.54735397269074
training  [-3.4815, -4.7835, -1.0098]  w:  [1.54829721 0.39319131 1.46514571]
-8.750731481160333  -  0.5839  =  -9.334631481160333
training  [2.8193, 4.1057, -4.526]  w:  [1.54829721 0.39319131 1.46514571]
-0.6518096345426709  -  66.8081  =  -67.45990963454267
training  [-3.9939, 3.0056, -1.5763]  w:  [1.54829721 0.39319131 1.46514571]
-7.311477605941737  -  14.4018  =  -21.713277605941737
training  [-2.0593, 2.4585, 2.3597]  w:  [1.54829721 0.39319131 1.46514571]
1.2355567310275326  -  70.6698  =  -69.43424326897247
training  [-2.6263, 3.1311, 2.9468]  w:  [1.54829721 0.39319131 1.46514571]
1.4823197364491136  -  77.309  =  -75.82668026355088
training  [0.3087, -1.1669, 0.4491]  w:  [1.54829721 0.39319131 1.46514571]
0.677141350966362  -  33.0798  =  -32.40265864903364
training  [-4.085, 1.1728, 1.8622]  w:  [1.54829721 0.39319131 1.46514571]
-3.135264974934807  -  26.4056  =  -29.540864974934806
training  [-0.9468, 0.7549, 3.9363]  w:  [1.54829721 0.39319131 1.46514571]
4.5981453930726035  -  79.7738  =  -75.1756546069274
training  [-3.9515, 0.3005, -4.4521]  w:  [1.54829721 0.39319131 1.46514571]
-12.522917650591609  -  1.0441  =  -13.567017650591609
training  [-3.8772, -2.2493, -1.9634]  w:  [1.54829721 0.39319131 1.46514571]
-9.7641302270782  -  1.0509  =  -10.8150302270782
training  [2.8443, -2.5137, -4.5381]  w:  [1.54829721 0.39319131 1.46514571]
-3.233521005615271  -  6.8897  =  -10.123221005615271
training  [-2.0843, -0.4836, -3.0452]  w:  [1.54829721 0.39319131 1.46514571]
-7.878924907793791  -  3.5346  =  -11.413524907793791
training  [1.0353, -2.7229, 2.2017]  w:  [1.54829721 0.39319131 1.46514571]
3.758142803618062  -  43.9562  =  -40.19805719638194
training  [4.6442, 3.0445, 2.2175]  w:  [1.54829721 0.39319131 1.46514571]
11.63663343715729  -  98.8492  =  -87.21256656284271
training  [-0.6752, 4.861, 3.778]  w:  [1.54829721 0.39319131 1.46514571]
6.401213173870573  -  97.017  =  -90.61578682612942
training  [1.9475, -4.7001, 0.8243]  w:  [1.54829721 0.39319131 1.46514571]
2.3749899575254148  -  18.7839  =  -16.408910042474584
training  [2.581, 0.3566, -4.2932]  w:  [1.54829721 0.39319131 1.46514571]
-2.1537964661346924  -  23.5455  =  -25.699296466134694
training  [-0.6736, -4.1292, 4.2274]  w:  [1.54829721 0.39319131 1.46514571]
3.527258443889985  -  31.2667  =  -27.739441556110016
training  [1.555, 3.0209, 3.0037]  w:  [1.54829721 0.39319131 1.46514571]
7.996251953015878  -  96.4078  =  -88.41154804698412
training  [-3.9024, 4.8914, -2.1405]  w:  [1.54829721 0.39319131 1.46514571]
-7.254963455961686  -  25.4308  =  -32.68576345596169
training  [4.3376, -4.3305, 0.4366]  w:  [1.54829721 0.39319131 1.46514571]
5.652861623811352  -  43.0907  =  -37.437838376188644
training  [-3.1254, 4.394, 4.8478]  w:  [1.54829721 0.39319131 1.46514571]
3.9913679030192144  -  92.8121  =  -88.82073209698079
training  [-2.3382, -4.8182, 2.1568]  w:  [1.54829721 0.39319131 1.46514571]
-2.3546766091370985  -  4.7434  =  -7.098076609137099
training  [2.9783, 1.8384, 3.3897]  w:  [1.54829721 0.39319131 1.46514571]
10.300540890934236  -  97.3486  =  -87.04805910906578
training  [-0.124, 2.8374, -0.6674]  w:  [1.54829721 0.39319131 1.46514571]
-0.05418608767868027  -  62.785  =  -62.83918608767868
training  [2.6896, 0.3414, -0.2938]  w:  [1.54829721 0.39319131 1.46514571]
3.868075867078899  -  70.4455  =  -66.5774241329211
training  [-1.0399, 3.8536, 0.6071]  w:  [1.54829721 0.39319131 1.46514571]
0.7946177187802259  -  77.0369  =  -76.24228228121977
training  [-2.2706, 3.99, -2.3091]  w:  [1.54829721 0.39319131 1.46514571]
-5.329898286587966  -  31.1134  =  -36.44329828658796
training  [-4.6277, 1.2594, 2.4902]  w:  [1.54829721 0.39319131 1.46514571]
-3.0213639936956906  -  28.1093  =  -31.13066399369569
training  [1.7329, -3.6213, 0.0389]  w:  [1.54829721 0.39319131 1.46514571]
1.31617471621536  -  19.3919  =  -18.07572528378464
training  [-0.7044, -2.822, 1.4681]  w:  [1.54829721 0.39319131 1.46514571]
-0.04922599927450655  -  17.8122  =  -17.86142599927451
training  [-0.4826, -3.1786, -1.9225]  w:  [1.54829721 0.39319131 1.46514571]
-4.813748753526967  -  3.5851  =  -8.398848753526968
training  [1.0986, -4.5818, -3.6128]  w:  [1.54829721 0.39319131 1.46514571]
-5.393843052118895  -  1.7158  =  -7.109643052118895
training  [-4.406, -3.9306, -0.2443]  w:  [1.54829721 0.39319131 1.46514571]
-8.725210339028378  -  0.8241  =  -9.549310339028377
training  [-1.8419, 1.1644, -1.3754]  w:  [1.54829721 0.39319131 1.46514571]
-4.409138079443345  -  17.8517  =  -22.260838079443346
training  [2.7272, 4.3966, 2.8811]  w:  [1.54829721 0.39319131 1.46514571]
10.17245235465484  -  98.904  =  -88.73154764534516
training  [1.9643, -1.4554, 2.803]  w:  [1.54829721 0.39319131 1.46514571]
6.575873006955272  -  76.0591  =  -69.48322699304472
training  [-3.7467, -0.8937, 1.6851]  w:  [1.54829721 0.39319131 1.46514571]
-3.68348317199126  -  12.1571  =  -15.840583171991259
training  [-3.6985, 4.8435, -3.665]  w:  [1.54829721 0.39319131 1.46514571]
-9.191714158706834  -  14.6793  =  -23.871014158706835
251269.74176080382
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.50393805 0.43392332 1.39640291]
11.18979337685225  -  87.3174  =  -76.12760662314776
training  [-4.1793, -4.9218, 1.7664]  w:  [1.50393805 0.43392332 1.39640291]
-5.954485997950333  -  1.5257  =  -7.480185997950333
training  [-3.9429, -0.7689, 4.883]  w:  [1.50393805 0.43392332 1.39640291]
0.5551144400507049  -  39.7859  =  -39.2307855599493
training  [-3.5796, 1.5557, 2.6683]  w:  [1.50393805 0.43392332 1.39640291]
-0.9824202396311801  -  45.5674  =  -46.54982023963118
training  [-3.3354, 2.2292, -1.633]  w:  [1.50393805 0.43392332 1.39640291]
-6.32925905565361  -  13.3589  =  -19.68815905565361
training  [1.2096, 0.3121, 1.6238]  w:  [1.50393805 0.43392332 1.39640291]
4.222069982751162  -  74.5119  =  -70.28983001724883
training  [0.7371, -3.9118, -2.5583]  w:  [1.50393805 0.43392332 1.39640291]
-4.161286087548351  -  3.3358  =  -7.497086087548351
training  [-4.4792, 1.3177, -2.0449]  w:  [1.50393805 0.43392332 1.39640291]
-9.020162865270795  -  4.2974  =  -13.317562865270794
training  [4.312, -3.735, 1.8018]  w:  [1.50393805 0.43392332 1.39640291]
7.380316027209977  -  66.5833  =  -59.202983972790015
training  [2.2866, -3.657, 0.2785]  w:  [1.50393805 0.43392332 1.39640291]
2.2409453642898143  -  26.0005  =  -23.759554635710185
training  [2.3784, -4.0141, -0.8841]  w:  [1.50393805 0.43392332 1.39640291]
0.6005948331174409  -  14.6809  =  -14.080305166882559
training  [-4.366, -3.5797, 1.0264]  w:  [1.50393805 0.43392332 1.39640291]
-6.686240895259221  -  1.8713  =  -8.557540895259221
training  [3.6044, -3.3175, 2.5052]  w:  [1.50393805 0.43392332 1.39640291]
7.479522258766543  -  71.0139  =  -63.53437774123346
training  [4.3441, -3.0375, 0.8353]  w:  [1.50393805 0.43392332 1.39640291]
6.381630541744222  -  63.8979  =  -57.51626945825578
training  [4.844, -1.8252, 0.5179]  w:  [1.50393805 0.43392332 1.39640291]
7.216276132795403  -  78.0461  =  -70.8298238672046
training  [3.5894, -1.8357, 0.8357]  w:  [1.50393805 0.43392332 1.39640291]
5.76865610603814  -  68.8838  =  -63.11514389396186
training  [2.8556, -2.8244, 0.1182]  w:  [1.50393805 0.43392332 1.39640291]
3.2341272864042967  -  39.5252  =  -36.2910727135957
training  [0.1338, -2.4896, -4.1741]  w:  [1.50393805 0.43392332 1.39640291]
-6.707793988655966  -  2.2644  =  -8.972193988655967
training  [-3.224, 3.9292, 2.1957]  w:  [1.50393805 0.43392332 1.39640291]
-0.07764287869020414  -  72.1211  =  -72.1987428786902
training  [-1.0141, 2.0322, 4.9616]  w:  [1.50393805 0.43392332 1.39640291]
6.285068088793795  -  92.3427  =  -86.0576319112062
training  [-3.6607, 0.5574, -1.4547]  w:  [1.50393805 0.43392332 1.39640291]
-7.294944475099075  -  5.8471  =  -13.142044475099075
training  [-4.6911, -3.1557, 4.7126]  w:  [1.50393805 0.43392332 1.39640291]
-1.8437672519119026  -  11.2337  =  -13.077467251911903
training  [4.3914, -2.8797, -1.5355]  w:  [1.50393805 0.43392332 1.39640291]
3.210647887897492  -  37.475  =  -34.26435211210251
training  [-1.9869, -4.2265, 3.8654]  w:  [1.50393805 0.43392332 1.39640291]
0.5755043812935732  -  15.7889  =  -15.213395618706427
training  [-2.0447, 4.138, -0.4531]  w:  [1.50393805 0.43392332 1.39640291]
-1.9122375802157245  -  57.936  =  -59.848237580215724
training  [-1.6706, 2.0672, -0.8657]  w:  [1.50393805 0.43392332 1.39640291]
-2.824338614146453  -  32.4185  =  -35.24283861414646
training  [-0.3293, 0.5779, -2.8227]  w:  [1.50393805 0.43392332 1.39640291]
-4.186109011472581  -  14.3434  =  -18.529509011472584
training  [1.482, -1.8657, -3.7435]  w:  [1.50393805 0.43392332 1.39640291]
-3.808168854833645  -  7.1519  =  -10.960068854833645
training  [-4.7477, -3.338, -1.9109]  w:  [1.50393805 0.43392332 1.39640291]
-11.25706905539195  -  0.4077  =  -11.66476905539195
training  [3.4221, 1.225, 2.261]  w:  [1.50393805 0.43392332 1.39640291]
8.835449454970213  -  95.0454  =  -86.20995054502978
training  [0.5903, 4.8793, 2.8287]  w:  [1.50393805 0.43392332 1.39640291]
6.955021617133969  -  97.4647  =  -90.50967838286603
training  [3.541, -3.2957, 1.9379]  w:  [1.50393805 0.43392332 1.39640291]
6.6014527428251615  -  64.3732  =  -57.77174725717484
training  [-1.5212, -2.4221, -4.902]  w:  [1.50393805 0.43392332 1.39640291]
-10.183963316543622  -  0.7227  =  -10.906663316543622
training  [-0.5397, -1.032, 3.4321]  w:  [1.50393805 0.43392332 1.39640291]
3.533110199898668  -  60.5921  =  -57.05898980010134
training  [-4.4576, -4.2601, 4.2233]  w:  [1.50393805 0.43392332 1.39640291]
-2.6550825798520927  -  6.0247  =  -8.679782579852093
training  [-3.2289, 1.841, 2.7095]  w:  [1.50393805 0.43392332 1.39640291]
-0.27365904158150833  -  54.0111  =  -54.28475904158151
training  [1.6281, -0.9761, -4.5734]  w:  [1.50393805 0.43392332 1.39640291]
-4.361300094519155  -  7.8658  =  -12.227100094519155
training  [-1.6917, 4.8284, -1.2181]  w:  [1.50393805 0.43392332 1.39640291]
-2.150015014298274  -  61.2837  =  -63.43371501429828
training  [3.9849, -0.9782, 2.0434]  w:  [1.50393805 0.43392332 1.39640291]
8.421988650959081  -  88.3402  =  -79.91821134904092
training  [-3.8184, 1.2067, 2.2951]  w:  [1.50393805 0.43392332 1.39640291]
-2.014137452374614  -  34.1122  =  -36.126337452374614
training  [4.8842, -3.4563, -2.7572]  w:  [1.50393805 0.43392332 1.39640291]
1.9956029332514569  -  23.7819  =  -21.786297066748542
training  [0.3998, -1.1865, -2.3095]  w:  [1.50393805 0.43392332 1.39640291]
-3.1385681156088387  -  11.4246  =  -14.563168115608839
training  [2.0692, -3.3887, 1.7303]  w:  [1.50393805 0.43392332 1.39640291]
4.057708607509555  -  42.6881  =  -38.630391392490445
training  [4.9949, 2.5811, -0.2251]  w:  [1.50393805 0.43392332 1.39640291]
8.317689358097388  -  95.9901  =  -87.67241064190262
training  [-2.1215, 3.7111, 1.2372]  w:  [1.50393805 0.43392332 1.39640291]
0.14735795333006507  -  71.3692  =  -71.22184204666993
training  [-0.8548, -1.4922, -2.6356]  w:  [1.50393805 0.43392332 1.39640291]
-5.613426142340082  -  4.7821  =  -10.395526142340081
training  [-0.3516, 1.8554, -3.2288]  w:  [1.50393805 0.43392332 1.39640291]
-4.2323890077001955  -  20.3834  =  -24.615789007700197
training  [2.6396, -2.0585, 3.2964]  w:  [1.50393805 0.43392332 1.39640291]
7.679666275721026  -  80.826  =  -73.14633372427897
training  [3.182, 0.3063, 2.6692]  w:  [1.50393805 0.43392332 1.39640291]
8.645720241256628  -  92.9483  =  -84.30257975874338
training  [-3.9978, 3.3242, 4.3448]  w:  [1.50393805 0.43392332 1.39640291]
1.4970957463880445  -  79.1768  =  -77.67970425361196
training  [-3.2188, 0.9749, -3.9211]  w:  [1.50393805 0.43392332 1.39640291]
-9.893279405943526  -  2.7053  =  -12.598579405943525
training  [-1.4037, -1.6469, -3.1777]  w:  [1.50393805 0.43392332 1.39640291]
-7.263055694566847  -  2.6234  =  -9.886455694566848
training  [-4.433, -2.0077, -4.009]  w:  [1.50393805 0.43392332 1.39640291]
-13.1363245046078  -  0.3253  =  -13.4616245046078
training  [0.2189, -0.4741, -0.1024]  w:  [1.50393805 0.43392332 1.39640291]
-0.019502666426349236  -  33.6531  =  -33.67260266642635
training  [-1.6415, -0.7735, -3.0675]  w:  [1.50393805 0.43392332 1.39640291]
-7.087819931774376  -  3.7641  =  -10.851919931774376
training  [-3.2433, -1.4039, 3.9589]  w:  [1.50393805 0.43392332 1.39640291]
0.04131225869211974  -  30.0658  =  -30.02448774130788
training  [-2.9105, 0.5832, -4.0091]  w:  [1.50393805 0.43392332 1.39640291]
-9.722466526981986  -  2.4887  =  -12.211166526981986
training  [4.0515, 2.4255, -4.5583]  w:  [1.50393805 0.43392332 1.39640291]
0.7804626342612204  -  61.2853  =  -60.50483736573878
training  [1.7539, -0.7567, 0.573]  w:  [1.50393805 0.43392332 1.39640291]
3.109546035862965  -  57.0797  =  -53.97015396413704
training  [-0.3153, -0.7064, 2.725]  w:  [1.50393805 0.43392332 1.39640291]
3.024482833058907  -  58.7004  =  -55.6759171669411
training  [4.1213, -3.7513, -1.8806]  w:  [1.50393805 0.43392332 1.39640291]
1.9443280075283789  -  22.1789  =  -20.23457199247162
training  [-3.9599, -4.7557, -3.2102]  w:  [1.50393805 0.43392332 1.39640291]
-12.50178605811983  -  0.1558  =  -12.65758605811983
training  [2.4555, -2.0981, -1.6104]  w:  [1.50393805 0.43392332 1.39640291]
0.5337381082054091  -  24.4796  =  -23.945861891794593
training  [2.3627, -1.8248, -2.8985]  w:  [1.50393805 0.43392332 1.39640291]
-1.2859426897390107  -  15.7052  =  -16.99114268973901
training  [0.6186, 1.5369, 0.1015]  w:  [1.50393805 0.43392332 1.39640291]
1.738967728014692  -  65.2154  =  -63.47643227198531
training  [-3.1581, 4.5694, 4.0636]  w:  [1.50393805 0.43392332 1.39640291]
2.9076053495107104  -  90.3564  =  -87.44879465048928
training  [0.9721, 4.3573, 1.2892]  w:  [1.50393805 0.43392332 1.39640291]
5.152954906924291  -  94.3178  =  -89.16484509307571
training  [-2.0006, -0.4211, -3.9847]  w:  [1.50393805 0.43392332 1.39640291]
-8.75575025746901  -  2.4051  =  -11.160850257469011
training  [-3.6588, -2.5952, -1.0915]  w:  [1.50393805 0.43392332 1.39640291]
-8.152900122597469  -  1.5176  =  -9.670500122597469
training  [-2.874, 2.639, -4.4538]  w:  [1.50393805 0.43392332 1.39640291]
-9.396493596150345  -  5.497  =  -14.893493596150345
training  [3.9494, 2.5933, 0.0128]  w:  [1.50393805 0.43392332 1.39640291]
7.082820244313831  -  94.1462  =  -87.06337975568616
training  [-4.2855, 2.4065, -0.6828]  w:  [1.50393805 0.43392332 1.39640291]
-6.354353944619261  -  14.4193  =  -20.773653944619262
training  [-2.5751, 2.4369, 4.9756]  w:  [1.50393805 0.43392332 1.39640291]
4.132579202505424  -  87.1991  =  -83.06652079749458
training  [-4.4625, -3.9408, 3.116]  w:  [1.50393805 0.43392332 1.39640291]
-4.0701371038644  -  4.1344  =  -8.2045371038644
training  [-0.5828, 1.8156, -0.1435]  w:  [1.50393805 0.43392332 1.39640291]
-0.289047728452119  -  51.1166  =  -51.40564772845212
training  [-4.8672, -0.3674, 3.9445]  w:  [1.50393805 0.43392332 1.39640291]
-1.9712794182890594  -  24.1396  =  -26.11087941828906
training  [3.9719, -2.8784, -3.6245]  w:  [1.50393805 0.43392332 1.39640291]
-0.3367757070088597  -  14.6104  =  -14.94717570700886
training  [-3.0334, -4.0148, -1.1]  w:  [1.50393805 0.43392332 1.39640291]
-7.840204240028742  -  1.021  =  -8.86120424002874
training  [-4.0663, 3.2357, 4.2736]  w:  [1.50393805 0.43392332 1.39640291]
1.2562498885669324  -  77.2328  =  -75.97655011143307
training  [-1.9263, -3.2499, 4.1749]  w:  [1.50393805 0.43392332 1.39640291]
1.5225992454461625  -  26.8814  =  -25.358800754553837
training  [-0.4394, -3.3643, 2.1357]  w:  [1.50393805 0.43392332 1.39640291]
0.8616190853209194  -  20.85  =  -19.988380914679084
training  [-3.9833, 1.6599, 1.1834]  w:  [1.50393805 0.43392332 1.39640291]
-3.6178639042509793  -  25.5397  =  -29.157563904250978
training  [4.9539, 3.9439, -1.5671]  w:  [1.50393805 0.43392332 1.39640291]
6.973405894363879  -  95.9509  =  -88.97749410563613
training  [-1.6791, 0.1656, 4.3603]  w:  [1.50393805 0.43392332 1.39640291]
3.6353309402857987  -  71.5733  =  -67.9379690597142
training  [-2.0265, 2.027, -3.7523]  w:  [1.50393805 0.43392332 1.39640291]
-7.407890529648519  -  8.503  =  -15.910890529648519
training  [-4.3795, -3.4641, 2.3059]  w:  [1.50393805 0.43392332 1.39640291]
-4.869684996819473  -  3.6654  =  -8.535084996819473
training  [-2.0176, 4.5346, 1.4648]  w:  [1.50393805 0.43392332 1.39640291]
0.9787742758212059  -  81.6212  =  -80.64242572417879
training  [-4.5365, 0.4088, 3.3315]  w:  [1.50393805 0.43392332 1.39640291]
-1.9931108071517194  -  28.9449  =  -30.93801080715172
training  [0.0543, 1.7973, -1.0172]  w:  [1.50393805 0.43392332 1.39640291]
-0.5588668179865277  -  47.9317  =  -48.490566817986526
training  [2.6143, -4.6344, 2.4982]  w:  [1.50393805 0.43392332 1.39640291]
5.409264751444452  -  43.5132  =  -38.103935248555544
training  [1.3107, 3.092, 3.3522]  w:  [1.50393805 0.43392332 1.39640291]
7.9939243578663755  -  96.6993  =  -88.70537564213362
training  [-4.1011, 2.4862, -1.7754]  w:  [1.50393805 0.43392332 1.39640291]
-7.568153901132873  -  10.0187  =  -17.586853901132873
training  [-4.1914, -3.7981, 0.5226]  w:  [1.50393805 0.43392332 1.39640291]
-7.221929952559418  -  1.4295  =  -8.651429952559418
training  [2.7724, 0.2505, 4.7913]  w:  [1.50393805 0.43392332 1.39640291]
10.968800914340786  -  96.7925  =  -85.82369908565921
training  [4.0513, -1.7417, 0.4931]  w:  [1.50393805 0.43392332 1.39640291]
6.025706245924579  -  71.1234  =  -65.09769375407542
training  [0.3377, 0.4645, -1.6958]  w:  [1.50393805 0.43392332 1.39640291]
-1.6585827954226513  -  27.9534  =  -29.611982795422648
training  [-3.9085, -1.0112, 1.1947]  w:  [1.50393805 0.43392332 1.39640291]
-4.648642572746683  -  8.608  =  -13.256642572746683
training  [3.2581, -0.8491, -1.3936]  w:  [1.50393805 0.43392332 1.39640291]
2.5855091685179517  -  50.1924  =  -47.60689083148205
training  [-1.619, -3.1926, 2.5651]  w:  [1.50393805 0.43392332 1.39640291]
-0.23830619329724234  -  16.4754  =  -16.71370619329724
training  [-2.0603, -2.4461, -0.861]  w:  [1.50393805 0.43392332 1.39640291]
-5.362286311272094  -  3.9784  =  -9.340686311272094
training  [2.4631, -4.7946, -0.0765]  w:  [1.50393805 0.43392332 1.39640291]
1.5170362242833655  -  15.394  =  -13.876963775716634
training  [-4.8966, 4.2368, 1.9474]  w:  [1.50393805 0.43392332 1.39640291]
-2.806381689820783  -  53.5883  =  -56.39468168982078
training  [-4.5155, 1.537, 4.7273]  w:  [1.50393805 0.43392332 1.39640291]
0.47712336934824595  -  59.2523  =  -58.77517663065175
training  [1.6792, 4.3261, -1.7225]  w:  [1.50393805 0.43392332 1.39640291]
1.9973044440030572  -  83.7729  =  -81.77559555599694
training  [1.0347, -3.3649, 3.378]  w:  [1.50393805 0.43392332 1.39640291]
4.813065148258644  -  50.5979  =  -45.78483485174136
training  [0.261, 4.211, 2.3907]  w:  [1.50393805 0.43392332 1.39640291]
5.558159385208153  -  94.9375  =  -89.37934061479184
training  [2.2971, 2.9466, 4.5417]  w:  [1.50393805 0.43392332 1.39640291]
11.075337663000159  -  98.7784  =  -87.70306233699985
training  [2.0725, 0.7739, -4.6808]  w:  [1.50393805 0.43392332 1.39640291]
-3.0835578830293207  -  19.5109  =  -22.59445788302932
training  [2.8138, -0.5996, -1.4313]  w:  [1.50393805 0.43392332 1.39640291]
1.972928972229062  -  47.2879  =  -45.31497102777094
training  [-2.1202, -2.4239, 1.6265]  w:  [1.50393805 0.43392332 1.39640291]
-1.9691868589105077  -  12.3599  =  -14.329086858910507
training  [1.9253, 2.5195, -2.185]  w:  [1.50393805 0.43392332 1.39640291]
0.9376613762645065  -  65.2467  =  -64.3090386237355
training  [0.5667, -2.7133, -2.6962]  w:  [1.50393805 0.43392332 1.39640291]
-4.090063990440001  -  5.1106  =  -9.20066399044
training  [-1.0348, -4.3581, 2.1113]  w:  [1.50393805 0.43392332 1.39640291]
-0.49913085880433883  -  10.5192  =  -11.018330858804338
training  [-4.3841, 2.6733, 1.2457]  w:  [1.50393805 0.43392332 1.39640291]
-3.693908477878157  -  32.4639  =  -36.15780847787816
training  [2.8018, 1.712, 0.9061]  w:  [1.50393805 0.43392332 1.39640291]
6.22189103529299  -  90.1138  =  -83.89190896470701
training  [-1.6242, 2.1521, 1.6044]  w:  [1.50393805 0.43392332 1.39640291]
0.7315390345821939  -  63.7879  =  -63.05636096541781
training  [1.0787, 1.4206, -4.5245]  w:  [1.50393805 0.43392332 1.39640291]
-4.079295528945155  -  18.0555  =  -22.134795528945155
training  [2.4125, -0.8095, -1.5122]  w:  [1.50393805 0.43392332 1.39640291]
1.16534913178748  -  38.8276  =  -37.66225086821252
training  [-3.9519, -1.0924, -0.4866]  w:  [1.50393805 0.43392332 1.39640291]
-7.096920273988584  -  3.6777  =  -10.774620273988583
training  [-3.7211, 3.1614, -2.591]  w:  [1.50393805 0.43392332 1.39640291]
-7.842578629727271  -  11.1518  =  -18.994378629727272
training  [0.4954, -1.8257, 2.1505]  w:  [1.50393805 0.43392332 1.39640291]
2.955801561865893  -  47.7531  =  -44.79729843813411
training  [-0.1477, 3.1454, 3.5618]  w:  [1.50393805 0.43392332 1.39640291]
6.116438661793123  -  94.1572  =  -88.04076133820688
training  [3.9048, 2.8907, -2.1849]  w:  [1.50393805 0.43392332 1.39640291]
4.075918723629736  -  85.8791  =  -81.80318127637025
training  [2.9896, 3.5226, 2.3105]  w:  [1.50393805 0.43392332 1.39640291]
9.251100419027876  -  98.038  =  -88.78689958097212
training  [2.3434, 0.0564, -3.6224]  w:  [1.50393805 0.43392332 1.39640291]
-1.5095282072997054  -  24.7629  =  -26.272428207299704
training  [-4.4867, 1.3566, 3.3672]  w:  [1.50393805 0.43392332 1.39640291]
-1.45709058295947  -  40.5785  =  -42.03559058295947
training  [-4.2711, 4.5089, -3.614]  w:  [1.50393805 0.43392332 1.39640291]
-9.513553058715093  -  10.0825  =  -19.596053058715093
training  [-4.1147, -0.5604, 0.8821]  w:  [1.50393805 0.43392332 1.39640291]
-5.199657515018778  -  8.344  =  -13.543657515018777
training  [2.9835, -4.3998, -1.3384]  w:  [1.50393805 0.43392332 1.39640291]
0.7088776785149731  -  13.2692  =  -12.560322321485026
training  [4.4301, 3.6675, 3.0676]  w:  [1.50393805 0.43392332 1.39640291]
12.537615314020806  -  99.3834  =  -86.84578468597918
training  [1.8372, 1.3119, 0.0378]  w:  [1.50393805 0.43392332 1.39640291]
3.3850830224162065  -  74.9026  =  -71.5175169775838
training  [-3.6792, -1.4493, -0.1041]  w:  [1.50393805 0.43392332 1.39640291]
-6.3075394878376265  -  4.2442  =  -10.551739487837626
training  [2.2272, 4.97, 3.7705]  w:  [1.50393805 0.43392332 1.39640291]
10.771306918878812  -  99.3199  =  -88.5485930811212
training  [-3.8965, -2.7583, -1.4686]  w:  [1.50393805 0.43392332 1.39640291]
-9.107742629134732  -  1.0337  =  -10.141442629134731
training  [-3.8251, 1.5245, -0.5056]  w:  [1.50393805 0.43392332 1.39640291]
-5.797218641164592  -  12.9762  =  -18.773418641164593
training  [1.4072, 1.0499, 4.6353]  w:  [1.50393805 0.43392332 1.39640291]
9.044664138666986  -  95.4618  =  -86.41713586133301
training  [-1.7119, -1.1275, -4.577]  w:  [1.50393805 0.43392332 1.39640291]
-9.455176222527498  -  1.4655  =  -10.920676222527499
training  [1.5381, -3.5781, 4.7296]  w:  [1.50393805 0.43392332 1.39640291]
7.365013286082688  -  69.9473  =  -62.58228671391731
training  [2.4913, -4.7487, -3.1079]  w:  [1.50393805 0.43392332 1.39640291]
-2.6536914298516754  -  3.9825  =  -6.636191429851675
training  [0.8319, -0.7889, 1.6712]  w:  [1.50393805 0.43392332 1.39640291]
3.2424725009579545  -  58.8336  =  -55.591127499042045
training  [2.4003, -3.159, 0.8644]  w:  [1.50393805 0.43392332 1.39640291]
3.446189401493714  -  39.0041  =  -35.55791059850629
training  [-2.6517, 2.2578, 1.7511]  w:  [1.50393805 0.43392332 1.39640291]
-0.5630393092035741  -  54.4525  =  -55.015539309203575
training  [2.3496, -1.2964, -1.3898]  w:  [1.50393805 0.43392332 1.39640291]
1.0303938790193687  -  33.888  =  -32.85760612098063
training  [4.706, 3.4156, 1.2028]  w:  [1.50393805 0.43392332 1.39640291]
10.239234386524407  -  98.4665  =  -88.2272656134756
training  [3.6693, 2.3423, 3.1115]  w:  [1.50393805 0.43392332 1.39640291]
10.879686146171423  -  98.3069  =  -87.42721385382858
training  [-4.1377, 0.7103, -4.8074]  w:  [1.50393805 0.43392332 1.39640291]
-12.627696092120761  -  0.9782  =  -13.60589609212076
training  [-1.3356, -3.2314, -4.1613]  w:  [1.50393805 0.43392332 1.39640291]
-9.221690922663505  -  0.7659  =  -9.987590922663506
training  [-1.308, 4.5738, 4.748]  w:  [1.50393805 0.43392332 1.39640291]
6.647648551155547  -  97.0884  =  -90.44075144884445
training  [1.8503, -2.3468, 1.5135]  w:  [1.50393805 0.43392332 1.39640291]
3.8778611270879106  -  50.2125  =  -46.33463887291209
training  [0.9794, 4.2458, -2.6876]  w:  [1.50393805 0.43392332 1.39640291]
-0.43766389653442594  -  68.3262  =  -68.76386389653443
training  [2.8936, -2.7623, -0.9651]  w:  [1.50393805 0.43392332 1.39640291]
1.8055002959956628  -  28.5596  =  -26.754099704004336
training  [-1.3235, -1.2644, -3.7798]  w:  [1.50393805 0.43392332 1.39640291]
-7.817238385358074  -  2.4511  =  -10.268338385358074
training  [-2.9397, -4.125, -2.3156]  w:  [1.50393805 0.43392332 1.39640291]
-9.444570974847068  -  0.554  =  -9.998570974847068
training  [-4.1333, 1.4012, -2.4215]  w:  [1.50393805 0.43392332 1.39640291]
-8.989603433065225  -  4.4072  =  -13.396803433065225
training  [2.7193, -3.1938, -1.6833]  w:  [1.50393805 0.43392332 1.39640291]
0.35322940867065  -  17.0949  =  -16.74167059132935
training  [-2.9433, -4.5495, -3.4777]  w:  [1.50393805 0.43392332 1.39640291]
-11.25694542647447  -  0.2509  =  -11.50784542647447
training  [-1.1173, 2.2317, -1.5199]  w:  [1.50393805 0.43392332 1.39640291]
-2.8343560896494417  -  33.1206  =  -35.95495608964944
training  [0.5178, -1.5256, -3.7834]  w:  [1.50393805 0.43392332 1.39640291]
-5.166405076593315  -  5.237  =  -10.403405076593316
training  [-2.7105, 1.6062, 3.8415]  w:  [1.50393805 0.43392332 1.39640291]
1.984825343726461  -  70.4458  =  -68.46097465627355
training  [1.4194, -1.1613, -4.0572]  w:  [1.50393805 0.43392332 1.39640291]
-4.03471138169057  -  8.3206  =  -12.355311381690571
training  [-0.1552, 1.2735, 4.3004]  w:  [1.50393805 0.43392332 1.39640291]
6.32428124932771  -  90.1085  =  -83.7842187506723
training  [-3.4815, -4.7835, -1.0098]  w:  [1.50393805 0.43392332 1.39640291]
-8.721720195727421  -  0.5839  =  -9.305620195727421
training  [2.8193, 4.1057, -4.526]  w:  [1.50393805 0.43392332 1.39640291]
-0.29850804971924383  -  66.8081  =  -67.10660804971924
training  [-3.9939, 3.0056, -1.5763]  w:  [1.50393805 0.43392332 1.39640291]
-6.903528148534685  -  14.4018  =  -21.305328148534684
training  [-2.0593, 2.4585, 2.3597]  w:  [1.50393805 0.43392332 1.39640291]
1.2648328146926748  -  70.6698  =  -69.40496718530731
training  [-2.6263, 3.1311, 2.9468]  w:  [1.50393805 0.43392332 1.39640291]
1.5237849170283355  -  77.309  =  -75.78521508297166
training  [0.3087, -1.1669, 0.4491]  w:  [1.50393805 0.43392332 1.39640291]
0.5850450984214643  -  33.0798  =  -32.49475490157853
training  [-4.085, 1.1728, 1.8622]  w:  [1.50393805 0.43392332 1.39640291]
-3.0343001577400943  -  26.4056  =  -29.439900157740094
training  [-0.9468, 0.7549, 3.9363]  w:  [1.50393805 0.43392332 1.39640291]
4.400300953587861  -  79.7738  =  -75.37349904641214
training  [-3.9515, 0.3005, -4.4521]  w:  [1.50393805 0.43392332 1.39640291]
-12.029342650265109  -  1.0441  =  -13.07344265026511
training  [-3.8772, -2.2493, -1.9634]  w:  [1.50393805 0.43392332 1.39640291]
-9.548789814361452  -  1.0509  =  -10.599689814361453
training  [2.8443, -2.5137, -4.5381]  w:  [1.50393805 0.43392332 1.39640291]
-3.1501181166487466  -  6.8897  =  -10.039818116648746
training  [-2.0843, -0.4836, -3.0452]  w:  [1.50393805 0.43392332 1.39640291]
-7.596829544023054  -  3.5346  =  -11.131429544023053
training  [1.0353, -2.7229, 2.2017]  w:  [1.50393805 0.43392332 1.39640291]
3.449957538854841  -  43.9562  =  -40.50624246114516
training  [4.6442, 3.0445, 2.2175]  w:  [1.50393805 0.43392332 1.39640291]
11.402192104833697  -  98.8492  =  -87.4470078951663
training  [-0.6752, 4.861, 3.778]  w:  [1.50393805 0.43392332 1.39640291]
6.369452502689512  -  97.017  =  -90.64754749731048
training  [1.9475, -4.7001, 0.8243]  w:  [1.50393805 0.43392332 1.39640291]
2.0404912629873704  -  18.7839  =  -16.74340873701263
training  [2.581, 0.3566, -4.2932]  w:  [1.50393805 0.43392332 1.39640291]
-1.9586358185725006  -  23.5455  =  -25.5041358185725
training  [-0.6736, -4.1292, 4.2274]  w:  [1.50393805 0.43392332 1.39640291]
3.0983448156221853  -  31.2667  =  -28.168355184377816
training  [1.555, 3.0209, 3.0037]  w:  [1.50393805 0.43392332 1.39640291]
7.843838060333014  -  96.4078  =  -88.56396193966698
training  [-3.9024, 4.8914, -2.1405]  w:  [1.50393805 0.43392332 1.39640291]
-6.735475737830651  -  25.4308  =  -32.16627573783065
training  [4.3376, -4.3305, 0.4366]  w:  [1.50393805 0.43392332 1.39640291]
5.25404624699712  -  43.0907  =  -37.83665375300288
training  [-3.1254, 4.394, 4.8478]  w:  [1.50393805 0.43392332 1.39640291]
3.9757331365686595  -  92.8121  =  -88.83636686343134
training  [-2.3382, -4.8182, 2.1568]  w:  [1.50393805 0.43392332 1.39640291]
-2.595475501281658  -  4.7434  =  -7.338875501281658
training  [2.9783, 1.8384, 3.3897]  w:  [1.50393805 0.43392332 1.39640291]
10.010290281514493  -  97.3486  =  -87.3383097184855
training  [-0.124, 2.8374, -0.6674]  w:  [1.50393805 0.43392332 1.39640291]
0.11276641441448221  -  62.785  =  -62.672233585585516
training  [2.6896, 0.3414, -0.2938]  w:  [1.50393805 0.43392332 1.39640291]
3.782870025676374  -  70.4455  =  -66.66262997432362
training  [-1.0399, 3.8536, 0.6071]  w:  [1.50393805 0.43392332 1.39640291]
0.9559779466349203  -  77.0369  =  -76.08092205336509
training  [-2.2706, 3.99, -2.3091]  w:  [1.50393805 0.43392332 1.39640291]
-4.907921642254834  -  31.1134  =  -36.02132164225483
training  [-4.6277, 1.2594, 2.4902]  w:  [1.50393805 0.43392332 1.39640291]
-2.9359685488501777  -  28.1093  =  -31.045268548850178
training  [1.7329, -3.6213, 0.0389]  w:  [1.50393805 0.43392332 1.39640291]
1.0891277909868355  -  19.3919  =  -18.302772209013163
training  [-0.7044, -2.822, 1.4681]  w:  [1.50393805 0.43392332 1.39640291]
-0.23384646403116527  -  17.8122  =  -18.046046464031164
training  [-0.4826, -3.1786, -1.9225]  w:  [1.50393805 0.43392332 1.39640291]
-4.789653775161213  -  3.5851  =  -8.374753775161214
training  [1.0986, -4.5818, -3.6128]  w:  [1.50393805 0.43392332 1.39640291]
-5.38084797958882  -  1.7158  =  -7.09664797958882
training  [-4.406, -3.9306, -0.2443]  w:  [1.50393805 0.43392332 1.39640291]
-8.673071291593702  -  0.8241  =  -9.497171291593702
training  [-1.8419, 1.1644, -1.3754]  w:  [1.50393805 0.43392332 1.39640291]
-4.185455742190244  -  17.8517  =  -22.037155742190244
training  [2.7272, 4.3966, 2.8811]  w:  [1.50393805 0.43392332 1.39640291]
10.032503560506287  -  98.904  =  -88.87149643949371
training  [1.9643, -1.4554, 2.803]  w:  [1.50393805 0.43392332 1.39640291]
6.236770869830394  -  76.0591  =  -69.8223291301696
training  [-3.7467, -0.8937, 1.6851]  w:  [1.50393805 0.43392332 1.39640291]
-3.669523417773823  -  12.1571  =  -15.826623417773822
training  [-3.6985, 4.8435, -3.665]  w:  [1.50393805 0.43392332 1.39640291]
-8.57842393608584  -  14.6793  =  -23.25772393608584
251809.0089913301
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.49528314 0.47959546 1.31692345]
10.610698398275002  -  87.3174  =  -76.706701601725
training  [-4.1793, -4.9218, 1.7664]  w:  [1.49528314 0.47959546 1.31692345]
-6.283496157692182  -  1.5257  =  -7.809196157692183
training  [-3.9429, -0.7689, 4.883]  w:  [1.49528314 0.47959546 1.31692345]
0.16602438475239634  -  39.7859  =  -39.6198756152476
training  [-3.5796, 1.5557, 2.6683]  w:  [1.49528314 0.47959546 1.31692345]
-1.0924620203391102  -  45.5674  =  -46.65986202033911
training  [-3.3354, 2.2292, -1.633]  w:  [1.49528314 0.47959546 1.31692345]
-6.068789183503117  -  13.3589  =  -19.42768918350312
training  [1.2096, 0.3121, 1.6238]  w:  [1.49528314 0.47959546 1.31692345]
4.096796528799361  -  74.5119  =  -70.41510347120064
training  [0.7371, -3.9118, -2.5583]  w:  [1.49528314 0.47959546 1.31692345]
-4.142993578789792  -  3.3358  =  -7.478793578789792
training  [-4.4792, 1.3177, -2.0449]  w:  [1.49528314 0.47959546 1.31692345]
-8.75868606703989  -  4.2974  =  -13.056086067039889
training  [4.312, -3.735, 1.8018]  w:  [1.49528314 0.47959546 1.31692345]
7.0292045350298835  -  66.5833  =  -59.55409546497011
training  [2.2866, -3.657, 0.2785]  w:  [1.49528314 0.47959546 1.31692345]
2.0319970169435826  -  26.0005  =  -23.968502983056418
training  [2.3784, -4.0141, -0.8841]  w:  [1.49528314 0.47959546 1.31692345]
0.46694526519220303  -  14.6809  =  -14.213954734807796
training  [-4.366, -3.5797, 1.0264]  w:  [1.49528314 0.47959546 1.31692345]
-6.893523810691611  -  1.8713  =  -8.764823810691611
training  [3.6044, -3.3175, 2.5052]  w:  [1.49528314 0.47959546 1.31692345]
7.097697246388812  -  71.0139  =  -63.916202753611195
training  [4.3441, -3.0375, 0.8353]  w:  [1.49528314 0.47959546 1.31692345]
6.138914438671014  -  63.8979  =  -57.758985561328984
training  [4.844, -1.8252, 0.5179]  w:  [1.49528314 0.47959546 1.31692345]
7.0498285491357775  -  78.0461  =  -70.99627145086421
training  [3.5894, -1.8357, 0.8357]  w:  [1.49528314 0.47959546 1.31692345]
5.587328844578823  -  68.8838  =  -63.29647115542117
training  [2.8556, -2.8244, 0.1182]  w:  [1.49528314 0.47959546 1.31692345]
3.0710214713668846  -  39.5252  =  -36.454178528633115
training  [0.1338, -2.4896, -4.1741]  w:  [1.49528314 0.47959546 1.31692345]
-6.490902150812738  -  2.2644  =  -8.755302150812739
training  [-3.224, 3.9292, 2.1957]  w:  [1.49528314 0.47959546 1.31692345]
-0.044797541070712654  -  72.1211  =  -72.1658975410707
training  [-1.0141, 2.0322, 4.9616]  w:  [1.49528314 0.47959546 1.31692345]
5.992314660560545  -  92.3427  =  -86.35038533943944
training  [-3.6607, 0.5574, -1.4547]  w:  [1.49528314 0.47959546 1.31692345]
-7.122185023070093  -  5.8471  =  -12.969285023070093
training  [-4.6911, -3.1557, 4.7126]  w:  [1.49528314 0.47959546 1.31692345]
-2.3218486542211556  -  11.2337  =  -13.555548654221155
training  [4.3914, -2.8797, -1.5355]  w:  [1.49528314 0.47959546 1.31692345]
3.1631593731020424  -  37.475  =  -34.31184062689796
training  [-1.9869, -4.2265, 3.8654]  w:  [1.49528314 0.47959546 1.31692345]
0.09244764358713553  -  15.7889  =  -15.696452356412864
training  [-2.0447, 4.138, -0.4531]  w:  [1.49528314 0.47959546 1.31692345]
-1.669537445404845  -  57.936  =  -59.60553744540484
training  [-1.6706, 2.0672, -0.8657]  w:  [1.49528314 0.47959546 1.31692345]
-2.646660913688891  -  32.4185  =  -35.06516091368889
training  [-0.3293, 0.5779, -2.8227]  w:  [1.49528314 0.47959546 1.31692345]
-3.932518351904179  -  14.3434  =  -18.27591835190418
training  [1.482, -1.8657, -3.7435]  w:  [1.49528314 0.47959546 1.31692345]
-3.6086745788620247  -  7.1519  =  -10.760574578862025
training  [-4.7477, -3.338, -1.9109]  w:  [1.49528314 0.47959546 1.31692345]
-11.216554419595326  -  0.4077  =  -11.624254419595326
training  [3.4221, 1.225, 2.261]  w:  [1.49528314 0.47959546 1.31692345]
8.68207678986139  -  95.0454  =  -86.36332321013862
training  [0.5903, 4.8793, 2.8287]  w:  [1.49528314 0.47959546 1.31692345]
6.947937123641028  -  97.4647  =  -90.51676287635897
training  [3.541, -3.2957, 1.9379]  w:  [1.49528314 0.47959546 1.31692345]
6.266260801774126  -  64.3732  =  -58.106939198225874
training  [-1.5212, -2.4221, -4.902]  w:  [1.49528314 0.47959546 1.31692345]
-9.891811632595928  -  0.7227  =  -10.614511632595928
training  [-0.5397, -1.032, 3.4321]  w:  [1.49528314 0.47959546 1.31692345]
3.2178661592320132  -  60.5921  =  -57.374233840767985
training  [-4.4576, -4.2601, 4.2233]  w:  [1.49528314 0.47959546 1.31692345]
-3.1467359102309524  -  6.0247  =  -9.171435910230953
training  [-3.2289, 1.841, 2.7095]  w:  [1.49528314 0.47959546 1.31692345]
-0.3769803933620266  -  54.0111  =  -54.388080393362024
training  [1.6281, -0.9761, -4.5734]  w:  [1.49528314 0.47959546 1.31692345]
-4.056480366397166  -  7.8658  =  -11.922280366397166
training  [-1.6917, 4.8284, -1.2181]  w:  [1.49528314 0.47959546 1.31692345]
-1.8180362347105181  -  61.2837  =  -63.10173623471052
training  [3.9849, -0.9782, 2.0434]  w:  [1.49528314 0.47959546 1.31692345]
8.180414884436985  -  88.3402  =  -80.15978511556301
training  [-3.8184, 1.2067, 2.2951]  w:  [1.49528314 0.47959546 1.31692345]
-2.1083902810220656  -  34.1122  =  -36.22059028102207
training  [4.8842, -3.4563, -2.7572]  w:  [1.49528314 0.47959546 1.31692345]
2.0146147808428205  -  23.7819  =  -21.76728521915718
training  [0.3998, -1.1865, -2.3095]  w:  [1.49528314 0.47959546 1.31692345]
-3.0126605254547267  -  11.4246  =  -14.437260525454727
training  [2.0692, -3.3887, 1.7303]  w:  [1.49528314 0.47959546 1.31692345]
3.7475073923334388  -  42.6881  =  -38.94059260766656
training  [4.9949, 2.5811, -0.2251]  w:  [1.49528314 0.47959546 1.31692345]
8.410234114868963  -  95.9901  =  -87.57986588513103
training  [-2.1215, 3.7111, 1.2372]  w:  [1.49528314 0.47959546 1.31692345]
0.2368812204641002  -  71.3692  =  -71.13231877953591
training  [-0.8548, -1.4922, -2.6356]  w:  [1.49528314 0.47959546 1.31692345]
-5.464703820212492  -  4.7821  =  -10.246803820212492
training  [-0.3516, 1.8554, -3.2288]  w:  [1.49528314 0.47959546 1.31692345]
-3.887982582718225  -  20.3834  =  -24.271382582718225
training  [2.6396, -2.0585, 3.2964]  w:  [1.49528314 0.47959546 1.31692345]
7.300808591352595  -  80.826  =  -73.5251914086474
training  [3.182, 0.3063, 2.6692]  w:  [1.49528314 0.47959546 1.31692345]
8.420023114635562  -  92.9483  =  -84.52827688536445
training  [-3.9978, 3.3242, 4.3448]  w:  [1.49528314 0.47959546 1.31692345]
1.338197306316249  -  79.1768  =  -77.83860269368375
training  [-3.2188, 0.9749, -3.9211]  w:  [1.49528314 0.47959546 1.31692345]
-9.509248303908398  -  2.7053  =  -12.214548303908398
training  [-1.4037, -1.6469, -3.1777]  w:  [1.49528314 0.47959546 1.31692345]
-7.07356235581538  -  2.6234  =  -9.69696235581538
training  [-4.433, -2.0077, -4.009]  w:  [1.49528314 0.47959546 1.31692345]
-12.871020074265143  -  0.3253  =  -13.196320074265143
training  [0.2189, -0.4741, -0.1024]  w:  [1.49528314 0.47959546 1.31692345]
-0.03491168904528358  -  33.6531  =  -33.68801168904528
training  [-1.6415, -0.7735, -3.0675]  w:  [1.49528314 0.47959546 1.31692345]
-6.865137048887197  -  3.7641  =  -10.629237048887198
training  [-3.2433, -1.4039, 3.9589]  w:  [1.49528314 0.47959546 1.31692345]
-0.3093876097411359  -  30.0658  =  -30.375187609741136
training  [-2.9105, 0.5832, -4.0091]  w:  [1.49528314 0.47959546 1.31692345]
-9.351999316945985  -  2.4887  =  -11.840699316945985
training  [4.0515, 2.4255, -4.5583]  w:  [1.49528314 0.47959546 1.31692345]
1.2184662443811582  -  61.2853  =  -60.066833755618845
training  [1.7539, -0.7567, 0.573]  w:  [1.49528314 0.47959546 1.31692345]
3.0142643519133068  -  57.0797  =  -54.0654356480867
training  [-0.3153, -0.7064, 2.725]  w:  [1.49528314 0.47959546 1.31692345]
2.7783674032486805  -  58.7004  =  -55.92203259675132
training  [4.1213, -3.7513, -1.8806]  w:  [1.49528314 0.47959546 1.31692345]
1.8867977129956546  -  22.1789  =  -20.292102287004344
training  [-3.9599, -4.7557, -3.2102]  w:  [1.49528314 0.47959546 1.31692345]
-12.42957148542824  -  0.1558  =  -12.58537148542824
training  [2.4555, -2.0981, -1.6104]  w:  [1.49528314 0.47959546 1.31692345]
0.5446549885959073  -  24.4796  =  -23.934945011404093
training  [2.3627, -1.8248, -2.8985]  w:  [1.49528314 0.47959546 1.31692345]
-1.1593629472503597  -  15.7052  =  -16.86456294725036
training  [0.6186, 1.5369, 0.1015]  w:  [1.49528314 0.47959546 1.31692345]
1.795740138835237  -  65.2154  =  -63.41965986116477
training  [-3.1581, 4.5694, 4.0636]  w:  [1.49528314 0.47959546 1.31692345]
2.8206599467570332  -  90.3564  =  -87.53574005324296
training  [0.9721, 4.3573, 1.2892]  w:  [1.49528314 0.47959546 1.31692345]
5.241083741796513  -  94.3178  =  -89.07671625820349
training  [-2.0006, -0.4211, -3.9847]  w:  [1.49528314 0.47959546 1.31692345]
-8.440965975247652  -  2.4051  =  -10.846065975247651
training  [-3.6588, -2.5952, -1.0915]  w:  [1.49528314 0.47959546 1.31692345]
-8.153010027172229  -  1.5176  =  -9.670610027172229
training  [-2.874, 2.639, -4.4538]  w:  [1.49528314 0.47959546 1.31692345]
-8.89710499974139  -  5.497  =  -14.39410499974139
training  [3.9494, 2.5933, 0.0128]  w:  [1.49528314 0.47959546 1.31692345]
7.1660627475895  -  94.1462  =  -86.98013725241049
training  [-4.2855, 2.4065, -0.6828]  w:  [1.49528314 0.47959546 1.31692345]
-6.15308475407366  -  14.4193  =  -20.57238475407366
training  [-2.5751, 2.4369, 4.9756]  w:  [1.49528314 0.47959546 1.31692345]
3.870706891561585  -  87.1991  =  -83.32839310843842
training  [-4.4625, -3.9408, 3.116]  w:  [1.49528314 0.47959546 1.31692345]
-4.45915730693824  -  4.1344  =  -8.59355730693824
training  [-0.5828, 1.8156, -0.1435]  w:  [1.49528314 0.47959546 1.31692345]
-0.18967601546462284  -  51.1166  =  -51.30627601546462
training  [-4.8672, -0.3674, 3.9445]  w:  [1.49528314 0.47959546 1.31692345]
-2.2594409040081844  -  24.1396  =  -26.399040904008185
training  [3.9719, -2.8784, -3.6245]  w:  [1.49528314 0.47959546 1.31692345]
-0.21454152169436647  -  14.6104  =  -14.824941521694367
training  [-3.0334, -4.0148, -1.1]  w:  [1.49528314 0.47959546 1.31692345]
-7.909887513535722  -  1.021  =  -8.930887513535723
training  [-4.0663, 3.2357, 4.2736]  w:  [1.49528314 0.47959546 1.31692345]
1.0995612635060414  -  77.2328  =  -76.13323873649395
training  [-1.9263, -3.2499, 4.1749]  w:  [1.49528314 0.47959546 1.31692345]
1.0590225343454875  -  26.8814  =  -25.82237746565451
training  [-0.4394, -3.3643, 2.1357]  w:  [1.49528314 0.47959546 1.31692345]
0.5420230081121238  -  20.85  =  -20.307976991887877
training  [-3.9833, 1.6599, 1.1834]  w:  [1.49528314 0.47959546 1.31692345]
-3.60163361127854  -  25.5397  =  -29.14133361127854
training  [4.9539, 3.9439, -1.5671]  w:  [1.49528314 0.47959546 1.31692345]
7.235208922692609  -  95.9509  =  -88.7156910773074
training  [-1.6791, 0.1656, 4.3603]  w:  [1.49528314 0.47959546 1.31692345]
3.3108724201190505  -  71.5733  =  -68.26242757988095
training  [-2.0265, 2.027, -3.7523]  w:  [1.49528314 0.47959546 1.31692345]
-6.999543158110864  -  8.503  =  -15.502543158110864
training  [-4.3795, -3.4641, 2.3059]  w:  [1.49528314 0.47959546 1.31692345]
-5.173265340642189  -  3.6654  =  -8.838665340642189
training  [-2.0176, 4.5346, 1.4648]  w:  [1.49528314 0.47959546 1.31692345]
1.0869197757767166  -  81.6212  =  -80.53428022422328
training  [-4.5365, 0.4088, 3.3315]  w:  [1.49528314 0.47959546 1.31692345]
-2.19996285224416  -  28.9449  =  -31.14486285224416
training  [0.0543, 1.7973, -1.0172]  w:  [1.49528314 0.47959546 1.31692345]
-0.39640374532357947  -  47.9317  =  -48.32810374532358
training  [2.6143, -4.6344, 2.4982]  w:  [1.49528314 0.47959546 1.31692345]
4.976419688593072  -  43.5132  =  -38.53678031140693
training  [1.3107, 3.092, 3.3522]  w:  [1.49528314 0.47959546 1.31692345]
7.857367562365329  -  96.6993  =  -88.84193243763467
training  [-4.1011, 2.4862, -1.7754]  w:  [1.49528314 0.47959546 1.31692345]
-7.278001349596491  -  10.0187  =  -17.296701349596493
training  [-4.1914, -3.7981, 0.5226]  w:  [1.49528314 0.47959546 1.31692345]
-7.400657058072167  -  1.4295  =  -8.830157058072167
training  [2.7724, 0.2505, 4.7913]  w:  [1.49528314 0.47959546 1.31692345]
10.575436973199594  -  96.7925  =  -86.21706302680042
training  [4.0513, -1.7417, 0.4931]  w:  [1.49528314 0.47959546 1.31692345]
5.871904124406731  -  71.1234  =  -65.25149587559328
training  [0.3377, 0.4645, -1.6958]  w:  [1.49528314 0.47959546 1.31692345]
-1.5055095848333193  -  27.9534  =  -29.458909584833318
training  [-3.9085, -1.0112, 1.1947]  w:  [1.49528314 0.47959546 1.31692345]
-4.7559526246388515  -  8.608  =  -13.363952624638852
training  [3.2581, -0.8491, -1.3936]  w:  [1.49528314 0.47959546 1.31692345]
2.6292929666978493  -  50.1924  =  -47.56310703330215
training  [-1.619, -3.1926, 2.5651]  w:  [1.49528314 0.47959546 1.31692345]
-0.5739795113641124  -  16.4754  =  -17.049379511364112
training  [-2.0603, -2.4461, -0.861]  w:  [1.49528314 0.47959546 1.31692345]
-5.387741391852433  -  3.9784  =  -9.366141391852434
training  [2.4631, -4.7946, -0.0765]  w:  [1.49528314 0.47959546 1.31692345]
1.2828188725213787  -  15.394  =  -14.111181127478622
training  [-4.8966, 4.2368, 1.9474]  w:  [1.49528314 0.47959546 1.31692345]
-2.7252766488597038  -  53.5883  =  -56.3135766488597
training  [-4.5155, 1.537, 4.7273]  w:  [1.49528314 0.47959546 1.31692345]
0.21067944410115924  -  59.2523  =  -59.04162055589884
training  [1.6792, 4.3261, -1.7225]  w:  [1.49528314 0.47959546 1.31692345]
2.3172567087248988  -  83.7729  =  -81.45564329127511
training  [1.0347, -3.3649, 3.378]  w:  [1.49528314 0.47959546 1.31692345]
4.381946130255327  -  50.5979  =  -46.21595386974467
training  [0.261, 4.211, 2.3907]  w:  [1.49528314 0.47959546 1.31692345]
5.558214269555957  -  94.9375  =  -89.37928573044404
training  [2.2971, 2.9466, 4.5417]  w:  [1.49528314 0.47959546 1.31692345]
10.829062117328753  -  98.7784  =  -87.94933788267124
training  [2.0725, 0.7739, -4.6808]  w:  [1.49528314 0.47959546 1.31692345]
-2.6941220674661905  -  19.5109  =  -22.20502206746619
training  [2.8138, -0.5996, -1.4313]  w:  [1.49528314 0.47959546 1.31692345]
2.0349497208394114  -  47.2879  =  -45.252950279160586
training  [-2.1202, -2.4239, 1.6265]  w:  [1.49528314 0.47959546 1.31692345]
-2.190814744527554  -  12.3599  =  -14.550714744527554
training  [1.9253, 2.5195, -2.185]  w:  [1.49528314 0.47959546 1.31692345]
1.2097316383727694  -  65.2467  =  -64.03696836162723
training  [0.5667, -2.7133, -2.6962]  w:  [1.49528314 0.47959546 1.31692345]
-4.004598413597152  -  5.1106  =  -9.115198413597152
training  [-1.0348, -4.3581, 2.1113]  w:  [1.49528314 0.47959546 1.31692345]
-0.8570234706319599  -  10.5192  =  -11.37622347063196
training  [-4.3841, 2.6733, 1.2457]  w:  [1.49528314 0.47959546 1.31692345]
-3.6328767252075074  -  32.4639  =  -36.09677672520751
training  [2.8018, 1.712, 0.9061]  w:  [1.49528314 0.47959546 1.31692345]
6.20381606118505  -  90.1138  =  -83.90998393881495
training  [-1.6242, 2.1521, 1.6044]  w:  [1.49528314 0.47959546 1.31692345]
0.716370498375549  -  63.7879  =  -63.071529501624454
training  [1.0787, 1.4206, -4.5245]  w:  [1.49528314 0.47959546 1.31692345]
-3.664144932289129  -  18.0555  =  -21.71964493228913
training  [2.4125, -0.8095, -1.5122]  w:  [1.49528314 0.47959546 1.31692345]
1.2276864035054174  -  38.8276  =  -37.59991359649458
training  [-3.9519, -1.0924, -0.4866]  w:  [1.49528314 0.47959546 1.31692345]
-7.073934464743082  -  3.6777  =  -10.751634464743082
training  [-3.7211, 3.1614, -2.591]  w:  [1.49528314 0.47959546 1.31692345]
-7.460053671819949  -  11.1518  =  -18.61185367181995
training  [0.4954, -1.8257, 2.1505]  w:  [1.49528314 0.47959546 1.31692345]
2.6972097242603748  -  47.7531  =  -45.05589027573963
training  [-0.1477, 3.1454, 3.5618]  w:  [1.49528314 0.47959546 1.31692345]
5.978284186383585  -  94.1572  =  -88.17891581361641
training  [3.9048, 2.8907, -2.1849]  w:  [1.49528314 0.47959546 1.31692345]
4.347802137129958  -  85.8791  =  -81.53129786287003
training  [2.9896, 3.5226, 2.3105]  w:  [1.49528314 0.47959546 1.31692345]
9.20247306706188  -  98.038  =  -88.83552693293811
training  [2.3434, 0.0564, -3.6224]  w:  [1.49528314 0.47959546 1.31692345]
-1.2393278240332029  -  24.7629  =  -26.002227824033202
training  [-4.4867, 1.3566, 3.3672]  w:  [1.49528314 0.47959546 1.31692345]
-1.6239230098644413  -  40.5785  =  -42.20242300986444
training  [-4.2711, 4.5089, -3.614]  w:  [1.49528314 0.47959546 1.31692345]
-8.983417210600509  -  10.0825  =  -19.06591721060051
training  [-4.1147, -0.5604, 0.8821]  w:  [1.49528314 0.47959546 1.31692345]
-5.259748646698288  -  8.344  =  -13.603748646698287
training  [2.9835, -4.3998, -1.3384]  w:  [1.49528314 0.47959546 1.31692345]
0.5884827997246098  -  13.2692  =  -12.68071720027539
training  [4.4301, 3.6675, 3.0676]  w:  [1.49528314 0.47959546 1.31692345]
12.422964555688127  -  99.3834  =  -86.96043544431187
training  [1.8372, 1.3119, 0.0378]  w:  [1.49528314 0.47959546 1.31692345]
3.4260951694014135  -  74.9026  =  -71.4765048305986
training  [-3.6792, -1.4493, -0.1041]  w:  [1.49528314 0.47959546 1.31692345]
-6.333615151166849  -  4.2442  =  -10.577815151166849
training  [2.2272, 4.97, 3.7705]  w:  [1.49528314 0.47959546 1.31692345]
10.679343908525805  -  99.3199  =  -88.6405560914742
training  [-3.8965, -2.7583, -1.4686]  w:  [1.49528314 0.47959546 1.31692345]
-9.083272682276796  -  1.0337  =  -10.116972682276796
training  [-3.8251, 1.5245, -0.5056]  w:  [1.49528314 0.47959546 1.31692345]
-5.654300755070174  -  12.9762  =  -18.630500755070173
training  [1.4072, 1.0499, 4.6353]  w:  [1.49528314 0.47959546 1.31692345]
8.712024982938152  -  95.4618  =  -86.74977501706185
training  [-1.7119, -1.1275, -4.577]  w:  [1.49528314 0.47959546 1.31692345]
-9.128077725452306  -  1.4655  =  -10.593577725452306
training  [1.5381, -3.5781, 4.7296]  w:  [1.49528314 0.47959546 1.31692345]
6.812375648981856  -  69.9473  =  -63.13492435101814
training  [2.4913, -4.7487, -3.1079]  w:  [1.49528314 0.47959546 1.31692345]
-2.64512246544852  -  3.9825  =  -6.627622465448519
training  [0.8319, -0.7889, 1.6712]  w:  [1.49528314 0.47959546 1.31692345]
3.0664156601127615  -  58.8336  =  -55.76718433988724
training  [2.4003, -3.159, 0.8644]  w:  [1.49528314 0.47959546 1.31692345]
3.2124346985629693  -  39.0041  =  -35.791665301437035
training  [-2.6517, 2.2578, 1.7511]  w:  [1.49528314 0.47959546 1.31692345]
-0.5761470159853364  -  54.4525  =  -55.028647015985335
training  [2.3496, -1.2964, -1.3898]  w:  [1.49528314 0.47959546 1.31692345]
1.0613094963217062  -  33.888  =  -32.82669050367829
training  [4.706, 3.4156, 1.2028]  w:  [1.49528314 0.47959546 1.31692345]
10.258904223509948  -  98.4665  =  -88.20759577649005
training  [3.6693, 2.3423, 3.1115]  w:  [1.49528314 0.47959546 1.31692345]
10.707606182966735  -  98.3069  =  -87.59929381703327
training  [-4.1377, 0.7103, -4.8074]  w:  [1.49528314 0.47959546 1.31692345]
-12.17735419388997  -  0.9782  =  -13.15555419388997
training  [-1.3356, -3.2314, -4.1613]  w:  [1.49528314 0.47959546 1.31692345]
-9.026978484756416  -  0.7659  =  -9.792878484756416
training  [-1.308, 4.5738, 4.748]  w:  [1.49528314 0.47959546 1.31692345]
6.490495912071756  -  97.0884  =  -90.59790408792824
training  [1.8503, -2.3468, 1.5135]  w:  [1.49528314 0.47959546 1.31692345]
3.63437141622882  -  50.2125  =  -46.578128583771175
training  [0.9794, 4.2458, -2.6876]  w:  [1.49528314 0.47959546 1.31692345]
-0.038616770828924896  -  68.3262  =  -68.36481677082892
training  [2.8936, -2.7623, -0.9651]  w:  [1.49528314 0.47959546 1.31692345]
1.7310019324317283  -  28.5596  =  -26.828598067568272
training  [-1.3235, -1.2644, -3.7798]  w:  [1.49528314 0.47959546 1.31692345]
-7.56311499629944  -  2.4511  =  -10.01421499629944
training  [-2.9397, -4.125, -2.3156]  w:  [1.49528314 0.47959546 1.31692345]
-9.42348305179574  -  0.554  =  -9.97748305179574
training  [-4.1333, 1.4012, -2.4215]  w:  [1.49528314 0.47959546 1.31692345]
-8.697374780960777  -  4.4072  =  -13.104574780960776
training  [2.7193, -3.1938, -1.6833]  w:  [1.49528314 0.47959546 1.31692345]
0.3176142177936985  -  17.0949  =  -16.7772857822063
training  [-2.9433, -4.5495, -3.4777]  w:  [1.49528314 0.47959546 1.31692345]
-11.162851087076861  -  0.2509  =  -11.41375108707686
training  [-1.1173, 2.2317, -1.5199]  w:  [1.49528314 0.47959546 1.31692345]
-2.601958623046372  -  33.1206  =  -35.722558623046375
training  [0.5178, -1.5256, -3.7834]  w:  [1.49528314 0.47959546 1.31692345]
-4.939861411511326  -  5.237  =  -10.176861411511325
training  [-2.7105, 1.6062, 3.8415]  w:  [1.49528314 0.47959546 1.31692345]
1.7763227203795822  -  70.4458  =  -68.66947727962042
training  [1.4194, -1.1613, -4.0572]  w:  [1.49528314 0.47959546 1.31692345]
-3.7775711499630464  -  8.3206  =  -12.098171149963047
training  [-0.1552, 1.2735, 4.3004]  w:  [1.49528314 0.47959546 1.31692345]
6.041994487565691  -  90.1085  =  -84.06650551243432
training  [-3.4815, -4.7835, -1.0098]  w:  [1.49528314 0.47959546 1.31692345]
-8.82980242079729  -  0.5839  =  -9.41370242079729
training  [2.8193, 4.1057, -4.526]  w:  [1.49528314 0.47959546 1.31692345]
0.22433127680378284  -  66.8081  =  -66.58376872319621
training  [-3.9939, 3.0056, -1.5763]  w:  [1.49528314 0.47959546 1.31692345]
-6.606405657018038  -  14.4018  =  -21.00820565701804
training  [-2.0593, 2.4585, 2.3597]  w:  [1.49528314 0.47959546 1.31692345]
1.2073931367870767  -  70.6698  =  -69.46240686321292
training  [-2.6263, 3.1311, 2.9468]  w:  [1.49528314 0.47959546 1.31692345]
1.4553092611449157  -  77.309  =  -75.85369073885508
training  [0.3087, -1.1669, 0.4491]  w:  [1.49528314 0.47959546 1.31692345]
0.4933842877407354  -  33.0798  =  -32.58641571225926
training  [-4.085, 1.1728, 1.8622]  w:  [1.49528314 0.47959546 1.31692345]
-3.093387214339876  -  26.4056  =  -29.498987214339877
training  [-0.9468, 0.7549, 3.9363]  w:  [1.49528314 0.47959546 1.31692345]
4.130118321751443  -  79.7738  =  -75.64368167824856
training  [-3.9515, 0.3005, -4.4521]  w:  [1.49528314 0.47959546 1.31692345]
-11.627567789409456  -  1.0441  =  -12.671667789409456
training  [-3.8772, -2.2493, -1.9634]  w:  [1.49528314 0.47959546 1.31692345]
-9.46191335403268  -  1.0509  =  -10.51281335403268
training  [2.8443, -2.5137, -4.5381]  w:  [1.49528314 0.47959546 1.31692345]
-2.928855591372362  -  6.8897  =  -9.818555591372363
training  [-2.0843, -0.4836, -3.0452]  w:  [1.49528314 0.47959546 1.31692345]
-7.358846306394461  -  3.5346  =  -10.89344630639446
training  [1.0353, -2.7229, 2.2017]  w:  [1.49528314 0.47959546 1.31692345]
3.1416465267928366  -  43.9562  =  -40.81455347320717
training  [4.6442, 3.0445, 2.2175]  w:  [1.49528314 0.47959546 1.31692345]
11.324800078470645  -  98.8492  =  -87.52439992152935
training  [-0.6752, 4.861, 3.778]  w:  [1.49528314 0.47959546 1.31692345]
6.297035148574288  -  97.017  =  -90.71996485142571
training  [1.9475, -4.7001, 0.8243]  w:  [1.49528314 0.47959546 1.31692345]
1.7434573031405198  -  18.7839  =  -17.04044269685948
training  [2.581, 0.3566, -4.2932]  w:  [1.49528314 0.47959546 1.31692345]
-1.6234662458889364  -  23.5455  =  -25.16896624588894
training  [-0.6736, -4.1292, 4.2274]  w:  [1.49528314 0.47959546 1.31692345]
2.57959391712608  -  31.2667  =  -28.68710608287392
training  [1.555, 3.0209, 3.0037]  w:  [1.49528314 0.47959546 1.31692345]
7.729618172832598  -  96.4078  =  -88.67818182716739
training  [-3.9024, 4.8914, -2.1405]  w:  [1.49528314 0.47959546 1.31692345]
-6.308174347590116  -  25.4308  =  -31.738974347590116
training  [4.3376, -4.3305, 0.4366]  w:  [1.49528314 0.47959546 1.31692345]
4.984020790912044  -  43.0907  =  -38.10667920908796
training  [-3.1254, 4.394, 4.8478]  w:  [1.49528314 0.47959546 1.31692345]
3.818166033568292  -  92.8121  =  -88.99393396643171
training  [-2.3382, -4.8182, 2.1568]  w:  [1.49528314 0.47959546 1.31692345]
-2.966717366259205  -  4.7434  =  -7.710117366259205
training  [2.9783, 1.8384, 3.3897]  w:  [1.49528314 0.47959546 1.31692345]
9.799065487662723  -  97.3486  =  -87.54953451233729
training  [-0.124, 2.8374, -0.6674]  w:  [1.49528314 0.47959546 1.31692345]
0.2964743303682066  -  62.785  =  -62.48852566963179
training  [2.6896, 0.3414, -0.2938]  w:  [1.49528314 0.47959546 1.31692345]
3.7985353080128785  -  70.4455  =  -66.64696469198712
training  [-1.0399, 3.8536, 0.6071]  w:  [1.49528314 0.47959546 1.31692345]
1.092728348270406  -  77.0369  =  -75.94417165172959
training  [-2.2706, 3.99, -2.3091]  w:  [1.49528314 0.47959546 1.31692345]
-4.522511962002962  -  31.1134  =  -35.635911962002965
training  [-4.6277, 1.2594, 2.4902]  w:  [1.49528314 0.47959546 1.31692345]
-3.036316478736668  -  28.1093  =  -31.14561647873667
training  [1.7329, -3.6213, 0.0389]  w:  [1.49528314 0.47959546 1.31692345]
0.9056454418156832  -  19.3919  =  -18.486254558184317
training  [-0.7044, -2.822, 1.4681]  w:  [1.49528314 0.47959546 1.31692345]
-0.4733205037509056  -  17.8122  =  -18.285520503750906
training  [-0.4826, -3.1786, -1.9225]  w:  [1.49528314 0.47959546 1.31692345]
-4.777851102003377  -  3.5851  =  -8.362951102003377
training  [1.0986, -4.5818, -3.6128]  w:  [1.49528314 0.47959546 1.31692345]
-5.312473461613064  -  1.7158  =  -7.028273461613064
training  [-4.406, -3.9306, -0.2443]  w:  [1.49528314 0.47959546 1.31692345]
-8.795039813466909  -  0.8241  =  -9.619139813466909
training  [-1.8419, 1.1644, -1.3754]  w:  [1.49528314 0.47959546 1.31692345]
-4.007017578285814  -  17.8517  =  -21.858717578285816
training  [2.7272, 4.3966, 2.8811]  w:  [1.49528314 0.47959546 1.31692345]
9.980713723601841  -  98.904  =  -88.92328627639816
training  [1.9643, -1.4554, 2.803]  w:  [1.49528314 0.47959546 1.31692345]
5.9305178770548  -  76.0591  =  -70.1285821229452
training  [-3.7467, -0.8937, 1.6851]  w:  [1.49528314 0.47959546 1.31692345]
-3.8118440854416518  -  12.1571  =  -15.968944085441652
training  [-3.6985, 4.8435, -3.665]  w:  [1.49528314 0.47959546 1.31692345]
-8.033908541464728  -  14.6793  =  -22.713208541464727
252297.8007083122
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.61735742 0.57067405 1.71903468]
12.577951096876665  -  87.3174  =  -74.73944890312335
training  [-4.1793, -4.9218, 1.7664]  w:  [1.61735742 0.57067405 1.71903468]
-6.531662528185146  -  1.5257  =  -8.057362528185147
training  [-3.9429, -0.7689, 4.883]  w:  [1.61735742 0.57067405 1.71903468]
1.5781765123207325  -  39.7859  =  -38.20772348767927
training  [-3.5796, 1.5557, 2.6683]  w:  [1.61735742 0.57067405 1.71903468]
-0.3147947639208013  -  45.5674  =  -45.8821947639208
training  [-3.3354, 2.2292, -1.633]  w:  [1.61735742 0.57067405 1.71903468]
-6.929571000316306  -  13.3589  =  -20.288471000316306
training  [1.2096, 0.3121, 1.6238]  w:  [1.61735742 0.57067405 1.71903468]
4.925831428309728  -  74.5119  =  -69.58606857169028
training  [0.7371, -3.9118, -2.5583]  w:  [1.61735742 0.57067405 1.71903468]
-5.438015013298064  -  3.3358  =  -8.773815013298064
training  [-4.4792, 1.3177, -2.0449]  w:  [1.61735742 0.57067405 1.71903468]
-10.007744199410107  -  4.2974  =  -14.305144199410107
training  [4.312, -3.735, 1.8018]  w:  [1.61735742 0.57067405 1.71903468]
7.93993433399948  -  66.5833  =  -58.64336566600051
training  [2.2866, -3.657, 0.2785]  w:  [1.61735742 0.57067405 1.71903468]
2.090045652318689  -  26.0005  =  -23.91045434768131
training  [2.3784, -4.0141, -0.8841]  w:  [1.61735742 0.57067405 1.71903468]
0.03618163724474477  -  14.6809  =  -14.644718362755254
training  [-4.366, -3.5797, 1.0264]  w:  [1.61735742 0.57067405 1.71903468]
-7.339807187661565  -  1.8713  =  -9.211107187661565
training  [3.6044, -3.3175, 2.5052]  w:  [1.61735742 0.57067405 1.71903468]
8.242917633926606  -  71.0139  =  -62.7709823660734
training  [4.3441, -3.0375, 0.8353]  w:  [1.61735742 0.57067405 1.71903468]
6.728449631959181  -  63.8979  =  -57.16945036804082
training  [4.844, -1.8252, 0.5179]  w:  [1.61735742 0.57067405 1.71903468]
7.683173144808075  -  78.0461  =  -70.36292685519192
training  [3.5894, -1.8357, 0.8357]  w:  [1.61735742 0.57067405 1.71903468]
6.194353668683159  -  68.8838  =  -62.68944633131684
training  [2.8556, -2.8244, 0.1182]  w:  [1.61735742 0.57067405 1.71903468]
3.2099039765142745  -  39.5252  =  -36.31529602348572
training  [0.1338, -2.4896, -4.1741]  w:  [1.61735742 0.57067405 1.71903468]
-8.379770360407221  -  2.2644  =  -10.644170360407221
training  [-3.224, 3.9292, 2.1957]  w:  [1.61735742 0.57067405 1.71903468]
0.8024165927123557  -  72.1211  =  -71.31868340728764
training  [-1.0141, 2.0322, 4.9616]  w:  [1.61735742 0.57067405 1.71903468]
8.048724127269306  -  92.3427  =  -84.29397587273068
training  [-3.6607, 0.5574, -1.4547]  w:  [1.61735742 0.57067405 1.71903468]
-8.103246356324467  -  5.8471  =  -13.950346356324467
training  [-4.6911, -3.1557, 4.7126]  w:  [1.61735742 0.57067405 1.71903468]
-1.2869386351767336  -  11.2337  =  -12.520638635176734
training  [4.3914, -2.8797, -1.5355]  w:  [1.61735742 0.57067405 1.71903468]
2.819515572156927  -  37.475  =  -34.65548442784308
training  [-1.9869, -4.2265, 3.8654]  w:  [1.61735742 0.57067405 1.71903468]
1.0192753510697896  -  15.7889  =  -14.769624648930211
training  [-2.0447, 4.138, -0.4531]  w:  [1.61735742 0.57067405 1.71903468]
-1.7244561315473814  -  57.936  =  -59.660456131547384
training  [-1.6706, 2.0672, -0.8657]  w:  [1.61735742 0.57067405 1.71903468]
-3.01042824645673  -  32.4185  =  -35.428928246456735
training  [-0.3293, 0.5779, -2.8227]  w:  [1.61735742 0.57067405 1.71903468]
-5.055122471919082  -  14.3434  =  -19.398522471919083
training  [1.482, -1.8657, -3.7435]  w:  [1.61735742 0.57067405 1.71903468]
-5.102989211466868  -  7.1519  =  -12.254889211466867
training  [-4.7477, -3.338, -1.9109]  w:  [1.61735742 0.57067405 1.71903468]
-12.868541177784744  -  0.4077  =  -13.276241177784744
training  [3.4221, 1.225, 2.261]  w:  [1.61735742 0.57067405 1.71903468]
10.12057196222733  -  95.0454  =  -84.92482803777267
training  [0.5903, 4.8793, 2.8287]  w:  [1.61735742 0.57067405 1.71903468]
8.60184937376424  -  97.4647  =  -88.86285062623575
training  [3.541, -3.2957, 1.9379]  w:  [1.61735742 0.57067405 1.71903468]
7.177609490988651  -  64.3732  =  -57.195590509011346
training  [-1.5212, -2.4221, -4.902]  w:  [1.61735742 0.57067405 1.71903468]
-12.269261742352917  -  0.7227  =  -12.991961742352917
training  [-0.5397, -1.032, 3.4321]  w:  [1.61735742 0.57067405 1.71903468]
4.438075524663143  -  60.5921  =  -56.15402447533686
training  [-4.4576, -4.2601, 4.2233]  w:  [1.61735742 0.57067405 1.71903468]
-2.3806617653562583  -  6.0247  =  -8.405361765356258
training  [-3.2289, 1.841, 2.7095]  w:  [1.61735742 0.57067405 1.71903468]
0.4860500183919987  -  54.0111  =  -53.525049981608
training  [1.6281, -0.9761, -4.5734]  w:  [1.61735742 0.57067405 1.71903468]
-5.785648545158886  -  7.8658  =  -13.651448545158885
training  [-1.6917, 4.8284, -1.2181]  w:  [1.61735742 0.57067405 1.71903468]
-2.074597133695026  -  61.2837  =  -63.35829713369503
training  [3.9849, -0.9782, 2.0434]  w:  [1.61735742 0.57067405 1.71903468]
9.399449712566742  -  88.3402  =  -78.94075028743325
training  [-3.8184, 1.2067, 2.2951]  w:  [1.61735742 0.57067405 1.71903468]
-1.541728702801863  -  34.1122  =  -35.65392870280186
training  [4.8842, -3.4563, -2.7572]  w:  [1.61735742 0.57067405 1.71903468]
1.1873539801613813  -  23.7819  =  -22.594546019838617
training  [0.3998, -1.1865, -2.3095]  w:  [1.61735742 0.57067405 1.71903468]
-4.000595863169076  -  11.4246  =  -15.425195863169076
training  [2.0692, -3.3887, 1.7303]  w:  [1.61735742 0.57067405 1.71903468]
4.387238550684878  -  42.6881  =  -38.30086144931512
training  [4.9949, 2.5811, -0.2251]  w:  [1.61735742 0.57067405 1.71903468]
9.164550660216637  -  95.9901  =  -86.82554933978336
training  [-2.1215, 3.7111, 1.2372]  w:  [1.61735742 0.57067405 1.71903468]
0.8133943954819824  -  71.3692  =  -70.55580560451803
training  [-0.8548, -1.4922, -2.6356]  w:  [1.61735742 0.57067405 1.71903468]
-6.7647647512784825  -  4.7821  =  -11.546864751278482
training  [-0.3516, 1.8554, -3.2288]  w:  [1.61735742 0.57067405 1.71903468]
-5.060253433443953  -  20.3834  =  -25.443653433443956
training  [2.6396, -2.0585, 3.2964]  w:  [1.61735742 0.57067405 1.71903468]
8.761070060415799  -  80.826  =  -72.06492993958419
training  [3.182, 0.3063, 2.6692]  w:  [1.61735742 0.57067405 1.71903468]
9.9096761569926  -  92.9483  =  -83.0386238430074
training  [-3.9978, 3.3242, 4.3448]  w:  [1.61735742 0.57067405 1.71903468]
2.900025062367834  -  79.1768  =  -76.27677493763217
training  [-3.2188, 0.9749, -3.9211]  w:  [1.61735742 0.57067405 1.71903468]
-11.39010684344822  -  2.7053  =  -14.09540684344822
training  [-1.4037, -1.6469, -3.1777]  w:  [1.61735742 0.57067405 1.71903468]
-8.67270421766895  -  2.6234  =  -11.296104217668951
training  [-4.433, -2.0077, -4.009]  w:  [1.61735742 0.57067405 1.71903468]
-15.207097784945205  -  0.3253  =  -15.532397784945205
training  [0.2189, -0.4741, -0.1024]  w:  [1.61735742 0.57067405 1.71903468]
-0.09254617752446728  -  33.6531  =  -33.74564617752447
training  [-1.6415, -0.7735, -3.0675]  w:  [1.61735742 0.57067405 1.71903468]
-8.369447478103243  -  3.7641  =  -12.133547478103242
training  [-3.2433, -1.4039, 3.9589]  w:  [1.61735742 0.57067405 1.71903468]
0.7587417929973119  -  30.0658  =  -29.307058207002687
training  [-2.9105, 0.5832, -4.0091]  w:  [1.61735742 0.57067405 1.71903468]
-11.266283626569576  -  2.4887  =  -13.754983626569576
training  [4.0515, 2.4255, -4.5583]  w:  [1.61735742 0.57067405 1.71903468]
0.10101769125544724  -  61.2853  =  -61.18428230874455
training  [1.7539, -0.7567, 0.573]  w:  [1.61735742 0.57067405 1.71903468]
3.3898610054521576  -  57.0797  =  -53.68983899454784
training  [-0.3153, -0.7064, 2.725]  w:  [1.61735742 0.57067405 1.71903468]
3.7712925741420475  -  58.7004  =  -54.92910742585796
training  [4.1213, -3.7513, -1.8806]  w:  [1.61735742 0.57067405 1.71903468]
1.2920289639030567  -  22.1789  =  -20.88687103609694
training  [-3.9599, -4.7557, -3.2102]  w:  [1.61735742 0.57067405 1.71903468]
-14.636973362395217  -  0.1558  =  -14.792773362395216
training  [2.4555, -2.0981, -1.6104]  w:  [1.61735742 0.57067405 1.71903468]
0.005756476120527321  -  24.4796  =  -24.473843523879474
training  [2.3627, -1.8248, -2.8985]  w:  [1.61735742 0.57067405 1.71903468]
-2.2026576530243496  -  15.7052  =  -17.90785765302435
training  [0.6186, 1.5369, 0.1015]  w:  [1.61735742 0.57067405 1.71903468]
2.052048263722807  -  65.2154  =  -63.16335173627719
training  [-3.1581, 4.5694, 4.0636]  w:  [1.61735742 0.57067405 1.71903468]
4.485330858867979  -  90.3564  =  -85.87106914113201
training  [0.9721, 4.3573, 1.2892]  w:  [1.61735742 0.57067405 1.71903468]
6.275010688100505  -  94.3178  =  -88.0427893118995
training  [-2.0006, -0.4211, -3.9847]  w:  [1.61735742 0.57067405 1.71903468]
-10.325833607060012  -  2.4051  =  -12.730933607060013
training  [-3.6588, -2.5952, -1.0915]  w:  [1.61735742 0.57067405 1.71903468]
-9.274926978796785  -  1.5176  =  -10.792526978796785
training  [-2.874, 2.639, -4.4538]  w:  [1.61735742 0.57067405 1.71903468]
-10.798513100116542  -  5.497  =  -16.295513100116544
training  [3.9494, 2.5933, 0.0128]  w:  [1.61735742 0.57067405 1.71903468]
7.889524050546822  -  94.1462  =  -86.25667594945317
training  [-4.2855, 2.4065, -0.6828]  w:  [1.61735742 0.57067405 1.71903468]
-6.731615020980275  -  14.4193  =  -21.150915020980275
training  [-2.5751, 2.4369, 4.9756]  w:  [1.61735742 0.57067405 1.71903468]
5.77904746401008  -  87.1991  =  -81.42005253598992
training  [-4.4625, -3.9408, 3.116]  w:  [1.61735742 0.57067405 1.71903468]
-4.109857699996289  -  4.1344  =  -8.24425769999629
training  [-0.5828, 1.8156, -0.1435]  w:  [1.61735742 0.57067405 1.71903468]
-0.1531615838362056  -  51.1166  =  -51.26976158383621
training  [-4.8672, -0.3674, 3.9445]  w:  [1.61735742 0.57067405 1.71903468]
-1.3009353745510106  -  24.1396  =  -25.44053537455101
training  [3.9719, -2.8784, -3.6245]  w:  [1.61735742 0.57067405 1.71903468]
-1.449287446295366  -  14.6104  =  -16.059687446295367
training  [-3.0334, -4.0148, -1.1]  w:  [1.61735742 0.57067405 1.71903468]
-9.08817231843944  -  1.021  =  -10.109172318439441
training  [-4.0663, 3.2357, 4.2736]  w:  [1.61735742 0.57067405 1.71903468]
2.616336156308374  -  77.2328  =  -74.61646384369162
training  [-1.9263, -3.2499, 4.1749]  w:  [1.61735742 0.57067405 1.71903468]
2.206648719561417  -  26.8814  =  -24.67475128043858
training  [-0.4394, -3.3643, 2.1357]  w:  [1.61735742 0.57067405 1.71903468]
1.0407568301909231  -  20.85  =  -19.80924316980908
training  [-3.9833, 1.6599, 1.1834]  w:  [1.61735742 0.57067405 1.71903468]
-3.4608523227180865  -  25.5397  =  -29.000552322718086
training  [4.9539, 3.9439, -1.5671]  w:  [1.61735742 0.57067405 1.71903468]
7.569009049696996  -  95.9509  =  -88.381890950303
training  [-1.6791, 0.1656, 4.3603]  w:  [1.61735742 0.57067405 1.71903468]
4.874305710644229  -  71.5733  =  -66.69899428935577
training  [-2.0265, 2.027, -3.7523]  w:  [1.61735742 0.57067405 1.71903468]
-8.571152370297035  -  8.503  =  -17.074152370297035
training  [-4.3795, -3.4641, 2.3059]  w:  [1.61735742 0.57067405 1.71903468]
-5.096166714055164  -  3.6654  =  -8.761566714055164
training  [-2.0176, 4.5346, 1.4648]  w:  [1.61735742 0.57067405 1.71903468]
1.8426402031434672  -  81.6212  =  -79.77855979685654
training  [-4.5365, 0.4088, 3.3315]  w:  [1.61735742 0.57067405 1.71903468]
-1.3768863419458892  -  28.9449  =  -30.321786341945888
training  [0.0543, 1.7973, -1.0172]  w:  [1.61735742 0.57067405 1.71903468]
-0.6351071094310685  -  47.9317  =  -48.56680710943107
training  [2.6143, -4.6344, 2.4982]  w:  [1.61735742 0.57067405 1.71903468]
5.878018155929503  -  43.5132  =  -37.635181844070495
training  [1.3107, 3.092, 3.3522]  w:  [1.61735742 0.57067405 1.71903468]
9.646942594531188  -  96.6993  =  -87.05235740546881
training  [-4.1011, 2.4862, -1.7754]  w:  [1.61735742 0.57067405 1.71903468]
-8.266108887349246  -  10.0187  =  -18.284808887349246
training  [-4.1914, -3.7981, 0.5226]  w:  [1.61735742 0.57067405 1.71903468]
-8.04810146770202  -  1.4295  =  -9.47760146770202
training  [2.7724, 0.2505, 4.7913]  w:  [1.61735742 0.57067405 1.71903468]
12.863326449536897  -  96.7925  =  -83.9291735504631
training  [4.0513, -1.7417, 0.4931]  w:  [1.61735742 0.57067405 1.71903468]
6.406113139231682  -  71.1234  =  -64.71728686076833
training  [0.3377, 0.4645, -1.6958]  w:  [1.61735742 0.57067405 1.71903468]
-2.1038793222918617  -  27.9534  =  -30.057279322291862
training  [-3.9085, -1.0112, 1.1947]  w:  [1.61735742 0.57067405 1.71903468]
-4.844776341274708  -  8.608  =  -13.452776341274708
training  [3.2581, -0.8491, -1.3936]  w:  [1.61735742 0.57067405 1.71903468]
2.389306146608964  -  50.1924  =  -47.80309385339103
training  [-1.619, -3.1926, 2.5651]  w:  [1.61735742 0.57067405 1.71903468]
-0.030939757213918284  -  16.4754  =  -16.50633975721392
training  [-2.0603, -2.4461, -0.861]  w:  [1.61735742 0.57067405 1.71903468]
-6.2082561448595435  -  3.9784  =  -10.186656144859544
training  [2.4631, -4.7946, -0.0765]  w:  [1.61735742 0.57067405 1.71903468]
1.11605312890083  -  15.394  =  -14.27794687109917
training  [-4.8966, 4.2368, 1.9474]  w:  [1.61735742 0.57067405 1.71903468]
-2.1540724065257653  -  53.5883  =  -55.74237240652576
training  [-4.5155, 1.537, 4.7273]  w:  [1.61735742 0.57067405 1.71903468]
1.700341236040507  -  59.2523  =  -57.55195876395949
training  [1.6792, 4.3261, -1.7225]  w:  [1.61735742 0.57067405 1.71903468]
2.2236223310278476  -  83.7729  =  -81.54927766897217
training  [1.0347, -3.3649, 3.378]  w:  [1.61735742 0.57067405 1.71903468]
5.560117790029984  -  50.5979  =  -45.03778220997002
training  [0.261, 4.211, 2.3907]  w:  [1.61735742 0.57067405 1.71903468]
6.934934917589771  -  94.9375  =  -88.00256508241023
training  [2.2971, 2.9466, 4.5417]  w:  [1.61735742 0.57067405 1.71903468]
13.20411970646067  -  98.7784  =  -85.57428029353933
training  [2.0725, 0.7739, -4.6808]  w:  [1.61735742 0.57067405 1.71903468]
-4.252839650631415  -  19.5109  =  -23.763739650631415
training  [2.8138, -0.5996, -1.4313]  w:  [1.61735742 0.57067405 1.71903468]
1.748289811085785  -  47.2879  =  -45.53961018891422
training  [-2.1202, -2.4239, 1.6265]  w:  [1.61735742 0.57067405 1.71903468]
-2.016368112499659  -  12.3599  =  -14.376268112499659
training  [1.9253, 2.5195, -2.185]  w:  [1.61735742 0.57067405 1.71903468]
0.7956207184495123  -  65.2467  =  -64.45107928155049
training  [0.5667, -2.7133, -2.6962]  w:  [1.61735742 0.57067405 1.71903468]
-5.266714756243793  -  5.1106  =  -10.377314756243793
training  [-1.0348, -4.3581, 2.1113]  w:  [1.61735742 0.57067405 1.71903468]
-0.5312980924959527  -  10.5192  =  -11.050498092495953
training  [-4.3841, 2.6733, 1.2457]  w:  [1.61735742 0.57067405 1.71903468]
-3.4236722377930664  -  32.4639  =  -35.887572237793066
training  [2.8018, 1.712, 0.9061]  w:  [1.61735742 0.57067405 1.71903468]
7.066123319874552  -  90.1138  =  -83.04767668012545
training  [-1.6242, 2.1521, 1.6044]  w:  [1.61735742 0.57067405 1.71903468]
1.359254939046545  -  63.7879  =  -62.42864506095346
training  [1.0787, 1.4206, -4.5245]  w:  [1.61735742 0.57067405 1.71903468]
-5.2224294293475495  -  18.0555  =  -23.277929429347548
training  [2.4125, -0.8095, -1.5122]  w:  [1.61735742 0.57067405 1.71903468]
0.8403898893548036  -  38.8276  =  -37.987210110645194
training  [-3.9519, -1.0924, -0.4866]  w:  [1.61735742 0.57067405 1.71903468]
-7.8515214012796966  -  3.6777  =  -11.529221401279697
training  [-3.7211, 3.1614, -2.591]  w:  [1.61735742 0.57067405 1.71903468]
-8.668238639658492  -  11.1518  =  -19.82003863965849
training  [0.4954, -1.8257, 2.1505]  w:  [1.61735742 0.57067405 1.71903468]
3.456143349413793  -  47.7531  =  -44.29695665058621
training  [-0.1477, 3.1454, 3.5618]  w:  [1.61735742 0.57067405 1.71903468]
7.678972194530274  -  94.1572  =  -86.47822780546973
training  [3.9048, 2.8907, -2.1849]  w:  [1.61735742 0.57067405 1.71903468]
4.209185844487153  -  85.8791  =  -81.66991415551284
training  [2.9896, 3.5226, 2.3105]  w:  [1.61735742 0.57067405 1.71903468]
10.817337783451201  -  98.038  =  -87.22066221654879
training  [2.3434, 0.0564, -3.6224]  w:  [1.61735742 0.57067405 1.71903468]
-2.40472984318804  -  24.7629  =  -27.16762984318804
training  [-4.4867, 1.3566, 3.3672]  w:  [1.61735742 0.57067405 1.71903468]
-0.6940875428098217  -  40.5785  =  -41.272587542809816
training  [-4.2711, 4.5089, -3.614]  w:  [1.61735742 0.57067405 1.71903468]
-10.547374426391904  -  10.0825  =  -20.629874426391904
training  [-4.1147, -0.5604, 0.8821]  w:  [1.61735742 0.57067405 1.71903468]
-5.458385823911229  -  8.344  =  -13.802385823911228
training  [2.9835, -4.3998, -1.3384]  w:  [1.61735742 0.57067405 1.71903468]
0.013778176208803838  -  13.2692  =  -13.255421823791195
training  [4.4301, 3.6675, 3.0676]  w:  [1.61735742 0.57067405 1.71903468]
14.53131297868726  -  99.3834  =  -84.85208702131274
training  [1.8372, 1.3119, 0.0378]  w:  [1.61735742 0.57067405 1.71903468]
3.7850558480801655  -  74.9026  =  -71.11754415191984
training  [-3.6792, -1.4493, -0.1041]  w:  [1.61735742 0.57067405 1.71903468]
-6.956610832666244  -  4.2442  =  -11.200810832666244
training  [2.2272, 4.97, 3.7705]  w:  [1.61735742 0.57067405 1.71903468]
12.920048739582565  -  99.3199  =  -86.39985126041744
training  [-3.8965, -2.7583, -1.4686]  w:  [1.61735742 0.57067405 1.71903468]
-10.400697754536909  -  1.0337  =  -11.434397754536908
training  [-3.8251, 1.5245, -0.5056]  w:  [1.61735742 0.57067405 1.71903468]
-6.185705226876123  -  12.9762  =  -19.161905226876122
training  [1.4072, 1.0499, 4.6353]  w:  [1.61735742 0.57067405 1.71903468]
10.843337519238048  -  95.4618  =  -84.61846248076195
training  [-1.7119, -1.1275, -4.577]  w:  [1.61735742 0.57067405 1.71903468]
-11.280210909561976  -  1.4655  =  -12.745710909561977
training  [1.5381, -3.5781, 4.7296]  w:  [1.61735742 0.57067405 1.71903468]
8.576075089247787  -  69.9473  =  -61.37122491075221
training  [2.4913, -4.7487, -3.1079]  w:  [1.61735742 0.57067405 1.71903468]
-4.023225196150445  -  3.9825  =  -8.005725196150445
training  [0.8319, -0.7889, 1.6712]  w:  [1.61735742 0.57067405 1.71903468]
3.768125648926463  -  58.8336  =  -55.06547435107353
training  [2.4003, -3.159, 0.8644]  w:  [1.61735742 0.57067405 1.71903468]
3.5653172880875625  -  39.0041  =  -35.43878271191244
training  [-2.6517, 2.2578, 1.7511]  w:  [1.61735742 0.57067405 1.71903468]
0.009922823077623821  -  54.4525  =  -54.44257717692238
training  [2.3496, -1.2964, -1.3898]  w:  [1.61735742 0.57067405 1.71903468]
0.6712067596764468  -  33.888  =  -33.216793240323554
training  [4.706, 3.4156, 1.2028]  w:  [1.61735742 0.57067405 1.71903468]
11.628133219095638  -  98.4665  =  -86.83836678090435
training  [3.6693, 2.3423, 3.1115]  w:  [1.61735742 0.57067405 1.71903468]
12.620035828377842  -  98.3069  =  -85.68686417162216
training  [-4.1377, 0.7103, -4.8074]  w:  [1.61735742 0.57067405 1.71903468]
-14.550877372086337  -  0.9782  =  -15.529077372086336
training  [-1.3356, -3.2314, -4.1613]  w:  [1.61735742 0.57067405 1.71903468]
-11.15763771977813  -  0.7659  =  -11.92353771977813
training  [-1.308, 4.5738, 4.748]  w:  [1.61735742 0.57067405 1.71903468]
8.656622128973417  -  97.0884  =  -88.43177787102658
training  [1.8503, -2.3468, 1.5135]  w:  [1.61735742 0.57067405 1.71903468]
4.255097580476642  -  50.2125  =  -45.957402419523355
training  [0.9794, 4.2458, -2.6876]  w:  [1.61735742 0.57067405 1.71903468]
-0.6130698928669913  -  68.3262  =  -68.93926989286699
training  [2.8936, -2.7623, -0.9651]  w:  [1.61735742 0.57067405 1.71903468]
1.444572142938791  -  28.5596  =  -27.115027857061207
training  [-1.3235, -1.2644, -3.7798]  w:  [1.61735742 0.57067405 1.71903468]
-9.359740113281115  -  2.4511  =  -11.810840113281115
training  [-2.9397, -4.125, -2.3156]  w:  [1.61735742 0.57067405 1.71903468]
-11.089172770614441  -  0.554  =  -11.643172770614441
training  [-4.1333, 1.4012, -2.4215]  w:  [1.61735742 0.57067405 1.71903468]
-10.048037446560187  -  4.4072  =  -14.455237446560186
training  [2.7193, -3.1938, -1.6833]  w:  [1.61735742 0.57067405 1.71903468]
-0.31818981728011675  -  17.0949  =  -17.413089817280117
training  [-2.9433, -4.5495, -3.4777]  w:  [1.61735742 0.57067405 1.71903468]
-13.334936597123274  -  0.2509  =  -13.585836597123274
training  [-1.1173, 2.2317, -1.5199]  w:  [1.61735742 0.57067405 1.71903468]
-3.146260995014505  -  33.1206  =  -36.26686099501451
training  [0.5178, -1.5256, -3.7834]  w:  [1.61735742 0.57067405 1.71903468]
-6.536948478288947  -  5.237  =  -11.773948478288947
training  [-2.7105, 1.6062, 3.8415]  w:  [1.61735742 0.57067405 1.71903468]
3.136441102780874  -  70.4458  =  -67.30935889721913
training  [1.4194, -1.1613, -4.0572]  w:  [1.61735742 0.57067405 1.71903468]
-5.3415141682862615  -  8.3206  =  -13.662114168286262
training  [-0.1552, 1.2735, 4.3004]  w:  [1.61735742 0.57067405 1.71903468]
7.868276284286157  -  90.1085  =  -82.24022371571385
training  [-3.4815, -4.7835, -1.0098]  w:  [1.61735742 0.57067405 1.71903468]
-10.096530390158815  -  0.5839  =  -10.680430390158815
training  [2.8193, 4.1057, -4.526]  w:  [1.61735742 0.57067405 1.71903468]
-0.8775187706486856  -  66.8081  =  -67.68561877064869
training  [-3.9939, 3.0056, -1.5763]  w:  [1.61735742 0.57067405 1.71903468]
-7.454060266253746  -  14.4018  =  -21.855860266253746
training  [-2.0593, 2.4585, 2.3597]  w:  [1.61735742 0.57067405 1.71903468]
2.1287841499871343  -  70.6698  =  -68.54101585001285
training  [-2.6263, 3.1311, 2.9468]  w:  [1.61735742 0.57067405 1.71903468]
2.604823118862723  -  77.309  =  -74.70417688113727
training  [0.3087, -1.1669, 0.4491]  w:  [1.61735742 0.57067405 1.71903468]
0.6053771681205611  -  33.0798  =  -32.47442283187944
training  [-4.085, 1.1728, 1.8622]  w:  [1.61735742 0.57067405 1.71903468]
-2.7364321566271057  -  26.4056  =  -29.142032156627106
training  [-0.9468, 0.7549, 3.9363]  w:  [1.61735742 0.57067405 1.71903468]
5.666124059961657  -  79.7738  =  -74.10767594003833
training  [-3.9515, 0.3005, -4.4521]  w:  [1.61735742 0.57067405 1.71903468]
-13.872814620944176  -  1.0441  =  -14.916914620944176
training  [-3.8772, -2.2493, -1.9634]  w:  [1.61735742 0.57067405 1.71903468]
-10.929588028589956  -  1.0509  =  -11.980488028589956
training  [2.8443, -2.5137, -4.5381]  w:  [1.61735742 0.57067405 1.71903468]
-4.635404938287844  -  6.8897  =  -11.525104938287845
training  [-2.0843, -0.4836, -3.0452]  w:  [1.61735742 0.57067405 1.71903468]
-8.881840464934815  -  3.5346  =  -12.416440464934816
training  [1.0353, -2.7229, 2.2017]  w:  [1.61735742 0.57067405 1.71903468]
3.9053604427787145  -  43.9562  =  -40.05083955722129
training  [4.6442, 3.0445, 2.2175]  w:  [1.61735742 0.57067405 1.71903468]
13.060707886290839  -  98.8492  =  -85.78849211370915
training  [-0.6752, 4.861, 3.778]  w:  [1.61735742 0.57067405 1.71903468]
8.176519847542124  -  97.017  =  -88.84048015245787
training  [1.9475, -4.7001, 0.8243]  w:  [1.61735742 0.57067405 1.71903468]
1.8845787835461956  -  18.7839  =  -16.899321216453803
training  [2.581, 0.3566, -4.2932]  w:  [1.61735742 0.57067405 1.71903468]
-3.0022578374693207  -  23.5455  =  -26.54775783746932
training  [-0.6736, -4.1292, 4.2274]  w:  [1.61735742 0.57067405 1.71903468]
3.8211679937259717  -  31.2667  =  -27.44553200627403
training  [1.555, 3.0209, 3.0037]  w:  [1.61735742 0.57067405 1.71903468]
9.402404500371457  -  96.4078  =  -87.00539549962853
training  [-3.9024, 4.8914, -2.1405]  w:  [1.61735742 0.57067405 1.71903468]
-7.199774314324859  -  25.4308  =  -32.63057431432486
training  [4.3376, -4.3305, 0.4366]  w:  [1.61735742 0.57067405 1.71903468]
5.294676137799224  -  43.0907  =  -37.79602386220078
training  [-3.1254, 4.394, 4.8478]  w:  [1.61735742 0.57067405 1.71903468]
5.786189218514222  -  92.8121  =  -87.02591078148578
training  [-2.3382, -4.8182, 2.1568]  w:  [1.61735742 0.57067405 1.71903468]
-2.8237128067522383  -  4.7434  =  -7.567112806752238
training  [2.9783, 1.8384, 3.3897]  w:  [1.61735742 0.57067405 1.71903468]
11.69311464713057  -  97.3486  =  -85.65548535286943
training  [-0.124, 2.8374, -0.6674]  w:  [1.61735742 0.57067405 1.71903468]
0.2713944707320699  -  62.785  =  -62.51360552926793
training  [2.6896, 0.3414, -0.2938]  w:  [1.61735742 0.57067405 1.71903468]
4.039820250867619  -  70.4455  =  -66.40567974913237
training  [-1.0399, 3.8536, 0.6071]  w:  [1.61735742 0.57067405 1.71903468]
1.5608854797514349  -  77.0369  =  -75.47601452024857
training  [-2.2706, 3.99, -2.3091]  w:  [1.61735742 0.57067405 1.71903468]
-5.36480530675295  -  31.1134  =  -36.47820530675295
training  [-4.6277, 1.2594, 2.4902]  w:  [1.61735742 0.57067405 1.71903468]
-2.485197875056228  -  28.1093  =  -30.594497875056227
training  [1.7329, -3.6213, 0.0389]  w:  [1.61735742 0.57067405 1.71903468]
0.8030072008698808  -  19.3919  =  -18.588892799130118
training  [-0.7044, -2.822, 1.4681]  w:  [1.61735742 0.57067405 1.71903468]
-0.2259939066475125  -  17.8122  =  -18.038193906647514
training  [-0.4826, -3.1786, -1.9225]  w:  [1.61735742 0.57067405 1.71903468]
-5.899325397285947  -  3.5851  =  -9.484425397285948
training  [1.0986, -4.5818, -3.6128]  w:  [1.61735742 0.57067405 1.71903468]
-7.048413991448395  -  1.7158  =  -8.764213991448395
training  [-4.406, -3.9306, -0.2443]  w:  [1.61735742 0.57067405 1.71903468]
-9.789128381255539  -  0.8241  =  -10.613228381255539
training  [-1.8419, 1.1644, -1.3754]  w:  [1.61735742 0.57067405 1.71903468]
-4.6788780807807635  -  17.8517  =  -22.530578080780764
training  [2.7272, 4.3966, 2.8811]  w:  [1.61735742 0.57067405 1.71903468]
11.872593503685906  -  98.904  =  -87.03140649631409
training  [1.9643, -1.4554, 2.803]  w:  [1.61735742 0.57067405 1.71903468]
7.16487039749858  -  76.0591  =  -68.89422960250143
training  [-3.7467, -0.8937, 1.6851]  w:  [1.61735742 0.57067405 1.71903468]
-3.6730191006000834  -  12.1571  =  -15.830119100600083
training  [-3.6985, 4.8435, -3.665]  w:  [1.61735742 0.57067405 1.71903468]
-9.51799879960868  -  14.6793  =  -24.19729879960868
246759.35389913255
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.58275665 0.60528335 1.65496734]
11.996407767203415  -  87.3174  =  -75.32099223279658
training  [-4.1793, -4.9218, 1.7664]  w:  [1.58275665 0.60528335 1.65496734]
-6.6705641703283485  -  1.5257  =  -8.196264170328348
training  [-3.9429, -0.7689, 4.883]  w:  [1.58275665 0.60528335 1.65496734]
1.375151960751059  -  39.7859  =  -38.410748039248936
training  [-3.5796, 1.5557, 2.6683]  w:  [1.58275665 0.60528335 1.65496734]
-0.3080470382443359  -  45.5674  =  -45.87544703824433
training  [-3.3354, 2.2292, -1.633]  w:  [1.58275665 0.60528335 1.65496734]
-6.632390556570657  -  13.3589  =  -19.991290556570657
training  [1.2096, 0.3121, 1.6238]  w:  [1.58275665 0.60528335 1.65496734]
4.7907473520144315  -  74.5119  =  -69.72115264798556
training  [0.7371, -3.9118, -2.5583]  w:  [1.58275665 0.60528335 1.65496734]
-5.435000446372809  -  3.3358  =  -8.77080044637281
training  [-4.4792, 1.3177, -2.0449]  w:  [1.58275665 0.60528335 1.65496734]
-9.676144440245174  -  4.2974  =  -13.973544440245174
training  [4.312, -3.735, 1.8018]  w:  [1.58275665 0.60528335 1.65496734]
7.546033516907279  -  66.5833  =  -59.037266483092715
training  [2.2866, -3.657, 0.2785]  w:  [1.58275665 0.60528335 1.65496734]
1.8665185422461106  -  26.0005  =  -24.133981457753887
training  [2.3784, -4.0141, -0.8841]  w:  [1.58275665 0.60528335 1.65496734]
-0.1283961152329085  -  14.6809  =  -14.809296115232907
training  [-4.366, -3.5797, 1.0264]  w:  [1.58275665 0.60528335 1.65496734]
-7.378389882322679  -  1.8713  =  -9.249689882322679
training  [3.6044, -3.3175, 2.5052]  w:  [1.58275665 0.60528335 1.65496734]
7.842884738821458  -  71.0139  =  -63.171015261178546
training  [4.3441, -3.0375, 0.8353]  w:  [1.58275665 0.60528335 1.65496734]
6.419499207672279  -  63.8979  =  -57.47840079232772
training  [4.844, -1.8252, 0.5179]  w:  [1.58275665 0.60528335 1.65496734]
7.419217632740228  -  78.0461  =  -70.62688236725977
training  [3.5894, -1.8357, 0.8357]  w:  [1.58275665 0.60528335 1.65496734]
5.953084283389093  -  68.8838  =  -62.9307157166109
training  [2.8556, -2.8244, 0.1182]  w:  [1.58275665 0.60528335 1.65496734]
3.0057747322377484  -  39.5252  =  -36.51942526776225
training  [0.1338, -2.4896, -4.1741]  w:  [1.58275665 0.60528335 1.65496734]
-8.20313978176091  -  2.2644  =  -10.46753978176091
training  [-3.224, 3.9292, 2.1957]  w:  [1.58275665 0.60528335 1.65496734]
0.9092837002753971  -  72.1211  =  -71.2118162997246
training  [-1.0141, 2.0322, 4.9616]  w:  [1.58275665 0.60528335 1.65496734]
7.836269277526622  -  92.3427  =  -84.50643072247337
training  [-3.6607, 0.5574, -1.4547]  w:  [1.58275665 0.60528335 1.65496734]
-7.864093328437145  -  5.8471  =  -13.711193328437144
training  [-4.6911, -3.1557, 4.7126]  w:  [1.58275665 0.60528335 1.65496734]
-1.5357633093323253  -  11.2337  =  -12.769463309332327
training  [4.3914, -2.8797, -1.5355]  w:  [1.58275665 0.60528335 1.65496734]
2.666280734350297  -  37.475  =  -34.80871926564971
training  [-1.9869, -4.2265, 3.8654]  w:  [1.58275665 0.60528335 1.65496734]
0.6941014815903088  -  15.7889  =  -15.094798518409691
training  [-2.0447, 4.138, -0.4531]  w:  [1.58275665 0.60528335 1.65496734]
-1.4814657131845799  -  57.936  =  -59.41746571318458
training  [-1.6706, 2.0672, -0.8657]  w:  [1.58275665 0.60528335 1.65496734]
-2.825616743418461  -  32.4185  =  -35.24411674341846
training  [-0.3293, 0.5779, -2.8227]  w:  [1.58275665 0.60528335 1.65496734]
-4.842884833908384  -  14.3434  =  -19.186284833908385
training  [1.482, -1.8657, -3.7435]  w:  [1.58275665 0.60528335 1.65496734]
-4.979002041528188  -  7.1519  =  -12.130902041528188
training  [-4.7477, -3.338, -1.9109]  w:  [1.58275665 0.60528335 1.65496734]
-12.697366685677071  -  0.4077  =  -13.105066685677071
training  [3.4221, 1.225, 2.261]  w:  [1.58275665 0.60528335 1.65496734]
9.899704808741292  -  95.0454  =  -85.14569519125871
training  [0.5903, 4.8793, 2.8287]  w:  [1.58275665 0.60528335 1.65496734]
8.569066440156623  -  97.4647  =  -88.89563355984338
training  [3.541, -3.2957, 1.9379]  w:  [1.58275665 0.60528335 1.65496734]
6.816870170658918  -  64.3732  =  -57.55632982934108
training  [-1.5212, -2.4221, -4.902]  w:  [1.58275665 0.60528335 1.65496734]
-11.986396143313211  -  0.7227  =  -12.70909614331321
training  [-0.5397, -1.032, 3.4321]  w:  [1.58275665 0.60528335 1.65496734]
4.201147231169543  -  60.5921  =  -56.39095276883046
training  [-4.4576, -4.2601, 4.2233]  w:  [1.58275665 0.60528335 1.65496734]
-2.6444400873345355  -  6.0247  =  -8.669140087334537
training  [-3.2289, 1.841, 2.7095]  w:  [1.58275665 0.60528335 1.65496734]
0.4878977148649035  -  54.0111  =  -53.5232022851351
training  [1.6281, -0.9761, -4.5734]  w:  [1.58275665 0.60528335 1.65496734]
-5.582758621231754  -  7.8658  =  -13.448558621231754
training  [-1.6917, 4.8284, -1.2181]  w:  [1.58275665 0.60528335 1.65496734]
-1.7709150050282068  -  61.2837  =  -63.05461500502821
training  [3.9849, -0.9782, 2.0434]  w:  [1.58275665 0.60528335 1.65496734]
9.096799074593319  -  88.3402  =  -79.24340092540668
training  [-3.8184, 1.2067, 2.2951]  w:  [1.58275665 0.60528335 1.65496734]
-1.5148870293829066  -  34.1122  =  -35.627087029382906
training  [4.8842, -3.4563, -2.7572]  w:  [1.58275665 0.60528335 1.65496734]
1.0753832283225506  -  23.7819  =  -22.70651677167745
training  [0.3998, -1.1865, -2.3095]  w:  [1.58275665 0.60528335 1.65496734]
-3.907529667301185  -  11.4246  =  -15.332129667301185
training  [2.0692, -3.3887, 1.7303]  w:  [1.58275665 0.60528335 1.65496734]
4.087506357964077  -  42.6881  =  -38.60059364203592
training  [4.9949, 2.5811, -0.2251]  w:  [1.58275665 0.60528335 1.65496734]
9.095474915843345  -  95.9901  =  -86.89462508415666
training  [-2.1215, 3.7111, 1.2372]  w:  [1.58275665 0.60528335 1.65496734]
0.9359744117879369  -  71.3692  =  -70.43322558821207
training  [-0.8548, -1.4922, -2.6356]  w:  [1.58275665 0.60528335 1.65496734]
-6.617976134545721  -  4.7821  =  -11.40007613454572
training  [-0.3516, 1.8554, -3.2288]  w:  [1.58275665 0.60528335 1.65496734]
-4.777013061199  -  20.3834  =  -25.160413061199
training  [2.6396, -2.0585, 3.2964]  w:  [1.58275665 0.60528335 1.65496734]
8.387303024380602  -  80.826  =  -72.4386969756194
training  [3.182, 0.3063, 2.6692]  w:  [1.58275665 0.60528335 1.65496734]
9.639168789143518  -  92.9483  =  -83.30913121085649
training  [-3.9978, 3.3242, 4.3448]  w:  [1.58275665 0.60528335 1.65496734]
2.875040490377131  -  79.1768  =  -76.30175950962287
training  [-3.2188, 0.9749, -3.9211]  w:  [1.58275665 0.60528335 1.65496734]
-10.993778817955672  -  2.7053  =  -13.699078817955671
training  [-1.4037, -1.6469, -3.1777]  w:  [1.58275665 0.60528335 1.65496734]
-8.47754639211006  -  2.6234  =  -11.10094639211006
training  [-4.433, -2.0077, -4.009]  w:  [1.58275665 0.60528335 1.65496734]
-14.866351704055777  -  0.3253  =  -15.191651704055777
training  [0.2189, -0.4741, -0.1024]  w:  [1.58275665 0.60528335 1.65496734]
-0.10996806259416236  -  33.6531  =  -33.763068062594165
training  [-1.6415, -0.7735, -3.0675]  w:  [1.58275665 0.60528335 1.65496734]
-8.142894041965931  -  3.7641  =  -11.90699404196593
training  [-3.2433, -1.4039, 3.9589]  w:  [1.58275665 0.60528335 1.65496734]
0.5687382637238905  -  30.0658  =  -29.49706173627611
training  [-2.9105, 0.5832, -4.0091]  w:  [1.58275665 0.60528335 1.65496734]
-10.888541557804018  -  2.4887  =  -13.377241557804018
training  [4.0515, 2.4255, -4.5583]  w:  [1.58275665 0.60528335 1.65496734]
0.3368157110348875  -  61.2853  =  -60.94848428896511
training  [1.7539, -0.7567, 0.573]  w:  [1.58275665 0.60528335 1.65496734]
3.2662752659098553  -  57.0797  =  -53.81342473409015
training  [-0.3153, -0.7064, 2.725]  w:  [1.58275665 0.60528335 1.65496734]
3.5831706757071418  -  58.7004  =  -55.11722932429286
training  [4.1213, -3.7513, -1.8806]  w:  [1.58275665 0.60528335 1.65496734]
1.1400839618622842  -  22.1789  =  -21.038816038137714
training  [-3.9599, -4.7557, -3.2102]  w:  [1.58275665 0.60528335 1.65496734]
-14.4588802736653  -  0.1558  =  -14.6146802736653
training  [2.4555, -2.0981, -1.6104]  w:  [1.58275665 0.60528335 1.65496734]
-0.04864545332329939  -  24.4796  =  -24.5282454533233
training  [2.3627, -1.8248, -2.8985]  w:  [1.58275665 0.60528335 1.65496734]
-2.16186476431767  -  15.7052  =  -17.867064764317668
training  [0.6186, 1.5369, 0.1015]  w:  [1.58275665 0.60528335 1.65496734]
2.077332436035892  -  65.2154  =  -63.138067563964114
training  [-3.1581, 4.5694, 4.0636]  w:  [1.58275665 0.60528335 1.65496734]
4.4924032659429525  -  90.3564  =  -85.86399673405704
training  [0.9721, 4.3573, 1.2892]  w:  [1.58275665 0.60528335 1.65496734]
6.309582795328587  -  94.3178  =  -88.00821720467142
training  [-2.0006, -0.4211, -3.9847]  w:  [1.58275665 0.60528335 1.65496734]
-10.015896148733207  -  2.4051  =  -12.420996148733206
training  [-3.6588, -2.5952, -1.0915]  w:  [1.58275665 0.60528335 1.65496734]
-9.168218251754096  -  1.5176  =  -10.685818251754096
training  [-2.874, 2.639, -4.4538]  w:  [1.58275665 0.60528335 1.65496734]
-10.322393399455922  -  5.497  =  -15.819393399455922
training  [3.9494, 2.5933, 0.0128]  w:  [1.58275665 0.60528335 1.65496734]
7.841804023873174  -  94.1462  =  -86.30439597612681
training  [-4.2855, 2.4065, -0.6828]  w:  [1.58275665 0.60528335 1.65496734]
-6.456300944073342  -  14.4193  =  -20.87560094407334
training  [-2.5751, 2.4369, 4.9756]  w:  [1.58275665 0.60528335 1.65496734]
5.633713859588396  -  87.1991  =  -81.5653861404116
training  [-4.4625, -3.9408, 3.116]  w:  [1.58275665 0.60528335 1.65496734]
-4.291473958794854  -  4.1344  =  -8.425873958794854
training  [-0.5828, 1.8156, -0.1435]  w:  [1.58275665 0.60528335 1.65496734]
-0.06096593411589654  -  51.1166  =  -51.1775659341159
training  [-4.8672, -0.3674, 3.9445]  w:  [1.58275665 0.60528335 1.65496734]
-1.3979555975025697  -  24.1396  =  -25.53755559750257
training  [3.9719, -2.8784, -3.6245]  w:  [1.58275665 0.60528335 1.65496734]
-1.4541255917703353  -  14.6104  =  -16.064525591770334
training  [-3.0334, -4.0148, -1.1]  w:  [1.58275665 0.60528335 1.65496734]
-9.051689712420465  -  1.021  =  -10.072689712420466
training  [-4.0663, 3.2357, 4.2736]  w:  [1.58275665 0.60528335 1.65496734]
2.595220408136923  -  77.2328  =  -74.63757959186307
training  [-1.9263, -3.2499, 4.1749]  w:  [1.58275665 0.60528335 1.65496734]
1.8933486501774182  -  26.8814  =  -24.98805134982258
training  [-0.4394, -3.3643, 2.1357]  w:  [1.58275665 0.60528335 1.65496734]
0.8026956952013884  -  20.85  =  -20.04730430479861
training  [-3.9833, 1.6599, 1.1834]  w:  [1.58275665 0.60528335 1.65496734]
-3.3413963804625118  -  25.5397  =  -28.881096380462512
training  [4.9539, 3.9439, -1.5671]  w:  [1.58275665 0.60528335 1.65496734]
7.63449587314828  -  95.9509  =  -88.31640412685172
training  [-1.6791, 0.1656, 4.3603]  w:  [1.58275665 0.60528335 1.65496734]
4.658782333337365  -  71.5733  =  -66.91451766666263
training  [-2.0265, 2.027, -3.7523]  w:  [1.58275665 0.60528335 1.65496734]
-8.19048095818888  -  8.503  =  -16.69348095818888
training  [-4.3795, -3.4641, 2.3059]  w:  [1.58275665 0.60528335 1.65496734]
-5.2122556264629125  -  3.6654  =  -8.877655626462913
training  [-2.0176, 4.5346, 1.4648]  w:  [1.58275665 0.60528335 1.65496734]
1.9755442366388714  -  81.6212  =  -79.64565576336113
training  [-4.5365, 0.4088, 3.3315]  w:  [1.58275665 0.60528335 1.65496734]
-1.4192120148739855  -  28.9449  =  -30.364112014873985
training  [0.0543, 1.7973, -1.0172]  w:  [1.58275665 0.60528335 1.65496734]
-0.5096133237998599  -  47.9317  =  -48.44131332379986
training  [2.6143, -4.6344, 2.4982]  w:  [1.58275665 0.60528335 1.65496734]
5.467114958178718  -  43.5132  =  -38.04608504182128
training  [1.3107, 3.092, 3.3522]  w:  [1.58275665 0.60528335 1.65496734]
9.493836798728893  -  96.6993  =  -87.2054632012711
training  [-4.1011, 2.4862, -1.7754]  w:  [1.58275665 0.60528335 1.65496734]
-7.924416852830516  -  10.0187  =  -17.943116852830517
training  [-4.1914, -3.7981, 0.5226]  w:  [1.58275665 0.60528335 1.65496734]
-8.068007002514587  -  1.4295  =  -9.497507002514588
training  [2.7724, 0.2505, 4.7913]  w:  [1.58275665 0.60528335 1.65496734]
12.469103051337672  -  96.7925  =  -84.32339694866234
training  [4.0513, -1.7417, 0.4931]  w:  [1.58275665 0.60528335 1.65496734]
6.174064404569625  -  71.1234  =  -64.94933559543038
training  [0.3377, 0.4645, -1.6958]  w:  [1.58275665 0.60528335 1.65496734]
-1.9908425807518049  -  27.9534  =  -29.944242580751805
training  [-3.9085, -1.0112, 1.1947]  w:  [1.58275665 0.60528335 1.65496734]
-4.821077417101769  -  8.608  =  -13.42907741710177
training  [3.2581, -0.8491, -1.3936]  w:  [1.58275665 0.60528335 1.65496734]
2.336470863869984  -  50.1924  =  -47.855929136130015
training  [-1.619, -3.1926, 2.5651]  w:  [1.58275665 0.60528335 1.65496734]
-0.2497539228145449  -  16.4754  =  -16.725153922814545
training  [-2.0603, -2.4461, -0.861]  w:  [1.58275665 0.60528335 1.65496734]
-6.1664640229725745  -  3.9784  =  -10.144864022972575
training  [2.4631, -4.7946, -0.0765]  w:  [1.58275665 0.60528335 1.65496734]
0.8697913418729475  -  15.394  =  -14.524208658127053
training  [-4.8966, 4.2368, 1.9474]  w:  [1.58275665 0.60528335 1.65496734]
-1.9627783076394176  -  53.5883  =  -55.551078307639415
training  [-4.5155, 1.537, 4.7273]  w:  [1.58275665 0.60528335 1.65496734]
1.6069099710618664  -  59.2523  =  -57.64539002893813
training  [1.6792, 4.3261, -1.7225]  w:  [1.58275665 0.60528335 1.65496734]
2.425600037289638  -  83.7729  =  -81.34729996271037
training  [1.0347, -3.3649, 3.378]  w:  [1.58275665 0.60528335 1.65496734]
5.191440035835085  -  50.5979  =  -45.40645996416492
training  [0.261, 4.211, 2.3907]  w:  [1.58275665 0.60528335 1.65496734]
6.91847811346857  -  94.9375  =  -88.01902188653143
training  [2.2971, 2.9466, 4.5417]  w:  [1.58275665 0.60528335 1.65496734]
12.935643414895779  -  98.7784  =  -85.84275658510423
training  [2.0725, 0.7739, -4.6808]  w:  [1.58275665 0.60528335 1.65496734]
-3.997879189274016  -  19.5109  =  -23.508779189274016
training  [2.8138, -0.5996, -1.4313]  w:  [1.58275665 0.60528335 1.65496734]
1.721878011210674  -  47.2879  =  -45.56602198878932
training  [-2.1202, -2.4239, 1.6265]  w:  [1.58275665 0.60528335 1.65496734]
-2.131102590964216  -  12.3599  =  -14.491002590964216
training  [1.9253, 2.5195, -2.185]  w:  [1.58275665 0.60528335 1.65496734]
0.9561891471521489  -  65.2467  =  -64.29051085284786
training  [0.5667, -2.7133, -2.6962]  w:  [1.58275665 0.60528335 1.65496734]
-5.207490077429672  -  5.1106  =  -10.318090077429673
training  [-1.0348, -4.3581, 2.1113]  w:  [1.58275665 0.60528335 1.65496734]
-0.7815894151682046  -  10.5192  =  -11.300789415168204
training  [-4.3841, 2.6733, 1.2457]  w:  [1.58275665 0.60528335 1.65496734]
-3.2592666308466662  -  32.4639  =  -35.72316663084667
training  [2.8018, 1.712, 0.9061]  w:  [1.58275665 0.60528335 1.65496734]
6.970378597913485  -  90.1138  =  -83.14342140208652
training  [-1.6242, 2.1521, 1.6044]  w:  [1.58275665 0.60528335 1.65496734]
1.3871465551953641  -  63.7879  =  -62.400753444804636
training  [1.0787, 1.4206, -4.5245]  w:  [1.58275665 0.60528335 1.65496734]
-4.9207146097865815  -  18.0555  =  -22.97621460978658
training  [2.4125, -0.8095, -1.5122]  w:  [1.58275665 0.60528335 1.65496734]
0.8257819328458602  -  38.8276  =  -38.00181806715413
training  [-3.9519, -1.0924, -0.4866]  w:  [1.58275665 0.60528335 1.65496734]
-7.721414657412817  -  3.6777  =  -11.399114657412817
training  [-3.7211, 3.1614, -2.591]  w:  [1.58275665 0.60528335 1.65496734]
-8.264073369581837  -  11.1518  =  -19.41587336958184
training  [0.4954, -1.8257, 2.1505]  w:  [1.58275665 0.60528335 1.65496734]
3.2380390977011815  -  47.7531  =  -44.51506090229882
training  [-0.1477, 3.1454, 3.5618]  w:  [1.58275665 0.60528335 1.65496734]
7.564747783488414  -  94.1572  =  -86.59245221651159
training  [3.9048, 2.8907, -2.1849]  w:  [1.58275665 0.60528335 1.65496734]
4.314102617383663  -  85.8791  =  -81.56499738261633
training  [2.9896, 3.5226, 2.3105]  w:  [1.58275665 0.60528335 1.65496734]
10.68778247289745  -  98.038  =  -87.35021752710254
training  [2.3434, 0.0564, -3.6224]  w:  [1.58275665 0.60528335 1.65496734]
-2.251783782740088  -  24.7629  =  -27.014683782740086
training  [-4.4867, 1.3566, 3.3672]  w:  [1.58275665 0.60528335 1.65496734]
-0.7076208371433257  -  40.5785  =  -41.28612083714332
training  [-4.2711, 4.5089, -3.614]  w:  [1.58275665 0.60528335 1.65496734]
-10.012001801146898  -  10.0825  =  -20.094501801146897
training  [-4.1147, -0.5604, 0.8821]  w:  [1.58275665 0.60528335 1.65496734]
-5.391922894389781  -  8.344  =  -13.73592289438978
training  [2.9835, -4.3998, -1.3384]  w:  [1.58275665 0.60528335 1.65496734]
-0.15597951827266154  -  13.2692  =  -13.42517951827266
training  [4.4301, 3.6675, 3.0676]  w:  [1.58275665 0.60528335 1.65496734]
14.30842476324888  -  99.3834  =  -85.07497523675111
training  [1.8372, 1.3119, 0.0378]  w:  [1.58275665 0.60528335 1.65496734]
3.764469517980519  -  74.9026  =  -71.13813048201949
training  [-3.6792, -1.4493, -0.1041]  w:  [1.58275665 0.60528335 1.65496734]
-6.872797538626033  -  4.2442  =  -11.116997538626034
training  [2.2272, 4.97, 3.7705]  w:  [1.58275665 0.60528335 1.65496734]
12.773428247418174  -  99.3199  =  -86.54647175258182
training  [-3.8965, -2.7583, -1.4686]  w:  [1.58275665 0.60528335 1.65496734]
-10.267249407820653  -  1.0337  =  -11.300949407820653
training  [-3.8251, 1.5245, -0.5056]  w:  [1.58275665 0.60528335 1.65496734]
-5.968199486012522  -  12.9762  =  -18.94439948601252
training  [1.4072, 1.0499, 4.6353]  w:  [1.58275665 0.60528335 1.65496734]
10.53401227718236  -  95.4618  =  -84.92778772281764
training  [-1.7119, -1.1275, -4.577]  w:  [1.58275665 0.60528335 1.65496734]
-10.966763621201771  -  1.4655  =  -12.432263621201772
training  [1.5381, -3.5781, 4.7296]  w:  [1.58275665 0.60528335 1.65496734]
8.096007183960198  -  69.9473  =  -61.8512928160398
training  [2.4913, -4.7487, -3.1079]  w:  [1.58275665 0.60528335 1.65496734]
-4.074660417347369  -  3.9825  =  -8.057160417347369
training  [0.8319, -0.7889, 1.6712]  w:  [1.58275665 0.60528335 1.65496734]
3.6049686445216524  -  58.8336  =  -55.22863135547834
training  [2.4003, -3.159, 0.8644]  w:  [1.58275665 0.60528335 1.65496734]
3.3175544496626683  -  39.0041  =  -35.686545550337335
training  [-2.6517, 2.2578, 1.7511]  w:  [1.58275665 0.60528335 1.65496734]
0.06762625484582596  -  54.4525  =  -54.384873745154174
training  [2.3496, -1.2964, -1.3898]  w:  [1.58275665 0.60528335 1.65496734]
0.6340820774257216  -  33.888  =  -33.253917922574274
training  [4.706, 3.4156, 1.2028]  w:  [1.58275665 0.60528335 1.65496734]
11.50645334612669  -  98.4665  =  -86.9600466538733
training  [3.6693, 2.3423, 3.1115]  w:  [1.58275665 0.60528335 1.65496734]
12.374795068832041  -  98.3069  =  -85.93210493116796
training  [-4.1377, 0.7103, -4.8074]  w:  [1.58275665 0.60528335 1.65496734]
-14.075129436677543  -  0.9782  =  -15.053329436677542
training  [-1.3356, -3.2314, -4.1613]  w:  [1.58275665 0.60528335 1.65496734]
-10.956658015820985  -  0.7659  =  -11.722558015820985
training  [-1.308, 4.5738, 4.748]  w:  [1.58275665 0.60528335 1.65496734]
8.555984244008425  -  97.0884  =  -88.53241575599156
training  [1.8503, -2.3468, 1.5135]  w:  [1.58275665 0.60528335 1.65496734]
4.012888732804522  -  50.2125  =  -46.19961126719548
training  [0.9794, 4.2458, -2.6876]  w:  [1.58275665 0.60528335 1.65496734]
-0.32782630354930387  -  68.3262  =  -68.6540263035493
training  [2.8936, -2.7623, -0.9651]  w:  [1.58275665 0.60528335 1.65496734]
1.3106814588889455  -  28.5596  =  -27.248918541111053
training  [-1.3235, -1.2644, -3.7798]  w:  [1.58275665 0.60528335 1.65496734]
-9.11554426300506  -  2.4511  =  -11.56664426300506
training  [-2.9397, -4.125, -2.3156]  w:  [1.58275665 0.60528335 1.65496734]
-10.98186594147795  -  0.554  =  -11.535865941477951
training  [-4.1333, 1.4012, -2.4215]  w:  [1.58275665 0.60528335 1.65496734]
-9.701388455564995  -  4.4072  =  -14.108588455564995
training  [2.7193, -3.1938, -1.6833]  w:  [1.58275665 0.60528335 1.65496734]
-0.4149703380847063  -  17.0949  =  -17.509870338084706
training  [-2.9433, -4.5495, -3.4777]  w:  [1.58275665 0.60528335 1.65496734]
-13.167744197907966  -  0.2509  =  -13.418644197907966
training  [-1.1173, 2.2317, -1.5199]  w:  [1.58275665 0.60528335 1.65496734]
-2.9329880118205116  -  33.1206  =  -36.053588011820516
training  [0.5178, -1.5256, -3.7834]  w:  [1.58275665 0.60528335 1.65496734]
-6.365272333925311  -  5.237  =  -11.602272333925312
training  [-2.7105, 1.6062, 3.8415]  w:  [1.58275665 0.60528335 1.65496734]
3.0397012638761716  -  70.4458  =  -67.40609873612384
training  [1.4194, -1.1613, -4.0572]  w:  [1.58275665 0.60528335 1.65496734]
-5.170884269244794  -  8.3206  =  -13.491484269244793
training  [-0.1552, 1.2735, 4.3004]  w:  [1.58275665 0.60528335 1.65496734]
7.642206078760331  -  90.1085  =  -82.46629392123967
training  [-3.4815, -4.7835, -1.0098]  w:  [1.58275665 0.60528335 1.65496734]
-10.076926227624163  -  0.5839  =  -10.660826227624163
training  [2.8193, 4.1057, -4.526]  w:  [1.58275665 0.60528335 1.65496734]
-0.5430045001158392  -  66.8081  =  -67.35110450011584
training  [-3.9939, 3.0056, -1.5763]  w:  [1.58275665 0.60528335 1.65496734]
-7.110857168055055  -  14.4018  =  -21.512657168055057
training  [-2.0593, 2.4585, 2.3597]  w:  [1.58275665 0.60528335 1.65496734]
2.13394478932021  -  70.6698  =  -68.53585521067978
training  [-2.6263, 3.1311, 2.9468]  w:  [1.58275665 0.60528335 1.65496734]
2.615266677998127  -  77.309  =  -74.69373332200188
training  [0.3087, -1.1669, 0.4491]  w:  [1.58275665 0.60528335 1.65496734]
0.525537667056509  -  33.0798  =  -32.55426233294349
training  [-4.085, 1.1728, 1.8622]  w:  [1.58275665 0.60528335 1.65496734]
-2.6738044211621754  -  26.4056  =  -29.079404421162174
training  [-0.9468, 0.7549, 3.9363]  w:  [1.58275665 0.60528335 1.65496734]
5.47282235645764  -  79.7738  =  -74.30097764354235
training  [-3.9515, 0.3005, -4.4521]  w:  [1.58275665 0.60528335 1.65496734]
-13.440455369408085  -  1.0441  =  -14.484555369408085
training  [-3.8772, -2.2493, -1.9634]  w:  [1.58275665 0.60528335 1.65496734]
-10.74749081874999  -  1.0509  =  -11.79839081874999
training  [2.8443, -2.5137, -4.5381]  w:  [1.58275665 0.60528335 1.65496734]
-4.5300733179552815  -  6.8897  =  -11.419773317955283
training  [-2.0843, -0.4836, -3.0452]  w:  [1.58275665 0.60528335 1.65496734]
-8.63136127160772  -  3.5346  =  -12.16596127160772
training  [1.0353, -2.7229, 2.2017]  w:  [1.58275665 0.60528335 1.65496734]
3.6342435174455203  -  43.9562  =  -40.321956482554484
training  [4.6442, 3.0445, 2.2175]  w:  [1.58275665 0.60528335 1.65496734]
12.86331369525489  -  98.8492  =  -85.98588630474511
training  [-0.6752, 4.861, 3.778]  w:  [1.58275665 0.60528335 1.65496734]
8.126071710070887  -  97.017  =  -88.89092828992911
training  [1.9475, -4.7001, 0.8243]  w:  [1.58275665 0.60528335 1.65496734]
1.6017158712951078  -  18.7839  =  -17.18218412870489
training  [2.581, 0.3566, -4.2932]  w:  [1.58275665 0.60528335 1.65496734]
-2.804166833030246  -  23.5455  =  -26.34966683303025
training  [-0.6736, -4.1292, 4.2274]  w:  [1.58275665 0.60528335 1.65496734]
3.4307280410715193  -  31.2667  =  -27.835971958928482
training  [1.555, 3.0209, 3.0037]  w:  [1.58275665 0.60528335 1.65496734]
9.2607124834607  -  96.4078  =  -87.1470875165393
training  [-3.9024, 4.8914, -2.1405]  w:  [1.58275665 0.60528335 1.65496734]
-6.758324161372482  -  25.4308  =  -32.18912416137248
training  [4.3376, -4.3305, 0.4366]  w:  [1.58275665 0.60528335 1.65496734]
4.966744433984  -  43.0907  =  -38.123955566016
training  [-3.1254, 4.394, 4.8478]  w:  [1.58275665 0.60528335 1.65496734]
5.735818098446529  -  92.8121  =  -87.07628190155347
training  [-2.3382, -4.8182, 2.1568]  w:  [1.58275665 0.60528335 1.65496734]
-3.0477442922373394  -  4.7434  =  -7.791144292237339
training  [2.9783, 1.8384, 3.3897]  w:  [1.58275665 0.60528335 1.65496734]
11.436519855250172  -  97.3486  =  -85.91208014474984
training  [-0.124, 2.8374, -0.6674]  w:  [1.58275665 0.60528335 1.65496734]
0.4166439574639442  -  62.785  =  -62.36835604253605
training  [2.6896, 0.3414, -0.2938]  w:  [1.58275665 0.60528335 1.65496734]
3.9773966228934716  -  70.4455  =  -66.46810337710653
training  [-1.0399, 3.8536, 0.6071]  w:  [1.58275665 0.60528335 1.65496734]
1.6913419618476497  -  77.0369  =  -75.34555803815235
training  [-2.2706, 3.99, -2.3091]  w:  [1.58275665 0.60528335 1.65496734]
-5.00021176527278  -  31.1134  =  -36.11361176527278
training  [-4.6277, 1.2594, 2.4902]  w:  [1.58275665 0.60528335 1.65496734]
-2.441029426596682  -  28.1093  =  -30.550329426596683
training  [1.7329, -3.6213, 0.0389]  w:  [1.58275665 0.60528335 1.65496734]
0.6152246244069159  -  19.3919  =  -18.776675375593083
training  [-0.7044, -2.822, 1.4681]  w:  [1.58275665 0.60528335 1.65496734]
-0.393345853060004  -  17.8122  =  -18.205545853060006
training  [-0.4826, -3.1786, -1.9225]  w:  [1.58275665 0.60528335 1.65496734]
-5.869466743681041  -  3.5851  =  -9.454566743681042
training  [1.0986, -4.5818, -3.6128]  w:  [1.58275665 0.60528335 1.65496734]
-7.0135368263158675  -  1.7158  =  -8.729336826315867
training  [-4.406, -3.9306, -0.2443]  w:  [1.58275665 0.60528335 1.65496734]
-9.757061079498826  -  0.8241  =  -10.581161079498825
training  [-1.8419, 1.1644, -1.3754]  w:  [1.58275665 0.60528335 1.65496734]
-4.486729623921438  -  17.8517  =  -22.33842962392144
training  [2.7272, 4.3966, 2.8811]  w:  [1.58275665 0.60528335 1.65496734]
11.745809144002493  -  98.904  =  -87.1581908559975
training  [1.9643, -1.4554, 2.803]  w:  [1.58275665 0.60528335 1.65496734]
6.866952960771481  -  76.0591  =  -69.19214703922852
training  [-3.7467, -0.8937, 1.6851]  w:  [1.58275665 0.60528335 1.65496734]
-3.6822706119087947  -  12.1571  =  -15.839370611908794
training  [-3.6985, 4.8435, -3.665]  w:  [1.58275665 0.60528335 1.65496734]
-8.98759086662635  -  14.6793  =  -23.66689086662635
247247.86093958438
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.66841507 0.49254956 1.68581479]
12.977106899454693  -  87.3174  =  -74.34029310054531
training  [-4.1793, -4.9218, 1.7664]  w:  [1.66841507 0.49254956 1.68581479]
-6.419214245681784  -  1.5257  =  -7.944914245681783
training  [-3.9429, -0.7689, 4.883]  w:  [1.66841507 0.49254956 1.68581479]
1.2747185101634129  -  39.7859  =  -38.51118148983659
training  [-3.5796, 1.5557, 2.6683]  w:  [1.66841507 0.49254956 1.68581479]
-0.7077396194368797  -  45.5674  =  -46.27513961943688
training  [-3.3354, 2.2292, -1.633]  w:  [1.66841507 0.49254956 1.68581479]
-7.21977570186719  -  13.3589  =  -20.57867570186719
training  [1.2096, 0.3121, 1.6238]  w:  [1.66841507 0.49254956 1.68581479]
4.909265642243328  -  74.5119  =  -69.60263435775667
training  [0.7371, -3.9118, -2.5583]  w:  [1.66841507 0.49254956 1.68581479]
-5.009786591090416  -  3.3358  =  -8.345586591090417
training  [-4.4792, 1.3177, -2.0449]  w:  [1.66841507 0.49254956 1.68581479]
-10.271454889264074  -  4.2974  =  -14.568854889264074
training  [4.312, -3.735, 1.8018]  w:  [1.66841507 0.49254956 1.68581479]
8.392034272241348  -  66.5833  =  -58.19126572775865
training  [2.2866, -3.657, 0.2785]  w:  [1.66841507 0.49254956 1.68581479]
2.483243586521356  -  26.0005  =  -23.51725641347864
training  [2.3784, -4.0141, -0.8841]  w:  [1.66841507 0.49254956 1.68581479]
0.5005863652752394  -  14.6809  =  -14.18031363472476
training  [-4.366, -3.5797, 1.0264]  w:  [1.66841507 0.49254956 1.68581479]
-7.317159526272112  -  1.8713  =  -9.188459526272112
training  [3.6044, -3.3175, 2.5052]  w:  [1.66841507 0.49254956 1.68581479]
8.60290533539995  -  71.0139  =  -62.410994664600054
training  [4.3441, -3.0375, 0.8353]  w:  [1.66841507 0.49254956 1.68581479]
7.159803714055412  -  63.8979  =  -56.738096285944586
training  [4.844, -1.8252, 0.5179]  w:  [1.66841507 0.49254956 1.68581479]
8.055884617722255  -  78.0461  =  -69.99021538227774
training  [3.5894, -1.8357, 0.8357]  w:  [1.66841507 0.49254956 1.68581479]
6.493271245029494  -  68.8838  =  -62.390528754970504
training  [2.8556, -2.8244, 0.1182]  w:  [1.66841507 0.49254956 1.68581479]
3.5724324088692336  -  39.5252  =  -35.952767591130765
training  [0.1338, -2.4896, -4.1741]  w:  [1.66841507 0.49254956 1.68581479]
-8.039776964740222  -  2.2644  =  -10.304176964740222
training  [-3.224, 3.9292, 2.1957]  w:  [1.66841507 0.49254956 1.68581479]
0.25789907858692684  -  72.1211  =  -71.86320092141307
training  [-1.0141, 2.0322, 4.9616]  w:  [1.66841507 0.49254956 1.68581479]
7.673358163313102  -  92.3427  =  -84.6693418366869
training  [-3.6607, 0.5574, -1.4547]  w:  [1.66841507 0.49254956 1.68581479]
-8.285374693412926  -  5.8471  =  -14.132474693412927
training  [-4.6911, -3.1557, 4.7126]  w:  [1.66841507 0.49254956 1.68581479]
-1.436469764092494  -  11.2337  =  -12.670169764092496
training  [4.3914, -2.8797, -1.5355]  w:  [1.66841507 0.49254956 1.68581479]
3.3197143561500124  -  37.475  =  -34.155285643849986
training  [-1.9869, -4.2265, 3.8654]  w:  [1.66841507 0.49254956 1.68581479]
1.119613904073665  -  15.7889  =  -14.669286095926335
training  [-2.0447, 4.138, -0.4531]  w:  [1.66841507 0.49254956 1.68581479]
-2.1370809081142017  -  57.936  =  -60.0730809081142
training  [-1.6706, 2.0672, -0.8657]  w:  [1.66841507 0.49254956 1.68581479]
-3.2284656354068226  -  32.4185  =  -35.64696563540682
training  [-0.3293, 0.5779, -2.8227]  w:  [1.66841507 0.49254956 1.68581479]
-5.023314108616071  -  14.3434  =  -19.366714108616073
training  [1.482, -1.8657, -3.7435]  w:  [1.66841507 0.49254956 1.68581479]
-4.757206253256104  -  7.1519  =  -11.909106253256105
training  [-4.7477, -3.338, -1.9109]  w:  [1.66841507 0.49254956 1.68581479]
-12.78668812037838  -  0.4077  =  -13.194388120378381
training  [3.4221, 1.225, 2.261]  w:  [1.66841507 0.49254956 1.68581479]
10.124483654269799  -  95.0454  =  -84.9209163457302
training  [0.5903, 4.8793, 2.8287]  w:  [1.66841507 0.49254956 1.68581479]
8.156826766817506  -  97.4647  =  -89.30787323318249
training  [3.541, -3.2957, 1.9379]  w:  [1.66841507 0.49254956 1.68581479]
7.551502668555107  -  64.3732  =  -56.82169733144489
training  [-1.5212, -2.4221, -4.902]  w:  [1.66841507 0.49254956 1.68581479]
-11.994861393748254  -  0.7227  =  -12.717561393748253
training  [-0.5397, -1.032, 3.4321]  w:  [1.66841507 0.49254956 1.68581479]
4.377130196405396  -  60.5921  =  -56.214969803594606
training  [-4.4576, -4.2601, 4.2233]  w:  [1.66841507 0.49254956 1.68581479]
-2.4157357535565174  -  6.0247  =  -8.440435753556518
training  [-3.2289, 1.841, 2.7095]  w:  [1.66841507 0.49254956 1.68581479]
0.08735350245517193  -  54.0111  =  -53.923746497544826
training  [1.6281, -0.9761, -4.5734]  w:  [1.66841507 0.49254956 1.68581479]
-5.4743364233810645  -  7.8658  =  -13.340136423381065
training  [-1.6917, 4.8284, -1.2181]  w:  [1.66841507 0.49254956 1.68581479]
-2.497722492312782  -  61.2837  =  -63.781422492312785
training  [3.9849, -0.9782, 2.0434]  w:  [1.66841507 0.49254956 1.68581479]
9.61144917354704  -  88.3402  =  -78.72875082645295
training  [-3.8184, 1.2067, 2.2951]  w:  [1.66841507 0.49254956 1.68581479]
-1.9072030131852356  -  34.1122  =  -36.01940301318524
training  [4.8842, -3.4563, -2.7572]  w:  [1.66841507 0.49254956 1.68581479]
1.798345295118673  -  23.7819  =  -21.98355470488133
training  [0.3998, -1.1865, -2.3095]  w:  [1.66841507 0.49254956 1.68581479]
-3.810766967977332  -  11.4246  =  -15.235366967977331
training  [2.0692, -3.3887, 1.7303]  w:  [1.66841507 0.49254956 1.68581479]
4.700147112787632  -  42.6881  =  -37.987952887212366
training  [4.9949, 2.5811, -0.2251]  w:  [1.66841507 0.49254956 1.68581479]
9.225409168906284  -  95.9901  =  -86.76469083109372
training  [-2.1215, 3.7111, 1.2372]  w:  [1.66841507 0.49254956 1.68581479]
0.37404815336232433  -  71.3692  =  -70.99515184663768
training  [-0.8548, -1.4922, -2.6356]  w:  [1.66841507 0.49254956 1.68581479]
-6.6042771146109995  -  4.7821  =  -11.386377114611
training  [-0.3516, 1.8554, -3.2288]  w:  [1.66841507 0.49254956 1.68581479]
-5.1158970941720705  -  20.3834  =  -25.49929709417207
training  [2.6396, -2.0585, 3.2964]  w:  [1.66841507 0.49254956 1.68581479]
8.947155033393397  -  80.826  =  -71.8788449666066
training  [3.182, 0.3063, 2.6692]  w:  [1.66841507 0.49254956 1.68581479]
9.959541517906914  -  92.9483  =  -82.98875848209309
training  [-3.9978, 3.3242, 4.3448]  w:  [1.66841507 0.49254956 1.68581479]
2.291871589103116  -  79.1768  =  -76.88492841089689
training  [-3.2188, 0.9749, -3.9211]  w:  [1.66841507 0.49254956 1.68581479]
-11.500356240244198  -  2.7053  =  -14.205656240244197
training  [-1.4037, -1.6469, -3.1777]  w:  [1.66841507 0.49254956 1.68581479]
-8.51014776049896  -  2.6234  =  -11.13354776049896
training  [-4.433, -2.0077, -4.009]  w:  [1.66841507 0.49254956 1.68581479]
-15.143407240929502  -  0.3253  =  -15.468707240929502
training  [0.2189, -0.4741, -0.1024]  w:  [1.66841507 0.49254956 1.68581479]
-0.04092912102143312  -  33.6531  =  -33.69402912102144
training  [-1.6415, -0.7735, -3.0675]  w:  [1.66841507 0.49254956 1.68581479]
-8.290927291165872  -  3.7641  =  -12.055027291165871
training  [-3.2433, -1.4039, 3.9589]  w:  [1.66841507 0.49254956 1.68581479]
0.5713112732934382  -  30.0658  =  -29.49448872670656
training  [-2.9105, 0.5832, -4.0091]  w:  [1.66841507 0.49254956 1.68581479]
-11.327267237818987  -  2.4887  =  -13.815967237818986
training  [4.0515, 2.4255, -4.5583]  w:  [1.66841507 0.49254956 1.68581479]
0.26981302376679395  -  61.2853  =  -61.015486976233205
training  [1.7539, -0.7567, 0.573]  w:  [1.66841507 0.49254956 1.68581479]
3.5194928137999053  -  57.0797  =  -53.560207186200095
training  [-0.3153, -0.7064, 2.725]  w:  [1.66841507 0.49254956 1.68581479]
3.71985703302509  -  58.7004  =  -54.98054296697491
training  [4.1213, -3.7513, -1.8806]  w:  [1.66841507 0.49254956 1.68581479]
1.8579945685159225  -  22.1789  =  -20.320905431484075
training  [-3.9599, -4.7557, -3.2102]  w:  [1.66841507 0.49254956 1.68581479]
-14.360977395991558  -  0.1558  =  -14.516777395991557
training  [2.4555, -2.0981, -1.6104]  w:  [1.66841507 0.49254956 1.68581479]
0.3485388322813985  -  24.4796  =  -24.131061167718602
training  [2.3627, -1.8248, -2.8985]  w:  [1.66841507 0.49254956 1.68581479]
-1.843174326790157  -  15.7052  =  -17.548374326790157
training  [0.6186, 1.5369, 0.1015]  w:  [1.66841507 0.49254956 1.68581479]
1.9601911746891052  -  65.2154  =  -63.255208825310895
training  [-3.1581, 4.5694, 4.0636]  w:  [1.66841507 0.49254956 1.68581479]
3.8321113085362977  -  90.3564  =  -86.5242886914637
training  [0.9721, 4.3573, 1.2892]  w:  [1.66841507 0.49254956 1.68581479]
5.941404897949969  -  94.3178  =  -88.37639510205004
training  [-2.0006, -0.4211, -3.9847]  w:  [1.66841507 0.49254956 1.68581479]
-10.262710006179166  -  2.4051  =  -12.667810006179167
training  [-3.6588, -2.5952, -1.0915]  w:  [1.66841507 0.49254956 1.68581479]
-9.222728502247588  -  1.5176  =  -10.740328502247587
training  [-2.874, 2.639, -4.4538]  w:  [1.66841507 0.49254956 1.68581479]
-11.003468548997908  -  5.497  =  -16.500468548997908
training  [3.9494, 2.5933, 0.0128]  w:  [1.66841507 0.49254956 1.68581479]
7.888145659776739  -  94.1462  =  -86.25805434022325
training  [-4.2855, 2.4065, -0.6828]  w:  [1.66841507 0.49254956 1.68581479]
-7.115746605044504  -  14.4193  =  -21.535046605044503
training  [-2.5751, 2.4369, 4.9756]  w:  [1.66841507 0.49254956 1.68581479]
5.291898455610287  -  87.1991  =  -81.90720154438972
training  [-4.4625, -3.9408, 3.116]  w:  [1.66841507 0.49254956 1.68581479]
-4.133342634115369  -  4.1344  =  -8.267742634115368
training  [-0.5828, 1.8156, -0.1435]  w:  [1.66841507 0.49254956 1.68581479]
-0.31999375016258325  -  51.1166  =  -51.43659375016258
training  [-4.8672, -0.3674, 3.9445]  w:  [1.66841507 0.49254956 1.68581479]
-1.651776072791482  -  24.1396  =  -25.791376072791483
training  [3.9719, -2.8784, -3.6245]  w:  [1.66841507 0.49254956 1.68581479]
-0.9012125521141527  -  14.6104  =  -15.511612552114153
training  [-3.0334, -4.0148, -1.1]  w:  [1.66841507 0.49254956 1.68581479]
-8.892854494539987  -  1.021  =  -9.913854494539986
training  [-4.0663, 3.2357, 4.2736]  w:  [1.66841507 0.49254956 1.68581479]
2.0139645080471196  -  77.2328  =  -75.21883549195287
training  [-1.9263, -3.2499, 4.1749]  w:  [1.66841507 0.49254956 1.68581479]
2.2235034318593705  -  26.8814  =  -24.65789656814063
training  [-0.4394, -3.3643, 2.1357]  w:  [1.66841507 0.49254956 1.68581479]
1.210208601005251  -  20.85  =  -19.63979139899475
training  [-3.9833, 1.6599, 1.1834]  w:  [1.66841507 0.49254956 1.68581479]
-3.8332215040597664  -  25.5397  =  -29.372921504059768
training  [4.9539, 3.9439, -1.5671]  w:  [1.66841507 0.49254956 1.68581479]
7.565887234231949  -  95.9509  =  -88.38501276576805
training  [-1.6791, 0.1656, 4.3603]  w:  [1.66841507 0.49254956 1.68581479]
4.6307887075052125  -  71.5733  =  -66.94251129249479
training  [-2.0265, 2.027, -3.7523]  w:  [1.66841507 0.49254956 1.68581479]
-8.708328030615883  -  8.503  =  -17.21132803061588
training  [-4.3795, -3.4641, 2.3059]  w:  [1.66841507 0.49254956 1.68581479]
-5.12574437375601  -  3.6654  =  -8.79114437375601
training  [-2.0176, 4.5346, 1.4648]  w:  [1.66841507 0.49254956 1.68581479]
1.336702485021772  -  81.6212  =  -80.28449751497823
training  [-4.5365, 0.4088, 3.3315]  w:  [1.66841507 0.49254956 1.68581479]
-1.7511187125990544  -  28.9449  =  -30.696018712599056
training  [0.0543, 1.7973, -1.0172]  w:  [1.66841507 0.49254956 1.68581479]
-0.7389565520185382  -  47.9317  =  -48.670656552018535
training  [2.6143, -4.6344, 2.4982]  w:  [1.66841507 0.49254956 1.68581479]
6.290568363421756  -  43.5132  =  -37.22263163657824
training  [1.3107, 3.092, 3.3522]  w:  [1.66841507 0.49254956 1.68581479]
9.36094320390338  -  96.6993  =  -87.33835679609662
training  [-4.1011, 2.4862, -1.7754]  w:  [1.66841507 0.49254956 1.68581479]
-8.610755909516762  -  10.0187  =  -18.629455909516764
training  [-4.1914, -3.7981, 0.5226]  w:  [1.66841507 0.49254956 1.68581479]
-7.982740571101362  -  1.4295  =  -9.412240571101362
training  [2.7724, 0.2505, 4.7913]  w:  [1.66841507 0.49254956 1.68581479]
12.826142012684318  -  96.7925  =  -83.96635798731569
training  [4.0513, -1.7417, 0.4931]  w:  [1.66841507 0.49254956 1.68581479]
6.7326516749139405  -  71.1234  =  -64.39074832508607
training  [0.3377, 0.4645, -1.6958]  w:  [1.66841507 0.49254956 1.68581479]
-2.066591688464946  -  27.9534  =  -30.019991688464945
training  [-3.9085, -1.0112, 1.1947]  w:  [1.66841507 0.49254956 1.68581479]
-5.0050234688332225  -  8.608  =  -13.613023468833223
training  [3.2581, -0.8491, -1.3936]  w:  [1.66841507 0.49254956 1.68581479]
2.6682878077918017  -  50.1924  =  -47.5241121922082
training  [-1.619, -3.1926, 2.5651]  w:  [1.66841507 0.49254956 1.68581479]
0.05060581832599631  -  16.4754  =  -16.424794181674002
training  [-2.0603, -2.4461, -0.861]  w:  [1.66841507 0.49254956 1.68581479]
-6.093747568606264  -  3.9784  =  -10.072147568606264
training  [2.4631, -4.7946, -0.0765]  w:  [1.66841507 0.49254956 1.68581479]
1.618930219620098  -  15.394  =  -13.775069780379901
training  [-4.8966, 4.2368, 1.9474]  w:  [1.66841507 0.49254956 1.68581479]
-2.7997715326394186  -  53.5883  =  -56.388071532639415
training  [-4.5155, 1.537, 4.7273]  w:  [1.66841507 0.49254956 1.68581479]
1.1926727005117144  -  59.2523  =  -58.059627299488284
training  [1.6792, 4.3261, -1.7225]  w:  [1.66841507 0.49254956 1.68581479]
2.0286052347515215  -  83.7729  =  -81.74429476524848
training  [1.0347, -3.3649, 3.378]  w:  [1.66841507 0.49254956 1.68581479]
5.76361143899057  -  50.5979  =  -44.83428856100943
training  [0.261, 4.211, 2.3907]  w:  [1.66841507 0.49254956 1.68581479]
6.539859937685876  -  94.9375  =  -88.39764006231412
training  [2.2971, 2.9466, 4.5417]  w:  [1.66841507 0.49254956 1.68581479]
12.94032781679162  -  98.7784  =  -85.83807218320838
training  [2.0725, 0.7739, -4.6808]  w:  [1.66841507 0.49254956 1.68581479]
-4.051987553236733  -  19.5109  =  -23.562887553236735
training  [2.8138, -0.5996, -1.4313]  w:  [1.66841507 0.49254956 1.68581479]
1.9863468899079084  -  47.2879  =  -45.301553110092094
training  [-2.1202, -2.4239, 1.6265]  w:  [1.66841507 0.49254956 1.68581479]
-1.9892867341659741  -  12.3599  =  -14.349186734165974
training  [1.9253, 2.5195, -2.185]  w:  [1.66841507 0.49254956 1.68581479]
0.7696728133738255  -  65.2467  =  -64.47702718662617
training  [0.5667, -2.7133, -2.6962]  w:  [1.66841507 0.49254956 1.68581479]
-4.9362377356392555  -  5.1106  =  -10.046837735639254
training  [-1.0348, -4.3581, 2.1113]  w:  [1.66841507 0.49254956 1.68581479]
-0.31379535975440076  -  10.5192  =  -10.8329953597544
training  [-4.3841, 2.6733, 1.2457]  w:  [1.66841507 0.49254956 1.68581479]
-3.8977462814351647  -  32.4639  =  -36.36164628143517
training  [2.8018, 1.712, 0.9061]  w:  [1.66841507 0.49254956 1.68581479]
7.045326959141009  -  90.1138  =  -83.06847304085899
training  [-1.6242, 2.1521, 1.6044]  w:  [1.66841507 0.49254956 1.68581479]
1.0548974004575582  -  63.7879  =  -62.733002599542445
training  [1.0787, 1.4206, -4.5245]  w:  [1.66841507 0.49254956 1.68581479]
-5.128033797202505  -  18.0555  =  -23.183533797202504
training  [2.4125, -0.8095, -1.5122]  w:  [1.66841507 0.49254956 1.68581479]
1.0770433548594598  -  38.8276  =  -37.750556645140534
training  [-3.9519, -1.0924, -0.4866]  w:  [1.66841507 0.49254956 1.68581479]
-7.951788117660064  -  3.6777  =  -11.629488117660065
training  [-3.7211, 3.1614, -2.591]  w:  [1.66841507 0.49254956 1.68581479]
-9.019139268658641  -  11.1518  =  -20.170939268658643
training  [0.4954, -1.8257, 2.1505]  w:  [1.66841507 0.49254956 1.68581479]
3.5526298117029187  -  47.7531  =  -44.20047018829708
training  [-0.1477, 3.1454, 3.5618]  w:  [1.66841507 0.49254956 1.68581479]
7.307375596545699  -  94.1572  =  -86.8498244034543
training  [3.9048, 2.8907, -2.1849]  w:  [1.66841507 0.49254956 1.68581479]
4.255303415813482  -  85.8791  =  -81.62379658418651
training  [2.9896, 3.5226, 2.3105]  w:  [1.66841507 0.49254956 1.68581479]
10.618023829697778  -  98.038  =  -87.41997617030222
training  [2.3434, 0.0564, -3.6224]  w:  [1.66841507 0.49254956 1.68581479]
-2.1691518413202173  -  24.7629  =  -26.932051841320217
training  [-4.4867, 1.3566, 3.3672]  w:  [1.66841507 0.49254956 1.68581479]
-1.141009584992739  -  40.5785  =  -41.719509584992736
training  [-4.2711, 4.5089, -3.614]  w:  [1.66841507 0.49254956 1.68581479]
-10.997645561941034  -  10.0825  =  -21.080145561941034
training  [-4.1147, -0.5604, 0.8821]  w:  [1.66841507 0.49254956 1.68581479]
-5.653995020079672  -  8.344  =  -13.99799502007967
training  [2.9835, -4.3998, -1.3384]  w:  [1.66841507 0.49254956 1.68581479]
0.5543022984557431  -  13.2692  =  -12.714897701544256
training  [4.4301, 3.6675, 3.0676]  w:  [1.66841507 0.49254956 1.68581479]
14.36907654439927  -  99.3834  =  -85.01432345560073
training  [1.8372, 1.3119, 0.0378]  w:  [1.66841507 0.49254956 1.68581479]
3.775111723349609  -  74.9026  =  -71.1274882766504
training  [-3.6792, -1.4493, -0.1041]  w:  [1.66841507 0.49254956 1.68581479]
-7.027778107120515  -  4.2442  =  -11.271978107120514
training  [2.2272, 4.97, 3.7705]  w:  [1.66841507 0.49254956 1.68581479]
12.520230007019865  -  99.3199  =  -86.79966999298014
training  [-3.8965, -2.7583, -1.4686]  w:  [1.66841507 0.49254956 1.68581479]
-10.335366354657468  -  1.0337  =  -11.369066354657468
training  [-3.8251, 1.5245, -0.5056]  w:  [1.66841507 0.49254956 1.68581479]
-6.483310635150289  -  12.9762  =  -19.459510635150288
training  [1.4072, 1.0499, 4.6353]  w:  [1.66841507 0.49254956 1.68581479]
10.679178770150367  -  95.4618  =  -84.78262122984962
training  [-1.7119, -1.1275, -4.577]  w:  [1.66841507 0.49254956 1.68581479]
-11.127483684295754  -  1.4655  =  -12.592983684295755
training  [1.5381, -3.5781, 4.7296]  w:  [1.66841507 0.49254956 1.68581479]
8.777027292358655  -  69.9473  =  -61.170272707641345
training  [2.4913, -4.7487, -3.1079]  w:  [1.66841507 0.49254956 1.68581479]
-3.421791413439867  -  3.9825  =  -7.404291413439867
training  [0.8319, -0.7889, 1.6712]  w:  [1.66841507 0.49254956 1.68581479]
3.8167158313566185  -  58.8336  =  -55.01688416864338
training  [2.4003, -3.159, 0.8644]  w:  [1.66841507 0.49254956 1.68581479]
3.905950945593385  -  39.0041  =  -35.09814905440662
training  [-2.6517, 2.2578, 1.7511]  w:  [1.66841507 0.49254956 1.68581479]
-0.3600275630701293  -  54.4525  =  -54.81252756307013
training  [2.3496, -1.2964, -1.3898]  w:  [1.66841507 0.49254956 1.68581479]
0.9386213989456134  -  33.888  =  -32.949378601054384
training  [4.706, 3.4156, 1.2028]  w:  [1.66841507 0.49254956 1.68581479]
11.561611602906517  -  98.4665  =  -86.90488839709349
training  [3.6693, 2.3423, 3.1115]  w:  [1.66841507 0.49254956 1.68581479]
12.521026958993739  -  98.3069  =  -85.78587304100625
training  [-4.1377, 0.7103, -4.8074]  w:  [1.66841507 0.49254956 1.68581479]
-14.657929108892349  -  0.9782  =  -15.636129108892348
training  [-1.3356, -3.2314, -4.1613]  w:  [1.66841507 0.49254956 1.68581479]
-10.835140895953131  -  0.7659  =  -11.601040895953131
training  [-1.308, 4.5738, 4.748]  w:  [1.66841507 0.49254956 1.68581479]
8.074784886773053  -  97.0884  =  -89.01361511322693
training  [1.8503, -2.3468, 1.5135]  w:  [1.66841507 0.49254956 1.68581479]
4.482633789863701  -  50.2125  =  -45.729866210136294
training  [0.9794, 4.2458, -2.6876]  w:  [1.66841507 0.49254956 1.68581479]
-0.8054832151424263  -  68.3262  =  -69.13168321514243
training  [2.8936, -2.7623, -0.9651]  w:  [1.66841507 0.49254956 1.68581479]
1.8401763439265812  -  28.5596  =  -26.719423656073417
training  [-1.3235, -1.2644, -3.7798]  w:  [1.66841507 0.49254956 1.68581479]
-9.202969753620337  -  2.4511  =  -11.654069753620337
training  [-2.9397, -4.125, -2.3156]  w:  [1.66841507 0.49254956 1.68581479]
-10.840079425800596  -  0.554  =  -11.394079425800596
training  [-4.1333, 1.4012, -2.4215]  w:  [1.66841507 0.49254956 1.68581479]
-10.288100080479452  -  4.4072  =  -14.695300080479452
training  [2.7193, -3.1938, -1.6833]  w:  [1.66841507 0.49254956 1.68581479]
0.12608428017302709  -  17.0949  =  -16.96881571982697
training  [-2.9433, -4.5495, -3.4777]  w:  [1.66841507 0.49254956 1.68581479]
-13.01425837714654  -  0.2509  =  -13.26515837714654
training  [-1.1173, 2.2317, -1.5199]  w:  [1.66841507 0.49254956 1.68581479]
-3.3271672140760087  -  33.1206  =  -36.44776721407601
training  [0.5178, -1.5256, -3.7834]  w:  [1.66841507 0.49254956 1.68581479]
-6.265639967418003  -  5.237  =  -11.502639967418002
training  [-2.7105, 1.6062, 3.8415]  w:  [1.66841507 0.49254956 1.68581479]
2.7449515829481506  -  70.4458  =  -67.70084841705186
training  [1.4194, -1.1613, -4.0572]  w:  [1.66841507 0.49254956 1.68581479]
-5.043537229710264  -  8.3206  =  -13.364137229710265
training  [-0.1552, 1.2735, 4.3004]  w:  [1.66841507 0.49254956 1.68581479]
7.618001775594488  -  90.1085  =  -82.49049822440551
training  [-3.4815, -4.7835, -1.0098]  w:  [1.66841507 0.49254956 1.68581479]
-9.867033635588635  -  0.5839  =  -10.450933635588635
training  [2.8193, 4.1057, -4.526]  w:  [1.66841507 0.49254956 1.68581479]
-0.9039744404438954  -  66.8081  =  -67.71207444044389
training  [-3.9939, 3.0056, -1.5763]  w:  [1.66841507 0.49254956 1.68581479]
-7.840425849699232  -  14.4018  =  -22.24222584969923
training  [-2.0593, 2.4585, 2.3597]  w:  [1.66841507 0.49254956 1.68581479]
1.7531831015359  -  70.6698  =  -68.9166168984641
training  [-2.6263, 3.1311, 2.9468]  w:  [1.66841507 0.49254956 1.68581479]
2.128222454500208  -  77.309  =  -75.1807775454998
training  [0.3087, -1.1669, 0.4491]  w:  [1.66841507 0.49254956 1.68581479]
0.6973830778165137  -  33.0798  =  -32.38241692218349
training  [-4.085, 1.1728, 1.8622]  w:  [1.66841507 0.49254956 1.68581479]
-3.098489123841324  -  26.4056  =  -29.504089123841325
training  [-0.9468, 0.7549, 3.9363]  w:  [1.66841507 0.49254956 1.68581479]
5.428043042545456  -  79.7738  =  -74.34575695745454
training  [-3.9515, 0.3005, -4.4521]  w:  [1.66841507 0.49254956 1.68581479]
-13.9501470355494  -  1.0441  =  -14.9942470355494
training  [-3.8772, -2.2493, -1.9634]  w:  [1.66841507 0.49254956 1.68581479]
-10.886599379292106  -  1.0509  =  -11.937499379292106
training  [2.8443, -2.5137, -4.5381]  w:  [1.66841507 0.49254956 1.68581479]
-4.14304495357927  -  6.8897  =  -11.032744953579272
training  [-2.0843, -0.4836, -3.0452]  w:  [1.66841507 0.49254956 1.68581479]
-8.849317696825594  -  3.5346  =  -12.383917696825595
training  [1.0353, -2.7229, 2.2017]  w:  [1.66841507 0.49254956 1.68581479]
4.097805362319462  -  43.9562  =  -39.85839463768054
training  [4.6442, 3.0445, 2.2175]  w:  [1.66841507 0.49254956 1.68581479]
12.986314681671193  -  98.8492  =  -85.86288531832881
training  [-0.6752, 4.861, 3.778]  w:  [1.66841507 0.49254956 1.68581479]
7.636777824941614  -  97.017  =  -89.38022217505838
training  [1.9475, -4.7001, 0.8243]  w:  [1.66841507 0.49254956 1.68581479]
2.323823309204216  -  18.7839  =  -16.460076690795784
training  [2.581, 0.3566, -4.2932]  w:  [1.66841507 0.49254956 1.68581479]
-2.7557176075586822  -  23.5455  =  -26.301217607558684
training  [-0.6736, -4.1292, 4.2274]  w:  [1.66841507 0.49254956 1.68581479]
3.968933438752071  -  31.2667  =  -27.29776656124793
training  [1.555, 3.0209, 3.0037]  w:  [1.66841507 0.49254956 1.68581479]
9.146010276168024  -  96.4078  =  -87.26178972383197
training  [-3.9024, 4.8914, -2.1405]  w:  [1.66841507 0.49254956 1.68581479]
-7.7100526244179886  -  25.4308  =  -33.14085262441799
training  [4.3376, -4.3305, 0.4366]  w:  [1.66841507 0.49254956 1.68581479]
5.839958082393079  -  43.0907  =  -37.250741917606916
training  [-3.1254, 4.394, 4.8478]  w:  [1.66841507 0.49254956 1.68581479]
5.1222912495518855  -  92.8121  =  -87.68980875044812
training  [-2.3382, -4.8182, 2.1568]  w:  [1.66841507 0.49254956 1.68581479]
-2.63832503615076  -  4.7434  =  -7.38172503615076
training  [2.9783, 1.8384, 3.3897]  w:  [1.66841507 0.49254956 1.68581479]
11.588950101539574  -  97.3486  =  -85.75964989846042
training  [-0.124, 2.8374, -0.6674]  w:  [1.66841507 0.49254956 1.68581479]
0.06556384913185287  -  62.785  =  -62.71943615086814
training  [2.6896, 0.3414, -0.2938]  w:  [1.66841507 0.49254956 1.68581479]
4.1602331974101725  -  70.4455  =  -66.28526680258982
training  [-1.0399, 3.8536, 0.6071]  w:  [1.66841507 0.49254956 1.68581479]
1.1865623010367126  -  77.0369  =  -75.85033769896329
training  [-2.2706, 3.99, -2.3091]  w:  [1.66841507 0.49254956 1.68581479]
-5.7157454613521335  -  31.1134  =  -36.829145461352134
training  [-4.6277, 1.2594, 2.4902]  w:  [1.66841507 0.49254956 1.68581479]
-2.9025914995215025  -  28.1093  =  -31.011891499521504
training  [1.7329, -3.6213, 0.0389]  w:  [1.66841507 0.49254956 1.68581479]
1.1731049585584978  -  19.3919  =  -18.218795041441503
training  [-0.7044, -2.822, 1.4681]  w:  [1.66841507 0.49254956 1.68581479]
-0.09026172323548076  -  17.8122  =  -17.902461723235483
training  [-0.4826, -3.1786, -1.9225]  w:  [1.66841507 0.49254956 1.68581479]
-5.611774069076761  -  3.5851  =  -9.196874069076761
training  [1.0986, -4.5818, -3.6128]  w:  [1.66841507 0.49254956 1.68581479]
-6.514354445651759  -  1.7158  =  -8.23015444565176
training  [-4.406, -3.9306, -0.2443]  w:  [1.66841507 0.49254956 1.68581479]
-9.698896625235847  -  0.8241  =  -10.522996625235846
training  [-1.8419, 1.1644, -1.3754]  w:  [1.66841507 0.49254956 1.68581479]
-4.818198675412765  -  17.8517  =  -22.669898675412767
training  [2.7272, 4.3966, 2.8811]  w:  [1.66841507 0.49254956 1.68581479]
11.572645948665244  -  98.904  =  -87.33135405133476
training  [1.9643, -1.4554, 2.803]  w:  [1.66841507 0.49254956 1.68581479]
7.285749956917613  -  76.0591  =  -68.77335004308239
training  [-3.7467, -0.8937, 1.6851]  w:  [1.66841507 0.49254956 1.68581479]
-3.8504757637738494  -  12.1571  =  -16.00757576377385
training  [-3.6985, 4.8435, -3.665]  w:  [1.66841507 0.49254956 1.68581479]
-9.963480567385126  -  14.6793  =  -24.642780567385124
247610.35267785093
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.86173529 0.92394392 2.01309295]
13.542753081550613  -  87.3174  =  -73.77464691844939
training  [-4.1793, -4.9218, 1.7664]  w:  [1.86173529 0.92394392 2.01309295]
-8.7722900881998  -  1.5257  =  -10.2979900881998
training  [-3.9429, -0.7689, 4.883]  w:  [1.86173529 0.92394392 2.01309295]
1.778876306002406  -  39.7859  =  -38.007023693997596
training  [-3.5796, 1.5557, 2.6683]  w:  [1.86173529 0.92394392 2.01309295]
0.1446478116424048  -  45.5674  =  -45.42275218835759
training  [-3.3354, 2.2292, -1.633]  w:  [1.86173529 0.92394392 2.01309295]
-7.43735690162082  -  13.3589  =  -20.796256901620822
training  [1.2096, 0.3121, 1.6238]  w:  [1.86173529 0.92394392 2.01309295]
5.809178235366862  -  74.5119  =  -68.70272176463314
training  [0.7371, -3.9118, -2.5583]  w:  [1.86173529 0.92394392 2.01309295]
-7.392094415906229  -  3.3358  =  -10.727894415906228
training  [-4.4792, 1.3177, -2.0449]  w:  [1.86173529 0.92394392 2.01309295]
-11.238177593735664  -  4.2974  =  -15.535577593735663
training  [4.312, -3.735, 1.8018]  w:  [1.86173529 0.92394392 2.01309295]
8.204062929336862  -  66.5833  =  -58.37923707066313
training  [2.2866, -3.657, 0.2785]  w:  [1.86173529 0.92394392 2.01309295]
1.4388274053635988  -  26.0005  =  -24.5616725946364
training  [2.3784, -4.0141, -0.8841]  w:  [1.86173529 0.92394392 2.01309295]
-1.0606275289613205  -  14.6809  =  -15.74152752896132
training  [-4.366, -3.5797, 1.0264]  w:  [1.86173529 0.92394392 2.01309295]
-9.369539719648538  -  1.8713  =  -11.240839719648537
training  [3.6044, -3.3175, 2.5052]  w:  [1.86173529 0.92394392 2.01309295]
8.68845520124861  -  71.0139  =  -62.3254447987514
training  [4.3441, -3.0375, 0.8353]  w:  [1.86173529 0.92394392 2.01309295]
6.962621178887314  -  63.8979  =  -56.93527882111269
training  [4.844, -1.8252, 0.5179]  w:  [1.86173529 0.92394392 2.01309295]
8.374444158878426  -  78.0461  =  -69.67165584112158
training  [3.5894, -1.8357, 0.8357]  w:  [1.86173529 0.92394392 2.01309295]
6.6687705889957565  -  68.8838  =  -62.21502941100424
training  [2.8556, -2.8244, 0.1182]  w:  [1.86173529 0.92394392 2.01309295]
2.94473169140485  -  39.5252  =  -36.58046830859515
training  [0.1338, -2.4896, -4.1741]  w:  [1.86173529 0.92394392 2.01309295]
-10.454001866697265  -  2.2644  =  -12.718401866697265
training  [-3.224, 3.9292, 2.1957]  w:  [1.86173529 0.92394392 2.01309295]
2.0482740384311757  -  72.1211  =  -70.07282596156882
training  [-1.0141, 2.0322, 4.9616]  w:  [1.86173529 0.92394392 2.01309295]
9.977815038613448  -  92.3427  =  -82.36488496138655
training  [-3.6607, 0.5574, -1.4547]  w:  [1.86173529 0.92394392 2.01309295]
-9.228694358021436  -  5.8471  =  -15.075794358021437
training  [-4.6911, -3.1557, 4.7126]  w:  [1.86173529 0.92394392 2.01309295]
-2.1623744164635426  -  11.2337  =  -13.396074416463543
training  [4.3914, -2.8797, -1.5355]  w:  [1.86173529 0.92394392 2.01309295]
2.423838846057737  -  37.475  =  -35.05116115394227
training  [-1.9869, -4.2265, 3.8654]  w:  [1.86173529 0.92394392 2.01309295]
0.1772786701104101  -  15.7889  =  -15.61162132988959
training  [-2.0447, 4.138, -0.4531]  w:  [1.86173529 0.92394392 2.01309295]
-0.8955426434185118  -  57.936  =  -58.83154264341851
training  [-1.6706, 2.0672, -0.8657]  w:  [1.86173529 0.92394392 2.01309295]
-2.942972681989516  -  32.4185  =  -35.36147268198952
training  [-0.3293, 0.5779, -2.8227]  w:  [1.86173529 0.92394392 2.01309295]
-5.76147970826375  -  14.3434  =  -20.104879708263752
training  [1.482, -1.8657, -3.7435]  w:  [1.86173529 0.92394392 2.01309295]
-6.500723912888934  -  7.1519  =  -13.652623912888934
training  [-4.7477, -3.338, -1.9109]  w:  [1.86173529 0.92394392 2.01309295]
-15.769904753623774  -  0.4077  =  -16.177604753623772
training  [3.4221, 1.225, 2.261]  w:  [1.86173529 0.92394392 2.01309295]
12.054478797162679  -  95.0454  =  -82.99092120283733
training  [0.5903, 4.8793, 2.8287]  w:  [1.86173529 0.92394392 2.01309295]
11.301617914782504  -  97.4647  =  -86.1630820852175
training  [3.541, -3.2957, 1.9379]  w:  [1.86173529 0.92394392 2.01309295]
7.4485355314498465  -  64.3732  =  -56.92466446855015
training  [-1.5212, -2.4221, -4.902]  w:  [1.86173529 0.92394392 2.01309295]
-14.93813791834349  -  0.7227  =  -15.66083791834349
training  [-0.5397, -1.032, 3.4321]  w:  [1.86173529 0.92394392 2.01309295]
4.950847649794838  -  60.5921  =  -55.641252350205164
training  [-4.4576, -4.2601, 4.2233]  w:  [1.86173529 0.92394392 2.01309295]
-3.733069266011327  -  6.0247  =  -9.757769266011326
training  [-3.2289, 1.841, 2.7095]  w:  [1.86173529 0.92394392 2.01309295]
1.1440990073295971  -  54.0111  =  -52.8670009926704
training  [1.6281, -0.9761, -4.5734]  w:  [1.86173529 0.92394392 2.01309295]
-7.0774497170266795  -  7.8658  =  -14.94324971702668
training  [-1.6917, 4.8284, -1.2181]  w:  [1.86173529 0.92394392 2.01309295]
-1.140475311255293  -  61.2837  =  -62.4241753112553
training  [3.9849, -0.9782, 2.0434]  w:  [1.86173529 0.92394392 2.01309295]
10.628581158737639  -  88.3402  =  -77.71161884126235
training  [-3.8184, 1.2067, 2.2951]  w:  [1.86173529 0.92394392 2.01309295]
-1.3736772911412967  -  34.1122  =  -35.4858772911413
training  [4.8842, -3.4563, -2.7572]  w:  [1.86173529 0.92394392 2.01309295]
0.3491602811831829  -  23.7819  =  -23.43273971881682
training  [0.3998, -1.1865, -2.3095]  w:  [1.86173529 0.92394392 2.01309295]
-5.001175850607797  -  11.4246  =  -16.425775850607796
training  [2.0692, -3.3887, 1.7303]  w:  [1.86173529 0.92394392 2.01309295]
4.204588647922511  -  42.6881  =  -38.483511352077485
training  [4.9949, 2.5811, -0.2251]  w:  [1.86173529 0.92394392 2.01309295]
11.230826030198415  -  95.9901  =  -84.75927396980158
training  [-2.1215, 3.7111, 1.2372]  w:  [1.86173529 0.92394392 2.01309295]
1.9697754391450868  -  71.3692  =  -69.39942456085492
training  [-0.8548, -1.4922, -2.6356]  w:  [1.86173529 0.92394392 2.01309295]
-8.275828213924276  -  4.7821  =  -13.057928213924276
training  [-0.3516, 1.8554, -3.2288]  w:  [1.86173529 0.92394392 2.01309295]
-5.4401750991429925  -  20.3834  =  -25.823575099142992
training  [2.6396, -2.0585, 3.2964]  w:  [1.86173529 0.92394392 2.01309295]
9.648257522020751  -  80.826  =  -71.17774247797924
training  [3.182, 0.3063, 2.6692]  w:  [1.86173529 0.92394392 2.01309295]
11.580393419527429  -  92.9483  =  -81.36790658047258
training  [-3.9978, 3.3242, 4.3448]  w:  [1.86173529 0.92394392 2.01309295]
4.3750152555507045  -  79.1768  =  -74.8017847444493
training  [-3.2188, 0.9749, -3.9211]  w:  [1.86173529 0.92394392 2.01309295]
-12.985339395417352  -  2.7053  =  -15.690639395417351
training  [-1.4037, -1.6469, -3.1777]  w:  [1.86173529 0.92394392 2.01309295]
-10.531966527000055  -  2.6234  =  -13.155366527000055
training  [-4.433, -2.0077, -4.009]  w:  [1.86173529 0.92394392 2.01309295]
-18.178564380928275  -  0.3253  =  -18.503864380928274
training  [0.2189, -0.4741, -0.1024]  w:  [1.86173529 0.92394392 2.01309295]
-0.2366486729237049  -  33.6531  =  -33.88974867292371
training  [-1.6415, -0.7735, -3.0675]  w:  [1.86173529 0.92394392 2.01309295]
-9.945871720508688  -  3.7641  =  -13.709971720508687
training  [-3.2433, -1.4039, 3.9589]  w:  [1.86173529 0.92394392 2.01309295]
0.6343427363436831  -  30.0658  =  -29.431457263656316
training  [-2.9105, 0.5832, -4.0091]  w:  [1.86173529 0.92394392 2.01309295]
-12.950427416083578  -  2.4887  =  -15.439127416083577
training  [4.0515, 2.4255, -4.5583]  w:  [1.86173529 0.92394392 2.01309295]
0.6075649180748126  -  61.2853  =  -60.677735081925185
training  [1.7539, -0.7567, 0.573]  w:  [1.86173529 0.92394392 2.01309295]
3.7196514275531367  -  57.0797  =  -53.360048572446864
training  [-0.3153, -0.7064, 2.725]  w:  [1.86173529 0.92394392 2.01309295]
4.245999164576987  -  58.7004  =  -54.454400835423016
training  [4.1213, -3.7513, -1.8806]  w:  [1.86173529 0.92394392 2.01309295]
0.4209562500554407  -  22.1789  =  -21.75794374994456
training  [-3.9599, -4.7557, -3.2102]  w:  [1.86173529 0.92394392 2.01309295]
-18.22871664766822  -  0.1558  =  -18.38451664766822
training  [2.4555, -2.0981, -1.6104]  w:  [1.86173529 0.92394392 2.01309295]
-0.60892060359657  -  24.4796  =  -25.08852060359657
training  [2.3627, -1.8248, -2.8985]  w:  [1.86173529 0.92394392 2.01309295]
-3.1222407933659264  -  15.7052  =  -18.827440793365927
training  [0.6186, 1.5369, 0.1015]  w:  [1.86173529 0.92394392 2.01309295]
2.776007790360386  -  65.2154  =  -62.439392209639614
training  [-3.1581, 4.5694, 4.0636]  w:  [1.86173529 0.92394392 2.01309295]
6.522727607442207  -  90.3564  =  -83.83367239255779
training  [0.9721, 4.3573, 1.2892]  w:  [1.86173529 0.92394392 2.01309295]
8.430973131260288  -  94.3178  =  -85.88682686873972
training  [-2.0006, -0.4211, -3.9847]  w:  [1.86173529 0.92394392 2.01309295]
-12.135231880321886  -  2.4051  =  -14.540331880321887
training  [-3.6588, -2.5952, -1.0915]  w:  [1.86173529 0.92394392 2.01309295]
-11.406827291185992  -  1.5176  =  -12.924427291185992
training  [-2.874, 2.639, -4.4538]  w:  [1.86173529 0.92394392 2.01309295]
-11.87825260988258  -  5.497  =  -17.37525260988258
training  [3.9494, 2.5933, 0.0128]  w:  [1.86173529 0.92394392 2.01309295]
9.77456871025604  -  94.1462  =  -84.37163128974396
training  [-4.2855, 2.4065, -0.6828]  w:  [1.86173529 0.92394392 2.01309295]
-7.12953542702025  -  14.4193  =  -21.54883542702025
training  [-2.5751, 2.4369, 4.9756]  w:  [1.86173529 0.92394392 2.01309295]
7.473749651289905  -  87.1991  =  -79.7253503487101
training  [-4.4625, -3.9408, 3.116]  w:  [1.86173529 0.92394392 2.01309295]
-5.676274298383846  -  4.1344  =  -9.810674298383846
training  [-0.5828, 1.8156, -0.1435]  w:  [1.86173529 0.92394392 2.01309295]
0.30361440712946336  -  51.1166  =  -50.81298559287053
training  [-4.8672, -0.3674, 3.9445]  w:  [1.86173529 0.92394392 2.01309295]
-1.4602498745743366  -  24.1396  =  -25.59984987457434
training  [3.9719, -2.8784, -3.6245]  w:  [1.86173529 0.92394392 2.01309295]
-2.5613091512047363  -  14.6104  =  -17.171709151204738
training  [-3.0334, -4.0148, -1.1]  w:  [1.86173529 0.92394392 2.01309295]
-11.571240112346198  -  1.021  =  -12.592240112346197
training  [-4.0663, 3.2357, 4.2736]  w:  [1.86173529 0.92394392 2.01309295]
4.022385133547124  -  77.2328  =  -73.21041486645288
training  [-1.9263, -3.2499, 4.1749]  w:  [1.86173529 0.92394392 2.01309295]
1.8154757245676798  -  26.8814  =  -25.06592427543232
training  [-0.4394, -3.3643, 2.1357]  w:  [1.86173529 0.92394392 2.01309295]
0.3728916063890928  -  20.85  =  -20.47710839361091
training  [-3.9833, 1.6599, 1.1834]  w:  [1.86173529 0.92394392 2.01309295]
-3.4999014889300133  -  25.5397  =  -29.039601488930014
training  [4.9539, 3.9439, -1.5671]  w:  [1.86173529 0.92394392 2.01309295]
9.712074914962063  -  95.9509  =  -86.23882508503794
training  [-1.6791, 0.1656, 4.3603]  w:  [1.86173529 0.92394392 2.01309295]
5.80465456602324  -  71.5733  =  -65.76864543397676
training  [-2.0265, 2.027, -3.7523]  w:  [1.86173529 0.92394392 2.01309295]
-9.453700922813878  -  8.503  =  -17.95670092281388
training  [-4.3795, -3.4641, 2.3059]  w:  [1.86173529 0.92394392 2.01309295]
-6.7121128019405765  -  3.6654  =  -10.377512801940576
training  [-2.0176, 4.5346, 1.4648]  w:  [1.86173529 0.92394392 2.01309295]
3.3822575057710846  -  81.6212  =  -78.23894249422892
training  [-4.5365, 0.4088, 3.3315]  w:  [1.86173529 0.92394392 2.01309295]
-1.361434723293673  -  28.9449  =  -30.306334723293674
training  [0.0543, 1.7973, -1.0172]  w:  [1.86173529 0.92394392 2.01309295]
-0.28602152080173804  -  47.9317  =  -48.21772152080174
training  [2.6143, -4.6344, 2.4982]  w:  [1.86173529 0.92394392 2.01309295]
5.614317694893309  -  43.5132  =  -37.89888230510669
training  [1.3107, 3.092, 3.3522]  w:  [1.86173529 0.92394392 2.01309295]
12.045301217090909  -  96.6993  =  -84.65399878290908
training  [-4.1011, 2.4862, -1.7754]  w:  [1.86173529 0.92394392 2.01309295]
-8.912098464446856  -  10.0187  =  -18.93079846444686
training  [-4.1914, -3.7981, 0.5226]  w:  [1.86173529 0.92394392 2.01309295]
-10.260466316231824  -  1.4295  =  -11.689966316231825
training  [2.7724, 0.2505, 4.7913]  w:  [1.86173529 0.92394392 2.01309295]
15.03825511909001  -  96.7925  =  -81.75424488091
training  [4.0513, -1.7417, 0.4931]  w:  [1.86173529 0.92394392 2.01309295]
6.925871204493144  -  71.1234  =  -64.19752879550686
training  [0.3377, 0.4645, -1.6958]  w:  [1.86173529 0.92394392 2.01309295]
-2.3559230647728047  -  27.9534  =  -30.309323064772805
training  [-3.9085, -1.0112, 1.1947]  w:  [1.86173529 0.92394392 2.01309295]
-5.805842332349037  -  8.608  =  -14.413842332349038
training  [3.2581, -0.8491, -1.3936]  w:  [1.86173529 0.92394392 2.01309295]
2.475752644134681  -  50.1924  =  -47.71664735586532
training  [-1.619, -3.1926, 2.5651]  w:  [1.86173529 0.92394392 2.01309295]
-0.8001480620599475  -  16.4754  =  -17.275548062059947
training  [-2.0603, -2.4461, -0.861]  w:  [1.86173529 0.92394392 2.01309295]
-7.8290654639220945  -  3.9784  =  -11.807465463922094
training  [2.4631, -4.7946, -0.0765]  w:  [1.86173529 0.92394392 2.01309295]
0.0016970891172379543  -  15.394  =  -15.392302910882762
training  [-4.8966, 4.2368, 1.9474]  w:  [1.86173529 0.92394392 2.01309295]
-1.2813102421120814  -  53.5883  =  -54.86961024211208
training  [-4.5155, 1.537, 4.7273]  w:  [1.86173529 0.92394392 2.01309295]
2.5299303810800575  -  59.2523  =  -56.72236961891994
training  [1.6792, 4.3261, -1.7225]  w:  [1.86173529 0.92394392 2.01309295]
3.6557470735900806  -  83.7729  =  -80.11715292640993
training  [1.0347, -3.3649, 3.378]  w:  [1.86173529 0.92394392 2.01309295]
5.617586604280033  -  50.5979  =  -44.98031339571997
training  [0.261, 4.211, 2.3907]  w:  [1.86173529 0.92394392 2.01309295]
9.18934205265743  -  94.9375  =  -85.74815794734258
training  [2.2971, 2.9466, 4.5417]  w:  [1.86173529 0.92394392 2.01309295]
16.141949526218312  -  98.7784  =  -82.6364504737817
training  [2.0725, 0.7739, -4.6808]  w:  [1.86173529 0.92394392 2.01309295]
-4.849398883047783  -  19.5109  =  -24.360298883047783
training  [2.8138, -0.5996, -1.4313]  w:  [1.86173529 0.92394392 2.01309295]
1.8032140565957042  -  47.2879  =  -45.484685943404294
training  [-2.1202, -2.4239, 1.6265]  w:  [1.86173529 0.92394392 2.01309295]
-2.9125031438458278  -  12.3599  =  -15.272403143845828
training  [1.9253, 2.5195, -2.185]  w:  [1.86173529 0.92394392 2.01309295]
1.513667562039437  -  65.2467  =  -63.73303243796057
training  [0.5667, -2.7133, -2.6962]  w:  [1.86173529 0.92394392 2.01309295]
-6.879592844170365  -  5.1106  =  -11.990192844170366
training  [-1.0348, -4.3581, 2.1113]  w:  [1.86173529 0.92394392 2.01309295]
-1.7029205181737765  -  10.5192  =  -12.222120518173776
training  [-4.3841, 2.6733, 1.2457]  w:  [1.86173529 0.92394392 2.01309295]
-3.1843445391008203  -  32.4639  =  -35.64824453910082
training  [2.8018, 1.712, 0.9061]  w:  [1.86173529 0.92394392 2.01309295]
8.622065446546017  -  90.1138  =  -81.49173455345398
training  [-1.6242, 2.1521, 1.6044]  w:  [1.86173529 0.92394392 2.01309295]
2.194395565883446  -  63.7879  =  -61.593504434116554
training  [1.0787, 1.4206, -4.5245]  w:  [1.86173529 0.92394392 2.01309295]
-5.787430458364858  -  18.0555  =  -23.842930458364854
training  [2.4125, -0.8095, -1.5122]  w:  [1.86173529 0.92394392 2.01309295]
0.6993046363188915  -  38.8276  =  -38.128295363681104
training  [-3.9519, -1.0924, -0.4866]  w:  [1.86173529 0.92394392 2.01309295]
-9.346279064155043  -  3.6777  =  -13.023979064155043
training  [-3.7211, 3.1614, -2.591]  w:  [1.86173529 0.92394392 2.01309295]
-9.222670730100514  -  11.1518  =  -20.374470730100512
training  [0.4954, -1.8257, 2.1505]  w:  [1.86173529 0.92394392 2.01309295]
3.564615642217527  -  47.7531  =  -44.18848435778248
training  [-0.1477, 3.1454, 3.5618]  w:  [1.86173529 0.92394392 2.01309295]
9.801429353834333  -  94.1572  =  -84.35577064616567
training  [3.9048, 2.8907, -2.1849]  w:  [1.86173529 0.92394392 2.01309295]
5.542141864080654  -  85.8791  =  -80.33695813591935
training  [2.9896, 3.5226, 2.3105]  w:  [1.86173529 0.92394392 2.01309295]
13.47177992520819  -  98.038  =  -84.5662200747918
training  [2.3434, 0.0564, -3.6224]  w:  [1.86173529 0.92394392 2.01309295]
-2.877326975377808  -  24.7629  =  -27.640226975377807
training  [-4.4867, 1.3566, 3.3672]  w:  [1.86173529 0.92394392 2.01309295]
-0.321138844042995  -  40.5785  =  -40.899638844043
training  [-4.2711, 4.5089, -3.614]  w:  [1.86173529 0.92394392 2.01309295]
-11.061004800509098  -  10.0825  =  -21.1435048005091
training  [-4.1147, -0.5604, 0.8821]  w:  [1.86173529 0.92394392 2.01309295]
-6.402511088039506  -  8.344  =  -14.746511088039505
training  [2.9835, -4.3998, -1.3384]  w:  [1.86173529 0.92394392 2.01309295]
-1.2050047983666143  -  13.2692  =  -14.474204798366614
training  [4.4301, 3.6675, 3.0676]  w:  [1.86173529 0.92394392 2.01309295]
17.81160175846562  -  99.3834  =  -81.57179824153437
training  [1.8372, 1.3119, 0.0378]  w:  [1.86173529 0.92394392 2.01309295]
4.7085970157278005  -  74.9026  =  -70.1940029842722
training  [-3.6792, -1.4493, -0.1041]  w:  [1.86173529 0.92394392 2.01309295]
-8.398331380733056  -  4.2442  =  -12.642531380733057
training  [2.2272, 4.97, 3.7705]  w:  [1.86173529 0.92394392 2.01309295]
16.328825066787118  -  99.3199  =  -82.99107493321289
training  [-3.8965, -2.7583, -1.4686]  w:  [1.86173529 0.92394392 2.01309295]
-12.759194373692052  -  1.0337  =  -13.792894373692052
training  [-3.8251, 1.5245, -0.5056]  w:  [1.86173529 0.92394392 2.01309295]
-6.73059096174166  -  12.9762  =  -19.70679096174166
training  [1.4072, 1.0499, 4.6353]  w:  [1.86173529 0.92394392 2.01309295]
12.921172364360276  -  95.4618  =  -82.54062763563972
training  [-1.7119, -1.1275, -4.577]  w:  [1.86173529 0.92394392 2.01309295]
-13.442777836913436  -  1.4655  =  -14.908277836913436
training  [1.5381, -3.5781, 4.7296]  w:  [1.86173529 0.92394392 2.01309295]
9.078695736649738  -  69.9473  =  -60.868604263350264
training  [2.4913, -4.7487, -3.1079]  w:  [1.86173529 0.92394392 2.01309295]
-6.005882913694527  -  3.9825  =  -9.988382913694526
training  [0.8319, -0.7889, 1.6712]  w:  [1.86173529 0.92394392 2.01309295]
4.18415916986359  -  58.8336  =  -54.649440830136406
training  [2.4003, -3.159, 0.8644]  w:  [1.86173529 0.92394392 2.01309295]
3.2901019366615327  -  39.0041  =  -35.713998063338465
training  [-2.6517, 2.2578, 1.7511]  w:  [1.86173529 0.92394392 2.01309295]
0.674444160439847  -  54.4525  =  -53.77805583956015
training  [2.3496, -1.2964, -1.3898]  w:  [1.86173529 0.92394392 2.01309295]
0.37873577069242037  -  33.888  =  -33.509264229307576
training  [4.706, 3.4156, 1.2028]  w:  [1.86173529 0.92394392 2.01309295]
14.33849732303738  -  98.4665  =  -84.12800267696261
training  [3.6693, 2.3423, 3.1115]  w:  [1.86173529 0.92394392 2.01309295]
15.25915785121608  -  98.3069  =  -83.04774214878393
training  [-4.1377, 0.7103, -4.8074]  w:  [1.86173529 0.92394392 2.01309295]
-16.724767795850468  -  0.9782  =  -17.70296779585047
training  [-1.3356, -3.2314, -4.1613]  w:  [1.86173529 0.92394392 2.01309295]
-13.849249712292337  -  0.7659  =  -14.615149712292338
training  [-1.308, 4.5738, 4.748]  w:  [1.86173529 0.92394392 2.01309295]
11.348950238917265  -  97.0884  =  -85.73944976108272
training  [1.8503, -2.3468, 1.5135]  w:  [1.86173529 0.92394392 2.01309295]
4.323273407130099  -  50.2125  =  -45.8892265928699
training  [0.9794, 4.2458, -2.6876]  w:  [1.86173529 0.92394392 2.01309295]
0.3358760150638078  -  68.3262  =  -67.9903239849362
training  [2.8936, -2.7623, -0.9651]  w:  [1.86173529 0.92394392 2.01309295]
0.892070958681086  -  28.5596  =  -27.667529041318915
training  [-1.3235, -1.2644, -3.7798]  w:  [1.86173529 0.92394392 2.01309295]
-11.241330072979464  -  2.4511  =  -13.692430072979464
training  [-2.9397, -4.125, -2.3156]  w:  [1.86173529 0.92394392 2.01309295]
-13.945729923059949  -  0.554  =  -14.499729923059949
training  [-4.1333, 1.4012, -2.4215]  w:  [1.86173529 0.92394392 2.01309295]
-11.275184843511745  -  4.4072  =  -15.682384843511745
training  [2.7193, -3.1938, -1.6833]  w:  [1.86173529 0.92394392 2.01309295]
-1.2769146580030886  -  17.0949  =  -18.37181465800309
training  [-2.9433, -4.5495, -3.4777]  w:  [1.86173529 0.92394392 2.01309295]
-16.684061677727545  -  0.2509  =  -16.934961677727546
training  [-1.1173, 2.2317, -1.5199]  w:  [1.86173529 0.92394392 2.01309295]
-3.077851177428284  -  33.1206  =  -36.19845117742829
training  [0.5178, -1.5256, -3.7834]  w:  [1.86173529 0.92394392 2.01309295]
-8.061898164626545  -  5.237  =  -13.298898164626545
training  [-2.7105, 1.6062, 3.8415]  w:  [1.86173529 0.92394392 2.01309295]
4.171101769032643  -  70.4458  =  -66.27469823096736
training  [1.4194, -1.1613, -4.0572]  w:  [1.86173529 0.92394392 2.01309295]
-6.597949705785398  -  8.3206  =  -14.918549705785399
training  [-0.1552, 1.2735, 4.3004]  w:  [1.86173529 0.92394392 2.01309295]
9.544806174770379  -  90.1085  =  -80.56369382522962
training  [-3.4815, -4.7835, -1.0098]  w:  [1.86173529 0.92394392 2.01309295]
-12.934138401004494  -  0.5839  =  -13.518038401004494
training  [2.8193, 4.1057, -4.526]  w:  [1.86173529 0.92394392 2.01309295]
-0.06903183951643754  -  66.8081  =  -66.87713183951644
training  [-3.9939, 3.0056, -1.5763]  w:  [1.86173529 0.92394392 2.01309295]
-7.8318171651929225  -  14.4018  =  -22.23361716519292
training  [-2.0593, 2.4585, 2.3597]  w:  [1.86173529 0.92394392 2.01309295]
3.187940059929972  -  70.6698  =  -67.48185994007002
training  [-2.6263, 3.1311, 2.9468]  w:  [1.86173529 0.92394392 2.01309295]
3.9356676969762887  -  77.309  =  -73.37333230302372
training  [0.3087, -1.1669, 0.4491]  w:  [1.86173529 0.92394392 2.01309295]
0.4006475724786992  -  33.0798  =  -32.6791524275213
training  [-4.085, 1.1728, 1.8622]  w:  [1.86173529 0.92394392 2.01309295]
-2.772805556190267  -  26.4056  =  -29.178405556190267
training  [-0.9468, 0.7549, 3.9363]  w:  [1.86173529 0.92394392 2.01309295]
6.858932060085202  -  79.7738  =  -72.91486793991479
training  [-3.9515, 0.3005, -4.4521]  w:  [1.86173529 0.92394392 2.01309295]
-16.04149297656044  -  1.0441  =  -17.08559297656044
training  [-3.8772, -2.2493, -1.9634]  w:  [1.86173529 0.92394392 2.01309295]
-13.249053820257267  -  1.0509  =  -14.299953820257267
training  [2.8443, -2.5137, -4.5381]  w:  [1.86173529 0.92394392 2.01309295]
-6.162801238401796  -  6.8897  =  -13.052501238401796
training  [-2.0843, -0.4836, -3.0452]  w:  [1.86173529 0.92394392 2.01309295]
-10.457504794004919  -  3.5346  =  -13.99210479400492
training  [1.0353, -2.7229, 2.2017]  w:  [1.86173529 0.92394392 2.01309295]
3.8438744042173854  -  43.9562  =  -40.112325595782615
training  [4.6442, 3.0445, 2.2175]  w:  [1.86173529 0.92394392 2.01309295]
15.923251909548046  -  98.8492  =  -82.92594809045195
training  [-0.6752, 4.861, 3.778]  w:  [1.86173529 0.92394392 2.01309295]
10.839712864587103  -  97.017  =  -86.1772871354129
training  [1.9475, -4.7001, 0.8243]  w:  [1.86173529 0.92394392 2.01309295]
0.9424932003565412  -  18.7839  =  -17.841406799643458
training  [2.581, 0.3566, -4.2932]  w:  [1.86173529 0.92394392 2.01309295]
-3.5079934561720627  -  23.5455  =  -27.053493456172063
training  [-0.6736, -4.1292, 4.2274]  w:  [1.86173529 0.92394392 2.01309295]
3.440935019873666  -  31.2667  =  -27.825764980126333
training  [1.555, 3.0209, 3.0037]  w:  [1.86173529 0.92394392 2.01309295]
11.732867844074265  -  96.4078  =  -84.67493215592573
training  [-3.9024, 4.8914, -2.1405]  w:  [1.86173529 0.92394392 2.01309295]
-7.05488199094054  -  25.4308  =  -32.48568199094054
training  [4.3376, -4.3305, 0.4366]  w:  [1.86173529 0.92394392 2.01309295]
4.953240257775846  -  43.0907  =  -38.13745974222415
training  [-3.1254, 4.394, 4.8478]  w:  [1.86173529 0.92394392 2.01309295]
8.000214078801859  -  92.8121  =  -84.81188592119814
training  [-2.3382, -4.8182, 2.1568]  w:  [1.86173529 0.92394392 2.01309295]
-4.463017164735238  -  4.7434  =  -9.206417164735239
training  [2.9783, 1.8384, 3.3897]  w:  [1.86173529 0.92394392 2.01309295]
14.067165883263218  -  97.3486  =  -83.28143411673679
training  [-0.124, 2.8374, -0.6674]  w:  [1.86173529 0.92394392 2.01309295]
1.0472050567922082  -  62.785  =  -61.73779494320779
training  [2.6896, 0.3414, -0.2938]  w:  [1.86173529 0.92394392 2.01309295]
4.731310986903455  -  70.4455  =  -65.71418901309654
training  [-1.0399, 3.8536, 0.6071]  w:  [1.86173529 0.92394392 2.01309295]
2.846640472557356  -  77.0369  =  -74.19025952744265
training  [-2.2706, 3.99, -2.3091]  w:  [1.86173529 0.92394392 2.01309295]
-5.189152857740905  -  31.1134  =  -36.302552857740906
training  [-4.6277, 1.2594, 2.4902]  w:  [1.86173529 0.92394392 2.01309295]
-2.4389333846332084  -  28.1093  =  -30.54823338463321
training  [1.7329, -3.6213, 0.0389]  w:  [1.86173529 0.92394392 2.01309295]
-0.041367698646971846  -  19.3919  =  -19.433267698646972
training  [-0.7044, -2.822, 1.4681]  w:  [1.86173529 0.92394392 2.01309295]
-0.9633543128750217  -  17.8122  =  -18.775554312875023
training  [-0.4826, -3.1786, -1.9225]  w:  [1.86173529 0.92394392 2.01309295]
-7.705492776282693  -  3.5851  =  -11.290592776282693
training  [1.0986, -4.5818, -3.6128]  w:  [1.86173529 0.92394392 2.01309295]
-9.46092604543132  -  1.7158  =  -11.17672604543132
training  [-4.406, -3.9306, -0.2443]  w:  [1.86173529 0.92394392 2.01309295]
-12.326258260948107  -  0.8241  =  -13.150358260948106
training  [-1.8419, 1.1644, -1.3754]  w:  [1.86173529 0.92394392 2.01309295]
-5.122097980590251  -  17.8517  =  -22.973797980590252
training  [2.7272, 4.3966, 2.8811]  w:  [1.86173529 0.92394392 2.01309295]
14.939458403302858  -  98.904  =  -83.96454159669713
training  [1.9643, -1.4554, 2.803]  w:  [1.86173529 0.92394392 2.01309295]
7.954998194004876  -  76.0591  =  -68.10410180599513
training  [-3.7467, -0.8937, 1.6851]  w:  [1.86173529 0.92394392 2.01309295]
-4.408829370039695  -  12.1571  =  -16.565929370039694
training  [-3.6985, 4.8435, -3.665]  w:  [1.86173529 0.92394392 2.01309295]
-9.788491278243669  -  14.6793  =  -24.467791278243666
239963.9315260294
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.9897201  0.8966713  1.94799072]
13.93712974305322  -  87.3174  =  -73.38027025694679
training  [-4.1793, -4.9218, 1.7664]  w:  [1.9897201  0.8966713  1.94799072]
-9.287943212806152  -  1.5257  =  -10.813643212806152
training  [-3.9429, -0.7689, 4.883]  w:  [1.9897201  0.8966713  1.94799072]
0.9773207231987353  -  39.7859  =  -38.80857927680126
training  [-3.5796, 1.5557, 2.6683]  w:  [1.9897201  0.8966713  1.94799072]
-0.5296269060505665  -  45.5674  =  -46.097026906050566
training  [-3.3354, 2.2292, -1.633]  w:  [1.9897201  0.8966713  1.94799072]
-7.818721610735518  -  13.3589  =  -21.177621610735518
training  [1.2096, 0.3121, 1.6238]  w:  [1.9897201  0.8966713  1.94799072]
5.849763874040855  -  74.5119  =  -68.66213612595914
training  [0.7371, -3.9118, -2.5583]  w:  [1.9897201  0.8966713  1.94799072]
-7.024520749535628  -  3.3358  =  -10.360320749535628
training  [-4.4792, 1.3177, -2.0449]  w:  [1.9897201  0.8966713  1.94799072]
-11.714256727765278  -  4.2974  =  -16.011656727765278
training  [4.312, -3.735, 1.8018]  w:  [1.9897201  0.8966713  1.94799072]
8.740495454350178  -  66.5833  =  -57.84280454564981
training  [2.2866, -3.657, 0.2785]  w:  [1.9897201  0.8966713  1.94799072]
1.8130824618937282  -  26.0005  =  -24.18741753810627
training  [2.3784, -4.0141, -0.8841]  w:  [1.9897201  0.8966713  1.94799072]
-0.5891965614091663  -  14.6809  =  -15.270096561409165
training  [-4.366, -3.5797, 1.0264]  w:  [1.9897201  0.8966713  1.94799072]
-9.897514537423403  -  1.8713  =  -11.768814537423403
training  [3.6044, -3.3175, 2.5052]  w:  [1.9897201  0.8966713  1.94799072]
9.077146448030707  -  71.0139  =  -61.9367535519693
training  [4.3441, -3.0375, 0.8353]  w:  [1.9897201  0.8966713  1.94799072]
7.547060671692068  -  63.8979  =  -56.350839328307934
training  [4.844, -1.8252, 0.5179]  w:  [1.9897201  0.8966713  1.94799072]
9.010464111544895  -  78.0461  =  -69.0356358884551
training  [3.5894, -1.8357, 0.8357]  w:  [1.9897201  0.8966713  1.94799072]
7.123817673381864  -  68.8838  =  -61.75998232661813
training  [2.8556, -2.8244, 0.1182]  w:  [1.9897201  0.8966713  1.94799072]
3.37953881056872  -  39.5252  =  -36.14566118943128
training  [0.1338, -2.4896, -4.1741]  w:  [1.9897201  0.8966713  1.94799072]
-10.09723636782807  -  2.2644  =  -12.361636367828071
training  [-3.224, 3.9292, 2.1957]  w:  [1.9897201  0.8966713  1.94799072]
1.3855464752030517  -  72.1211  =  -70.73555352479694
training  [-1.0141, 2.0322, 4.9616]  w:  [1.9897201  0.8966713  1.94799072]
9.469591000537733  -  92.3427  =  -82.87310899946226
training  [-3.6607, 0.5574, -1.4547]  w:  [1.9897201  0.8966713  1.94799072]
-9.617705891132614  -  5.8471  =  -15.464805891132613
training  [-4.6911, -3.1557, 4.7126]  w:  [1.9897201  0.8966713  1.94799072]
-2.983500529523825  -  11.2337  =  -14.217200529523826
training  [4.3914, -2.8797, -1.5355]  w:  [1.9897201  0.8966713  1.94799072]
3.1643727705039697  -  37.475  =  -34.310627229496035
training  [-1.9869, -4.2265, 3.8654]  w:  [1.9897201  0.8966713  1.94799072]
-0.21339279250075727  -  15.7889  =  -16.002292792500757
training  [-2.0447, 4.138, -0.4531]  w:  [1.9897201  0.8966713  1.94799072]
-1.240589454155843  -  57.936  =  -59.176589454155845
training  [-1.6706, 2.0672, -0.8657]  w:  [1.9897201  0.8966713  1.94799072]
-3.15680305834219  -  32.4185  =  -35.57530305834219
training  [-0.3293, 0.5779, -2.8227]  w:  [1.9897201  0.8966713  1.94799072]
-5.635621884315024  -  14.3434  =  -19.979021884315024
training  [1.482, -1.8657, -3.7435]  w:  [1.9897201  0.8966713  1.94799072]
-6.016457700953763  -  7.1519  =  -13.168357700953763
training  [-4.7477, -3.338, -1.9109]  w:  [1.9897201  0.8966713  1.94799072]
-16.162098381718145  -  0.4077  =  -16.569798381718144
training  [3.4221, 1.225, 2.261]  w:  [1.9897201  0.8966713  1.94799072]
12.311850512151572  -  95.0454  =  -82.73354948784842
training  [0.5903, 4.8793, 2.8287]  w:  [1.9897201  0.8966713  1.94799072]
11.059941383410152  -  97.4647  =  -86.40475861658985
training  [3.541, -3.2957, 1.9379]  w:  [1.9897201  0.8966713  1.94799072]
7.865450493897245  -  64.3732  =  -56.507749506102755
training  [-1.5212, -2.4221, -4.902]  w:  [1.9897201  0.8966713  1.94799072]
-14.74764026663428  -  0.7227  =  -15.47034026663428
training  [-0.5397, -1.032, 3.4321]  w:  [1.9897201  0.8966713  1.94799072]
4.686482222685845  -  60.5921  =  -55.905617777314156
training  [-4.4576, -4.2601, 4.2233]  w:  [1.9897201  0.8966713  1.94799072]
-4.462336525495825  -  6.0247  =  -10.487036525495824
training  [-3.2289, 1.841, 2.7095]  w:  [1.9897201  0.8966713  1.94799072]
0.5042454725165335  -  54.0111  =  -53.50685452748347
training  [1.6281, -0.9761, -4.5734]  w:  [1.9897201  0.8966713  1.94799072]
-6.544718303650921  -  7.8658  =  -14.410518303650921
training  [-1.6917, 4.8284, -1.2181]  w:  [1.9897201  0.8966713  1.94799072]
-1.4093692928534267  -  61.2837  =  -62.69306929285343
training  [3.9849, -0.9782, 2.0434]  w:  [1.9897201  0.8966713  1.94799072]
11.032236001166698  -  88.3402  =  -77.3079639988333
training  [-3.8184, 1.2067, 2.2951]  w:  [1.9897201  0.8966713  1.94799072]
-2.0447004851167554  -  34.1122  =  -36.15690048511676
training  [4.8842, -3.4563, -2.7572]  w:  [1.9897201  0.8966713  1.94799072]
1.2480259066186443  -  23.7819  =  -22.533874093381357
training  [0.3998, -1.1865, -2.3095]  w:  [1.9897201  0.8966713  1.94799072]
-4.767294960482237  -  11.4246  =  -16.191894960482237
training  [2.0692, -3.3887, 1.7303]  w:  [1.9897201  0.8966713  1.94799072]
4.449187144630071  -  42.6881  =  -38.238912855369925
training  [4.9949, 2.5811, -0.2251]  w:  [1.9897201  0.8966713  1.94799072]
11.814358512880773  -  95.9901  =  -84.17574148711923
training  [-2.1215, 3.7111, 1.2372]  w:  [1.9897201  0.8966713  1.94799072]
1.5164997745017677  -  71.3692  =  -69.85270022549824
training  [-0.8548, -1.4922, -2.6356]  w:  [1.9897201  0.8966713  1.94799072]
-8.17294998880153  -  4.7821  =  -12.95504998880153
training  [-0.3516, 1.8554, -3.2288]  w:  [1.9897201  0.8966713  1.94799072]
-5.325574089537565  -  20.3834  =  -25.708974089537566
training  [2.6396, -2.0585, 3.2964]  w:  [1.9897201  0.8966713  1.94799072]
9.8276239139492  -  80.826  =  -70.9983760860508
training  [3.182, 0.3063, 2.6692]  w:  [1.9897201  0.8966713  1.94799072]
11.80551660498447  -  92.9483  =  -81.14278339501553
training  [-3.9978, 3.3242, 4.3448]  w:  [1.9897201  0.8966713  1.94799072]
3.4898417759615405  -  79.1768  =  -75.68695822403846
training  [-3.2188, 0.9749, -3.9211]  w:  [1.9897201  0.8966713  1.94799072]
-13.168612616666099  -  2.7053  =  -15.873912616666098
training  [-1.4037, -1.6469, -3.1777]  w:  [1.9897201  0.8966713  1.94799072]
-10.459828170329214  -  2.6234  =  -13.083228170329214
training  [-4.433, -2.0077, -4.009]  w:  [1.9897201  0.8966713  1.94799072]
-18.430170962006997  -  0.3253  =  -18.755470962006996
training  [0.2189, -0.4741, -0.1024]  w:  [1.9897201  0.8966713  1.94799072]
-0.18903638166520612  -  33.6531  =  -33.842136381665206
training  [-1.6415, -0.7735, -3.0675]  w:  [1.9897201  0.8966713  1.94799072]
-9.935162321638268  -  3.7641  =  -13.699262321638269
training  [-3.2433, -1.4039, 3.9589]  w:  [1.9897201  0.8966713  1.94799072]
-0.00019558997562452163  -  30.0658  =  -30.065995589975625
training  [-2.9105, 0.5832, -4.0091]  w:  [1.9897201  0.8966713  1.94799072]
-13.077831239945787  -  2.4887  =  -15.566531239945787
training  [4.0515, 2.4255, -4.5583]  w:  [1.9897201  0.8966713  1.94799072]
1.356701138298563  -  61.2853  =  -59.92859886170144
training  [1.7539, -0.7567, 0.573]  w:  [1.9897201  0.8966713  1.94799072]
3.9274575960472085  -  57.0797  =  -53.1522424039528
training  [-0.3153, -0.7064, 2.725]  w:  [1.9897201  0.8966713  1.94799072]
4.047507351889793  -  58.7004  =  -54.65289264811021
training  [4.1213, -3.7513, -1.8806]  w:  [1.9897201  0.8966713  1.94799072]
1.1731590710026847  -  22.1789  =  -21.005740928997312
training  [-3.9599, -4.7557, -3.2102]  w:  [1.9897201  0.8966713  1.94799072]
-18.396832124162295  -  0.1558  =  -18.552632124162294
training  [2.4555, -2.0981, -1.6104]  w:  [1.9897201  0.8966713  1.94799072]
-0.13259259237542054  -  24.4796  =  -24.612192592375422
training  [2.3627, -1.8248, -2.8985]  w:  [1.9897201  0.8966713  1.94799072]
-2.5813851951244073  -  15.7052  =  -18.286585195124406
training  [0.6186, 1.5369, 0.1015]  w:  [1.9897201  0.8966713  1.94799072]
2.806656030822151  -  65.2154  =  -62.40874396917785
training  [-3.1581, 4.5694, 4.0636]  w:  [1.9897201  0.8966713  1.94799072]
5.729369856033542  -  90.3564  =  -84.62703014396645
training  [0.9721, 4.3573, 1.2892]  w:  [1.9897201  0.8966713  1.94799072]
8.352622391126934  -  94.3178  =  -85.96517760887308
training  [-2.0006, -0.4211, -3.9847]  w:  [1.9897201  0.8966713  1.94799072]
-12.120380930683595  -  2.4051  =  -14.525480930683596
training  [-3.6588, -2.5952, -1.0915]  w:  [1.9897201  0.8966713  1.94799072]
-11.7332611289206  -  1.5176  =  -13.250861128920599
training  [-2.874, 2.639, -4.4538]  w:  [1.9897201  0.8966713  1.94799072]
-12.028101073533987  -  5.497  =  -17.52510107353399
training  [3.9494, 2.5933, 0.0128]  w:  [1.9897201  0.8966713  1.94799072]
10.208472528118806  -  94.1462  =  -83.93772747188119
training  [-4.2855, 2.4065, -0.6828]  w:  [1.9897201  0.8966713  1.94799072]
-7.699194078462238  -  14.4193  =  -22.118494078462238
training  [-2.5751, 2.4369, 4.9756]  w:  [1.9897201  0.8966713  1.94799072]
6.753792666271414  -  87.1991  =  -80.44530733372859
training  [-4.4625, -3.9408, 3.116]  w:  [1.9897201  0.8966713  1.94799072]
-6.3427891298867936  -  4.1344  =  -10.477189129886794
training  [-0.5828, 1.8156, -0.1435]  w:  [1.9897201  0.8966713  1.94799072]
0.18885086573121412  -  51.1166  =  -50.92774913426879
training  [-4.8672, -0.3674, 3.9445]  w:  [1.9897201  0.8966713  1.94799072]
-2.329953328839321  -  24.1396  =  -26.46955332883932
training  [3.9719, -2.8784, -3.6245]  w:  [1.9897201  0.8966713  1.94799072]
-1.7385017481262492  -  14.6104  =  -16.34890174812625
training  [-3.0334, -4.0148, -1.1]  w:  [1.9897201  0.8966713  1.94799072]
-11.77836267330135  -  1.021  =  -12.79936267330135
training  [-4.0663, 3.2357, 4.2736]  w:  [1.9897201  0.8966713  1.94799072]
3.1354936000326497  -  77.2328  =  -74.09730639996735
training  [-1.9263, -3.2499, 4.1749]  w:  [1.9897201  0.8966713  1.94799072]
1.3857765624712197  -  26.8814  =  -25.495623437528778
training  [-0.4394, -3.3643, 2.1357]  w:  [1.9897201  0.8966713  1.94799072]
0.2693695141523844  -  20.85  =  -20.580630485847617
training  [-3.9833, 1.6599, 1.1834]  w:  [1.9897201  0.8966713  1.94799072]
-4.132015178105682  -  25.5397  =  -29.671715178105682
training  [4.9539, 3.9439, -1.5671]  w:  [1.9897201  0.8966713  1.94799072]
10.340560091062256  -  95.9509  =  -85.61033990893775
training  [-1.6791, 0.1656, 4.3603]  w:  [1.9897201  0.8966713  1.94799072]
5.30137366943603  -  71.5733  =  -66.27192633056397
training  [-2.0265, 2.027, -3.7523]  w:  [1.9897201  0.8966713  1.94799072]
-9.524060633589878  -  8.503  =  -18.027060633589876
training  [-4.3795, -3.4641, 2.3059]  w:  [1.9897201  0.8966713  1.94799072]
-7.328266433798972  -  3.6654  =  -10.993666433798971
training  [-2.0176, 4.5346, 1.4648]  w:  [1.9897201  0.8966713  1.94799072]
2.9050031943722296  -  81.6212  =  -78.71619680562777
training  [-4.5365, 0.4088, 3.3315]  w:  [1.9897201  0.8966713  1.94799072]
-2.1700749393755627  -  28.9449  =  -31.114974939375564
training  [0.0543, 1.7973, -1.0172]  w:  [1.9897201  0.8966713  1.94799072]
-0.2618670320697316  -  47.9317  =  -48.19356703206973
training  [2.6143, -4.6344, 2.4982]  w:  [1.9897201  0.8966713  1.94799072]
5.9126622078350906  -  43.5132  =  -37.60053779216491
training  [1.3107, 3.092, 3.3522]  w:  [1.9897201  0.8966713  1.94799072]
11.910488274020347  -  96.6993  =  -84.78881172597964
training  [-4.1011, 2.4862, -1.7754]  w:  [1.9897201  0.8966713  1.94799072]
-9.389199647102018  -  10.0187  =  -19.40789964710202
training  [-4.1914, -3.7981, 0.5226]  w:  [1.9897201  0.8966713  1.94799072]
-10.727340142624572  -  1.4295  =  -12.15684014262457
training  [2.7724, 0.2505, 4.7913]  w:  [1.9897201  0.8966713  1.94799072]
15.074324094336308  -  96.7925  =  -81.7181759056637
training  [4.0513, -1.7417, 0.4931]  w:  [1.9897201  0.8966713  1.94799072]
7.459774870572838  -  71.1234  =  -63.66362512942717
training  [0.3377, 0.4645, -1.6958]  w:  [1.9897201  0.8966713  1.94799072]
-2.214970362273234  -  27.9534  =  -30.168370362273233
training  [-3.9085, -1.0112, 1.1947]  w:  [1.9897201  0.8966713  1.94799072]
-6.35627052388249  -  8.608  =  -14.96427052388249
training  [3.2581, -0.8491, -1.3936]  w:  [1.9897201  0.8966713  1.94799072]
3.0066236001303777  -  50.1924  =  -47.185776399869624
training  [-1.619, -3.1926, 2.5651]  w:  [1.9897201  0.8966713  1.94799072]
-1.0872786418009488  -  16.4754  =  -17.56267864180095
training  [-2.0603, -2.4461, -0.861]  w:  [1.9897201  0.8966713  1.94799072]
-7.969987995519785  -  3.9784  =  -11.948387995519786
training  [2.4631, -4.7946, -0.0765]  w:  [1.9897201  0.8966713  1.94799072]
0.45267808637792156  -  15.394  =  -14.941321913622078
training  [-4.8966, 4.2368, 1.9474]  w:  [1.9897201  0.8966713  1.94799072]
-2.1503293706349575  -  53.5883  =  -55.73862937063495
training  [-4.5155, 1.537, 4.7273]  w:  [1.9897201  0.8966713  1.94799072]
1.6023391846969393  -  59.2523  =  -57.64996081530306
training  [1.6792, 4.3261, -1.7225]  w:  [1.9897201  0.8966713  1.94799072]
3.8648136868650522  -  83.7729  =  -79.90808631313496
training  [1.0347, -3.3649, 3.378]  w:  [1.9897201  0.8966713  1.94799072]
5.621866781454337  -  50.5979  =  -44.976033218545666
training  [0.261, 4.211, 2.3907]  w:  [1.9897201  0.8966713  1.94799072]
8.952261191157405  -  94.9375  =  -85.9852388088426
training  [2.2971, 2.9466, 4.5417]  w:  [1.9897201  0.8966713  1.94799072]
16.059907133897536  -  98.7784  =  -82.71849286610247
training  [2.0725, 0.7739, -4.6808]  w:  [1.9897201  0.8966713  1.94799072]
-4.300526121767751  -  19.5109  =  -23.811426121767752
training  [2.8138, -0.5996, -1.4313]  w:  [1.9897201  0.8966713  1.94799072]
2.272871197810338  -  47.2879  =  -45.01502880218966
training  [-2.1202, -2.4239, 1.6265]  w:  [1.9897201  0.8966713  1.94799072]
-3.2236392172233974  -  12.3599  =  -15.583539217223397
training  [1.9253, 2.5195, -2.185]  w:  [1.9897201  0.8966713  1.94799072]
1.8336117298400003  -  65.2467  =  -63.41308827016
training  [0.5667, -2.7133, -2.6962]  w:  [1.9897201  0.8966713  1.94799072]
-6.557536423955601  -  5.1106  =  -11.668136423955602
training  [-1.0348, -4.3581, 2.1113]  w:  [1.9897201  0.8966713  1.94799072]
-1.8539527439740473  -  10.5192  =  -12.373152743974046
training  [-4.3841, 2.6733, 1.2457]  w:  [1.9897201  0.8966713  1.94799072]
-3.8994484796064155  -  32.4639  =  -36.363348479606415
training  [2.8018, 1.712, 0.9061]  w:  [1.9897201  0.8966713  1.94799072]
8.874973432275025  -  90.1138  =  -81.23882656772497
training  [-1.6242, 2.1521, 1.6044]  w:  [1.9897201  0.8966713  1.94799072]
1.823379218670258  -  63.7879  =  -61.96452078132974
training  [1.0787, 1.4206, -4.5245]  w:  [1.9897201  0.8966713  1.94799072]
-5.393561681139731  -  18.0555  =  -23.44906168113973
training  [2.4125, -0.8095, -1.5122]  w:  [1.9897201  0.8966713  1.94799072]
1.1285927664990414  -  38.8276  =  -37.69900723350096
training  [-3.9519, -1.0924, -0.4866]  w:  [1.9897201  0.8966713  1.94799072]
-9.79059087889106  -  3.6777  =  -13.46829087889106
training  [-3.7211, 3.1614, -2.591]  w:  [1.9897201  0.8966713  1.94799072]
-9.616454777088123  -  11.1518  =  -20.768254777088124
training  [0.4954, -1.8257, 2.1505]  w:  [1.9897201  0.8966713  1.94799072]
3.537808587122457  -  47.7531  =  -44.21529141287755
training  [-0.1477, 3.1454, 3.5618]  w:  [1.9897201  0.8966713  1.94799072]
9.464861579469233  -  94.1572  =  -84.69233842053077
training  [3.9048, 2.8907, -2.1849]  w:  [1.9897201  0.8966713  1.94799072]
6.105301855995269  -  85.8791  =  -79.77379814400473
training  [2.9896, 3.5226, 2.3105]  w:  [1.9897201  0.8966713  1.94799072]
13.607914083329156  -  98.038  =  -84.43008591667083
training  [2.3434, 0.0564, -3.6224]  w:  [1.9897201  0.8966713  1.94799072]
-2.343119227343249  -  24.7629  =  -27.106019227343246
training  [-4.4867, 1.3566, 3.3672]  w:  [1.9897201  0.8966713  1.94799072]
-1.1515785533158995  -  40.5785  =  -41.7300785533159
training  [-4.2711, 4.5089, -3.614]  w:  [1.9897201  0.8966713  1.94799072]
-11.495330762651797  -  10.0825  =  -21.577830762651796
training  [-4.1147, -0.5604, 0.8821]  w:  [1.9897201  0.8966713  1.94799072]
-6.971273285899857  -  8.344  =  -15.315273285899856
training  [2.9835, -4.3998, -1.3384]  w:  [1.9897201  0.8966713  1.94799072]
-0.6160352305196684  -  13.2692  =  -13.885235230519669
training  [4.4301, 3.6675, 3.0676]  w:  [1.9897201  0.8966713  1.94799072]
18.07885733300746  -  99.3834  =  -81.30454266699253
training  [1.8372, 1.3119, 0.0378]  w:  [1.9897201  0.8966713  1.94799072]
4.905490895906485  -  74.9026  =  -69.99710910409352
training  [-3.6792, -1.4493, -0.1041]  w:  [1.9897201  0.8966713  1.94799072]
-8.822909744070726  -  4.2442  =  -13.067109744070727
training  [2.2272, 4.97, 3.7705]  w:  [1.9897201  0.8966713  1.94799072]
16.232859962198532  -  99.3199  =  -83.08704003780147
training  [-3.8965, -2.7583, -1.4686]  w:  [1.9897201  0.8966713  1.94799072]
-13.087051985346923  -  1.0337  =  -14.120751985346923
training  [-3.8251, 1.5245, -0.5056]  w:  [1.9897201  0.8966713  1.94799072]
-7.228807073505972  -  12.9762  =  -20.20500707350597
training  [1.4072, 1.0499, 4.6353]  w:  [1.9897201  0.8966713  1.94799072]
12.770870695391753  -  95.4618  =  -82.69092930460825
training  [-1.7119, -1.1275, -4.577]  w:  [1.9897201  0.8966713  1.94799072]
-13.333152244274814  -  1.4655  =  -14.798652244274814
training  [1.5381, -3.5781, 4.7296]  w:  [1.9897201  0.8966713  1.94799072]
9.065225813514168  -  69.9473  =  -60.88207418648583
training  [2.4913, -4.7487, -3.1079]  w:  [1.9897201  0.8966713  1.94799072]
-5.355193654937924  -  3.9825  =  -9.337693654937924
training  [0.8319, -0.7889, 1.6712]  w:  [1.9897201  0.8966713  1.94799072]
4.203346252391681  -  58.8336  =  -54.630253747608315
training  [2.4003, -3.159, 0.8644]  w:  [1.9897201  0.8966713  1.94799072]
3.6271837052619755  -  39.0041  =  -35.376916294738024
training  [-2.6517, 2.2578, 1.7511]  w:  [1.9897201  0.8966713  1.94799072]
0.15949020868679176  -  54.4525  =  -54.29300979131321
training  [2.3496, -1.2964, -1.3898]  w:  [1.9897201  0.8966713  1.94799072]
0.8052841808479236  -  33.888  =  -33.08271581915207
training  [4.706, 3.4156, 1.2028]  w:  [1.9897201  0.8966713  1.94799072]
14.769336519215337  -  98.4665  =  -83.69716348078467
training  [3.6693, 2.3423, 3.1115]  w:  [1.9897201  0.8966713  1.94799072]
15.462326267861233  -  98.3069  =  -82.84457373213877
training  [-4.1377, 0.7103, -4.8074]  w:  [1.9897201  0.8966713  1.94799072]
-16.960729816403568  -  0.9782  =  -17.93892981640357
training  [-1.3356, -3.2314, -4.1613]  w:  [1.9897201  0.8966713  1.94799072]
-13.661147572972663  -  0.7659  =  -14.427047572972663
training  [-1.308, 4.5738, 4.748]  w:  [1.9897201  0.8966713  1.94799072]
10.747701216800557  -  97.0884  =  -86.34069878319943
training  [1.8503, -2.3468, 1.5135]  w:  [1.9897201  0.8966713  1.94799072]
4.525554852386094  -  50.2125  =  -45.686945147613905
training  [0.9794, 4.2458, -2.6876]  w:  [1.9897201  0.8966713  1.94799072]
0.5203990131152096  -  68.3262  =  -67.80580098688479
training  [2.8936, -2.7623, -0.9651]  w:  [1.9897201  0.8966713  1.94799072]
1.4005731178723189  -  28.5596  =  -27.15902688212768
training  [-1.3235, -1.2644, -3.7798]  w:  [1.9897201  0.8966713  1.94799072]
-11.13016105758966  -  2.4511  =  -13.58126105758966
training  [-2.9397, -4.125, -2.3156]  w:  [1.9897201  0.8966713  1.94799072]
-14.058716592920952  -  0.554  =  -14.612716592920952
training  [-4.1333, 1.4012, -2.4215]  w:  [1.9897201  0.8966713  1.94799072]
-11.684753795387998  -  4.4072  =  -16.091953795387997
training  [2.7193, -3.1938, -1.6833]  w:  [1.9897201  0.8966713  1.94799072]
-0.7321956942426198  -  17.0949  =  -17.82709569424262
training  [-2.9433, -4.5495, -3.4777]  w:  [1.9897201  0.8966713  1.94799072]
-16.710276564057544  -  0.2509  =  -16.961176564057546
training  [-1.1173, 2.2317, -1.5199]  w:  [1.9897201  0.8966713  1.94799072]
-3.182764024887192  -  33.1206  =  -36.303364024887195
training  [0.5178, -1.5256, -3.7834]  w:  [1.9897201  0.8966713  1.94799072]
-7.707712744086118  -  5.237  =  -12.944712744086118
training  [-2.7105, 1.6062, 3.8415]  w:  [1.9897201  0.8966713  1.94799072]
3.5303034445170356  -  70.4458  =  -66.91549655548297
training  [1.4194, -1.1613, -4.0572]  w:  [1.9897201  0.8966713  1.94799072]
-6.120483604953078  -  8.3206  =  -14.441083604953079
training  [-0.1552, 1.2735, 4.3004]  w:  [1.9897201  0.8966713  1.94799072]
9.210245619582698  -  90.1085  =  -80.89825438041731
training  [-3.4815, -4.7835, -1.0098]  w:  [1.9897201  0.8966713  1.94799072]
-13.18351871502615  -  0.5839  =  -13.76741871502615
training  [2.8193, 4.1057, -4.526]  w:  [1.9897201  0.8966713  1.94799072]
0.47447524437200705  -  66.8081  =  -66.333624755628
training  [-3.9939, 3.0056, -1.5763]  w:  [1.9897201  0.8966713  1.94799072]
-8.322325628109631  -  14.4018  =  -22.724125628109633
training  [-2.0593, 2.4585, 2.3597]  w:  [1.9897201  0.8966713  1.94799072]
2.703709477058995  -  70.6698  =  -67.966090522941
training  [-2.6263, 3.1311, 2.9468]  w:  [1.9897201  0.8966713  1.94799072]
3.3223046447538223  -  77.309  =  -73.98669535524617
training  [0.3087, -1.1669, 0.4491]  w:  [1.9897201  0.8966713  1.94799072]
0.44274348875837855  -  33.0798  =  -32.63705651124162
training  [-4.085, 1.1728, 1.8622]  w:  [1.9897201  0.8966713  1.94799072]
-3.448842202791456  -  26.4056  =  -29.854442202791457
training  [-0.9468, 0.7549, 3.9363]  w:  [1.9897201  0.8966713  1.94799072]
6.46090603168831  -  79.7738  =  -73.31289396831168
training  [-3.9515, 0.3005, -4.4521]  w:  [1.9897201  0.8966713  1.94799072]
-16.26557872956146  -  1.0441  =  -17.309678729561462
training  [-3.8772, -2.2493, -1.9634]  w:  [1.9897201  0.8966713  1.94799072]
-13.556110503603314  -  1.0509  =  -14.607010503603314
training  [2.8443, -2.5137, -4.5381]  w:  [1.9897201  0.8966713  1.94799072]
-5.434778431737465  -  6.8897  =  -12.324478431737464
training  [-2.0843, -0.4836, -3.0452]  w:  [1.9897201  0.8966713  1.94799072]
-10.51282518031579  -  3.5346  =  -14.047425180315791
training  [1.0353, -2.7229, 2.2017]  w:  [1.9897201  0.8966713  1.94799072]
3.907302106033696  -  43.9562  =  -40.048897893966306
training  [4.6442, 3.0445, 2.2175]  w:  [1.9897201  0.8966713  1.94799072]
16.290243279149813  -  98.8492  =  -82.55895672085018
training  [-0.6752, 4.861, 3.778]  w:  [1.9897201  0.8966713  1.94799072]
10.37476909806024  -  97.017  =  -86.64223090193975
training  [1.9475, -4.7001, 0.8243]  w:  [1.9897201  0.8966713  1.94799072]
1.2662638778898805  -  18.7839  =  -17.51763612211012
training  [2.581, 0.3566, -4.2932]  w:  [1.9897201  0.8966713  1.94799072]
-2.9078931807284416  -  23.5455  =  -26.45339318072844
training  [-0.6736, -4.1292, 4.2274]  w:  [1.9897201  0.8966713  1.94799072]
3.1921253740060385  -  31.2667  =  -28.07457462599396
training  [1.555, 3.0209, 3.0037]  w:  [1.9897201  0.8966713  1.94799072]
11.653948800535705  -  96.4078  =  -84.7538511994643
training  [-3.9024, 4.8914, -2.1405]  w:  [1.9897201  0.8966713  1.94799072]
-7.548379867523544  -  25.4308  =  -32.97917986752355
training  [4.3376, -4.3305, 0.4366]  w:  [1.9897201  0.8966713  1.94799072]
5.598067603491454  -  43.0907  =  -37.49263239650855
training  [-3.1254, 4.394, 4.8478]  w:  [1.9897201  0.8966713  1.94799072]
7.164771878257688  -  92.8121  =  -85.64732812174232
training  [-2.3382, -4.8182, 2.1568]  w:  [1.9897201  0.8966713  1.94799072]
-4.771278811097119  -  4.7434  =  -9.51467881109712
training  [2.9783, 1.8384, 3.3897]  w:  [1.9897201  0.8966713  1.94799072]
14.177528028070045  -  97.3486  =  -83.17107197192996
training  [-0.124, 2.8374, -0.6674]  w:  [1.9897201  0.8966713  1.94799072]
0.9974008439629973  -  62.785  =  -61.787599156037
training  [2.6896, 0.3414, -0.2938]  w:  [1.9897201  0.8966713  1.94799072]
5.085355093802204  -  70.4455  =  -65.36014490619779
training  [-1.0399, 3.8536, 0.6071]  w:  [1.9897201  0.8966713  1.94799072]
2.568927745387321  -  77.0369  =  -74.46797225461268
training  [-2.2706, 3.99, -2.3091]  w:  [1.9897201  0.8966713  1.94799072]
-5.43824534876353  -  31.1134  =  -36.55164534876353
training  [-4.6277, 1.2594, 2.4902]  w:  [1.9897201  0.8966713  1.94799072]
-3.227673396999921  -  28.1093  =  -31.336973396999923
training  [1.7329, -3.6213, 0.0389]  w:  [1.9897201  0.8966713  1.94799072]
0.27664703106336924  -  19.3919  =  -19.11525296893663
training  [-0.7044, -2.822, 1.4681]  w:  [1.9897201  0.8966713  1.94799072]
-1.0721200707429666  -  17.8122  =  -18.884320070742966
training  [-0.4826, -3.1786, -1.9225]  w:  [1.9897201  0.8966713  1.94799072]
-7.555410463579987  -  3.5851  =  -11.140510463579988
training  [1.0986, -4.5818, -3.6128]  w:  [1.9897201  0.8966713  1.94799072]
-8.960162914062831  -  1.7158  =  -10.675962914062831
training  [-4.406, -3.9306, -0.2443]  w:  [1.9897201  0.8966713  1.94799072]
-12.767057104627265  -  0.8241  =  -13.591157104627264
training  [-1.8419, 1.1644, -1.3754]  w:  [1.9897201  0.8966713  1.94799072]
-5.300047828389266  -  17.8517  =  -23.15174782838927
training  [2.7272, 4.3966, 2.8811]  w:  [1.9897201  0.8966713  1.94799072]
14.981025746595655  -  98.904  =  -83.92297425340433
training  [1.9643, -1.4554, 2.803]  w:  [1.9897201  0.8966713  1.94799072]
8.063609769248952  -  76.0591  =  -67.99549023075105
training  [-3.7467, -0.8937, 1.6851]  w:  [1.9897201  0.8966713  1.94799072]
-4.973680286083844  -  12.1571  =  -17.130780286083844
training  [-3.6985, 4.8435, -3.665]  w:  [1.9897201  0.8966713  1.94799072]
-10.155338342675966  -  14.6793  =  -24.834638342675966
240424.332394876
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.82471118 0.96838444 2.07099141]
13.45373316945043  -  87.3174  =  -73.86366683054958
training  [-4.1793, -4.9218, 1.7664]  w:  [1.82471118 0.96838444 2.07099141]
-8.734010768720623  -  1.5257  =  -10.259710768720623
training  [-3.9429, -0.7689, 4.883]  w:  [1.82471118 0.96838444 2.07099141]
2.173406549986658  -  39.7859  =  -37.61249345001334
training  [-3.5796, 1.5557, 2.6683]  w:  [1.82471118 0.96838444 2.07099141]
0.500805913898926  -  45.5674  =  -45.06659408610108
training  [-3.3354, 2.2292, -1.633]  w:  [1.82471118 0.96838444 2.07099141]
-7.309348062995982  -  13.3589  =  -20.668248062995982
training  [1.2096, 0.3121, 1.6238]  w:  [1.82471118 0.96838444 2.07099141]
5.8722792915116715  -  74.5119  =  -68.63962070848832
training  [0.7371, -3.9118, -2.5583]  w:  [1.82471118 0.96838444 2.07099141]
-7.741348985160147  -  3.3358  =  -11.077148985160147
training  [-4.4792, 1.3177, -2.0449]  w:  [1.82471118 0.96838444 2.07099141]
-11.13217649867157  -  4.2974  =  -15.429576498671569
training  [4.312, -3.735, 1.8018]  w:  [1.82471118 0.96838444 2.07099141]
7.982751062026946  -  66.5833  =  -58.600548937973045
training  [2.2866, -3.657, 0.2785]  w:  [1.82471118 0.96838444 2.07099141]
1.207773794814484  -  26.0005  =  -24.792726205185517
training  [2.3784, -4.0141, -0.8841]  w:  [1.82471118 0.96838444 2.07099141]
-1.3782624213173678  -  14.6809  =  -16.059162421317367
training  [-4.366, -3.5797, 1.0264]  w:  [1.82471118 0.96838444 2.07099141]
-9.307549232559978  -  1.8713  =  -11.178849232559978
training  [3.6044, -3.3175, 2.5052]  w:  [1.82471118 0.96838444 2.07099141]
8.552621293870786  -  71.0139  =  -62.46127870612922
training  [4.3441, -3.0375, 0.8353]  w:  [1.82471118 0.96838444 2.07099141]
6.715159238037711  -  63.8979  =  -57.182740761962286
training  [4.844, -1.8252, 0.5179]  w:  [1.82471118 0.96838444 2.07099141]
8.143972144221681  -  78.0461  =  -69.90212785577832
training  [3.5894, -1.8357, 0.8357]  w:  [1.82471118 0.96838444 2.07099141]
6.5026825274231035  -  68.8838  =  -62.38111747257689
training  [2.8556, -2.8244, 0.1182]  w:  [1.82471118 0.96838444 2.07099141]
2.7203314220379196  -  39.5252  =  -36.804868577962075
training  [0.1338, -2.4896, -4.1741]  w:  [1.82471118 0.96838444 2.07099141]
-10.811268815082975  -  2.2644  =  -13.075668815082976
training  [-3.224, 3.9292, 2.1957]  w:  [1.82471118 0.96838444 2.07099141]
2.4693831438156324  -  72.1211  =  -69.65171685618436
training  [-1.0141, 2.0322, 4.9616]  w:  [1.82471118 0.96838444 2.07099141]
10.392942254270617  -  92.3427  =  -81.94975774572937
training  [-3.6607, 0.5574, -1.4547]  w:  [1.82471118 0.96838444 2.07099141]
-9.152613953676031  -  5.8471  =  -14.999713953676032
training  [-4.6911, -3.1557, 4.7126]  w:  [1.82471118 0.96838444 2.07099141]
-1.8560792833111694  -  11.2337  =  -13.08977928331117
training  [4.3914, -2.8797, -1.5355]  w:  [1.82471118 0.96838444 2.07099141]
2.0443726970991163  -  37.475  =  -35.43062730290089
training  [-1.9869, -4.2265, 3.8654]  w:  [1.82471118 0.96838444 2.07099141]
0.28681471315882767  -  15.7889  =  -15.502085286841172
training  [-2.0447, 4.138, -0.4531]  w:  [1.82471118 0.96838444 2.07099141]
-0.6621783432720854  -  57.936  =  -58.59817834327208
training  [-1.6706, 2.0672, -0.8657]  w:  [1.82471118 0.96838444 2.07099141]
-2.8393754512025646  -  32.4185  =  -35.257875451202565
training  [-0.3293, 0.5779, -2.8227]  w:  [1.82471118 0.96838444 2.07099141]
-5.887035488543569  -  14.3434  =  -20.23043548854357
training  [1.482, -1.8657, -3.7435]  w:  [1.82471118 0.96838444 2.07099141]
-6.855249239702898  -  7.1519  =  -14.007149239702898
training  [-4.7477, -3.338, -1.9109]  w:  [1.82471118 0.96838444 2.07099141]
-15.853106052937129  -  0.4077  =  -16.260806052937127
training  [3.4221, 1.225, 2.261]  w:  [1.82471118 0.96838444 2.07099141]
12.113126673534929  -  95.0454  =  -82.93227332646507
training  [0.5903, 4.8793, 2.8287]  w:  [1.82471118 0.96838444 2.07099141]
11.660378637921145  -  97.4647  =  -85.80432136207885
training  [3.541, -3.2957, 1.9379]  w:  [1.82471118 0.96838444 2.07099141]
7.2831719563157264  -  64.3732  =  -57.09002804368427
training  [-1.5212, -2.4221, -4.902]  w:  [1.82471118 0.96838444 2.07099141]
-15.273274525402908  -  0.7227  =  -15.995974525402907
training  [-0.5397, -1.032, 3.4321]  w:  [1.82471118 0.96838444 2.07099141]
5.123680261885456  -  60.5921  =  -55.46841973811455
training  [-4.4576, -4.2601, 4.2233]  w:  [1.82471118 0.96838444 2.07099141]
-3.512829099582831  -  6.0247  =  -9.53752909958283
training  [-3.2289, 1.841, 2.7095]  w:  [1.82471118 0.96838444 2.07099141]
1.5023370540056433  -  54.0111  =  -52.508762945994356
training  [1.6281, -0.9761, -4.5734]  w:  [1.82471118 0.96838444 2.07099141]
-7.445899910024047  -  7.8658  =  -15.311699910024046
training  [-1.6917, 4.8284, -1.2181]  w:  [1.82471118 0.96838444 2.07099141]
-0.9337911078344381  -  61.2837  =  -62.21749110783444
training  [3.9849, -0.9782, 2.0434]  w:  [1.82471118 0.96838444 2.07099141]
10.555881791599528  -  88.3402  =  -77.78431820840046
training  [-3.8184, 1.2067, 2.2951]  w:  [1.82471118 0.96838444 2.07099141]
-1.0457952832662585  -  34.1122  =  -35.15799528326626
training  [4.8842, -3.4563, -2.7572]  w:  [1.82471118 0.96838444 2.07099141]
-0.1449103119985633  -  23.7819  =  -23.926810311998565
training  [0.3998, -1.1865, -2.3095]  w:  [1.82471118 0.96838444 2.07099141]
-5.202423281434297  -  11.4246  =  -16.627023281434298
training  [2.0692, -3.3887, 1.7303]  w:  [1.82471118 0.96838444 2.07099141]
4.077564464706493  -  42.6881  =  -38.61053553529351
training  [4.9949, 2.5811, -0.2251]  w:  [1.82471118 0.96838444 2.07099141]
11.147566811859098  -  95.9901  =  -84.8425331881409
training  [-2.1215, 3.7111, 1.2372]  w:  [1.82471118 0.96838444 2.07099141]
2.2848773067123744  -  71.3692  =  -69.08432269328763
training  [-0.8548, -1.4922, -2.6356]  w:  [1.82471118 0.96838444 2.07099141]
-8.463091357451294  -  4.7821  =  -13.245191357451294
training  [-0.3516, 1.8554, -3.2288]  w:  [1.82471118 0.96838444 2.07099141]
-5.531645035485972  -  20.3834  =  -25.915045035485974
training  [2.6396, -2.0585, 3.2964]  w:  [1.82471118 0.96838444 2.07099141]
9.649904364037791  -  80.826  =  -71.1760956359622
training  [3.182, 0.3063, 2.6692]  w:  [1.82471118 0.96838444 2.07099141]
11.630737425845627  -  92.9483  =  -81.31756257415438
training  [-3.9978, 3.3242, 4.3448]  w:  [1.82471118 0.96838444 2.07099141]
4.922316690060805  -  79.1768  =  -74.25448330993919
training  [-3.2188, 0.9749, -3.9211]  w:  [1.82471118 0.96838444 2.07099141]
-13.049866800740025  -  2.7053  =  -15.755166800740025
training  [-1.4037, -1.6469, -3.1777]  w:  [1.82471118 0.96838444 2.07099141]
-10.73716884543609  -  2.6234  =  -13.36056884543609
training  [-4.433, -2.0077, -4.009]  w:  [1.82471118 0.96838444 2.07099141]
-18.33577470524814  -  0.3253  =  -18.66107470524814
training  [0.2189, -0.4741, -0.1024]  w:  [1.82471118 0.96838444 2.07099141]
-0.27175130700031125  -  33.6531  =  -33.92485130700031
training  [-1.6415, -0.7735, -3.0675]  w:  [1.82471118 0.96838444 2.07099141]
-10.09707493873151  -  3.7641  =  -13.861174938731509
training  [-3.2433, -1.4039, 3.9589]  w:  [1.82471118 0.96838444 2.07099141]
0.9212472071999036  -  30.0658  =  -29.144552792800095
training  [-2.9105, 0.5832, -4.0091]  w:  [1.82471118 0.96838444 2.07099141]
-13.04887177341717  -  2.4887  =  -15.53757177341717
training  [4.0515, 2.4255, -4.5583]  w:  [1.82471118 0.96838444 2.07099141]
0.3014336649557059  -  61.2853  =  -60.9838663350443
training  [1.7539, -0.7567, 0.573]  w:  [1.82471118 0.96838444 2.07099141]
3.654262518303078  -  57.0797  =  -53.425437481696925
training  [-0.3153, -0.7064, 2.725]  w:  [1.82471118 0.96838444 2.07099141]
4.384053397159295  -  58.7004  =  -54.31634660284071
training  [4.1213, -3.7513, -1.8806]  w:  [1.82471118 0.96838444 2.07099141]
-0.007224811250702068  -  22.1789  =  -22.1861248112507
training  [-3.9599, -4.7557, -3.2102]  w:  [1.82471118 0.96838444 2.07099141]
-18.479316351394605  -  0.1558  =  -18.635116351394604
training  [2.4555, -2.0981, -1.6104]  w:  [1.82471118 0.96838444 2.07099141]
-0.8863136606217186  -  24.4796  =  -25.36591366062172
training  [2.3627, -1.8248, -2.8985]  w:  [1.82471118 0.96838444 2.07099141]
-3.458631431031624  -  15.7052  =  -19.163831431031625
training  [0.6186, 1.5369, 0.1015]  w:  [1.82471118 0.96838444 2.07099141]
2.8272820173615285  -  65.2154  =  -62.38811798263848
training  [-3.1581, 4.5694, 4.0636]  w:  [1.82471118 0.96838444 2.07099141]
7.077996193983139  -  90.3564  =  -83.27840380601685
training  [0.9721, 4.3573, 1.2892]  w:  [1.82471118 0.96838444 2.07099141]
8.66326540650055  -  94.3178  =  -85.65453459349945
training  [-2.0006, -0.4211, -3.9847]  w:  [1.82471118 0.96838444 2.07099141]
-12.310583372475966  -  2.4051  =  -14.715683372475965
training  [-3.6588, -2.5952, -1.0915]  w:  [1.82471118 0.96838444 2.07099141]
-11.449891715458863  -  1.5176  =  -12.967491715458863
training  [-2.874, 2.639, -4.4538]  w:  [1.82471118 0.96838444 2.07099141]
-11.912434959410122  -  5.497  =  -17.40943495941012
training  [3.9494, 2.5933, 0.0128]  w:  [1.82471118 0.96838444 2.07099141]
9.744334416513853  -  94.1462  =  -84.40186558348614
training  [-4.2855, 2.4065, -0.6828]  w:  [1.82471118 0.96838444 2.07099141]
-6.903455555440026  -  14.4193  =  -21.322755555440025
training  [-2.5751, 2.4369, 4.9756]  w:  [1.82471118 0.96838444 2.07099141]
7.965467159681897  -  87.1991  =  -79.23363284031811
training  [-4.4625, -3.9408, 3.116]  w:  [1.82471118 0.96838444 2.07099141]
-5.505773824826917  -  4.1344  =  -9.640173824826917
training  [-0.5828, 1.8156, -0.1435]  w:  [1.82471118 0.96838444 2.07099141]
0.39756984847568466  -  51.1166  =  -50.719030151524315
training  [-4.8672, -0.3674, 3.9445]  w:  [1.82471118 0.96838444 2.07099141]
-1.0679930860084603  -  24.1396  =  -25.207593086008462
training  [3.9719, -2.8784, -3.6245]  w:  [1.82471118 0.96838444 2.07099141]
-3.0461358093566  -  14.6104  =  -17.6565358093566
training  [-3.0334, -4.0148, -1.1]  w:  [1.82471118 0.96838444 2.07099141]
-11.701039323073868  -  1.021  =  -12.722039323073869
training  [-4.0663, 3.2357, 4.2736]  w:  [1.82471118 0.96838444 2.07099141]
4.564167362051674  -  77.2328  =  -72.66863263794832
training  [-1.9263, -3.2499, 4.1749]  w:  [1.82471118 0.96838444 2.07099141]
1.9840883005884447  -  26.8814  =  -24.897311699411553
training  [-0.4394, -3.3643, 2.1357]  w:  [1.82471118 0.96838444 2.07099141]
0.3633024879543427  -  20.85  =  -20.48669751204566
training  [-3.9833, 1.6599, 1.1834]  w:  [1.82471118 0.96838444 2.07099141]
-3.2101394832895096  -  25.5397  =  -28.74983948328951
training  [4.9539, 3.9439, -1.5671]  w:  [1.82471118 0.96838444 2.07099141]
9.613197494103503  -  95.9509  =  -86.3377025058965
training  [-1.6791, 0.1656, 4.3603]  w:  [1.82471118 0.96838444 2.07099141]
6.1266357782681755  -  71.5733  =  -65.44666422173182
training  [-2.0265, 2.027, -3.7523]  w:  [1.82471118 0.96838444 2.07099141]
-9.505843032779204  -  8.503  =  -18.008843032779204
training  [-4.3795, -3.4641, 2.3059]  w:  [1.82471118 0.96838444 2.07099141]
-6.5704040773400045  -  3.6654  =  -10.235804077340005
training  [-2.0176, 4.5346, 1.4648]  w:  [1.82471118 0.96838444 2.07099141]
3.7432870333741883  -  81.6212  =  -77.87791296662581
training  [-4.5365, 0.4088, 3.3315]  w:  [1.82471118 0.96838444 2.07099141]
-0.9824188298009222  -  28.9449  =  -29.927318829800925
training  [0.0543, 1.7973, -1.0172]  w:  [1.82471118 0.96838444 2.07099141]
-0.26705329009757195  -  47.9317  =  -48.19875329009757
training  [2.6143, -4.6344, 2.4982]  w:  [1.82471118 0.96838444 2.07099141]
5.456212337694964  -  43.5132  =  -38.05698766230503
training  [1.3107, 3.092, 3.3522]  w:  [1.82471118 0.96838444 2.07099141]
12.328271065553237  -  96.6993  =  -84.37102893444676
training  [-4.1011, 2.4862, -1.7754]  w:  [1.82471118 0.96838444 2.07099141]
-8.752563792257737  -  10.0187  =  -18.771263792257738
training  [-4.1914, -3.7981, 0.5226]  w:  [1.82471118 0.96838444 2.07099141]
-10.243815296668892  -  1.4295  =  -11.673315296668893
training  [2.7724, 0.2505, 4.7913]  w:  [1.82471118 0.96838444 2.07099141]
15.22415075321078  -  96.7925  =  -81.56834924678923
training  [4.0513, -1.7417, 0.4931]  w:  [1.82471118 0.96838444 2.07099141]
6.727023102466415  -  71.1234  =  -64.39637689753359
training  [0.3377, 0.4645, -1.6958]  w:  [1.82471118 0.96838444 2.07099141]
-2.445967699769221  -  27.9534  =  -30.39936769976922
training  [-3.9085, -1.0112, 1.1947]  w:  [1.82471118 0.96838444 2.07099141]
-5.636900569183792  -  8.608  =  -14.244900569183793
training  [3.2581, -0.8491, -1.3936]  w:  [1.82471118 0.96838444 2.07099141]
2.23670264357714  -  50.1924  =  -47.95569735642286
training  [-1.619, -3.1926, 2.5651]  w:  [1.82471118 0.96838444 2.07099141]
-0.7335715026998377  -  16.4754  =  -17.20897150269984
training  [-2.0603, -2.4461, -0.861]  w:  [1.82471118 0.96838444 2.07099141]
-7.911341246185106  -  3.9784  =  -11.889741246185107
training  [2.4631, -4.7946, -0.0765]  w:  [1.82471118 0.96838444 2.07099141]
-0.3070007755159204  -  15.394  =  -15.70100077551592
training  [-4.8966, 4.2368, 1.9474]  w:  [1.82471118 0.96838444 2.07099141]
-0.7989808963014573  -  53.5883  =  -54.387280896301455
training  [-4.5155, 1.537, 4.7273]  w:  [1.82471118 0.96838444 2.07099141]
3.0391212496433226  -  59.2523  =  -56.213178750356676
training  [1.6792, 4.3261, -1.7225]  w:  [1.82471118 0.96838444 2.07099141]
3.6861002477149567  -  83.7729  =  -80.08679975228505
training  [1.0347, -3.3649, 3.378]  w:  [1.82471118 0.96838444 2.07099141]
5.625320847814367  -  50.5979  =  -44.97257915218564
training  [0.261, 4.211, 2.3907]  w:  [1.82471118 0.96838444 2.07099141]
9.505235682324482  -  94.9375  =  -85.43226431767552
training  [2.2971, 2.9466, 4.5417]  w:  [1.82471118 0.96838444 2.07099141]
16.45080736690264  -  98.7784  =  -82.32759263309737
training  [2.0725, 0.7739, -4.6808]  w:  [1.82471118 0.96838444 2.07099141]
-5.162749962603913  -  19.5109  =  -24.67364996260391
training  [2.8138, -0.5996, -1.4313]  w:  [1.82471118 0.96838444 2.07099141]
1.589519006652257  -  47.2879  =  -45.69838099334774
training  [-2.1202, -2.4239, 1.6265]  w:  [1.82471118 0.96838444 2.07099141]
-2.8475521683937037  -  12.3599  =  -15.207452168393704
training  [1.9253, 2.5195, -2.185]  w:  [1.82471118 0.96838444 2.07099141]
1.427844806457439  -  65.2467  =  -63.81885519354257
training  [0.5667, -2.7133, -2.6962]  w:  [1.82471118 0.96838444 2.07099141]
-7.17726073214537  -  5.1106  =  -12.287860732145369
training  [-1.0348, -4.3581, 2.1113]  w:  [1.82471118 0.96838444 2.07099141]
-1.7360432009493536  -  10.5192  =  -12.255243200949353
training  [-4.3841, 2.6733, 1.2457]  w:  [1.82471118 0.96838444 2.07099141]
-2.8311001663371163  -  32.4639  =  -35.29500016633712
training  [2.8018, 1.712, 0.9061]  w:  [1.82471118 0.96838444 2.07099141]
8.646875282467764  -  90.1138  =  -81.46692471753224
training  [-1.6242, 2.1521, 1.6044]  w:  [1.82471118 0.96838444 2.07099141]
2.4430628794236413  -  63.7879  =  -61.34483712057636
training  [1.0787, 1.4206, -4.5245]  w:  [1.82471118 0.96838444 2.07099141]
-6.0261977601123  -  18.0555  =  -24.0816977601123
training  [2.4125, -0.8095, -1.5122]  w:  [1.82471118 0.96838444 2.07099141]
0.48645530847555873  -  38.8276  =  -38.34114469152444
training  [-3.9519, -1.0924, -0.4866]  w:  [1.82471118 0.96838444 2.07099141]
-9.276683716213528  -  3.6777  =  -12.954383716213528
training  [-3.7211, 3.1614, -2.591]  w:  [1.82471118 0.96838444 2.07099141]
-9.094420963944586  -  11.1518  =  -20.246220963944587
training  [0.4954, -1.8257, 2.1505]  w:  [1.82471118 0.96838444 2.07099141]
3.5896494796716443  -  47.7531  =  -44.16345052032836
training  [-0.1477, 3.1454, 3.5618]  w:  [1.82471118 0.96838444 2.07099141]
10.152903804301857  -  94.1572  =  -84.00429619569815
training  [3.9048, 2.8907, -2.1849]  w:  [1.82471118 0.96838444 2.07099141]
5.399531999799688  -  85.8791  =  -80.4795680002003
training  [2.9896, 3.5226, 2.3105]  w:  [1.82471118 0.96838444 2.07099141]
13.651413257428452  -  98.038  =  -84.38658674257155
training  [2.3434, 0.0564, -3.6224]  w:  [1.82471118 0.96838444 2.07099141]
-3.171314227705343  -  24.7629  =  -27.93421422770534
training  [-4.4867, 1.3566, 3.3672]  w:  [1.82471118 0.96838444 2.07099141]
0.10022095564708344  -  40.5785  =  -40.47827904435292
training  [-4.2711, 4.5089, -3.614]  w:  [1.82471118 0.96838444 2.07099141]
-10.911738295237068  -  10.0825  =  -20.994238295237068
training  [-4.1147, -0.5604, 0.8821]  w:  [1.82471118 0.96838444 2.07099141]
-6.224000224602092  -  8.344  =  -14.568000224602091
training  [2.9835, -4.3998, -1.3384]  w:  [1.82471118 0.96838444 2.07099141]
-1.5884869629466647  -  13.2692  =  -14.857686962946664
training  [4.4301, 3.6675, 3.0676]  w:  [1.82471118 0.96838444 2.07099141]
17.988176223722828  -  99.3834  =  -81.39522377627716
training  [1.8372, 1.3119, 0.0378]  w:  [1.82471118 0.96838444 2.07099141]
4.701066413602042  -  74.9026  =  -70.20153358639797
training  [-3.6792, -1.4493, -0.1041]  w:  [1.82471118 0.96838444 2.07099141]
-8.332547168001271  -  4.2442  =  -12.576747168001273
training  [2.2272, 4.97, 3.7705]  w:  [1.82471118 0.96838444 2.07099141]
16.685540558196404  -  99.3199  =  -82.6343594418036
training  [-3.8965, -2.7583, -1.4686]  w:  [1.82471118 0.96838444 2.07099141]
-12.822539928900866  -  1.0337  =  -13.856239928900866
training  [-3.8251, 1.5245, -0.5056]  w:  [1.82471118 0.96838444 2.07099141]
-6.550493926293514  -  12.9762  =  -19.526693926293515
training  [1.4072, 1.0499, 4.6353]  w:  [1.82471118 0.96838444 2.07099141]
13.184106907658801  -  95.4618  =  -82.2776930923412
training  [-1.7119, -1.1275, -4.577]  w:  [1.82471118 0.96838444 2.07099141]
-13.694504238779999  -  1.4655  =  -15.16000423878
training  [1.5381, -3.5781, 4.7296]  w:  [1.82471118 0.96838444 2.07099141]
9.136572890256993  -  69.9473  =  -60.810727109743006
training  [2.4913, -4.7487, -3.1079]  w:  [1.82471118 0.96838444 2.07099141]
-6.489098447523947  -  3.9825  =  -10.471598447523947
training  [0.8319, -0.7889, 1.6712]  w:  [1.82471118 0.96838444 2.07099141]
4.2150595986615915  -  58.8336  =  -54.61854040133841
training  [2.4003, -3.159, 0.8644]  w:  [1.82471118 0.96838444 2.07099141]
3.1108927786607232  -  39.0041  =  -35.89320722133928
training  [-2.6517, 2.2578, 1.7511]  w:  [1.82471118 0.96838444 2.07099141]
0.9743448138198354  -  54.4525  =  -53.47815518618017
training  [2.3496, -1.2964, -1.3898]  w:  [1.82471118 0.96838444 2.07099141]
0.1536639388532115  -  33.888  =  -33.734336061146784
training  [4.706, 3.4156, 1.2028]  w:  [1.82471118 0.96838444 2.07099141]
14.385693208857582  -  98.4665  =  -84.08080679114241
training  [3.6693, 2.3423, 3.1115]  w:  [1.82471118 0.96838444 2.07099141]
15.407549414181075  -  98.3069  =  -82.89935058581892
training  [-4.1377, 0.7103, -4.8074]  w:  [1.82471118 0.96838444 2.07099141]
-16.818348121934424  -  0.9782  =  -17.796548121934425
training  [-1.3356, -3.2314, -4.1613]  w:  [1.82471118 0.96838444 2.07099141]
-14.184338318695172  -  0.7659  =  -14.950238318695172
training  [-1.308, 4.5738, 4.748]  w:  [1.82471118 0.96838444 2.07099141]
11.875541771250326  -  97.0884  =  -85.21285822874967
training  [1.8503, -2.3468, 1.5135]  w:  [1.82471118 0.96838444 2.07099141]
4.23810399894269  -  50.2125  =  -45.97439600105731
training  [0.9794, 4.2458, -2.6876]  w:  [1.82471118 0.96838444 2.07099141]
0.3326922763447602  -  68.3262  =  -67.99350772365524
training  [2.8936, -2.7623, -0.9651]  w:  [1.82471118 0.96838444 2.07099141]
0.6063021218208475  -  28.5596  =  -27.953297878179153
training  [-1.3235, -1.2644, -3.7798]  w:  [1.82471118 0.96838444 2.07099141]
-11.467363889610759  -  2.4511  =  -13.91846388961076
training  [-2.9397, -4.125, -2.3156]  w:  [1.82471118 0.96838444 2.07099141]
-14.154277013960368  -  0.554  =  -14.708277013960368
training  [-4.1333, 1.4012, -2.4215]  w:  [1.82471118 0.96838444 2.07099141]
-11.200084165724789  -  4.4072  =  -15.607284165724788
training  [2.7193, -3.1938, -1.6833]  w:  [1.82471118 0.96838444 2.07099141]
-1.6169889584434092  -  17.0949  =  -18.71188895844341
training  [-2.9433, -4.5495, -3.4777]  w:  [1.82471118 0.96838444 2.07099141]
-16.97862429280341  -  0.2509  =  -17.22952429280341
training  [-1.1173, 2.2317, -1.5199]  w:  [1.82471118 0.96838444 2.07099141]
-3.0253060954024757  -  33.1206  =  -36.14590609540248
training  [0.5178, -1.5256, -3.7834]  w:  [1.82471118 0.96838444 2.07099141]
-8.367920771843256  -  5.237  =  -13.604920771843256
training  [-2.7105, 1.6062, 3.8415]  w:  [1.82471118 0.96838444 2.07099141]
4.565252945661687  -  70.4458  =  -65.88054705433832
training  [1.4194, -1.1613, -4.0572]  w:  [1.82471118 0.96838444 2.07099141]
-6.937016164914015  -  8.3206  =  -15.257616164914015
training  [-0.1552, 1.2735, 4.3004]  w:  [1.82471118 0.96838444 2.07099141]
9.856133890350128  -  90.1085  =  -80.25236610964988
training  [-3.4815, -4.7835, -1.0098]  w:  [1.82471118 0.96838444 2.07099141]
-13.076286100376626  -  0.5839  =  -13.660186100376626
training  [2.8193, 4.1057, -4.526]  w:  [1.82471118 0.96838444 2.07099141]
-0.253002892479838  -  66.8081  =  -67.06110289247984
training  [-3.9939, 3.0056, -1.5763]  w:  [1.82471118 0.96838444 2.07099141]
-7.641641483084082  -  14.4018  =  -22.04344148308408
training  [-2.0593, 2.4585, 2.3597]  w:  [1.82471118 0.96838444 2.07099141]
3.510063851739609  -  70.6698  =  -67.15973614826038
training  [-2.6263, 3.1311, 2.9468]  w:  [1.82471118 0.96838444 2.07099141]
4.34266704597443  -  77.309  =  -72.96633295402557
training  [0.3087, -1.1669, 0.4491]  w:  [1.82471118 0.96838444 2.07099141]
0.363362780279169  -  33.0798  =  -32.71643721972083
training  [-4.085, 1.1728, 1.8622]  w:  [1.82471118 0.96838444 2.07099141]
-2.461623700824466  -  26.4056  =  -28.867223700824464
training  [-0.9468, 0.7549, 3.9363]  w:  [1.82471118 0.96838444 2.07099141]
7.155440370948691  -  79.7738  =  -72.6183596290513
training  [-3.9515, 0.3005, -4.4521]  w:  [1.82471118 0.96838444 2.07099141]
-16.139607594648712  -  1.0441  =  -17.183707594648713
training  [-3.8772, -2.2493, -1.9634]  w:  [1.82471118 0.96838444 2.07099141]
-13.319141873406425  -  1.0509  =  -14.370041873406425
training  [2.8443, -2.5137, -4.5381]  w:  [1.82471118 0.96838444 2.07099141]
-6.642568090368947  -  6.8897  =  -13.532268090368948
training  [-2.0843, -0.4836, -3.0452]  w:  [1.82471118 0.96838444 2.07099141]
-10.578139292528327  -  3.5346  =  -14.112739292528328
training  [1.0353, -2.7229, 2.2017]  w:  [1.82471118 0.96838444 2.07099141]
3.8120112862219653  -  43.9562  =  -40.144188713778036
training  [4.6442, 3.0445, 2.2175]  w:  [1.82471118 0.96838444 2.07099141]
16.014993579012504  -  98.8492  =  -82.8342064209875
training  [-0.6752, 4.861, 3.778]  w:  [1.82471118 0.96838444 2.07099141]
11.299477348695657  -  97.017  =  -85.71752265130434
training  [1.9475, -4.7001, 0.8243]  w:  [1.82471118 0.96838444 2.07099141]
0.7092395338068842  -  18.7839  =  -18.074660466193116
training  [2.581, 0.3566, -4.2932]  w:  [1.82471118 0.96838444 2.07099141]
-3.8362748813114305  -  23.5455  =  -27.38177488131143
training  [-0.6736, -4.1292, 4.2274]  w:  [1.82471118 0.96838444 2.07099141]
3.5271306095562753  -  31.2667  =  -27.739569390443727
training  [1.555, 3.0209, 3.0037]  w:  [1.82471118 0.96838444 2.07099141]
11.983455366060564  -  96.4078  =  -84.42434463393943
training  [-3.9024, 4.8914, -2.1405]  w:  [1.82471118 0.96838444 2.07099141]
-6.816954383253539  -  25.4308  =  -32.24775438325354
training  [4.3376, -4.3305, 0.4366]  w:  [1.82471118 0.96838444 2.07099141]
4.6254732537777645  -  43.0907  =  -38.465226746222235
training  [-3.1254, 4.394, 4.8478]  w:  [1.82471118 0.96838444 2.07099141]
8.59188108551792  -  92.8121  =  -84.22021891448207
training  [-2.3382, -4.8182, 2.1568]  w:  [1.82471118 0.96838444 2.07099141]
-4.465695331180497  -  4.7434  =  -9.209095331180498
training  [2.9783, 1.8384, 3.3897]  w:  [1.82471118 0.96838444 2.07099141]
14.234854876623622  -  97.3486  =  -83.11374512337639
training  [-0.124, 2.8374, -0.6674]  w:  [1.82471118 0.96838444 2.07099141]
1.1392501615635515  -  62.785  =  -61.645749838436444
training  [2.6896, 0.3414, -0.2938]  w:  [1.82471118 0.96838444 2.07099141]
4.62989237213252  -  70.4455  =  -65.81560762786748
training  [-1.0399, 3.8536, 0.6071]  w:  [1.82471118 0.96838444 2.07099141]
3.091548016431415  -  77.0369  =  -73.94535198356859
training  [-2.2706, 3.99, -2.3091]  w:  [1.82471118 0.96838444 2.07099141]
-5.0614615622719334  -  31.1134  =  -36.17486156227193
training  [-4.6277, 1.2594, 2.4902]  w:  [1.82471118 0.96838444 2.07099141]
-2.0674497595135968  -  28.1093  =  -30.176749759513598
training  [1.7329, -3.6213, 0.0389]  w:  [1.82471118 0.96838444 2.07099141]
-0.26420700609679393  -  19.3919  =  -19.656107006096793
training  [-0.7044, -2.822, 1.4681]  w:  [1.82471118 0.96838444 2.07099141]
-0.9776849606440097  -  17.8122  =  -18.78988496064401
training  [-0.4826, -3.1786, -1.9225]  w:  [1.82471118 0.96838444 2.07099141]
-7.940193401692814  -  3.5851  =  -11.525293401692814
training  [1.0986, -4.5818, -3.6128]  w:  [1.82471118 0.96838444 2.07099141]
-9.914393915230056  -  1.7158  =  -11.630193915230056
training  [-4.406, -3.9306, -0.2443]  w:  [1.82471118 0.96838444 2.07099141]
-12.351952571101279  -  0.8241  =  -13.176052571101279
training  [-1.8419, 1.1644, -1.3754]  w:  [1.82471118 0.96838444 2.07099141]
-5.081790275973545  -  17.8517  =  -22.933490275973547
training  [2.7272, 4.3966, 2.8811]  w:  [1.82471118 0.96838444 2.07099141]
15.200684746815988  -  98.904  =  -83.703315253184
training  [1.9643, -1.4554, 2.803]  w:  [1.82471118 0.96838444 2.07099141]
7.979882395090186  -  76.0591  =  -68.07921760490981
training  [-3.7467, -0.8937, 1.6851]  w:  [1.82471118 0.96838444 2.07099141]
-4.2122629379731675  -  12.1571  =  -16.369362937973168
training  [-3.6985, 4.8435, -3.665]  w:  [1.82471118 0.96838444 2.07099141]
-9.648507798734748  -  14.6793  =  -24.327807798734746
239161.14015906822
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.55839842 1.19881247 2.17690521]
11.793429223102645  -  87.3174  =  -75.52397077689736
training  [-4.1793, -4.9218, 1.7664]  w:  [1.55839842 1.19881247 2.17690521]
-8.568044418698662  -  1.5257  =  -10.093744418698662
training  [-3.9429, -0.7689, 4.883]  w:  [1.55839842 1.19881247 2.17690521]
3.5634520569451142  -  39.7859  =  -36.22244794305488
training  [-3.5796, 1.5557, 2.6683]  w:  [1.55839842 1.19881247 2.17690521]
2.095185725251089  -  45.5674  =  -43.47221427474891
training  [-3.3354, 2.2292, -1.633]  w:  [1.55839842 1.19881247 2.17690521]
-6.080375536639336  -  13.3589  =  -19.439275536639336
training  [1.2096, 0.3121, 1.6238]  w:  [1.55839842 1.19881247 2.17690521]
5.794046779678372  -  74.5119  =  -68.71785322032163
training  [0.7371, -3.9118, -2.5583]  w:  [1.55839842 1.19881247 2.17690521]
-9.109995745746488  -  3.3358  =  -12.445795745746487
training  [-4.4792, 1.3177, -2.0449]  w:  [1.55839842 1.19881247 2.17690521]
-9.8522564791759  -  4.2974  =  -14.1496564791759
training  [4.312, -3.735, 1.8018]  w:  [1.55839842 1.19881247 2.17690521]
6.1645972123629145  -  66.5833  =  -60.41870278763708
training  [2.2866, -3.657, 0.2785]  w:  [1.55839842 1.19881247 2.17690521]
-0.2143552825606313  -  26.0005  =  -26.21485528256063
training  [2.3784, -4.0141, -0.8841]  w:  [1.55839842 1.19881247 2.17690521]
-3.0302602333521085  -  14.6809  =  -17.711160233352107
training  [-4.366, -3.5797, 1.0264]  w:  [1.55839842 1.19881247 2.17690521]
-8.860981034172223  -  1.8713  =  -10.732281034172223
training  [3.6044, -3.3175, 2.5052]  w:  [1.55839842 1.19881247 2.17690521]
7.093613816622131  -  71.0139  =  -63.920286183377875
training  [4.3441, -3.0375, 0.8353]  w:  [1.55839842 1.19881247 2.17690521]
4.946814622076026  -  63.8979  =  -58.951085377923974
training  [4.844, -1.8252, 0.5179]  w:  [1.55839842 1.19881247 2.17690521]
6.488228645343754  -  78.0461  =  -71.55787135465624
training  [3.5894, -1.8357, 0.8357]  w:  [1.55839842 1.19881247 2.17690521]
5.212294925174464  -  68.8838  =  -63.67150507482553
training  [2.8556, -2.8244, 0.1182]  w:  [1.55839842 1.19881247 2.17690521]
1.3215467829560368  -  39.5252  =  -38.203653217043964
training  [0.1338, -2.4896, -4.1741]  w:  [1.55839842 1.19881247 2.17690521]
-11.862669844297463  -  2.2644  =  -14.127069844297463
training  [-3.224, 3.9292, 2.1957]  w:  [1.55839842 1.19881247 2.17690521]
4.465928213543999  -  72.1211  =  -67.655171786456
training  [-1.0141, 2.0322, 4.9616]  w:  [1.55839842 1.19881247 2.17690521]
11.656787734361908  -  92.3427  =  -80.68591226563808
training  [-3.6607, 0.5574, -1.4547]  w:  [1.55839842 1.19881247 2.17690521]
-8.203355041105254  -  5.8471  =  -14.050455041105256
training  [-4.6911, -3.1557, 4.7126]  w:  [1.55839842 1.19881247 2.17690521]
-0.834811905612753  -  11.2337  =  -12.068511905612754
training  [4.3914, -2.8797, -1.5355]  w:  [1.55839842 1.19881247 2.17690521]
0.04869261573907124  -  37.475  =  -37.42630738426093
training  [-1.9869, -4.2265, 3.8654]  w:  [1.55839842 1.19881247 2.17690521]
0.251446626320865  -  15.7889  =  -15.537453373679135
training  [-2.0447, 4.138, -0.4531]  w:  [1.55839842 1.19881247 2.17690521]
0.7878730129185508  -  57.936  =  -57.14812698708145
training  [-1.6706, 2.0672, -0.8657]  w:  [1.55839842 1.19881247 2.17690521]
-2.009822096530712  -  32.4185  =  -34.428322096530714
training  [-0.3293, 0.5779, -2.8227]  w:  [1.55839842 1.19881247 2.17690521]
-5.96513719461533  -  14.3434  =  -20.308537194615333
training  [1.482, -1.8657, -3.7435]  w:  [1.55839842 1.19881247 2.17690521]
-8.076322604155228  -  7.1519  =  -15.228222604155228
training  [-4.7477, -3.338, -1.9109]  w:  [1.55839842 1.19881247 2.17690521]
-15.560292396701872  -  0.4077  =  -15.967992396701872
training  [3.4221, 1.225, 2.261]  w:  [1.55839842 1.19881247 2.17690521]
11.72352319865428  -  95.0454  =  -83.32187680134572
training  [0.5903, 4.8793, 2.8287]  w:  [1.55839842 1.19881247 2.17690521]
12.92710005107375  -  97.4647  =  -84.53759994892624
training  [3.541, -3.2957, 1.9379]  w:  [1.55839842 1.19881247 2.17690521]
5.785987145588393  -  64.3732  =  -58.587212854411604
training  [-1.5212, -2.4221, -4.902]  w:  [1.55839842 1.19881247 2.17690521]
-15.945468693614618  -  0.7227  =  -16.668168693614618
training  [-0.5397, -1.032, 3.4321]  w:  [1.55839842 1.19881247 2.17690521]
5.393114251010152  -  60.5921  =  -55.19898574898985
training  [-4.4576, -4.2601, 4.2233]  w:  [1.55839842 1.19881247 2.17690521]
-2.8600540873176765  -  6.0247  =  -8.884754087317678
training  [-3.2289, 1.841, 2.7095]  w:  [1.55839842 1.19881247 2.17690521]
3.0734257461792738  -  54.0111  =  -50.937674253820724
training  [1.6281, -0.9761, -4.5734]  w:  [1.55839842 1.19881247 2.17690521]
-8.588790646657113  -  7.8658  =  -16.454590646657113
training  [-1.6917, 4.8284, -1.2181]  w:  [1.55839842 1.19881247 2.17690521]
0.5003153073157223  -  61.2837  =  -60.78338469268428
training  [3.9849, -0.9782, 2.0434]  w:  [1.55839842 1.19881247 2.17690521]
9.485671615268759  -  88.3402  =  -78.85452838473124
training  [-3.8184, 1.2067, 2.2951]  w:  [1.55839842 1.19881247 2.17690521]
0.49223360529029847  -  34.1122  =  -33.61996639470971
training  [4.8842, -3.4563, -2.7572]  w:  [1.55839842 1.19881247 2.17690521]
-2.5340890026283835  -  23.7819  =  -26.315989002628385
training  [0.3998, -1.1865, -2.3095]  w:  [1.55839842 1.19881247 2.17690521]
-5.826905882243791  -  11.4246  =  -17.25150588224379
training  [2.0692, -3.3887, 1.7303]  w:  [1.55839842 1.19881247 2.17690521]
2.928921263690708  -  42.6881  =  -39.75917873630929
training  [4.9949, 2.5811, -0.2251]  w:  [1.55839842 1.19881247 2.17690521]
10.388277807060701  -  95.9901  =  -85.6018221929393
training  [-2.1215, 3.7111, 1.2372]  w:  [1.55839842 1.19881247 2.17690521]
3.8360378367285177  -  71.3692  =  -67.53316216327148
training  [-0.8548, -1.4922, -2.6356]  w:  [1.55839842 1.19881247 2.17690521]
-8.858438306497126  -  4.7821  =  -13.640538306497126
training  [-0.3516, 1.8554, -3.2288]  w:  [1.55839842 1.19881247 2.17690521]
-5.352447746970198  -  20.3834  =  -25.7358477469702
training  [2.6396, -2.0585, 3.2964]  w:  [1.55839842 1.19881247 2.17690521]
8.821743320493647  -  80.826  =  -72.00425667950634
training  [3.182, 0.3063, 2.6692]  w:  [1.55839842 1.19881247 2.17690521]
11.136615421241345  -  92.9483  =  -81.81168457875866
training  [-3.9978, 3.3242, 4.3448]  w:  [1.55839842 1.19881247 2.17690521]
7.21314494186257  -  79.1768  =  -71.96365505813743
training  [-3.2188, 0.9749, -3.9211]  w:  [1.55839842 1.19881247 2.17690521]
-12.383313567089587  -  2.7053  =  -15.088613567089586
training  [-1.4037, -1.6469, -3.1777]  w:  [1.55839842 1.19881247 2.17690521]
-11.079399803223623  -  2.6234  =  -13.702799803223623
training  [-4.433, -2.0077, -4.009]  w:  [1.55839842 1.19881247 2.17690521]
-18.04244898841226  -  0.3253  =  -18.36774898841226
training  [0.2189, -0.4741, -0.1024]  w:  [1.55839842 1.19881247 2.17690521]
-0.45013867209417835  -  33.6531  =  -34.10323867209418
training  [-1.6415, -0.7735, -3.0675]  w:  [1.55839842 1.19881247 2.17690521]
-10.163049179641275  -  3.7641  =  -13.927149179641276
training  [-3.2433, -1.4039, 3.9589]  w:  [1.55839842 1.19881247 2.17690521]
1.8807835732916  -  30.0658  =  -28.1850164267084
training  [-2.9105, 0.5832, -4.0091]  w:  [1.55839842 1.19881247 2.17690521]
-12.56400183717216  -  2.4887  =  -15.05270183717216
training  [4.0515, 2.4255, -4.5583]  w:  [1.55839842 1.19881247 2.17690521]
-0.7014161225042592  -  61.2853  =  -61.98671612250426
training  [1.7539, -0.7567, 0.573]  w:  [1.55839842 1.19881247 2.17690521]
3.073500279725958  -  57.0797  =  -54.00619972027405
training  [-0.3153, -0.7064, 2.725]  w:  [1.55839842 1.19881247 2.17690521]
4.593862528656456  -  58.7004  =  -54.10653747134354
training  [4.1213, -3.7513, -1.8806]  w:  [1.55839842 1.19881247 2.17690521]
-2.168365737874929  -  22.1789  =  -24.347265737874928
training  [-3.9599, -4.7557, -3.2102]  w:  [1.55839842 1.19881247 2.17690521]
-18.860595496153508  -  0.1558  =  -19.016395496153507
training  [2.4555, -2.0981, -1.6104]  w:  [1.55839842 1.19881247 2.17690521]
-2.1942692639551993  -  24.4796  =  -26.6738692639552
training  [2.3627, -1.8248, -2.8985]  w:  [1.55839842 1.19881247 2.17690521]
-4.815324783158768  -  15.7052  =  -20.52052478315877
training  [0.6186, 1.5369, 0.1015]  w:  [1.55839842 1.19881247 2.17690521]
3.027436035940116  -  65.2154  =  -62.18796396405989
training  [-3.1581, 4.5694, 4.0636]  w:  [1.55839842 1.19881247 2.17690521]
9.402347648614636  -  90.3564  =  -80.95405235138536
training  [0.9721, 4.3573, 1.2892]  w:  [1.55839842 1.19881247 2.17690521]
9.544970894512181  -  94.3178  =  -84.77282910548783
training  [-2.0006, -0.4211, -3.9847]  w:  [1.55839842 1.19881247 2.17690521]
-12.296865991966326  -  2.4051  =  -14.701965991966325
training  [-3.6588, -2.5952, -1.0915]  w:  [1.55839842 1.19881247 2.17690521]
-11.189118321048488  -  1.5176  =  -12.706718321048488
training  [-2.874, 2.639, -4.4538]  w:  [1.55839842 1.19881247 2.17690521]
-11.010671354096539  -  5.497  =  -16.507671354096537
training  [3.9494, 2.5933, 0.0128]  w:  [1.55839842 1.19881247 2.17690521]
9.291483514737992  -  94.1462  =  -84.854716485262
training  [-4.2855, 2.4065, -0.6828]  w:  [1.55839842 1.19881247 2.17690521]
-5.279965102097012  -  14.4193  =  -19.699265102097012
training  [-2.5751, 2.4369, 4.9756]  w:  [1.55839842 1.19881247 2.17690521]
9.739763875067304  -  87.1991  =  -77.45933612493269
training  [-4.4625, -3.9408, 3.116]  w:  [1.55839842 1.19881247 2.17690521]
-4.8953965500894405  -  4.1344  =  -9.02979655008944
training  [-0.5828, 1.8156, -0.1435]  w:  [1.55839842 1.19881247 2.17690521]
0.9559434301668761  -  51.1166  =  -50.16065656983312
training  [-4.8672, -0.3674, 3.9445]  w:  [1.55839842 1.19881247 2.17690521]
0.5613220667282661  -  24.1396  =  -23.578277933271735
training  [3.9719, -2.8784, -3.6245]  w:  [1.55839842 1.19881247 2.17690521]
-5.151052040625453  -  14.6104  =  -19.761452040625453
training  [-3.0334, -4.0148, -1.1]  w:  [1.55839842 1.19881247 2.17690521]
-11.934833829565692  -  1.021  =  -12.955833829565691
training  [-4.0663, 3.2357, 4.2736]  w:  [1.55839842 1.19881247 2.17690521]
6.845304095176784  -  77.2328  =  -70.38749590482321
training  [-1.9263, -3.2499, 4.1749]  w:  [1.55839842 1.19881247 2.17690521]
2.1903979945341296  -  26.8814  =  -24.69100200546587
training  [-0.4394, -3.3643, 2.1357]  w:  [1.55839842 1.19881247 2.17690521]
-0.06870862946557921  -  20.85  =  -20.91870862946558
training  [-3.9833, 1.6599, 1.1834]  w:  [1.55839842 1.19881247 2.17690521]
-1.6415099979535093  -  25.5397  =  -27.18120999795351
training  [4.9539, 3.9439, -1.5671]  w:  [1.55839842 1.19881247 2.17690521]
9.036718326775922  -  95.9509  =  -86.91418167322408
training  [-1.6791, 0.1656, 4.3603]  w:  [1.55839842 1.19881247 2.17690521]
7.073776317125497  -  71.5733  =  -64.49952368287451
training  [-2.0265, 2.027, -3.7523]  w:  [1.55839842 1.19881247 2.17690521]
-8.896502922400675  -  8.503  =  -17.399502922400675
training  [-4.3795, -3.4641, 2.3059]  w:  [1.55839842 1.19881247 2.17690521]
-5.958086480881527  -  3.6654  =  -9.623486480881528
training  [-2.0176, 4.5346, 1.4648]  w:  [1.55839842 1.19881247 2.17690521]
5.480641130560263  -  81.6212  =  -76.14055886943974
training  [-4.5365, 0.4088, 3.3315]  w:  [1.55839842 1.19881247 2.17690521]
0.6727597777594685  -  28.9449  =  -28.27214022224053
training  [0.0543, 1.7973, -1.0172]  w:  [1.55839842 1.19881247 2.17690521]
0.024898720411646647  -  47.9317  =  -47.90680127958835
training  [2.6143, -4.6344, 2.4982]  w:  [1.55839842 1.19881247 2.17690521]
3.9566890522793727  -  43.5132  =  -39.556510947720625
training  [1.3107, 3.092, 3.3522]  w:  [1.55839842 1.19881247 2.17690521]
13.046742615096408  -  96.6993  =  -83.65255738490359
training  [-4.1011, 2.4862, -1.7754]  w:  [1.55839842 1.19881247 2.17690521]
-7.275537705512303  -  10.0187  =  -17.2942377055123
training  [-4.1914, -3.7981, 0.5226]  w:  [1.55839842 1.19881247 2.17690521]
-9.947430156051157  -  1.4295  =  -11.376930156051156
training  [2.7724, 0.2505, 4.7913]  w:  [1.55839842 1.19881247 2.17690521]
15.05101222627853  -  96.7925  =  -81.74148777372147
training  [4.0513, -1.7417, 0.4931]  w:  [1.55839842 1.19881247 2.17690521]
5.298999806787399  -  71.1234  =  -65.82440019321261
training  [0.3377, 0.4645, -1.6958]  w:  [1.55839842 1.19881247 2.17690521]
-2.608476304441499  -  27.9534  =  -30.561876304441498
training  [-3.9085, -1.0112, 1.1947]  w:  [1.55839842 1.19881247 2.17690521]
-4.702490767910133  -  8.608  =  -13.310490767910133
training  [3.2581, -0.8491, -1.3936]  w:  [1.55839842 1.19881247 2.17690521]
1.0257711408034753  -  50.1924  =  -49.16662885919652
training  [-1.619, -3.1926, 2.5651]  w:  [1.55839842 1.19881247 2.17690521]
-0.7663962140319995  -  16.4754  =  -17.241796214032
training  [-2.0603, -2.4461, -0.861]  w:  [1.55839842 1.19881247 2.17690521]
-8.017498849744094  -  3.9784  =  -11.995898849744094
training  [2.4631, -4.7946, -0.0765]  w:  [1.55839842 1.19881247 2.17690521]
-2.0758683795707036  -  15.394  =  -17.469868379570705
training  [-4.8966, 4.2368, 1.9474]  w:  [1.55839842 1.19881247 2.17690521]
1.6875801634868646  -  53.5883  =  -51.90071983651313
training  [-4.5155, 1.537, 4.7273]  w:  [1.55839842 1.19881247 2.17690521]
5.096510663839924  -  59.2523  =  -54.155789336160076
training  [1.6792, 4.3261, -1.7225]  w:  [1.55839842 1.19881247 2.17690521]
4.053326064993364  -  83.7729  =  -79.71957393500665
training  [1.0347, -3.3649, 3.378]  w:  [1.55839842 1.19881247 2.17690521]
4.932176536927301  -  50.5979  =  -45.6657234630727
training  [0.261, 4.211, 2.3907]  w:  [1.55839842 1.19881247 2.17690521]
10.659268593261372  -  94.9375  =  -84.27823140673863
training  [2.2971, 2.9466, 4.5417]  w:  [1.55839842 1.19881247 2.17690521]
16.99906822870802  -  98.7784  =  -81.779331771292
training  [2.0725, 0.7739, -4.6808]  w:  [1.55839842 1.19881247 2.17690521]
-6.032116175275845  -  19.5109  =  -25.543016175275845
training  [2.8138, -0.5996, -1.4313]  w:  [1.55839842 1.19881247 2.17690521]
0.5504091069809296  -  47.2879  =  -46.73749089301907
training  [-2.1202, -2.4239, 1.6265]  w:  [1.55839842 1.19881247 2.17690521]
-2.6691815806882473  -  12.3599  =  -15.029081580688247
training  [1.9253, 2.5195, -2.185]  w:  [1.55839842 1.19881247 2.17690521]
1.2642546432643096  -  65.2467  =  -63.982445356735695
training  [0.5667, -2.7133, -2.6962]  w:  [1.55839842 1.19881247 2.17690521]
-8.238965314249134  -  5.1106  =  -13.349565314249134
training  [-1.0348, -4.3581, 2.1113]  w:  [1.55839842 1.19881247 2.17690521]
-2.241075375682353  -  10.5192  =  -12.760275375682353
training  [-4.3841, 2.6733, 1.2457]  w:  [1.55839842 1.19881247 2.17690521]
-0.9156183304444974  -  32.4639  =  -33.3795183304445
training  [2.8018, 1.712, 0.9061]  w:  [1.55839842 1.19881247 2.17690521]
8.391181468649874  -  90.1138  =  -81.72261853135012
training  [-1.6242, 2.1521, 1.6044]  w:  [1.55839842 1.19881247 2.17690521]
3.541440316637999  -  63.7879  =  -60.246459683362005
training  [1.0787, 1.4206, -4.5245]  w:  [1.55839842 1.19881247 2.17690521]
-6.465330218651054  -  18.0555  =  -24.520830218651053
training  [2.4125, -0.8095, -1.5122]  w:  [1.55839842 1.19881247 2.17690521]
-0.5027185502847757  -  38.8276  =  -39.33031855028477
training  [-3.9519, -1.0924, -0.4866]  w:  [1.55839842 1.19881247 2.17690521]
-8.52749955384718  -  3.6777  =  -12.20519955384718
training  [-3.7211, 3.1614, -2.591]  w:  [1.55839842 1.19881247 2.17690521]
-7.649392006647048  -  11.1518  =  -18.80119200664705
training  [0.4954, -1.8257, 2.1505]  w:  [1.55839842 1.19881247 2.17690521]
3.2647932882231636  -  47.7531  =  -44.48830671177684
training  [-0.1477, 3.1454, 3.5618]  w:  [1.55839842 1.19881247 2.17690521]
11.294270269947578  -  94.1572  =  -82.86292973005243
training  [3.9048, 2.8907, -2.1849]  w:  [1.55839842 1.19881247 2.17690521]
4.794321205652113  -  85.8791  =  -81.08477879434788
training  [2.9896, 3.5226, 2.3105]  w:  [1.55839842 1.19881247 2.17690521]
13.911664229373452  -  98.038  =  -84.12633577062654
training  [2.3434, 0.0564, -3.6224]  w:  [1.55839842 1.19881247 2.17690521]
-4.166057523507487  -  24.7629  =  -28.928957523507485
training  [-4.4867, 1.3566, 3.3672]  w:  [1.55839842 1.19881247 2.17690521]
1.9643179985563757  -  40.5785  =  -38.61418200144362
training  [-4.2711, 4.5089, -3.614]  w:  [1.55839842 1.19881247 2.17690521]
-9.11808535542783  -  10.0825  =  -19.20058535542783
training  [-4.1147, -0.5604, 0.8821]  w:  [1.55839842 1.19881247 2.17690521]
-5.163908426609842  -  8.344  =  -13.507908426609841
training  [2.9835, -4.3998, -1.3384]  w:  [1.55839842 1.19881247 2.17690521]
-3.538623352833271  -  13.2692  =  -16.80782335283327
training  [4.4301, 3.6675, 3.0676]  w:  [1.55839842 1.19881247 2.17690521]
17.978380018232407  -  99.3834  =  -81.4050199817676
training  [1.8372, 1.3119, 0.0378]  w:  [1.55839842 1.19881247 2.17690521]
4.518098687679291  -  74.9026  =  -70.38450131232072
training  [-3.6792, -1.4493, -0.1041]  w:  [1.55839842 1.19881247 2.17690521]
-7.697714234714455  -  4.2442  =  -11.941914234714456
training  [2.2272, 4.97, 3.7705]  w:  [1.55839842 1.19881247 2.17690521]
17.636984045766688  -  99.3199  =  -81.68291595423332
training  [-3.8965, -2.7583, -1.4686]  w:  [1.55839842 1.19881247 2.17690521]
-12.575986894012587  -  1.0337  =  -13.609686894012587
training  [-3.8251, 1.5245, -0.5056]  w:  [1.55839842 1.19881247 2.17690521]
-5.234083467715123  -  12.9762  =  -18.210283467715122
training  [1.4072, 1.0499, 4.6353]  w:  [1.55839842 1.19881247 2.17690521]
13.542220177357368  -  95.4618  =  -81.91957982264263
training  [-1.7119, -1.1275, -4.577]  w:  [1.55839842 1.19881247 2.17690521]
-13.983178451872597  -  1.4655  =  -15.448678451872597
training  [1.5381, -3.5781, 4.7296]  w:  [1.55839842 1.19881247 2.17690521]
8.403392559478874  -  69.9473  =  -61.543907440521124
training  [2.4913, -4.7487, -3.1079]  w:  [1.55839842 1.19881247 2.17690521]
-8.575966490229431  -  3.9825  =  -12.558466490229431
training  [0.8319, -0.7889, 1.6712]  w:  [1.55839842 1.19881247 2.17690521]
3.988732466924574  -  58.8336  =  -54.84486753307542
training  [2.4003, -3.159, 0.8644]  w:  [1.55839842 1.19881247 2.17690521]
1.8352919903421703  -  39.0041  =  -37.16880800965783
training  [-2.6517, 2.2578, 1.7511]  w:  [1.55839842 1.19881247 2.17690521]
2.3862524076248004  -  54.4525  =  -52.0662475923752
training  [2.3496, -1.2964, -1.3898]  w:  [1.55839842 1.19881247 2.17690521]
-0.917990407965346  -  33.888  =  -34.805990407965346
training  [4.706, 3.4156, 1.2028]  w:  [1.55839842 1.19881247 2.17690521]
14.046868454681373  -  98.4665  =  -84.41963154531862
training  [3.6693, 2.3423, 3.1115]  w:  [1.55839842 1.19881247 2.17690521]
15.299650344028482  -  98.3069  =  -83.00724965597152
training  [-4.1377, 0.7103, -4.8074]  w:  [1.55839842 1.19881247 2.17690521]
-16.061922743443418  -  0.9782  =  -17.04012274344342
training  [-1.3356, -3.2314, -4.1613]  w:  [1.55839842 1.19881247 2.17690521]
-15.013995196292974  -  0.7659  =  -15.779895196292975
training  [-1.308, 4.5738, 4.748]  w:  [1.55839842 1.19881247 2.17690521]
13.78068927105268  -  97.0884  =  -83.30771072894731
training  [1.8503, -2.3468, 1.5135]  w:  [1.55839842 1.19881247 2.17690521]
3.364877517391923  -  50.2125  =  -46.847622482608074
training  [0.9794, 4.2458, -2.6876]  w:  [1.55839842 1.19881247 2.17690521]
0.765562992353467  -  68.3262  =  -67.56063700764653
training  [2.8936, -2.7623, -0.9651]  w:  [1.55839842 1.19881247 2.17690521]
-0.9030292309511263  -  28.5596  =  -29.462629230951126
training  [-1.3235, -1.2644, -3.7798]  w:  [1.55839842 1.19881247 2.17690521]
-11.806585102046554  -  2.4511  =  -14.257685102046555
training  [-2.9397, -4.125, -2.3156]  w:  [1.55839842 1.19881247 2.17690521]
-14.567166999241362  -  0.554  =  -15.121166999241362
training  [-4.1333, 1.4012, -2.4215]  w:  [1.55839842 1.19881247 2.17690521]
-10.032928122762282  -  4.4072  =  -14.440128122762282
training  [2.7193, -3.1938, -1.6833]  w:  [1.55839842 1.19881247 2.17690521]
-3.255398977454958  -  17.0949  =  -20.35029897745496
training  [-2.9433, -4.5495, -3.4777]  w:  [1.55839842 1.19881247 2.17690521]
-17.611454667915947  -  0.2509  =  -17.862354667915948
training  [-1.1173, 2.2317, -1.5199]  w:  [1.55839842 1.19881247 2.17690521]
-2.374486981375574  -  33.1206  =  -35.49508698137558
training  [0.5178, -1.5256, -3.7834]  w:  [1.55839842 1.19881247 2.17690521]
-9.258072760125705  -  5.237  =  -14.495072760125705
training  [-2.7105, 1.6062, 3.8415]  w:  [1.55839842 1.19881247 2.17690521]
6.064075012601446  -  70.4458  =  -64.38172498739856
training  [1.4194, -1.1613, -4.0572]  w:  [1.55839842 1.19881247 2.17690521]
-8.012330001262015  -  8.3206  =  -16.332930001262014
training  [-0.1552, 1.2735, 4.3004]  w:  [1.55839842 1.19881247 2.17690521]
10.646387395048952  -  90.1085  =  -79.46211260495106
training  [-3.4815, -4.7835, -1.0098]  w:  [1.55839842 1.19881247 2.17690521]
-13.358322463312359  -  0.5839  =  -13.942222463312358
training  [2.8193, 4.1057, -4.526]  w:  [1.55839842 1.19881247 2.17690521]
-0.5371159032071233  -  66.8081  =  -67.34521590320712
training  [-3.9939, 3.0056, -1.5763]  w:  [1.55839842 1.19881247 2.17690521]
-6.052392368754228  -  14.4018  =  -20.454192368754228
training  [-2.0593, 2.4585, 2.3597]  w:  [1.55839842 1.19881247 2.17690521]
4.874913805789702  -  70.6698  =  -65.79488619421029
training  [-2.6263, 3.1311, 2.9468]  w:  [1.55839842 1.19881247 2.17690521]
6.07568421544993  -  77.309  =  -71.23331578455007
training  [0.3087, -1.1669, 0.4491]  w:  [1.55839842 1.19881247 2.17690521]
0.05983144464297796  -  33.0798  =  -33.01996855535702
training  [-4.085, 1.1728, 1.8622]  w:  [1.55839842 1.19881247 2.17690521]
-0.906257420868287  -  26.4056  =  -27.311857420868286
training  [-0.9468, 0.7549, 3.9363]  w:  [1.55839842 1.19881247 2.17690521]
7.998443867699023  -  79.7738  =  -71.77535613230097
training  [-3.9515, 0.3005, -4.4521]  w:  [1.55839842 1.19881247 2.17690521]
-15.489567889515895  -  1.0441  =  -16.533667889515893
training  [-3.8772, -2.2493, -1.9634]  w:  [1.55839842 1.19881247 2.17690521]
-13.012846950339576  -  1.0509  =  -14.063746950339576
training  [2.8443, -2.5137, -4.5381]  w:  [1.55839842 1.19881247 2.17690521]
-8.459915790000618  -  6.8897  =  -15.34961579000062
training  [-2.0843, -0.4836, -3.0452]  w:  [1.55839842 1.19881247 2.17690521]
-10.457027279545425  -  3.5346  =  -13.991627279545426
training  [1.0353, -2.7229, 2.2017]  w:  [1.55839842 1.19881247 2.17690521]
3.1420555918928725  -  43.9562  =  -40.81414440810713
training  [4.6442, 3.0445, 2.2175]  w:  [1.55839842 1.19881247 2.17690521]
15.714585834359916  -  98.8492  =  -83.13461416564007
training  [-0.6752, 4.861, 3.778]  w:  [1.55839842 1.19881247 2.17690521]
12.999544687811548  -  97.017  =  -84.01745531218845
training  [1.9475, -4.7001, 0.8243]  w:  [1.55839842 1.19881247 2.17690521]
-0.8051346196149964  -  18.7839  =  -19.589034619614996
training  [2.581, 0.3566, -4.2932]  w:  [1.55839842 1.19881247 2.17690521]
-4.896166564566857  -  23.5455  =  -28.44166656456686
training  [-0.6736, -4.1292, 4.2274]  w:  [1.55839842 1.19881247 2.17690521]
3.2027754152477375  -  31.2667  =  -28.063924584752264
training  [1.555, 3.0209, 3.0037]  w:  [1.55839842 1.19881247 2.17690521]
12.583572319270601  -  96.4078  =  -83.8242276807294
training  [-3.9024, 4.8914, -2.1405]  w:  [1.55839842 1.19881247 2.17690521]
-4.87728826502707  -  25.4308  =  -30.30808826502707
training  [4.3376, -4.3305, 0.4366]  w:  [1.55839842 1.19881247 2.17690521]
2.5186883973648246  -  43.0907  =  -40.57201160263517
training  [-3.1254, 4.394, 4.8478]  w:  [1.55839842 1.19881247 2.17690521]
10.95016463090791  -  92.8121  =  -81.8619353690921
training  [-2.3382, -4.8182, 2.1568]  w:  [1.55839842 1.19881247 2.17690521]
-4.724816314906498  -  4.7434  =  -9.468216314906499
training  [2.9783, 1.8384, 3.3897]  w:  [1.55839842 1.19881247 2.17690521]
14.224330454811133  -  97.3486  =  -83.12426954518887
training  [-0.124, 2.8374, -0.6674]  w:  [1.55839842 1.19881247 2.17690521]
1.755402576916641  -  62.785  =  -61.02959742308335
training  [2.6896, 0.3414, -0.2938]  w:  [1.55839842 1.19881247 2.17690521]
3.9611682320940087  -  70.4455  =  -66.48433176790599
training  [-1.0399, 3.8536, 0.6071]  w:  [1.55839842 1.19881247 2.17690521]
4.32076438054774  -  77.0369  =  -72.71613561945226
training  [-2.2706, 3.99, -2.3091]  w:  [1.55839842 1.19881247 2.17690521]
-3.7819294981283527  -  31.1134  =  -34.89532949812835
training  [-4.6277, 1.2594, 2.4902]  w:  [1.55839842 1.19881247 2.17690521]
-0.2810866167238011  -  28.1093  =  -28.390386616723802
training  [1.7329, -3.6213, 0.0389]  w:  [1.55839842 1.19881247 2.17690521]
-1.5560293720091178  -  19.3919  =  -20.947929372009117
training  [-0.7044, -2.822, 1.4681]  w:  [1.55839842 1.19881247 2.17690521]
-1.2848701219182095  -  17.8122  =  -19.09707012191821
training  [-0.4826, -3.1786, -1.9225]  w:  [1.55839842 1.19881247 2.17690521]
-8.747728668304871  -  3.5851  =  -12.332828668304872
training  [1.0986, -4.5818, -3.6128]  w:  [1.55839842 1.19881247 2.17690521]
-11.64538561208209  -  1.7158  =  -13.36118561208209
training  [-4.406, -3.9306, -0.2443]  w:  [1.55839842 1.19881247 2.17690521]
-12.11017371264383  -  0.8241  =  -12.93427371264383
training  [-1.8419, 1.1644, -1.3754]  w:  [1.55839842 1.19881247 2.17690521]
-4.468632231775631  -  17.8517  =  -22.32033223177563
training  [2.7272, 4.3966, 2.8811]  w:  [1.55839842 1.19881247 2.17690521]
15.792644695637199  -  98.904  =  -83.1113553043628
training  [1.9643, -1.4554, 2.803]  w:  [1.55839842 1.19881247 2.17690521]
7.418275639658605  -  76.0591  =  -68.6408243603414
training  [-3.7467, -0.8937, 1.6851]  w:  [1.55839842 1.19881247 2.17690521]
-3.241927124466946  -  12.1571  =  -15.399027124466945
training  [-3.6985, 4.8435, -3.665]  w:  [1.55839842 1.19881247 2.17690521]
-7.935645929017941  -  14.6793  =  -22.614945929017942
237301.14993694754
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.52313833 1.23408127 2.11161705]
11.200804497452717  -  87.3174  =  -76.11659550254728
training  [-4.1793, -4.9218, 1.7664]  w:  [1.52313833 1.23408127 2.11161705]
-8.709592852611038  -  1.5257  =  -10.235292852611039
training  [-3.9429, -0.7689, 4.883]  w:  [1.52313833 1.23408127 2.11161705]
3.35655884188274  -  39.7859  =  -36.42934115811726
training  [-3.5796, 1.5557, 2.6683]  w:  [1.52313833 1.23408127 2.11161705]
2.102062029859421  -  45.5674  =  -43.46533797014058
training  [-3.3354, 2.2292, -1.633]  w:  [1.52313833 1.23408127 2.11161705]
-5.777532274655327  -  13.3589  =  -19.136432274655327
training  [1.2096, 0.3121, 1.6238]  w:  [1.52313833 1.23408127 2.11161705]
5.656388655907691  -  74.5119  =  -68.8555113440923
training  [0.7371, -3.9118, -2.5583]  w:  [1.52313833 1.23408127 2.11161705]
-9.106923735793186  -  3.3358  =  -12.442723735793187
training  [-4.4792, 1.3177, -2.0449]  w:  [1.52313833 1.23408127 2.11161705]
-9.51433803651899  -  4.2974  =  -13.811738036518989
training  [4.312, -3.735, 1.8018]  w:  [1.52313833 1.23408127 2.11161705]
5.763190555710681  -  66.5833  =  -60.820109444289315
training  [2.2866, -3.657, 0.2785]  w:  [1.52313833 1.23408127 2.11161705]
-0.44214173547465874  -  26.0005  =  -26.44264173547466
training  [2.3784, -4.0141, -0.8841]  w:  [1.52313833 1.23408127 2.11161705]
-3.1979740397591936  -  14.6809  =  -17.878874039759193
training  [-4.366, -3.5797, 1.0264]  w:  [1.52313833 1.23408127 2.11161705]
-8.9002989279072  -  1.8713  =  -10.771598927907199
training  [3.6044, -3.3175, 2.5052]  w:  [1.52313833 1.23408127 2.11161705]
6.6859582342842945  -  71.0139  =  -64.3279417657157
training  [4.3441, -3.0375, 0.8353]  w:  [1.52313833 1.23408127 2.11161705]
4.631977100793945  -  63.8979  =  -59.26592289920605
training  [4.844, -1.8252, 0.5179]  w:  [1.52313833 1.23408127 2.11161705]
6.219243421128587  -  78.0461  =  -71.82685657887141
training  [3.5894, -1.8357, 0.8357]  w:  [1.52313833 1.23408127 2.11161705]
4.96642811530501  -  68.8838  =  -63.91737188469499
training  [2.8556, -2.8244, 0.1182]  w:  [1.52313833 1.23408127 2.11161705]
1.1135278251004392  -  39.5252  =  -38.41167217489956
training  [0.1338, -2.4896, -4.1741]  w:  [1.52313833 1.23408127 2.11161705]
-11.682673543298755  -  2.2644  =  -13.947073543298755
training  [-3.224, 3.9292, 2.1957]  w:  [1.52313833 1.23408127 2.11161705]
4.574831689981657  -  72.1211  =  -67.54626831001835
training  [-1.0141, 2.0322, 4.9616]  w:  [1.52313833 1.23408127 2.11161705]
11.44028452537059  -  92.3427  =  -80.90241547462941
training  [-3.6607, 0.5574, -1.4547]  w:  [1.52313833 1.23408127 2.11161705]
-7.959644916152561  -  5.8471  =  -13.80674491615256
training  [-4.6911, -3.1557, 4.7126]  w:  [1.52313833 1.23408127 2.11161705]
-1.0883779715140545  -  11.2337  =  -12.322077971514055
training  [4.3914, -2.8797, -1.5355]  w:  [1.52313833 1.23408127 2.11161705]
-0.10746213504482816  -  37.475  =  -37.58246213504483
training  [-1.9869, -4.2265, 3.8654]  w:  [1.52313833 1.23408127 2.11161705]
-0.0799234803521447  -  15.7889  =  -15.868823480352145
training  [-2.0447, 4.138, -0.4531]  w:  [1.52313833 1.23408127 2.11161705]
1.0354936504017909  -  57.936  =  -56.90050634959821
training  [-1.6706, 2.0672, -0.8657]  w:  [1.52313833 1.23408127 2.11161705]
-1.8214889823902023  -  32.4185  =  -34.2399889823902
training  [-0.3293, 0.5779, -2.8227]  w:  [1.52313833 1.23408127 2.11161705]
-5.748855336358356  -  14.3434  =  -20.092255336358356
training  [1.482, -1.8657, -3.7435]  w:  [1.52313833 1.23408127 2.11161705]
-7.9499728399677405  -  7.1519  =  -15.10187283996774
training  [-4.7477, -3.338, -1.9109]  w:  [1.52313833 1.23408127 2.11161705]
-15.385856148794817  -  0.4077  =  -15.793556148794817
training  [3.4221, 1.225, 2.261]  w:  [1.52313833 1.23408127 2.11161705]
11.498447388201278  -  95.0454  =  -83.54695261179873
training  [0.5903, 4.8793, 2.8287]  w:  [1.52313833 1.23408127 2.11161705]
12.893692433715074  -  97.4647  =  -84.57100756628492
training  [3.541, -3.2957, 1.9379]  w:  [1.52313833 1.23408127 2.11161705]
5.418373883027775  -  64.3732  =  -58.95482611697222
training  [-1.5212, -2.4221, -4.902]  w:  [1.52313833 1.23408127 2.11161705]
-15.65721304786438  -  0.7227  =  -16.37991304786438
training  [-0.5397, -1.032, 3.4321]  w:  [1.52313833 1.23408127 2.11161705]
5.151671253101051  -  60.5921  =  -55.44042874689895
training  [-4.4576, -4.2601, 4.2233]  w:  [1.52313833 1.23408127 2.11161705]
-3.1288587450593557  -  6.0247  =  -9.153558745059357
training  [-3.2289, 1.841, 2.7095]  w:  [1.52313833 1.23408127 2.11161705]
3.075308650787523  -  54.0111  =  -50.93579134921248
training  [1.6281, -0.9761, -4.5734]  w:  [1.52313833 1.23408127 2.11161705]
-8.382034624587344  -  7.8658  =  -16.247834624587345
training  [-1.6917, 4.8284, -1.2181]  w:  [1.52313833 1.23408127 2.11161705]
0.809784144809016  -  61.2837  =  -60.47391585519099
training  [3.9849, -0.9782, 2.0434]  w:  [1.52313833 1.23408127 2.11161705]
9.17725392367981  -  88.3402  =  -79.16294607632018
training  [-3.8184, 1.2067, 2.2951]  w:  [1.52313833 1.23408127 2.11161705]
0.5195867508501175  -  34.1122  =  -33.592613249149885
training  [4.8842, -3.4563, -2.7572]  w:  [1.52313833 1.23408127 2.11161705]
-2.648193374054304  -  23.7819  =  -26.430093374054305
training  [0.3998, -1.1865, -2.3095]  w:  [1.52313833 1.23408127 2.11161705]
-5.732066295957966  -  11.4246  =  -17.156666295957965
training  [2.0692, -3.3887, 1.7303]  w:  [1.52313833 1.23408127 2.11161705]
2.6234776287694386  -  42.6881  =  -40.06462237123056
training  [4.9949, 2.5811, -0.2251]  w:  [1.52313833 1.23408127 2.11161705]
10.317885813945951  -  95.9901  =  -85.67221418605405
training  [-2.1215, 3.7111, 1.2372]  w:  [1.52313833 1.23408127 2.11161705]
3.960953633758288  -  71.3692  =  -67.40824636624171
training  [-0.8548, -1.4922, -2.6356]  w:  [1.52313833 1.23408127 2.11161705]
-8.708852610503222  -  4.7821  =  -13.490952610503221
training  [-0.3516, 1.8554, -3.2288]  w:  [1.52313833 1.23408127 2.11161705]
-5.063810186654683  -  20.3834  =  -25.447210186654686
training  [2.6396, -2.0585, 3.2964]  w:  [1.52313833 1.23408127 2.11161705]
8.440854097137239  -  80.826  =  -72.38514590286276
training  [3.182, 0.3063, 2.6692]  w:  [1.52313833 1.23408127 2.11161705]
10.860953494643514  -  92.9483  =  -82.08734650535649
training  [-3.9978, 3.3242, 4.3448]  w:  [1.52313833 1.23408127 2.11161705]
7.187684285079198  -  79.1768  =  -71.9891157149208
training  [-3.2188, 0.9749, -3.9211]  w:  [1.52313833 1.23408127 2.11161705]
-11.979433451214357  -  2.7053  =  -14.684733451214356
training  [-1.4037, -1.6469, -3.1777]  w:  [1.52313833 1.23408127 2.11161705]
-10.880523215824269  -  2.6234  =  -13.503923215824269
training  [-4.433, -2.0077, -4.009]  w:  [1.52313833 1.23408127 2.11161705]
-17.695209939489036  -  0.3253  =  -18.020509939489035
training  [0.2189, -0.4741, -0.1024]  w:  [1.52313833 1.23408127 2.11161705]
-0.4678925338150818  -  33.6531  =  -34.120992533815084
training  [-1.6415, -0.7735, -3.0675]  w:  [1.52313833 1.23408127 2.11161705]
-9.932178733562289  -  3.7641  =  -13.696278733562288
training  [-3.2433, -1.4039, 3.9589]  w:  [1.52313833 1.23408127 2.11161705]
1.6871594980718818  -  30.0658  =  -28.378640501928118
training  [-2.9105, 0.5832, -4.0091]  w:  [1.52313833 1.23408127 2.11161705]
-12.179061836236368  -  2.4887  =  -14.667761836236368
training  [4.0515, 2.4255, -4.5583]  w:  [1.52313833 1.23408127 2.11161705]
-0.4611249358456462  -  61.2853  =  -61.746424935845646
training  [1.7539, -0.7567, 0.573]  w:  [1.52313833 1.23408127 2.11161705]
2.947559595251679  -  57.0797  =  -54.13214040474833
training  [-0.3153, -0.7064, 2.725]  w:  [1.52313833 1.23408127 2.11161705]
4.402155939035061  -  58.7004  =  -54.29824406096494
training  [4.1213, -3.7513, -1.8806]  w:  [1.52313833 1.23408127 2.11161705]
-2.3232060748776493  -  22.1789  =  -24.50210607487765
training  [-3.9599, -4.7557, -3.2102]  w:  [1.52313833 1.23408127 2.11161705]
-18.67910881672067  -  0.1558  =  -18.83490881672067
training  [2.4555, -2.0981, -1.6104]  w:  [1.52313833 1.23408127 2.11161705]
-2.249707830380833  -  24.4796  =  -26.729307830380833
training  [2.3627, -1.8248, -2.8985]  w:  [1.52313833 1.23408127 2.11161705]
-4.773754579796885  -  15.7052  =  -20.478954579796884
training  [0.6186, 1.5369, 0.1015]  w:  [1.52313833 1.23408127 2.11161705]
3.0532020019752633  -  65.2154  =  -62.16219799802474
training  [-3.1581, 4.5694, 4.0636]  w:  [1.52313833 1.23408127 2.11161705]
9.409554821474561  -  90.3564  =  -80.94684517852544
training  [0.9721, 4.3573, 1.2892]  w:  [1.52313833 1.23408127 2.11161705]
9.580201778464875  -  94.3178  =  -84.73759822153514
training  [-2.0006, -0.4211, -3.9847]  w:  [1.52313833 1.23408127 2.11161705]
-11.98102262856164  -  2.4051  =  -14.38612262856164
training  [-3.6588, -2.5952, -1.0915]  w:  [1.52313833 1.23408127 2.11161705]
-11.080376243095916  -  1.5176  =  -12.597976243095916
training  [-2.874, 2.639, -4.4538]  w:  [1.52313833 1.23408127 2.11161705]
-10.525479120632074  -  5.497  =  -16.022479120632074
training  [3.9494, 2.5933, 0.0128]  w:  [1.52313833 1.23408127 2.11161705]
9.242854175748983  -  94.1462  =  -84.903345824251
training  [-4.2855, 2.4065, -0.6828]  w:  [1.52313833 1.23408127 2.11161705]
-4.999404873874282  -  14.4193  =  -19.418704873874283
training  [-2.5751, 2.4369, 4.9756]  w:  [1.52313833 1.23408127 2.11161705]
9.591660916863814  -  87.1991  =  -77.60743908313619
training  [-4.4625, -3.9408, 3.116]  w:  [1.52313833 1.23408127 2.11161705]
-5.080473534128684  -  4.1344  =  -9.214873534128685
training  [-0.5828, 1.8156, -0.1435]  w:  [1.52313833 1.23408127 2.11161705]
1.0498958819167983  -  51.1166  =  -50.0667041180832
training  [-4.8672, -0.3674, 3.9445]  w:  [1.52313833 1.23408127 2.11161705]
0.4624531087755228  -  24.1396  =  -23.677146891224478
training  [3.9719, -2.8784, -3.6245]  w:  [1.52313833 1.23408127 2.11161705]
-5.155982377693148  -  14.6104  =  -19.766382377693148
training  [-3.0334, -4.0148, -1.1]  w:  [1.52313833 1.23408127 2.11161705]
-11.897656041979104  -  1.021  =  -12.918656041979105
training  [-4.0663, 3.2357, 4.2736]  w:  [1.52313833 1.23408127 2.11161705]
6.823785983234842  -  77.2328  =  -70.40901401676516
training  [-1.9263, -3.2499, 4.1749]  w:  [1.52313833 1.23408127 2.11161705]
1.8711279450107074  -  26.8814  =  -25.010272054989294
training  [-0.4394, -3.3643, 2.1357]  w:  [1.52313833 1.23408127 2.11161705]
-0.3113060553364102  -  20.85  =  -21.16130605533641
training  [-3.9833, 1.6599, 1.1834]  w:  [1.52313833 1.23408127 2.11161705]
-1.5197778046769748  -  25.5397  =  -27.059477804676973
training  [4.9539, 3.9439, -1.5671]  w:  [1.52313833 1.23408127 2.11161705]
9.10345301153846  -  95.9509  =  -86.84744698846154
training  [-1.6791, 0.1656, 4.3603]  w:  [1.52313833 1.23408127 2.11161705]
6.854146109313827  -  71.5733  =  -64.71915389068617
training  [-2.0265, 2.027, -3.7523]  w:  [1.52313833 1.23408127 2.11161705]
-8.508577759042478  -  8.503  =  -17.011577759042478
training  [-4.3795, -3.4641, 2.3059]  w:  [1.52313833 1.23408127 2.11161705]
-6.076387485047967  -  3.6654  =  -9.741787485047967
training  [-2.0176, 4.5346, 1.4648]  w:  [1.52313833 1.23408127 2.11161705]
5.616077670486249  -  81.6212  =  -76.00512232951375
training  [-4.5365, 0.4088, 3.3315]  w:  [1.52313833 1.23408127 2.11161705]
0.6296275827413336  -  28.9449  =  -28.31527241725867
training  [0.0543, 1.7973, -1.0172]  w:  [1.52313833 1.23408127 2.11161705]
0.15278380908122458  -  47.9317  =  -47.77891619091878
training  [2.6143, -4.6344, 2.4982]  w:  [1.52313833 1.23408127 2.11161705]
3.537956032037257  -  43.5132  =  -39.97524396796274
training  [1.3107, 3.092, 3.3522]  w:  [1.52313833 1.23408127 2.11161705]
12.890719365231725  -  96.6993  =  -83.80858063476828
training  [-4.1011, 2.4862, -1.7754]  w:  [1.52313833 1.23408127 2.11161705]
-6.927334677670505  -  10.0187  =  -16.946034677670504
training  [-4.1914, -3.7981, 0.5226]  w:  [1.52313833 1.23408127 2.11161705]
-9.967714993835886  -  1.4295  =  -11.397214993835885
training  [2.7724, 0.2505, 4.7913]  w:  [1.52313833 1.23408127 2.11161705]
14.64927684168756  -  96.7925  =  -82.14322315831245
training  [4.0513, -1.7417, 0.4931]  w:  [1.52313833 1.23408127 2.11161705]
5.0625293484403295  -  71.1234  =  -66.06087065155967
training  [0.3377, 0.4645, -1.6958]  w:  [1.52313833 1.23408127 2.11161705]
-2.4932856307196003  -  27.9534  =  -30.4466856307196
training  [-3.9085, -1.0112, 1.1947]  w:  [1.52313833 1.23408127 2.11161705]
-4.678340257157862  -  8.608  =  -13.286340257157862
training  [3.2581, -0.8491, -1.3936]  w:  [1.52313833 1.23408127 2.11161705]
0.9719290737722579  -  50.1924  =  -49.22047092622774
training  [-1.619, -3.1926, 2.5651]  w:  [1.52313833 1.23408127 2.11161705]
-0.9893799166053725  -  16.4754  =  -17.464779916605373
training  [-2.0603, -2.4461, -0.861]  w:  [1.52313833 1.23408127 2.11161705]
-7.974910372662755  -  3.9784  =  -11.953310372662756
training  [2.4631, -4.7946, -0.0765]  w:  [1.52313833 1.23408127 2.11161705]
-2.326822722143009  -  15.394  =  -17.72082272214301
training  [-4.8966, 4.2368, 1.9474]  w:  [1.52313833 1.23408127 2.11161705]
1.8825194003183965  -  53.5883  =  -51.7057805996816
training  [-4.5155, 1.537, 4.7273]  w:  [1.52313833 1.23408127 2.11161705]
5.001299051996309  -  59.2523  =  -54.25100094800369
training  [1.6792, 4.3261, -1.7225]  w:  [1.52313833 1.23408127 2.11161705]
4.259152486952411  -  83.7729  =  -79.51374751304759
training  [1.0347, -3.3649, 3.378]  w:  [1.52313833 1.23408127 2.11161705]
4.5564735724452845  -  50.5979  =  -46.04142642755472
training  [0.261, 4.211, 2.3907]  w:  [1.52313833 1.23408127 2.11161705]
10.642498202252188  -  94.9375  =  -84.29500179774782
training  [2.2971, 2.9466, 4.5417]  w:  [1.52313833 1.23408127 2.11161705]
16.72547608085972  -  98.7784  =  -82.05292391914028
training  [2.0725, 0.7739, -4.6808]  w:  [1.52313833 1.23408127 2.11161705]
-5.772297403820926  -  19.5109  =  -25.283197403820925
training  [2.8138, -0.5996, -1.4313]  w:  [1.52313833 1.23408127 2.11161705]
0.5234940262702574  -  47.2879  =  -46.764405973729744
training  [-2.1202, -2.4239, 1.6265]  w:  [1.52313833 1.23408127 2.11161705]
-2.78610234196815  -  12.3599  =  -15.146002341968149
training  [1.9253, 2.5195, -2.185]  w:  [1.52313833 1.23408127 2.11161705]
1.4278827276263204  -  65.2467  =  -63.818817272373686
training  [0.5667, -2.7133, -2.6962]  w:  [1.52313833 1.23408127 2.11161705]
-8.178612100235583  -  5.1106  =  -13.289212100235583
training  [-1.0348, -4.3581, 2.1113]  w:  [1.52313833 1.23408127 2.11161705]
-2.4961360373093058  -  10.5192  =  -13.015336037309305
training  [-4.3841, 2.6733, 1.2457]  w:  [1.52313833 1.23408127 2.11161705]
-0.7480799498277619  -  32.4639  =  -33.211979949827764
training  [2.8018, 1.712, 0.9061]  w:  [1.52313833 1.23408127 2.11161705]
8.293612316551638  -  90.1138  =  -81.82018768344835
training  [-1.6242, 2.1521, 1.6044]  w:  [1.52313833 1.23408127 2.11161705]
3.56986341174497  -  63.7879  =  -60.21803658825503
training  [1.0787, 1.4206, -4.5245]  w:  [1.52313833 1.23408127 2.11161705]
-6.157866177635745  -  18.0555  =  -24.21336617763574
training  [2.4125, -0.8095, -1.5122]  w:  [1.52313833 1.23408127 2.11161705]
-0.5176048636112194  -  38.8276  =  -39.345204863611215
training  [-3.9519, -1.0924, -0.4866]  w:  [1.52313833 1.23408127 2.11161705]
-8.39491360632606  -  3.6777  =  -12.07261360632606
training  [-3.7211, 3.1614, -2.591]  w:  [1.52313833 1.23408127 2.11161705]
-7.237525306308511  -  11.1518  =  -18.38932530630851
training  [0.4954, -1.8257, 2.1505]  w:  [1.52313833 1.23408127 2.11161705]
3.0425330270541586  -  47.7531  =  -44.71056697294584
training  [-0.1477, 3.1454, 3.5618]  w:  [1.52313833 1.23408127 2.11161705]
11.177869295502148  -  94.1572  =  -82.97933070449785
training  [3.9048, 2.8907, -2.1849]  w:  [1.52313833 1.23408127 2.11161705]
4.901237183501613  -  85.8791  =  -80.97786281649839
training  [2.9896, 3.5226, 2.3105]  w:  [1.52313833 1.23408127 2.11161705]
13.779640222810523  -  98.038  =  -84.25835977718947
training  [2.3434, 0.0564, -3.6224]  w:  [1.52313833 1.23408127 2.11161705]
-4.01019705277845  -  24.7629  =  -28.773097052778446
training  [-4.4867, 1.3566, 3.3672]  w:  [1.52313833 1.23408127 2.11161705]
1.950526825255432  -  40.5785  =  -38.62797317474457
training  [-4.2711, 4.5089, -3.614]  w:  [1.52313833 1.23408127 2.11161705]
-8.572511123952129  -  10.0825  =  -18.65501112395213
training  [-4.1147, -0.5604, 0.8821]  w:  [1.52313833 1.23408127 2.11161705]
-5.09617903592855  -  8.344  =  -13.44017903592855
training  [2.9835, -4.3998, -1.3384]  w:  [1.52313833 1.23408127 2.11161705]
-3.7116158058213706  -  13.2692  =  -16.980815805821372
training  [4.4301, 3.6675, 3.0676]  w:  [1.52313833 1.23408127 2.11161705]
17.75124463418632  -  99.3834  =  -81.63215536581367
training  [1.8372, 1.3119, 0.0378]  w:  [1.52313833 1.23408127 2.11161705]
4.497120081950468  -  74.9026  =  -70.40547991804954
training  [-3.6792, -1.4493, -0.1041]  w:  [1.52313833 1.23408127 2.11161705]
-7.612303865698091  -  4.2442  =  -11.856503865698091
training  [2.2272, 4.97, 3.7705]  w:  [1.52313833 1.23408127 2.11161705]
17.487569677980193  -  99.3199  =  -81.83233032201981
training  [-3.8965, -2.7583, -1.4686]  w:  [1.52313833 1.23408127 2.11161705]
-12.439995668895119  -  1.0337  =  -13.473695668895118
training  [-3.8251, 1.5245, -0.5056]  w:  [1.52313833 1.23408127 2.11161705]
-5.012433122109749  -  12.9762  =  -17.98863312210975
training  [1.4072, 1.0499, 4.6353]  w:  [1.52313833 1.23408127 2.11161705]
13.22700069609731  -  95.4618  =  -82.23479930390269
training  [-1.7119, -1.1275, -4.577]  w:  [1.52313833 1.23408127 2.11161705]
-13.663758378093139  -  1.4655  =  -15.12925837809314
training  [1.5381, -3.5781, 4.7296]  w:  [1.52313833 1.23408127 2.11161705]
7.914176887751983  -  69.9473  =  -62.03312311224801
training  [2.4913, -4.7487, -3.1079]  w:  [1.52313833 1.23408127 2.11161705]
-8.62838181733446  -  3.9825  =  -12.61088181733446
training  [0.8319, -0.7889, 1.6712]  w:  [1.52313833 1.23408127 2.11161705]
3.8224664811594335  -  58.8336  =  -55.011133518840566
training  [2.4003, -3.159, 0.8644]  w:  [1.52313833 1.23408127 2.11161705]
1.582807993611781  -  39.0041  =  -37.42129200638822
training  [-2.6517, 2.2578, 1.7511]  w:  [1.52313833 1.23408127 2.11161705]
2.4450553870002216  -  54.4525  =  -52.00744461299978
training  [2.3496, -1.2964, -1.3898]  w:  [1.52313833 1.23408127 2.11161705]
-0.9558225066432524  -  33.888  =  -34.84382250664325
training  [4.706, 3.4156, 1.2028]  w:  [1.52313833 1.23408127 2.11161705]
13.922869953355844  -  98.4665  =  -84.54363004664415
training  [3.6693, 2.3423, 3.1115]  w:  [1.52313833 1.23408127 2.11161705]
15.049736484771133  -  98.3069  =  -83.25716351522887
training  [-4.1377, 0.7103, -4.8074]  w:  [1.52313833 1.23408127 2.11161705]
-15.577109359273802  -  0.9782  =  -16.555309359273803
training  [-1.3356, -3.2314, -4.1613]  w:  [1.52313833 1.23408127 2.11161705]
-14.809185793723213  -  0.7659  =  -15.575085793723213
training  [-1.308, 4.5738, 4.748]  w:  [1.52313833 1.23408127 2.11161705]
13.678133715990466  -  97.0884  =  -83.41026628400952
training  [1.8503, -2.3468, 1.5135]  w:  [1.52313833 1.23408127 2.11161705]
3.118053343546916  -  50.2125  =  -47.09444665645308
training  [0.9794, 4.2458, -2.6876]  w:  [1.52313833 1.23408127 2.11161705]
1.056241941345581  -  68.3262  =  -67.26995805865442
training  [2.8936, -2.7623, -0.9651]  w:  [1.52313833 1.23408127 2.11161705]
-1.039471222206883  -  28.5596  =  -29.59907122220688
training  [-1.3235, -1.2644, -3.7798]  w:  [1.52313833 1.23408127 2.11161705]
-11.557736062962897  -  2.4511  =  -14.008836062962898
training  [-2.9397, -4.125, -2.3156]  w:  [1.52313833 1.23408127 2.11161705]
-14.45781542226926  -  0.554  =  -15.01181542226926
training  [-4.1333, 1.4012, -2.4215]  w:  [1.52313833 1.23408127 2.11161705]
-9.67967368288972  -  4.4072  =  -14.086873682889719
training  [2.7193, -3.1938, -1.6833]  w:  [1.52313833 1.23408127 2.11161705]
-3.3540236657001175  -  17.0949  =  -20.448923665700118
training  [-2.9433, -4.5495, -3.4777]  w:  [1.52313833 1.23408127 2.11161705]
-17.441076392282735  -  0.2509  =  -17.691976392282736
training  [-1.1173, 2.2317, -1.5199]  w:  [1.52313833 1.23408127 2.11161705]
-2.1571500492764706  -  33.1206  =  -35.27775004927648
training  [0.5178, -1.5256, -3.7834]  w:  [1.52313833 1.23408127 2.11161705]
-9.08312530090319  -  5.237  =  -14.32012530090319
training  [-2.7105, 1.6062, 3.8415]  w:  [1.52313833 1.23408127 2.11161705]
5.965491781455919  -  70.4458  =  -64.48030821854408
training  [1.4194, -1.1613, -4.0572]  w:  [1.52313833 1.23408127 2.11161705]
-7.8384487237242935  -  8.3206  =  -16.159048723724293
training  [-0.1552, 1.2735, 4.3004]  w:  [1.52313833 1.23408127 2.11161705]
10.416009387613737  -  90.1085  =  -79.69249061238627
training  [-3.4815, -4.7835, -1.0098]  w:  [1.52313833 1.23408127 2.11161705]
-13.338344740499815  -  0.5839  =  -13.922244740499815
training  [2.8193, 4.1057, -4.526]  w:  [1.52313833 1.23408127 2.11161705]
-0.1962274127280068  -  66.8081  =  -67.004327412728
training  [-3.9939, 3.0056, -1.5763]  w:  [1.52313833 1.23408127 2.11161705]
-5.702649483685832  -  14.4018  =  -20.104449483685833
training  [-2.0593, 2.4585, 2.3597]  w:  [1.52313833 1.23408127 2.11161705]
4.8801727818846725  -  70.6698  =  -65.78962721811533
training  [-2.6263, 3.1311, 2.9468]  w:  [1.52313833 1.23408127 2.11161705]
6.086326778181938  -  77.309  =  -71.22267322181806
training  [0.3087, -1.1669, 0.4491]  w:  [1.52313833 1.23408127 2.11161705]
-0.02152941017190846  -  33.0798  =  -33.10132941017191
training  [-4.085, 1.1728, 1.8622]  w:  [1.52313833 1.23408127 2.11161705]
-0.842436304445485  -  26.4056  =  -27.248036304445485
training  [-0.9468, 0.7549, 3.9363]  w:  [1.52313833 1.23408127 2.11161705]
7.801458771040626  -  79.7738  =  -71.97234122895937
training  [-3.9515, 0.3005, -4.4521]  w:  [1.52313833 1.23408127 2.11161705]
-15.04896996714311  -  1.0441  =  -16.09306996714311
training  [-3.8772, -2.2493, -1.9634]  w:  [1.52313833 1.23408127 2.11161705]
-12.827279850664198  -  1.0509  =  -13.878179850664198
training  [2.8443, -2.5137, -4.5381]  w:  [1.52313833 1.23408127 2.11161705]
-8.352577059734518  -  6.8897  =  -15.24227705973452
training  [-2.0843, -0.4836, -3.0452]  w:  [1.52313833 1.23408127 2.11161705]
-10.201775167359926  -  3.5346  =  -13.736375167359927
training  [1.0353, -2.7229, 2.2017]  w:  [1.52313833 1.23408127 2.11161705]
2.8657724926010095  -  43.9562  =  -41.09042750739899
training  [4.6442, 3.0445, 2.2175]  w:  [1.52313833 1.23408127 2.11161705]
15.513430267201581  -  98.8492  =  -83.33576973279841
training  [-0.6752, 4.861, 3.778]  w:  [1.52313833 1.23408127 2.11161705]
12.948135253461677  -  97.017  =  -84.06886474653832
training  [1.9475, -4.7001, 0.8243]  w:  [1.52313833 1.23408127 2.11161705]
-1.0933875273794558  -  18.7839  =  -19.877287527379455
training  [2.581, 0.3566, -4.2932]  w:  [1.52313833 1.23408127 2.11161705]
-4.694300906120762  -  23.5455  =  -28.239800906120763
training  [-0.6736, -4.1292, 4.2274]  w:  [1.52313833 1.23408127 2.11161705]
2.804895570327804  -  31.2667  =  -28.461804429672195
training  [1.555, 3.0209, 3.0037]  w:  [1.52313833 1.23408127 2.11161705]
12.439180339578044  -  96.4078  =  -83.96861966042195
training  [-3.9024, 4.8914, -2.1405]  w:  [1.52313833 1.23408127 2.11161705]
-4.427426212738527  -  25.4308  =  -29.85822621273853
training  [4.3376, -4.3305, 0.4366]  w:  [1.52313833 1.23408127 2.11161705]
2.1845079054062913  -  43.0907  =  -40.906192094593706
training  [-3.1254, 4.394, 4.8478]  w:  [1.52313833 1.23408127 2.11161705]
10.898833681539841  -  92.8121  =  -81.91326631846016
training  [-2.3382, -4.8182, 2.1568]  w:  [1.52313833 1.23408127 2.11161705]
-4.953116754182708  -  4.7434  =  -9.696516754182708
training  [2.9783, 1.8384, 3.3897]  w:  [1.52313833 1.23408127 2.11161705]
13.962846210418267  -  97.3486  =  -83.38575378958174
training  [-0.124, 2.8374, -0.6674]  w:  [1.52313833 1.23408127 2.11161705]
1.9034198145550374  -  62.785  =  -60.88158018544496
training  [2.6896, 0.3414, -0.2938]  w:  [1.52313833 1.23408127 2.11161705]
3.897555112461052  -  70.4455  =  -66.54794488753895
training  [-1.0399, 3.8536, 0.6071]  w:  [1.52313833 1.23408127 2.11161705]
4.453706730612975  -  77.0369  =  -72.58319326938702
training  [-2.2706, 3.99, -2.3091]  w:  [1.52313833 1.23408127 2.11161705]
-3.4103885716511777  -  31.1134  =  -34.523788571651174
training  [-4.6277, 1.2594, 2.4902]  w:  [1.52313833 1.23408127 2.11161705]
-0.2360765318081537  -  28.1093  =  -28.345376531808157
training  [1.7329, -3.6213, 0.0389]  w:  [1.52313833 1.23408127 2.11161705]
-1.74739017382715  -  19.3919  =  -21.13929017382715
training  [-0.7044, -2.822, 1.4681]  w:  [1.52313833 1.23408127 2.11161705]
-1.455410984944543  -  17.8122  =  -19.267610984944543
training  [-0.4826, -3.1786, -1.9225]  w:  [1.52313833 1.23408127 2.11161705]
-8.71730105354601  -  3.5851  =  -12.30240105354601
training  [1.0986, -4.5818, -3.6128]  w:  [1.52313833 1.23408127 2.11161705]
-11.609843857300508  -  1.7158  =  -13.325643857300507
training  [-4.406, -3.9306, -0.2443]  w:  [1.52313833 1.23408127 2.11161705]
-12.077495363609057  -  0.8241  =  -12.901595363609056
training  [-1.8419, 1.1644, -1.3754]  w:  [1.52313833 1.23408127 2.11161705]
-4.272822357050913  -  17.8517  =  -22.124522357050914
training  [2.7272, 4.3966, 2.8811]  w:  [1.52313833 1.23408127 2.11161705]
15.663444440831935  -  98.904  =  -83.24055555916806
training  [1.9643, -1.4554, 2.803]  w:  [1.52313833 1.23408127 2.11161705]
7.114681341180578  -  76.0591  =  -68.94441865881942
training  [-3.7467, -0.8937, 1.6851]  w:  [1.52313833 1.23408127 2.11161705]
-3.251354924720888  -  12.1571  =  -15.408454924720887
training  [-3.6985, 4.8435, -3.665]  w:  [1.52313833 1.23408127 2.11161705]
-7.395130992765794  -  14.6793  =  -22.074430992765794
237793.14540618725
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.53055329 1.21223448 2.05743829]
11.081667015271755  -  87.3174  =  -76.23573298472826
training  [-4.1793, -4.9218, 1.7664]  w:  [1.53055329 1.21223448 2.05743829]
-8.728758066576802  -  1.5257  =  -10.254458066576802
training  [-3.9429, -0.7689, 4.883]  w:  [1.53055329 1.21223448 2.05743829]
3.07956548904104  -  39.7859  =  -36.70633451095896
training  [-3.5796, 1.5557, 2.6683]  w:  [1.53055329 1.21223448 2.05743829]
1.8969672045160655  -  45.5674  =  -43.67043279548393
training  [-3.3354, 2.2292, -1.633]  w:  [1.53055329 1.21223448 2.05743829]
-5.762491065745751  -  13.3589  =  -19.12139106574575
training  [1.2096, 0.3121, 1.6238]  w:  [1.53055329 1.21223448 2.05743829]
5.570563937726565  -  74.5119  =  -68.94133606227344
training  [0.7371, -3.9118, -2.5583]  w:  [1.53055329 1.21223448 2.05743829]
-8.877392394779449  -  3.3358  =  -12.213192394779448
training  [-4.4792, 1.3177, -2.0449]  w:  [1.53055329 1.21223448 2.05743829]
-9.465548484921468  -  4.2974  =  -13.762948484921468
training  [4.312, -3.735, 1.8018]  w:  [1.53055329 1.21223448 2.05743829]
5.779142308641903  -  66.5833  =  -60.80415769135809
training  [2.2866, -3.657, 0.2785]  w:  [1.53055329 1.21223448 2.05743829]
-0.3603817851465969  -  26.0005  =  -26.360881785146596
training  [2.3784, -4.0141, -0.8841]  w:  [1.53055329 1.21223448 2.05743829]
-3.044743680981221  -  14.6809  =  -17.72564368098122
training  [-4.366, -3.5797, 1.0264]  w:  [1.53055329 1.21223448 2.05743829]
-8.910076798820239  -  1.8713  =  -10.781376798820238
training  [3.6044, -3.3175, 2.5052]  w:  [1.53055329 1.21223448 2.05743829]
6.6494327876919295  -  71.0139  =  -64.36446721230807
training  [4.3441, -3.0375, 0.8353]  w:  [1.53055329 1.21223448 2.05743829]
4.6852925162503105  -  63.8979  =  -59.21260748374969
training  [4.844, -1.8252, 0.5179]  w:  [1.53055329 1.21223448 2.05743829]
6.266977059384477  -  78.0461  =  -71.77912294061552
training  [3.5894, -1.8357, 0.8357]  w:  [1.53055329 1.21223448 2.05743829]
4.987870324279249  -  68.8838  =  -63.895929675720744
training  [2.8556, -2.8244, 0.1182]  w:  [1.53055329 1.21223448 2.05743829]
1.1900021120702187  -  39.5252  =  -38.33519788792978
training  [0.1338, -2.4896, -4.1741]  w:  [1.53055329 1.21223448 2.05743829]
-11.401144099451118  -  2.2644  =  -13.665544099451118
training  [-3.224, 3.9292, 2.1957]  w:  [1.53055329 1.21223448 2.05743829]
4.346125167850675  -  72.1211  =  -67.77497483214933
training  [-1.0141, 2.0322, 4.9616]  w:  [1.53055329 1.21223448 2.05743829]
11.119554634951577  -  92.3427  =  -81.22314536504842
training  [-3.6607, 0.5574, -1.4547]  w:  [1.53055329 1.21223448 2.05743829]
-7.9201524152081095  -  5.8471  =  -13.767252415208109
training  [-4.6911, -3.1557, 4.7126]  w:  [1.53055329 1.21223448 2.05743829]
-1.3095432349871263  -  11.2337  =  -12.543243234987127
training  [4.3914, -2.8797, -1.5355]  w:  [1.53055329 1.21223448 2.05743829]
0.07120359477869664  -  37.475  =  -37.40379640522131
training  [-1.9869, -4.2265, 3.8654]  w:  [1.53055329 1.21223448 2.05743829]
-0.21174342398447354  -  15.7889  =  -16.000643423984474
training  [-2.0447, 4.138, -0.4531]  w:  [1.53055329 1.21223448 2.05743829]
0.9544786882675653  -  57.936  =  -56.981521311732436
training  [-1.6706, 2.0672, -0.8657]  w:  [1.53055329 1.21223448 2.05743829]
-1.8321355318657666  -  32.4185  =  -34.25063553186577
training  [-0.3293, 0.5779, -2.8227]  w:  [1.53055329 1.21223448 2.05743829]
-5.610991947287562  -  14.3434  =  -19.95439194728756
training  [1.482, -1.8657, -3.7435]  w:  [1.53055329 1.21223448 2.05743829]
-7.695406128818052  -  7.1519  =  -14.847306128818053
training  [-4.7477, -3.338, -1.9109]  w:  [1.53055329 1.21223448 2.05743829]
-15.24460539995667  -  0.4077  =  -15.65230539995667
training  [3.4221, 1.225, 2.261]  w:  [1.53055329 1.21223448 2.05743829]
11.374561635436212  -  95.0454  =  -83.67083836456379
training  [0.5903, 4.8793, 2.8287]  w:  [1.53055329 1.21223448 2.05743829]
12.63821701180618  -  97.4647  =  -84.82648298819382
training  [3.541, -3.2957, 1.9379]  w:  [1.53055329 1.21223448 2.05743829]
5.411637679761286  -  64.3732  =  -58.96156232023871
training  [-1.5212, -2.4221, -4.902]  w:  [1.53055329 1.21223448 2.05743829]
-15.349993301231741  -  0.7227  =  -16.07269330123174
training  [-0.5397, -1.032, 3.4321]  w:  [1.53055329 1.21223448 2.05743829]
4.984268349655904  -  60.5921  =  -55.607831650344096
training  [-4.4576, -4.2601, 4.2233]  w:  [1.53055329 1.21223448 2.05743829]
-3.297655359568255  -  6.0247  =  -9.322355359568256
training  [-3.2289, 1.841, 2.7095]  w:  [1.53055329 1.21223448 2.05743829]
2.864349199992776  -  54.0111  =  -51.146750800007226
training  [1.6281, -0.9761, -4.5734]  w:  [1.53055329 1.21223448 2.05743829]
-8.100856531314822  -  7.8658  =  -15.966656531314822
training  [-1.6917, 4.8284, -1.2181]  w:  [1.53055329 1.21223448 2.05743829]
0.7577503977512308  -  61.2837  =  -60.52594960224877
training  [3.9849, -0.9782, 2.0434]  w:  [1.53055329 1.21223448 2.05743829]
9.117463442179503  -  88.3402  =  -79.2227365578205
training  [-3.8184, 1.2067, 2.2951]  w:  [1.53055329 1.21223448 2.05743829]
0.3405652741730121  -  34.1122  =  -33.77163472582699
training  [4.8842, -3.4563, -2.7572]  w:  [1.53055329 1.21223448 2.05743829]
-2.3870865027263024  -  23.7819  =  -26.168986502726302
training  [0.3998, -1.1865, -2.3095]  w:  [1.53055329 1.21223448 2.05743829]
-5.5780547353940895  -  11.4246  =  -17.00265473539409
training  [2.0692, -3.3887, 1.7303]  w:  [1.53055329 1.21223448 2.05743829]
2.61910734791674  -  42.6881  =  -40.06899265208326
training  [4.9949, 2.5811, -0.2251]  w:  [1.53055329 1.21223448 2.05743829]
10.310729709378132  -  95.9901  =  -85.67937029062186
training  [-2.1215, 3.7111, 1.2372]  w:  [1.53055329 1.21223448 2.05743829]
3.7971172328431906  -  71.3692  =  -67.57208276715681
training  [-0.8548, -1.4922, -2.6356]  w:  [1.53055329 1.21223448 2.05743829]
-8.539797603939796  -  4.7821  =  -13.321897603939796
training  [-0.3516, 1.8554, -3.2288]  w:  [1.53055329 1.21223448 2.05743829]
-4.9320194214232655  -  20.3834  =  -25.315419421423268
training  [2.6396, -2.0585, 3.2964]  w:  [1.53055329 1.21223448 2.05743829]
8.326803359745224  -  80.826  =  -72.49919664025477
training  [3.182, 0.3063, 2.6692]  w:  [1.53055329 1.21223448 2.05743829]
10.733242278784896  -  92.9483  =  -82.2150577212151
training  [-3.9978, 3.3242, 4.3448]  w:  [1.53055329 1.21223448 2.05743829]
6.850021792479343  -  79.1768  =  -72.32677820752066
training  [-3.2188, 0.9749, -3.9211]  w:  [1.53055329 1.21223448 2.05743829]
-11.812158812272322  -  2.7053  =  -14.517458812272322
training  [-1.4037, -1.6469, -3.1777]  w:  [1.53055329 1.21223448 2.05743829]
-10.682788277019021  -  2.6234  =  -13.306188277019022
training  [-4.433, -2.0077, -4.009]  w:  [1.53055329 1.21223448 2.05743829]
-17.467016017412895  -  0.3253  =  -17.792316017412894
training  [0.2189, -0.4741, -0.1024]  w:  [1.53055329 1.21223448 2.05743829]
-0.4503639337472676  -  33.6531  =  -34.10346393374727
training  [-1.6415, -0.7735, -3.0675]  w:  [1.53055329 1.21223448 2.05743829]
-9.76125855244501  -  3.7641  =  -13.52535855244501
training  [-3.2433, -1.4039, 3.9589]  w:  [1.53055329 1.21223448 2.05743829]
1.4792929531912176  -  30.0658  =  -28.586507046808784
training  [-2.9105, 0.5832, -4.0091]  w:  [1.53055329 1.21223448 2.05743829]
-11.996176048829795  -  2.4887  =  -14.484876048829795
training  [4.0515, 2.4255, -4.5583]  w:  [1.53055329 1.21223448 2.05743829]
-0.23710954327558298  -  61.2853  =  -61.522409543275586
training  [1.7539, -0.7567, 0.573]  w:  [1.53055329 1.21223448 2.05743829]
2.9460517252946374  -  57.0797  =  -54.133648274705365
training  [-0.3153, -0.7064, 2.725]  w:  [1.53055329 1.21223448 2.05743829]
4.267613442870035  -  58.7004  =  -54.432786557129965
training  [4.1213, -3.7513, -1.8806]  w:  [1.53055329 1.21223448 2.05743829]
-2.1088043789985034  -  22.1789  =  -24.2877043789985
training  [-3.9599, -4.7557, -3.2102]  w:  [1.53055329 1.21223448 2.05743829]
-18.430649911667  -  0.1558  =  -18.586449911667
training  [2.4555, -2.0981, -1.6104]  w:  [1.53055329 1.21223448 2.05743829]
-2.0984141797650313  -  24.4796  =  -26.578014179765034
training  [2.3627, -1.8248, -2.8985]  w:  [1.53055329 1.21223448 2.05743829]
-4.559332099974279  -  15.7052  =  -20.26453209997428
training  [0.6186, 1.5369, 0.1015]  w:  [1.53055329 1.21223448 2.05743829]
3.0187134313895356  -  65.2154  =  -62.19668656861047
training  [-3.1581, 4.5694, 4.0636]  w:  [1.53055329 1.21223448 2.05743829]
9.066150125028898  -  90.3564  =  -81.2902498749711
training  [0.9721, 4.3573, 1.2892]  w:  [1.53055329 1.21223448 2.05743829]
9.422369613625962  -  94.3178  =  -84.89543038637404
training  [-2.0006, -0.4211, -3.9847]  w:  [1.53055329 1.21223448 2.05743829]
-11.770771205717327  -  2.4051  =  -14.175871205717328
training  [-3.6588, -2.5952, -1.0915]  w:  [1.53055329 1.21223448 2.05743829]
-10.991673211519988  -  1.5176  =  -12.509273211519988
training  [-2.874, 2.639, -4.4538]  w:  [1.53055329 1.21223448 2.05743829]
-10.363142008482136  -  5.497  =  -15.860142008482136
training  [3.9494, 2.5933, 0.0128]  w:  [1.53055329 1.21223448 2.05743829]
9.214790071330846  -  94.1462  =  -84.93140992866915
training  [-4.2855, 2.4065, -0.6828]  w:  [1.53055329 1.21223448 2.05743829]
-5.046762713664339  -  14.4193  =  -19.46606271366434
training  [-2.5751, 2.4369, 4.9756]  w:  [1.53055329 1.21223448 2.05743829]
9.249756376696501  -  87.1991  =  -77.9493436233035
training  [-4.4625, -3.9408, 3.116]  w:  [1.53055329 1.21223448 2.05743829]
-5.196290016575743  -  4.1344  =  -9.330690016575744
training  [-0.5828, 1.8156, -0.1435]  w:  [1.53055329 1.21223448 2.05743829]
1.0136840755679808  -  51.1166  =  -50.10291592443202
training  [-4.8672, -0.3674, 3.9445]  w:  [1.53055329 1.21223448 2.05743829]
0.22068139234986717  -  24.1396  =  -23.918918607650134
training  [3.9719, -2.8784, -3.6245]  w:  [1.53055329 1.21223448 2.05743829]
-4.867276190826708  -  14.6104  =  -19.477676190826706
training  [-3.0334, -4.0148, -1.1]  w:  [1.53055329 1.21223448 2.05743829]
-11.77284148101818  -  1.021  =  -12.79384148101818
training  [-4.0663, 3.2357, 4.2736]  w:  [1.53055329 1.21223448 2.05743829]
6.491406533983145  -  77.2328  =  -70.74139346601686
training  [-1.9263, -3.2499, 4.1749]  w:  [1.53055329 1.21223448 2.05743829]
1.701653452715986  -  26.8814  =  -25.17974654728401
training  [-0.4394, -3.3643, 2.1357]  w:  [1.53055329 1.21223448 2.05743829]
-0.3567746387043007  -  20.85  =  -21.206774638704303
training  [-3.9833, 1.6599, 1.1834]  w:  [1.53055329 1.21223448 2.05743829]
-1.6496924407450861  -  25.5397  =  -27.189392440745085
training  [4.9539, 3.9439, -1.5671]  w:  [1.53055329 1.21223448 2.05743829]
9.138927996174498  -  95.9509  =  -86.8119720038255
training  [-1.6791, 0.1656, 4.3603]  w:  [1.53055329 1.21223448 2.05743829]
6.60184216498252  -  71.5733  =  -64.97145783501749
training  [-2.0265, 2.027, -3.7523]  w:  [1.53055329 1.21223448 2.05743829]
-8.364592637840207  -  8.503  =  -16.867592637840207
training  [-4.3795, -3.4641, 2.3059]  w:  [1.53055329 1.21223448 2.05743829]
-6.158112672126252  -  3.6654  =  -9.823512672126252
training  [-2.0176, 4.5346, 1.4648]  w:  [1.53055329 1.21223448 2.05743829]
5.422689771829546  -  81.6212  =  -76.19851022817045
training  [-4.5365, 0.4088, 3.3315]  w:  [1.53055329 1.21223448 2.05743829]
0.4065621019357879  -  28.9449  =  -28.538337898064214
training  [0.0543, 1.7973, -1.0172]  w:  [1.53055329 1.21223448 2.05743829]
0.1690318548562062  -  47.9317  =  -47.76266814514379
training  [2.6143, -4.6344, 2.4982]  w:  [1.53055329 1.21223448 2.05743829]
3.5232383127534117  -  43.5132  =  -39.989961687246584
training  [1.3107, 3.092, 3.3522]  w:  [1.53055329 1.21223448 2.05743829]
12.65126985474134  -  96.6993  =  -84.04803014525865
training  [-4.1011, 2.4862, -1.7754]  w:  [1.53055329 1.21223448 2.05743829]
-6.915870671861407  -  10.0187  =  -16.934570671861408
training  [-4.1914, -3.7981, 0.5226]  w:  [1.53055329 1.21223448 2.05743829]
-9.944131614809637  -  1.4295  =  -11.373631614809636
training  [2.7724, 0.2505, 4.7913]  w:  [1.53055329 1.21223448 2.05743829]
14.40477475737762  -  96.7925  =  -82.38772524262238
training  [4.0513, -1.7417, 0.4931]  w:  [1.53055329 1.21223448 2.05743829]
5.103904574111397  -  71.1234  =  -66.0194954258886
training  [0.3377, 0.4645, -1.6958]  w:  [1.53055329 1.21223448 2.05743829]
-2.409053084500357  -  27.9534  =  -30.362453084500356
training  [-3.9085, -1.0112, 1.1947]  w:  [1.53055329 1.21223448 2.05743829]
-4.749957531667246  -  8.608  =  -13.357957531667246
training  [3.2581, -0.8491, -1.3936]  w:  [1.53055329 1.21223448 2.05743829]
1.0901413842099794  -  50.1924  =  -49.10225861579002
training  [-1.619, -3.1926, 2.5651]  w:  [1.53055329 1.21223448 2.05743829]
-1.0706106409267147  -  16.4754  =  -17.546010640926717
training  [-2.0603, -2.4461, -0.861]  w:  [1.53055329 1.21223448 2.05743829]
-7.890100086143493  -  3.9784  =  -11.868500086143493
training  [2.4631, -4.7946, -0.0765]  w:  [1.53055329 1.21223448 2.05743829]
-2.19966767016522  -  15.394  =  -17.59366767016522
training  [-4.8966, 4.2368, 1.9474]  w:  [1.53055329 1.21223448 2.05743829]
1.6481431307388004  -  53.5883  =  -51.940156869261195
training  [-4.5155, 1.537, 4.7273]  w:  [1.53055329 1.21223448 2.05743829]
4.678119028521064  -  59.2523  =  -54.57418097147893
training  [1.6792, 4.3261, -1.7225]  w:  [1.53055329 1.21223448 2.05743829]
4.270415238293332  -  83.7729  =  -79.50248476170668
training  [1.0347, -3.3649, 3.378]  w:  [1.53055329 1.21223448 2.05743829]
4.45464221487028  -  50.5979  =  -46.14325778512972
training  [0.261, 4.211, 2.3907]  w:  [1.53055329 1.21223448 2.05743829]
10.42291153669423  -  94.9375  =  -84.51458846330577
training  [2.2971, 2.9466, 4.5417]  w:  [1.53055329 1.21223448 2.05743829]
16.432071572579034  -  98.7784  =  -82.34632842742097
training  [2.0725, 0.7739, -4.6808]  w:  [1.53055329 1.21223448 2.05743829]
-5.52023717341571  -  19.5109  =  -25.031137173415708
training  [2.8138, -0.5996, -1.4313]  w:  [1.53055329 1.21223448 2.05743829]
0.6350036365202429  -  47.2879  =  -46.652896363479755
training  [-2.1202, -2.4239, 1.6265]  w:  [1.53055329 1.21223448 2.05743829]
-2.8369908808245783  -  12.3599  =  -15.196890880824578
training  [1.9253, 2.5195, -2.185]  w:  [1.53055329 1.21223448 2.05743829]
1.5054963767495035  -  65.2467  =  -63.7412036232505
training  [0.5667, -2.7133, -2.6962]  w:  [1.53055329 1.21223448 2.05743829]
-7.969056386883517  -  5.1106  =  -13.079656386883517
training  [-1.0348, -4.3581, 2.1113]  w:  [1.53055329 1.21223448 2.05743829]
-2.5229861934878093  -  10.5192  =  -13.042186193487808
training  [-4.3841, 2.6733, 1.2457]  w:  [1.53055329 1.21223448 2.05743829]
-0.9064813691468432  -  32.4639  =  -33.37038136914685
training  [2.8018, 1.712, 0.9061]  w:  [1.53055329 1.21223448 2.05743829]
8.227894484873495  -  90.1138  =  -81.8859055151265
training  [-1.6242, 2.1521, 1.6044]  w:  [1.53055329 1.21223448 2.05743829]
3.4238791643911752  -  63.7879  =  -60.36402083560883
training  [1.0787, 1.4206, -4.5245]  w:  [1.53055329 1.21223448 2.05743829]
-5.935771390533354  -  18.0555  =  -23.991271390533353
training  [2.4125, -0.8095, -1.5122]  w:  [1.53055329 1.21223448 2.05743829]
-0.4001021755266838  -  38.8276  =  -39.22770217552668
training  [-3.9519, -1.0924, -0.4866]  w:  [1.53055329 1.21223448 2.05743829]
-8.3739879786879  -  3.6777  =  -12.0516879786879
training  [-3.7211, 3.1614, -2.591]  w:  [1.53055329 1.21223448 2.05743829]
-7.193806365014764  -  11.1518  =  -18.345606365014763
training  [0.4954, -1.8257, 2.1505]  w:  [1.53055329 1.21223448 2.05743829]
2.9695806428705813  -  47.7531  =  -44.78351935712942
training  [-0.1477, 3.1454, 3.5618]  w:  [1.53055329 1.21223448 2.05743829]
10.915083319314002  -  94.1572  =  -83.242116680686
training  [3.9048, 2.8907, -2.1849]  w:  [1.53055329 1.21223448 2.05743829]
4.985413803903507  -  85.8791  =  -80.89368619609648
training  [2.9896, 3.5226, 2.3105]  w:  [1.53055329 1.21223448 2.05743829]
13.599670481756117  -  98.038  =  -84.43832951824388
training  [2.3434, 0.0564, -3.6224]  w:  [1.53055329 1.21223448 2.05743829]
-3.797795844321942  -  24.7629  =  -28.56069584432194
training  [-4.4867, 1.3566, 3.3672]  w:  [1.53055329 1.21223448 2.05743829]
1.705190046617929  -  40.5785  =  -38.87330995338207
training  [-4.2711, 4.5089, -3.614]  w:  [1.53055329 1.21223448 2.05743829]
-8.50688407785876  -  10.0825  =  -18.58938407785876
training  [-4.1147, -0.5604, 0.8821]  w:  [1.53055329 1.21223448 2.05743829]
-5.162237524198631  -  8.344  =  -13.506237524198632
training  [2.9835, -4.3998, -1.3384]  w:  [1.53055329 1.21223448 2.05743829]
-3.5208589383445545  -  13.2692  =  -16.790058938344554
training  [4.4301, 3.6675, 3.0676]  w:  [1.53055329 1.21223448 2.05743829]
17.537771804642745  -  99.3834  =  -81.84562819535725
training  [1.8372, 1.3119, 0.0378]  w:  [1.53055329 1.21223448 2.05743829]
4.480034096048321  -  74.9026  =  -70.42256590395169
training  [-3.6792, -1.4493, -0.1041]  w:  [1.53055329 1.21223448 2.05743829]
-7.602282437807533  -  4.2442  =  -11.846482437807534
training  [2.2272, 4.97, 3.7705]  w:  [1.53055329 1.21223448 2.05743829]
17.19122474419322  -  99.3199  =  -82.12867525580678
training  [-3.8965, -2.7583, -1.4686]  w:  [1.53055329 1.21223448 2.05743829]
-12.329061152013193  -  1.0337  =  -13.362761152013192
training  [-3.8251, 1.5245, -0.5056]  w:  [1.53055329 1.21223448 2.05743829]
-5.046708727801635  -  12.9762  =  -18.022908727801635
training  [1.4072, 1.0499, 4.6353]  w:  [1.53055329 1.21223448 2.05743829]
12.963363275617436  -  95.4618  =  -82.49843672438256
training  [-1.7119, -1.1275, -4.577]  w:  [1.53055329 1.21223448 2.05743829]
-13.403843607648804  -  1.4655  =  -14.869343607648805
training  [1.5381, -3.5781, 4.7296]  w:  [1.53055329 1.21223448 2.05743829]
7.747507940848946  -  69.9473  =  -62.19979205915105
training  [2.4913, -4.7487, -3.1079]  w:  [1.53055329 1.21223448 2.05743829]
-8.33778293148773  -  3.9825  =  -12.32028293148773
training  [0.8319, -0.7889, 1.6712]  w:  [1.53055329 1.21223448 2.05743829]
3.755326367189942  -  58.8336  =  -55.07827363281005
training  [2.4003, -3.159, 0.8644]  w:  [1.53055329 1.21223448 2.05743829]
1.6227879902858127  -  39.0041  =  -37.381312009714186
training  [-2.6517, 2.2578, 1.7511]  w:  [1.53055329 1.21223448 2.05743829]
2.281195037966779  -  54.4525  =  -52.17130496203322
training  [2.3496, -1.2964, -1.3898]  w:  [1.53055329 1.21223448 2.05743829]
-0.8347805013545391  -  33.888  =  -34.722780501354535
training  [4.706, 3.4156, 1.2028]  w:  [1.53055329 1.21223448 2.05743829]
13.817978671692945  -  98.4665  =  -84.64852132830706
training  [3.6693, 2.3423, 3.1115]  w:  [1.53055329 1.21223448 2.05743829]
14.857195262377235  -  98.3069  =  -83.44970473762277
training  [-4.1377, 0.7103, -4.8074]  w:  [1.53055329 1.21223448 2.05743829]
-15.36284903224443  -  0.9782  =  -16.34104903224443
training  [-1.3356, -3.2314, -4.1613]  w:  [1.53055329 1.21223448 2.05743829]
-14.523039437800861  -  0.7659  =  -15.288939437800861
training  [-1.308, 4.5738, 4.748]  w:  [1.53055329 1.21223448 2.05743829]
13.311271368068272  -  97.0884  =  -83.77712863193172
training  [1.8503, -2.3468, 1.5135]  w:  [1.53055329 1.21223448 2.05743829]
3.101043719999339  -  50.2125  =  -47.11145628000066
training  [0.9794, 4.2458, -2.6876]  w:  [1.53055329 1.21223448 2.05743829]
1.116357923017211  -  68.3262  =  -67.2098420769828
training  [2.8936, -2.7623, -0.9651]  w:  [1.53055329 1.21223448 2.05743829]
-0.9053799990144893  -  28.5596  =  -29.46497999901449
training  [-1.3235, -1.2644, -3.7798]  w:  [1.53055329 1.21223448 2.05743829]
-11.335141806214954  -  2.4511  =  -13.786241806214955
training  [-2.9397, -4.125, -2.3156]  w:  [1.53055329 1.21223448 2.05743829]
-14.264038860805362  -  0.554  =  -14.818038860805363
training  [-4.1333, 1.4012, -2.4215]  w:  [1.53055329 1.21223448 2.05743829]
-9.60973978092422  -  4.4072  =  -14.01693978092422
training  [2.7193, -3.1938, -1.6833]  w:  [1.53055329 1.21223448 2.05743829]
-3.1728867963421554  -  17.0949  =  -20.267786796342154
training  [-2.9433, -4.5495, -3.4777]  w:  [1.53055329 1.21223448 2.05743829]
-17.175091425833067  -  0.2509  =  -17.425991425833068
training  [-1.1173, 2.2317, -1.5199]  w:  [1.53055329 1.21223448 2.05743829]
-2.1318439505844484  -  33.1206  =  -35.25244395058445
training  [0.5178, -1.5256, -3.7834]  w:  [1.53055329 1.21223448 2.05743829]
-8.840976453380842  -  5.237  =  -14.077976453380842
training  [-2.7105, 1.6062, 3.8415]  w:  [1.53055329 1.21223448 2.05743829]
5.702175512411718  -  70.4458  =  -64.74362448758829
training  [1.4194, -1.1613, -4.0572]  w:  [1.53055329 1.21223448 2.05743829]
-7.5827391855236845  -  8.3206  =  -15.903339185523684
training  [-0.1552, 1.2735, 4.3004]  w:  [1.53055329 1.21223448 2.05743829]
10.15404635895437  -  90.1085  =  -79.95445364104563
training  [-3.4815, -4.7835, -1.0098]  w:  [1.53055329 1.21223448 2.05743829]
-13.204946125633334  -  0.5839  =  -13.788846125633334
training  [2.8193, 4.1057, -4.526]  w:  [1.53055329 1.21223448 2.05743829]
-0.019805674033772647  -  66.8081  =  -66.82790567403377
training  [-3.9939, 3.0056, -1.5763]  w:  [1.53055329 1.21223448 2.05743829]
-5.7125248047699575  -  14.4018  =  -20.114324804769957
training  [-2.0593, 2.4585, 2.3597]  w:  [1.53055329 1.21223448 2.05743829]
4.68334721170519  -  70.6698  =  -65.9864527882948
training  [-2.6263, 3.1311, 2.9468]  w:  [1.53055329 1.21223448 2.05743829]
5.83879442762281  -  77.309  =  -71.47020557237718
training  [0.3087, -1.1669, 0.4491]  w:  [1.53055329 1.21223448 2.05743829]
-0.01807908252238799  -  33.0798  =  -33.09787908252239
training  [-4.085, 1.1728, 1.8622]  w:  [1.53055329 1.21223448 2.05743829]
-0.9992400176470593  -  26.4056  =  -27.40484001764706
training  [-0.9468, 0.7549, 3.9363]  w:  [1.53055329 1.21223448 2.05743829]
7.564682288361597  -  79.7738  =  -72.2091177116384
training  [-3.9515, 0.3005, -4.4521]  w:  [1.53055329 1.21223448 2.05743829]
-14.84362587682029  -  1.0441  =  -15.88772587682029
training  [-3.8772, -2.2493, -1.9634]  w:  [1.53055329 1.21223448 2.05743829]
-12.700514586196244  -  1.0509  =  -13.751414586196244
training  [2.8443, -2.5137, -4.5381]  w:  [1.53055329 1.21223448 2.05743829]
-8.03070178755423  -  6.8897  =  -14.92040178755423
training  [-2.0843, -0.4836, -3.0452]  w:  [1.53055329 1.21223448 2.05743829]
-10.041679899752495  -  3.5346  =  -13.576279899752496
training  [1.0353, -2.7229, 2.2017]  w:  [1.53055329 1.21223448 2.05743829]
2.8136504270296383  -  43.9562  =  -41.14254957297037
training  [4.6442, 3.0445, 2.2175]  w:  [1.53055329 1.21223448 2.05743829]
15.361212892320804  -  98.8492  =  -83.48798710767919
training  [-0.6752, 4.861, 3.778]  w:  [1.53055329 1.21223448 2.05743829]
12.63224409586311  -  97.017  =  -84.38475590413688
training  [1.9475, -4.7001, 0.8243]  w:  [1.53055329 1.21223448 2.05743829]
-1.0209243791070857  -  18.7839  =  -19.804824379107085
training  [2.581, 0.3566, -4.2932]  w:  [1.53055329 1.21223448 2.05743829]
-4.45035319367117  -  23.5455  =  -27.99585319367117
training  [-0.6736, -4.1292, 4.2274]  w:  [1.53055329 1.21223448 2.05743829]
2.6610752909518993  -  31.2667  =  -28.6056247090481
training  [1.555, 3.0209, 3.0037]  w:  [1.53055329 1.21223448 2.05743829]
12.221976908892556  -  96.4078  =  -84.18582309110744
training  [-3.9024, 4.8914, -2.1405]  w:  [1.53055329 1.21223448 2.05743829]
-4.44725407102722  -  25.4308  =  -29.878054071027222
training  [4.3376, -4.3305, 0.4366]  w:  [1.53055329 1.21223448 2.05743829]
2.287624086676284  -  43.0907  =  -40.80307591332372
training  [-3.1254, 4.394, 4.8478]  w:  [1.53055329 1.21223448 2.05743829]
10.517016394870936  -  92.8121  =  -82.29508360512907
training  [-2.3382, -4.8182, 2.1568]  w:  [1.53055329 1.21223448 2.05743829]
-4.982044999115661  -  4.7434  =  -9.72544499911566
training  [2.9783, 1.8384, 3.3897]  w:  [1.53055329 1.21223448 2.05743829]
13.761117312483531  -  97.3486  =  -83.58748268751647
training  [-0.124, 2.8374, -0.6674]  w:  [1.53055329 1.21223448 2.05743829]
1.8766712026714447  -  62.785  =  -60.90832879732855
training  [2.6896, 0.3414, -0.2938]  w:  [1.53055329 1.21223448 2.05743829]
3.9259576197698074  -  70.4455  =  -66.51954238023019
training  [-1.0399, 3.8536, 0.6071]  w:  [1.53055329 1.21223448 2.05743829]
4.328915222762566  -  77.0369  =  -72.70798477723744
training  [-2.2706, 3.99, -2.3091]  w:  [1.53055329 1.21223448 2.05743829]
-3.389289467151097  -  31.1134  =  -34.50268946715109
training  [-4.6277, 1.2594, 2.4902]  w:  [1.53055329 1.21223448 2.05743829]
-0.4328205382771557  -  28.1093  =  -28.542120538277157
training  [1.7329, -3.6213, 0.0389]  w:  [1.53055329 1.21223448 2.05743829]
-1.65753458610717  -  19.3919  =  -21.049434586107168
training  [-0.7044, -2.822, 1.4681]  w:  [1.53055329 1.21223448 2.05743829]
-1.4785223018994547  -  17.8122  =  -19.290722301899457
training  [-0.4826, -3.1786, -1.9225]  w:  [1.53055329 1.21223448 2.05743829]
-8.547278658650747  -  3.5851  =  -12.132378658650747
training  [1.0986, -4.5818, -3.6128]  w:  [1.53055329 1.21223448 2.05743829]
-11.305863158615896  -  1.7158  =  -13.021663158615896
training  [-4.406, -3.9306, -0.2443]  w:  [1.53055329 1.21223448 2.05743829]
-12.011058843792805  -  0.8241  =  -12.835158843792804
training  [-1.8419, 1.1644, -1.3754]  w:  [1.53055329 1.21223448 2.05743829]
-4.237400898465628  -  17.8517  =  -22.08910089846563
training  [2.7272, 4.3966, 2.8811]  w:  [1.53055329 1.21223448 2.05743829]
15.43152052392799  -  98.904  =  -83.47247947607201
training  [1.9643, -1.4554, 2.803]  w:  [1.53055329 1.21223448 2.05743829]
7.009179286984628  -  76.0591  =  -69.04992071301537
training  [-3.7467, -0.8937, 1.6851]  w:  [1.53055329 1.21223448 2.05743829]
-3.350908720496858  -  12.1571  =  -15.508008720496857
training  [-3.6985, 4.8435, -3.665]  w:  [1.53055329 1.21223448 2.05743829]
-7.32980495685186  -  14.6793  =  -22.00910495685186
238451.21844377188
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.49637112 1.24642509 1.99414602]
10.507159082260323  -  87.3174  =  -76.81024091773969
training  [-4.1793, -4.9218, 1.7664]  w:  [1.49637112 1.24642509 1.99414602]
-8.865979304011372  -  1.5257  =  -10.391679304011372
training  [-3.9429, -0.7689, 4.883]  w:  [1.49637112 1.24642509 1.99414602]
2.8789970885086147  -  39.7859  =  -36.906902911491386
training  [-3.5796, 1.5557, 2.6683]  w:  [1.49637112 1.24642509 1.99414602]
1.9036332975363273  -  45.5674  =  -43.663766702463676
training  [-3.3354, 2.2292, -1.633]  w:  [1.49637112 1.24642509 1.99414602]
-5.468905852475981  -  13.3589  =  -18.827805852475983
training  [1.2096, 0.3121, 1.6238]  w:  [1.49637112 1.24642509 1.99414602]
5.437114081980175  -  74.5119  =  -69.07478591801983
training  [0.7371, -3.9118, -2.5583]  w:  [1.49637112 1.24642509 1.99414602]
-8.874414297491107  -  3.3358  =  -12.210214297491106
training  [-4.4792, 1.3177, -2.0449]  w:  [1.49637112 1.24642509 1.99414602]
-9.137960354331142  -  4.2974  =  -13.435360354331142
training  [4.312, -3.735, 1.8018]  w:  [1.49637112 1.24642509 1.99414602]
5.390006826052318  -  66.5833  =  -61.19329317394768
training  [2.2866, -3.657, 0.2785]  w:  [1.49637112 1.24642509 1.99414602]
-0.5812047082673383  -  26.0005  =  -26.58170470826734
training  [2.3784, -4.0141, -0.8841]  w:  [1.49637112 1.24642509 1.99414602]
-3.2073304042245763  -  14.6809  =  -17.888230404224576
training  [-4.366, -3.5797, 1.0264]  w:  [1.49637112 1.24642509 1.99414602]
-8.948192727640578  -  1.8713  =  -10.819492727640577
training  [3.6044, -3.3175, 2.5052]  w:  [1.49637112 1.24642509 1.99414602]
6.254239411761427  -  71.0139  =  -64.75966058823857
training  [4.3441, -3.0375, 0.8353]  w:  [1.49637112 1.24642509 1.99414602]
4.380079713345665  -  63.8979  =  -59.517820286654334
training  [4.844, -1.8252, 0.5179]  w:  [1.49637112 1.24642509 1.99414602]
6.006214829113043  -  78.0461  =  -72.03988517088695
training  [3.5894, -1.8357, 0.8357]  w:  [1.49637112 1.24642509 1.99414602]
4.749519768488138  -  68.8838  =  -64.13428023151185
training  [2.8556, -2.8244, 0.1182]  w:  [1.49637112 1.24642509 1.99414602]
0.9883423831857254  -  39.5252  =  -38.536857616814274
training  [0.1338, -2.4896, -4.1741]  w:  [1.49637112 1.24642509 1.99414602]
-11.226650362756175  -  2.2644  =  -13.491050362756175
training  [-3.224, 3.9292, 2.1957]  w:  [1.49637112 1.24642509 1.99414602]
4.451699418194926  -  72.1211  =  -67.66940058180508
training  [-1.0141, 2.0322, 4.9616]  w:  [1.49637112 1.24642509 1.99414602]
10.909670022136048  -  92.3427  =  -81.43302997786395
training  [-3.6607, 0.5574, -1.4547]  w:  [1.49637112 1.24642509 1.99414602]
-7.683892613548672  -  5.8471  =  -13.530992613548673
training  [-4.6911, -3.1557, 4.7126]  w:  [1.49637112 1.24642509 1.99414602]
-1.5553576772432027  -  11.2337  =  -12.789057677243203
training  [4.3914, -2.8797, -1.5355]  w:  [1.49637112 1.24642509 1.99414602]
-0.08017743814122769  -  37.475  =  -37.55517743814123
training  [-1.9869, -4.2265, 3.8654]  w:  [1.49637112 1.24642509 1.99414602]
-0.5329834040371217  -  15.7889  =  -16.321883404037123
training  [-2.0447, 4.138, -0.4531]  w:  [1.49637112 1.24642509 1.99414602]
1.19452945640832  -  57.936  =  -56.74147054359168
training  [-1.6706, 2.0672, -0.8657]  w:  [1.49637112 1.24642509 1.99414602]
-1.6495598419908468  -  32.4185  =  -34.068059841990845
training  [-0.3293, 0.5779, -2.8227]  w:  [1.49637112 1.24642509 1.99414602]
-5.401321918419266  -  14.3434  =  -19.744721918419266
training  [1.482, -1.8657, -3.7435]  w:  [1.49637112 1.24642509 1.99414602]
-7.572918931240821  -  7.1519  =  -14.724818931240822
training  [-4.7477, -3.338, -1.9109]  w:  [1.49637112 1.24642509 1.99414602]
-15.075501743140048  -  0.4077  =  -15.483201743140048
training  [3.4221, 1.225, 2.261]  w:  [1.49637112 1.24642509 1.99414602]
11.156366489271132  -  95.0454  =  -83.88903351072886
training  [0.5903, 4.8793, 2.8287]  w:  [1.49637112 1.24642509 1.99414602]
12.605830679672433  -  97.4647  =  -84.85886932032756
training  [3.541, -3.2957, 1.9379]  w:  [1.49637112 1.24642509 1.99414602]
5.055262512677814  -  64.3732  =  -59.31793748732218
training  [-1.5212, -2.4221, -4.902]  w:  [1.49637112 1.24642509 1.99414602]
-15.07054975449611  -  0.7227  =  -15.79324975449611
training  [-0.5397, -1.032, 3.4321]  w:  [1.49637112 1.24642509 1.99414602]
4.750206367991677  -  60.5921  =  -55.84189363200832
training  [-4.4576, -4.2601, 4.2233]  w:  [1.49637112 1.24642509 1.99414602]
-3.5582425433609206  -  6.0247  =  -9.582942543360922
training  [-3.2289, 1.841, 2.7095]  w:  [1.49637112 1.24642509 1.99414602]
2.8661745433976726  -  54.0111  =  -51.14492545660232
training  [1.6281, -0.9761, -4.5734]  w:  [1.49637112 1.24642509 1.99414602]
-7.900421129726233  -  7.8658  =  -15.766221129726233
training  [-1.6917, 4.8284, -1.2181]  w:  [1.49637112 1.24642509 1.99414602]
1.057758639838564  -  61.2837  =  -60.22594136016144
training  [3.9849, -0.9782, 2.0434]  w:  [1.49637112 1.24642509 1.99414602]
8.81847421201432  -  88.3402  =  -79.52172578798567
training  [-3.8184, 1.2067, 2.2951]  w:  [1.49637112 1.24642509 1.99414602]
0.3670822223136714  -  34.1122  =  -33.74511777768633
training  [4.8842, -3.4563, -2.7572]  w:  [1.49637112 1.24642509 1.99414602]
-2.4977026544631062  -  23.7819  =  -26.279602654463105
training  [0.3998, -1.1865, -2.3095]  w:  [1.49637112 1.24642509 1.99414602]
-5.486114436033523  -  11.4246  =  -16.910714436033523
training  [2.0692, -3.3887, 1.7303]  w:  [1.49637112 1.24642509 1.99414602]
2.3230012562283275  -  42.6881  =  -40.36509874377167
training  [4.9949, 2.5811, -0.2251]  w:  [1.49637112 1.24642509 1.99414602]
10.242489629755132  -  95.9901  =  -85.74761037024487
training  [-2.1215, 3.7111, 1.2372]  w:  [1.49637112 1.24642509 1.99414602]
3.9182143002551935  -  71.3692  =  -67.45098569974482
training  [-0.8548, -1.4922, -2.6356]  w:  [1.49637112 1.24642509 1.99414602]
-8.394784806980834  -  4.7821  =  -13.176884806980834
training  [-0.3516, 1.8554, -3.2288]  w:  [1.49637112 1.24642509 1.99414602]
-4.652205635414807  -  20.3834  =  -25.03560563541481
training  [2.6396, -2.0585, 3.2964]  w:  [1.49637112 1.24642509 1.99414602]
7.957558083694958  -  80.826  =  -72.86844191630503
training  [3.182, 0.3063, 2.6692]  w:  [1.49637112 1.24642509 1.99414602]
10.466007455793015  -  92.9483  =  -82.48229254420698
training  [-3.9978, 3.3242, 4.3448]  w:  [1.49637112 1.24642509 1.99414602]
6.825339478919632  -  79.1768  =  -72.35146052108037
training  [-3.2188, 0.9749, -3.9211]  w:  [1.49637112 1.24642509 1.99414602]
-11.420625485171556  -  2.7053  =  -14.125925485171555
training  [-1.4037, -1.6469, -3.1777]  w:  [1.49637112 1.24642509 1.99414602]
-10.489991432395525  -  2.6234  =  -13.113391432395526
training  [-4.433, -2.0077, -4.009]  w:  [1.49637112 1.24642509 1.99414602]
-17.13039221549684  -  0.3253  =  -17.45569221549684
training  [0.2189, -0.4741, -0.1024]  w:  [1.49637112 1.24642509 1.99414602]
-0.4675750522827978  -  33.6531  =  -34.1206750522828
training  [-1.6415, -0.7735, -3.0675]  w:  [1.49637112 1.24642509 1.99414602]
-9.537445915156201  -  3.7641  =  -13.3015459151562
training  [-3.2433, -1.4039, 3.9589]  w:  [1.49637112 1.24642509 1.99414602]
1.291588049191918  -  30.0658  =  -28.77421195080808
training  [-2.9105, 0.5832, -4.0091]  w:  [1.49637112 1.24642509 1.99414602]
-11.623003829212216  -  2.4887  =  -14.111703829212216
training  [4.0515, 2.4255, -4.5583]  w:  [1.49637112 1.24642509 1.99414602]
-0.004164161496740704  -  61.2853  =  -61.28946416149674
training  [1.7539, -0.7567, 0.573]  w:  [1.49637112 1.24642509 1.99414602]
2.823961101687914  -  57.0797  =  -54.25573889831209
training  [-0.3153, -0.7064, 2.725]  w:  [1.49637112 1.24642509 1.99414602]
4.081767406109972  -  58.7004  =  -54.61863259389003
training  [4.1213, -3.7513, -1.8806]  w:  [1.49637112 1.24642509 1.99414602]
-2.258911180331621  -  22.1789  =  -24.43781118033162
training  [-3.9599, -4.7557, -3.2102]  w:  [1.49637112 1.24642509 1.99414602]
-18.254711358047384  -  0.1558  =  -18.410511358047383
training  [2.4555, -2.0981, -1.6104]  w:  [1.49637112 1.24642509 1.99414602]
-2.152157965381431  -  24.4796  =  -26.631757965381432
training  [2.3627, -1.8248, -2.8985]  w:  [1.49637112 1.24642509 1.99414602]
-4.51903271560062  -  15.7052  =  -20.22423271560062
training  [0.6186, 1.5369, 0.1015]  w:  [1.49637112 1.24642509 1.99414602]
3.043691720765939  -  65.2154  =  -62.17170827923406
training  [-3.1581, 4.5694, 4.0636]  w:  [1.49637112 1.24642509 1.99414602]
9.073136971516059  -  90.3564  =  -81.28326302848393
training  [0.9721, 4.3573, 1.2892]  w:  [1.49637112 1.24642509 1.99414602]
9.456523474310108  -  94.3178  =  -84.8612765256899
training  [-2.0006, -0.4211, -3.9847]  w:  [1.49637112 1.24642509 1.99414602]
-11.464583309716186  -  2.4051  =  -13.869683309716187
training  [-3.6588, -2.5952, -1.0915]  w:  [1.49637112 1.24642509 1.99414602]
-10.88625542563975  -  1.5176  =  -12.40385542563975
training  [-2.874, 2.639, -4.4538]  w:  [1.49637112 1.24642509 1.99414602]
-9.892782310183737  -  5.497  =  -15.389782310183737
training  [3.9494, 2.5933, 0.0128]  w:  [1.49637112 1.24642509 1.99414602]
9.167647352140978  -  94.1462  =  -84.97855264785902
training  [-4.2855, 2.4065, -0.6828]  w:  [1.49637112 1.24642509 1.99414602]
-4.774779332234064  -  14.4193  =  -19.194079332234065
training  [-2.5751, 2.4369, 4.9756]  w:  [1.49637112 1.24642509 1.99414602]
9.106180989596254  -  87.1991  =  -78.09291901040375
training  [-4.4625, -3.9408, 3.116]  w:  [1.49637112 1.24642509 1.99414602]
-5.375709117646436  -  4.1344  =  -9.510109117646437
training  [-0.5828, 1.8156, -0.1435]  w:  [1.49637112 1.24642509 1.99414602]
1.1047643604767963  -  51.1166  =  -50.0118356395232
training  [-4.8672, -0.3674, 3.9445]  w:  [1.49637112 1.24642509 1.99414602]
0.12483490094650751  -  24.1396  =  -24.014765099053495
training  [3.9719, -2.8784, -3.6245]  w:  [1.49637112 1.24642509 1.99414602]
-4.872055805370641  -  14.6104  =  -19.48245580537064
training  [-3.0334, -4.0148, -1.1]  w:  [1.49637112 1.24642509 1.99414602]
-11.73680023438122  -  1.021  =  -12.757800234381222
training  [-4.0663, 3.2357, 4.2736]  w:  [1.49637112 1.24642509 1.99414602]
6.470546239974121  -  77.2328  =  -70.76225376002587
training  [-1.9263, -3.2499, 4.1749]  w:  [1.49637112 1.24642509 1.99414602]
1.3921436258639233  -  26.8814  =  -25.489256374136076
training  [-0.4394, -3.3643, 2.1357]  w:  [1.49637112 1.24642509 1.99414602]
-0.5919557569711698  -  20.85  =  -21.441955756971172
training  [-3.9833, 1.6599, 1.1834]  w:  [1.49637112 1.24642509 1.99414602]
-1.531681652950918  -  25.5397  =  -27.07138165295092
training  [4.9539, 3.9439, -1.5671]  w:  [1.49637112 1.24642509 1.99414602]
9.20362257293393  -  95.9509  =  -86.74727742706608
training  [-1.6791, 0.1656, 4.3603]  w:  [1.49637112 1.24642509 1.99414602]
6.388926147044904  -  71.5733  =  -65.1843738529551
training  [-2.0265, 2.027, -3.7523]  w:  [1.49637112 1.24642509 1.99414602]
-7.98852651349883  -  8.503  =  -16.49152651349883
training  [-4.3795, -3.4641, 2.3059]  w:  [1.49637112 1.24642509 1.99414602]
-6.2727971637365245  -  3.6654  =  -9.938197163736525
training  [-2.0176, 4.5346, 1.4648]  w:  [1.49637112 1.24642509 1.99414602]
5.5539859585044535  -  81.6212  =  -76.06721404149555
training  [-4.5365, 0.4088, 3.3315]  w:  [1.49637112 1.24642509 1.99414602]
0.36474847666232435  -  28.9449  =  -28.580151523337676
training  [0.0543, 1.7973, -1.0172]  w:  [1.49637112 1.24642509 1.99414602]
0.2930074413860595  -  47.9317  =  -47.63869255861394
training  [2.6143, -4.6344, 2.4982]  w:  [1.49637112 1.24642509 1.99414602]
3.1173061409576674  -  43.5132  =  -40.39589385904233
training  [1.3107, 3.092, 3.3522]  w:  [1.49637112 1.24642509 1.99414602]
12.500016302700997  -  96.6993  =  -84.199283697299
training  [-4.1011, 2.4862, -1.7754]  w:  [1.49637112 1.24642509 1.99414602]
-6.578312360276744  -  10.0187  =  -16.597012360276743
training  [-4.1914, -3.7981, 0.5226]  w:  [1.49637112 1.24642509 1.99414602]
-9.963796336382629  -  1.4295  =  -11.39329633638263
training  [2.7724, 0.2505, 4.7913]  w:  [1.49637112 1.24642509 1.99414602]
14.015320596203708  -  96.7925  =  -82.7771794037963
training  [4.0513, -1.7417, 0.4931]  w:  [1.49637112 1.24642509 1.99414602]
4.874663119337045  -  71.1234  =  -66.24873688066296
training  [0.3377, 0.4645, -1.6958]  w:  [1.49637112 1.24642509 1.99414602]
-2.2973838391957746  -  27.9534  =  -30.250783839195773
training  [-3.9085, -1.0112, 1.1947]  w:  [1.49637112 1.24642509 1.99414602]
-4.72654531241122  -  8.608  =  -13.33454531241122
training  [3.2581, -0.8491, -1.3936]  w:  [1.49637112 1.24642509 1.99414602]
1.0379452923151566  -  50.1924  =  -49.15445470768484
training  [-1.619, -3.1926, 2.5651]  w:  [1.49637112 1.24642509 1.99414602]
-1.2867776358494663  -  16.4754  =  -17.76217763584947
training  [-2.0603, -2.4461, -0.861]  w:  [1.49637112 1.24642509 1.99414602]
-7.848813557115749  -  3.9784  =  -11.82721355711575
training  [2.4631, -4.7946, -0.0765]  w:  [1.49637112 1.24642509 1.99414602]
-2.442950230597273  -  15.394  =  -17.836950230597274
training  [-4.8966, 4.2368, 1.9474]  w:  [1.49637112 1.24642509 1.99414602]
1.8371229912940374  -  53.5883  =  -51.75117700870596
training  [-4.5155, 1.537, 4.7273]  w:  [1.49637112 1.24642509 1.99414602]
4.585818076583946  -  59.2523  =  -54.66648192341605
training  [1.6792, 4.3261, -1.7225]  w:  [1.49637112 1.24642509 1.99414602]
4.4699494580462265  -  83.7729  =  -79.30295054195378
training  [1.0347, -3.3649, 3.378]  w:  [1.49637112 1.24642509 1.99414602]
4.090424651530991  -  50.5979  =  -46.507475348469015
training  [0.261, 4.211, 2.3907]  w:  [1.49637112 1.24642509 1.99414602]
10.406653823747959  -  94.9375  =  -84.53084617625204
training  [2.2971, 2.9466, 4.5417]  w:  [1.49637112 1.24642509 1.99414602]
16.1668432543105  -  98.7784  =  -82.61155674568951
training  [2.0725, 0.7739, -4.6808]  w:  [1.49637112 1.24642509 1.99414602]
-5.26836117350289  -  19.5109  =  -24.77926117350289
training  [2.8138, -0.5996, -1.4313]  w:  [1.49637112 1.24642509 1.99414602]
0.6089113613979631  -  47.2879  =  -46.678988638602036
training  [-2.1202, -2.4239, 1.6265]  w:  [1.49637112 1.24642509 1.99414602]
-2.9503373241667337  -  12.3599  =  -15.310237324166733
training  [1.9253, 2.5195, -2.185]  w:  [1.49637112 1.24642509 1.99414602]
1.664122280227195  -  65.2467  =  -63.58257771977281
training  [0.5667, -2.7133, -2.6962]  w:  [1.49637112 1.24642509 1.99414602]
-7.9105481965688185  -  5.1106  =  -13.021148196568818
training  [-1.0348, -4.3581, 2.1113]  w:  [1.49637112 1.24642509 1.99414602]
-2.770249541035663  -  10.5192  =  -13.289449541035662
training  [-4.3841, 2.6733, 1.2457]  w:  [1.49637112 1.24642509 1.99414602]
-0.7440647088520103  -  32.4639  =  -33.20796470885201
training  [2.8018, 1.712, 0.9061]  w:  [1.49637112 1.24642509 1.99414602]
8.133308063700868  -  90.1138  =  -81.98049193629913
training  [-1.6242, 2.1521, 1.6044]  w:  [1.49637112 1.24642509 1.99414602]
3.451433353261349  -  63.7879  =  -60.33646664673865
training  [1.0787, 1.4206, -4.5245]  w:  [1.49637112 1.24642509 1.99414602]
-5.63770665743379  -  18.0555  =  -23.693206657433787
training  [2.4125, -0.8095, -1.5122]  w:  [1.49637112 1.24642509 1.99414602]
-0.41453340785496096  -  38.8276  =  -39.24213340785496
training  [-3.9519, -1.0924, -0.4866]  w:  [1.49637112 1.24642509 1.99414602]
-8.245455240582544  -  3.6777  =  -11.923155240582544
training  [-3.7211, 3.1614, -2.591]  w:  [1.49637112 1.24642509 1.99414602]
-6.794530606771246  -  11.1518  =  -17.946330606771244
training  [0.4954, -1.8257, 2.1505]  w:  [1.49637112 1.24642509 1.99414602]
2.7541149734374524  -  47.7531  =  -44.99898502656255
training  [-0.1477, 3.1454, 3.5618]  w:  [1.49637112 1.24642509 1.99414602]
10.802240772699326  -  94.1572  =  -83.35495922730068
training  [3.9048, 2.8907, -2.1849]  w:  [1.49637112 1.24642509 1.99414602]
5.089061314345885  -  85.8791  =  -80.79003868565411
training  [2.9896, 3.5226, 2.3105]  w:  [1.49637112 1.24642509 1.99414602]
13.471682505832277  -  98.038  =  -84.56631749416772
training  [2.3434, 0.0564, -3.6224]  w:  [1.49637112 1.24642509 1.99414602]
-3.6467000951890878  -  24.7629  =  -28.409600095189084
training  [-4.4867, 1.3566, 3.3672]  w:  [1.49637112 1.24642509 1.99414602]
1.6918204754137598  -  40.5785  =  -38.88667952458624
training  [-4.2711, 4.5089, -3.614]  w:  [1.49637112 1.24642509 1.99414602]
-7.9779882851871635  -  10.0825  =  -18.060488285187162
training  [-4.1147, -0.5604, 0.8821]  w:  [1.49637112 1.24642509 1.99414602]
-5.096578650108017  -  8.344  =  -13.440578650108016
training  [2.9835, -4.3998, -1.3384]  w:  [1.49637112 1.24642509 1.99414602]
-3.6885629376735993  -  13.2692  =  -16.9577629376736
training  [4.4301, 3.6675, 3.0676]  w:  [1.49637112 1.24642509 1.99414602]
17.31758004693475  -  99.3834  =  -82.06581995306524
training  [1.8372, 1.3119, 0.0378]  w:  [1.49637112 1.24642509 1.99414602]
4.459696815315544  -  74.9026  =  -70.44290318468447
training  [-3.6792, -1.4493, -0.1041]  w:  [1.49637112 1.24642509 1.99414602]
-7.519483100490783  -  4.2442  =  -11.763683100490784
training  [2.2272, 4.97, 3.7705]  w:  [1.49637112 1.24642509 1.99414602]
17.046378037864713  -  99.3199  =  -82.27352196213529
training  [-3.8965, -2.7583, -1.4686]  w:  [1.49637112 1.24642509 1.99414602]
-12.197227237111573  -  1.0337  =  -13.230927237111572
training  [-3.8251, 1.5245, -0.5056]  w:  [1.49637112 1.24642509 1.99414602]
-4.831834328551148  -  12.9762  =  -17.808034328551148
training  [1.4072, 1.0499, 4.6353]  w:  [1.49637112 1.24642509 1.99414602]
12.657780189415547  -  95.4618  =  -82.80401981058445
training  [-1.7119, -1.1275, -4.577]  w:  [1.49637112 1.24642509 1.99414602]
-13.094188342846714  -  1.4655  =  -14.559688342846714
training  [1.5381, -3.5781, 4.7296]  w:  [1.49637112 1.24642509 1.99414602]
7.273247802525521  -  69.9473  =  -62.67405219747448
training  [2.4913, -4.7487, -3.1079]  w:  [1.49637112 1.24642509 1.99414602]
-8.388595899509276  -  3.9825  =  -12.371095899509276
training  [0.8319, -0.7889, 1.6712]  w:  [1.49637112 1.24642509 1.99414602]
3.5941432040890744  -  58.8336  =  -55.239456795910925
training  [2.4003, -3.159, 0.8644]  w:  [1.49637112 1.24642509 1.99414602]
1.3780225378809006  -  39.0041  =  -37.6260774621191
training  [-2.6517, 2.2578, 1.7511]  w:  [1.49637112 1.24642509 1.99414602]
2.3382003849826964  -  54.4525  =  -52.1142996150173
training  [2.3496, -1.2964, -1.3898]  w:  [1.49637112 1.24642509 1.99414602]
-0.8714560565114586  -  33.888  =  -34.75945605651145
training  [4.706, 3.4156, 1.2028]  w:  [1.49637112 1.24642509 1.99414602]
13.697770857861151  -  98.4665  =  -84.76872914213885
training  [3.6693, 2.3423, 3.1115]  w:  [1.49637112 1.24642509 1.99414602]
14.614921377237888  -  98.3069  =  -83.69197862276211
training  [-4.1377, 0.7103, -4.8074]  w:  [1.49637112 1.24642509 1.99414602]
-14.892856601655065  -  0.9782  =  -15.871056601655065
training  [-1.3356, -3.2314, -4.1613]  w:  [1.49637112 1.24642509 1.99414602]
-14.324491146717298  -  0.7659  =  -15.090391146717298
training  [-1.308, 4.5738, 4.748]  w:  [1.49637112 1.24642509 1.99414602]
13.211850980413981  -  97.0884  =  -83.87654901958601
training  [1.8503, -2.3468, 1.5135]  w:  [1.49637112 1.24642509 1.99414602]
2.8617650672609884  -  50.2125  =  -47.35073493273901
training  [0.9794, 4.2458, -2.6876]  w:  [1.49637112 1.24642509 1.99414602]
1.398150691572809  -  68.3262  =  -66.92804930842719
training  [2.8936, -2.7623, -0.9651]  w:  [1.49637112 1.24642509 1.99414602]
-1.0376508999397622  -  28.5596  =  -29.597250899939763
training  [-1.3235, -1.2644, -3.7798]  w:  [1.49637112 1.24642509 1.99414602]
-11.09390018923881  -  2.4511  =  -13.54500018923881
training  [-2.9397, -4.125, -2.3156]  w:  [1.49637112 1.24642509 1.99414602]
-14.15803020855265  -  0.554  =  -14.712030208552651
training  [-4.1333, 1.4012, -2.4215]  w:  [1.49637112 1.24642509 1.99414602]
-9.267284481146227  -  4.4072  =  -13.674484481146226
training  [2.7193, -3.1938, -1.6833]  w:  [1.49637112 1.24642509 1.99414602]
-3.2684964854679075  -  17.0949  =  -20.363396485467906
training  [-2.9433, -4.5495, -3.4777]  w:  [1.49637112 1.24642509 1.99414602]
-17.00992168733331  -  0.2509  =  -17.260821687333312
training  [-1.1173, 2.2317, -1.5199]  w:  [1.49637112 1.24642509 1.99414602]
-1.9211511019349645  -  33.1206  =  -35.04175110193497
training  [0.5178, -1.5256, -3.7834]  w:  [1.49637112 1.24642509 1.99414602]
-8.671377213198443  -  5.237  =  -13.908377213198444
training  [-2.7105, 1.6062, 3.8415]  w:  [1.49637112 1.24642509 1.99414602]
5.60660601302424  -  70.4458  =  -64.83919398697577
training  [1.4194, -1.1613, -4.0572]  w:  [1.49637112 1.24642509 1.99414602]
-7.4141735333936145  -  8.3206  =  -15.734773533393614
training  [-0.1552, 1.2735, 4.3004]  w:  [1.49637112 1.24642509 1.99414602]
9.930711106248287  -  90.1085  =  -80.17778889375172
training  [-3.4815, -4.7835, -1.0098]  w:  [1.49637112 1.24642509 1.99414602]
-13.185579130395801  -  0.5839  =  -13.769479130395801
training  [2.8193, 4.1057, -4.526]  w:  [1.49637112 1.24642509 1.99414602]
0.3106617087399819  -  66.8081  =  -66.49743829126001
training  [-3.9939, 3.0056, -1.5763]  w:  [1.49637112 1.24642509 1.99414602]
-5.373473710056114  -  14.4018  =  -19.775273710056112
training  [-2.0593, 2.4585, 2.3597]  w:  [1.49637112 1.24642509 1.99414602]
4.68844541864005  -  70.6698  =  -65.98135458135994
training  [-2.6263, 3.1311, 2.9468]  w:  [1.49637112 1.24642509 1.99414602]
5.849111642636755  -  77.309  =  -71.45988835736324
training  [0.3087, -1.1669, 0.4491]  w:  [1.49637112 1.24642509 1.99414602]
-0.09695270102772713  -  33.0798  =  -33.17675270102772
training  [-4.085, 1.1728, 1.8622]  w:  [1.49637112 1.24642509 1.99414602]
-0.9373699401906475  -  26.4056  =  -27.34296994019065
training  [-0.9468, 0.7549, 3.9363]  w:  [1.49637112 1.24642509 1.99414602]
7.373719110793937  -  79.7738  =  -72.40008088920605
training  [-3.9515, 0.3005, -4.4521]  w:  [1.49637112 1.24642509 1.99414602]
-14.416497222351953  -  1.0441  =  -15.460597222351954
training  [-3.8772, -2.2493, -1.9634]  w:  [1.49637112 1.24642509 1.99414602]
-12.520620352535119  -  1.0509  =  -13.571520352535119
training  [2.8443, -2.5137, -4.5381]  w:  [1.49637112 1.24642509 1.99414602]
-7.926644448418372  -  6.8897  =  -14.816344448418374
training  [-2.0843, -0.4836, -3.0452]  w:  [1.49637112 1.24642509 1.99414602]
-9.794230954371976  -  3.5346  =  -13.328830954371977
training  [1.0353, -2.7229, 2.2017]  w:  [1.49637112 1.24642509 1.99414602]
2.545813420860031  -  43.9562  =  -41.410386579139974
training  [4.6442, 3.0445, 2.2175]  w:  [1.49637112 1.24642509 1.99414602]
15.166206737329318  -  98.8492  =  -83.68299326267068
training  [-0.6752, 4.861, 3.778]  w:  [1.49637112 1.24642509 1.99414602]
12.582406270022753  -  97.017  =  -84.43459372997724
training  [1.9475, -4.7001, 0.8243]  w:  [1.49637112 1.24642509 1.99414602]
-1.300365271558339  -  18.7839  =  -20.084265271558337
training  [2.581, 0.3566, -4.2932]  w:  [1.49637112 1.24642509 1.99414602]
-4.254658655187863  -  23.5455  =  -27.800158655187865
training  [-0.6736, -4.1292, 4.2274]  w:  [1.49637112 1.24642509 1.99414602]
2.2753588039437442  -  31.2667  =  -28.991341196056254
training  [1.555, 3.0209, 3.0037]  w:  [1.49637112 1.24642509 1.99414602]
12.081999054094775  -  96.4078  =  -84.32580094590521
training  [-3.9024, 4.8914, -2.1405]  w:  [1.49637112 1.24642509 1.99414602]
-4.011144495077394  -  25.4308  =  -29.441944495077394
training  [4.3376, -4.3305, 0.4366]  w:  [1.49637112 1.24642509 1.99414602]
1.963659636024504  -  43.0907  =  -41.127040363975496
training  [-3.1254, 4.394, 4.8478]  w:  [1.49637112 1.24642509 1.99414602]
10.467254654692745  -  92.8121  =  -82.34484534530725
training  [-2.3382, -4.8182, 2.1568]  w:  [1.49637112 1.24642509 1.99414602]
-5.203366195814526  -  4.7434  =  -9.946766195814526
training  [2.9783, 1.8384, 3.3897]  w:  [1.49637112 1.24642509 1.99414602]
13.507626753856481  -  97.3486  =  -83.84097324614352
training  [-0.124, 2.8374, -0.6674]  w:  [1.49637112 1.24642509 1.99414602]
2.0201634897211243  -  62.785  =  -60.76483651027887
training  [2.6896, 0.3414, -0.2938]  w:  [1.49637112 1.24642509 1.99414602]
3.864289180551955  -  70.4455  =  -66.58121081944805
training  [-1.0399, 3.8536, 0.6071]  w:  [1.49637112 1.24642509 1.99414602]
4.457793468033043  -  77.0369  =  -72.57910653196696
training  [-2.2706, 3.99, -2.3091]  w:  [1.49637112 1.24642509 1.99414602]
-3.0291067065255404  -  31.1134  =  -34.14250670652554
training  [-4.6277, 1.2594, 2.4902]  w:  [1.49637112 1.24642509 1.99414602]
-0.3891864310076718  -  28.1093  =  -28.498486431007674
training  [1.7329, -3.6213, 0.0389]  w:  [1.49637112 1.24642509 1.99414602]
-1.843045405945676  -  19.3919  =  -21.234945405945677
training  [-0.7044, -2.822, 1.4681]  w:  [1.49637112 1.24642509 1.99414602]
-1.643849657425827  -  17.8122  =  -19.45604965742583
training  [-0.4826, -3.1786, -1.9225]  w:  [1.49637112 1.24642509 1.99414602]
-8.517781229156203  -  3.5851  =  -12.102881229156203
training  [1.0986, -4.5818, -3.6128]  w:  [1.49637112 1.24642509 1.99414602]
-11.271407930557746  -  1.7158  =  -12.987207930557746
training  [-4.406, -3.9306, -0.2443]  w:  [1.49637112 1.24642509 1.99414602]
-11.979379485936779  -  0.8241  =  -12.803479485936778
training  [-1.8419, 1.1644, -1.3754]  w:  [1.49637112 1.24642509 1.99414602]
-4.047577015791894  -  17.8517  =  -21.899277015791895
training  [2.7272, 4.3966, 2.8811]  w:  [1.49637112 1.24642509 1.99414602]
15.306269976456624  -  98.904  =  -83.59773002354338
training  [1.9643, -1.4554, 2.803]  w:  [1.49637112 1.24642509 1.99414602]
6.714865996729339  -  76.0591  =  -69.34423400327066
training  [-3.7467, -0.8937, 1.6851]  w:  [1.49637112 1.24642509 1.99414602]
-3.360048308843931  -  12.1571  =  -15.51714830884393
training  [-3.6985, 4.8435, -3.665]  w:  [1.49637112 1.24642509 1.99414602]
-6.80581379457379  -  14.6793  =  -21.485113794573792
238941.4375644569
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.32189825 1.29917876 2.12508525]
10.094031453460257  -  87.3174  =  -77.22336854653975
training  [-4.1793, -4.9218, 1.7664]  w:  [1.32189825 1.29917876 2.12508525]
-8.165156818391516  -  1.5257  =  -9.690856818391516
training  [-3.9429, -0.7689, 4.883]  w:  [1.32189825 1.29917876 2.12508525]
4.165740098455279  -  39.7859  =  -35.62015990154472
training  [-3.5796, 1.5557, 2.6683]  w:  [1.32189825 1.29917876 2.12508525]
2.959630388916823  -  45.5674  =  -42.60776961108318
training  [-3.3354, 2.2292, -1.633]  w:  [1.32189825 1.29917876 2.12508525]
-4.983194336728982  -  13.3589  =  -18.342094336728984
training  [1.2096, 0.3121, 1.6238]  w:  [1.32189825 1.29917876 2.12508525]
5.455155241963503  -  74.5119  =  -69.0567447580365
training  [0.7371, -3.9118, -2.5583]  w:  [1.32189825 1.29917876 2.12508525]
-9.544361875616147  -  3.3358  =  -12.880161875616146
training  [-4.4792, 1.3177, -2.0449]  w:  [1.32189825 1.29917876 2.12508525]
-8.55470561299111  -  4.2974  =  -12.85210561299111
training  [4.312, -3.735, 1.8018]  w:  [1.32189825 1.29917876 2.12508525]
4.6765711764439715  -  66.5833  =  -61.90672882355602
training  [2.2866, -3.657, 0.2785]  w:  [1.32189825 1.29917876 2.12508525]
-1.1366079557803783  -  26.0005  =  -27.137107955780376
training  [2.3784, -4.0141, -0.8841]  w:  [1.32189825 1.29917876 2.12508525]
-3.9498185417582237  -  14.6809  =  -18.630718541758224
training  [-4.366, -3.5797, 1.0264]  w:  [1.32189825 1.29917876 2.12508525]
-8.240890486559852  -  1.8713  =  -10.112190486559852
training  [3.6044, -3.3175, 2.5052]  w:  [1.32189825 1.29917876 2.12508525]
5.778388070915238  -  71.0139  =  -65.23551192908477
training  [4.3441, -3.0375, 0.8353]  w:  [1.32189825 1.29917876 2.12508525]
3.5712864060258136  -  63.8979  =  -60.32661359397419
training  [4.844, -1.8252, 0.5179]  w:  [1.32189825 1.29917876 2.12508525]
5.132595699290535  -  78.0461  =  -72.91350430070946
training  [3.5894, -1.8357, 0.8357]  w:  [1.32189825 1.29917876 2.12508525]
4.135852868028695  -  68.8838  =  -64.7479471319713
training  [2.8556, -2.8244, 0.1182]  w:  [1.32189825 1.29917876 2.12508525]
0.3565972225174884  -  39.5252  =  -39.16860277748251
training  [0.1338, -2.4896, -4.1741]  w:  [1.32189825 1.29917876 2.12508525]
-11.92788379619451  -  2.2644  =  -14.192283796194511
training  [-3.224, 3.9292, 2.1957]  w:  [1.32189825 1.29917876 2.12508525]
5.508982914376641  -  72.1211  =  -66.61211708562335
training  [-1.0141, 2.0322, 4.9616]  w:  [1.32189825 1.29917876 2.12508525]
11.843477031745806  -  92.3427  =  -80.49922296825419
training  [-3.6607, 0.5574, -1.4547]  w:  [1.32189825 1.29917876 2.12508525]
-7.206272195157867  -  5.8471  =  -13.053372195157866
training  [-4.6911, -3.1557, 4.7126]  w:  [1.32189825 1.29917876 2.12508525]
-0.28629857224414046  -  11.2337  =  -11.519998572244141
training  [4.3914, -2.8797, -1.5355]  w:  [1.32189825 1.29917876 2.12508525]
-1.19932950300998  -  37.475  =  -38.67432950300998
training  [-1.9869, -4.2265, 3.8654]  w:  [1.32189825 1.29917876 2.12508525]
0.09684583676274627  -  15.7889  =  -15.692054163237254
training  [-2.0447, 4.138, -0.4531]  w:  [1.32189825 1.29917876 2.12508525]
1.710240243788676  -  57.936  =  -56.225759756211325
training  [-1.6706, 2.0672, -0.8657]  w:  [1.32189825 1.29917876 2.12508525]
-1.3623871772802503  -  32.4185  =  -33.78088717728025
training  [-0.3293, 0.5779, -2.8227]  w:  [1.32189825 1.29917876 2.12508525]
-5.682983815282188  -  14.3434  =  -20.026383815282188
training  [1.482, -1.8657, -3.7435]  w:  [1.32189825 1.29917876 2.12508525]
-8.420081235664284  -  7.1519  =  -15.571981235664285
training  [-4.7477, -3.338, -1.9109]  w:  [1.32189825 1.29917876 2.12508525]
-14.673460439909821  -  0.4077  =  -15.081160439909821
training  [3.4221, 1.225, 2.261]  w:  [1.32189825 1.29917876 2.12508525]
10.919979735858215  -  95.0454  =  -84.12542026414178
training  [0.5903, 4.8793, 2.8287]  w:  [1.32189825 1.29917876 2.12508525]
13.130628119012766  -  97.4647  =  -84.33407188098722
training  [3.541, -3.2957, 1.9379]  w:  [1.32189825 1.29917876 2.12508525]
4.517340957823378  -  64.3732  =  -59.85585904217662
training  [-1.5212, -2.4221, -4.902]  w:  [1.32189825 1.29917876 2.12508525]
-15.574780387182207  -  0.7227  =  -16.29748038718221
training  [-0.5397, -1.032, 3.4321]  w:  [1.32189825 1.29917876 2.12508525]
5.239324108379147  -  60.5921  =  -55.35277589162085
training  [-4.4576, -4.2601, 4.2233]  w:  [1.32189825 1.29917876 2.12508525]
-2.4522525687931633  -  6.0247  =  -8.476952568793163
training  [-3.2289, 1.841, 2.7095]  w:  [1.32189825 1.29917876 2.12508525]
3.8814293190712816  -  54.0111  =  -50.12967068092872
training  [1.6281, -0.9761, -4.5734]  w:  [1.32189825 1.29917876 2.12508525]
-8.834810720125287  -  7.8658  =  -16.700610720125287
training  [-1.6917, 4.8284, -1.2181]  w:  [1.32189825 1.29917876 2.12508525]
1.4481331303684808  -  61.2837  =  -59.83556686963152
training  [3.9849, -0.9782, 2.0434]  w:  [1.32189825 1.29917876 2.12508525]
8.33917486979011  -  88.3402  =  -80.00102513020988
training  [-3.8184, 1.2067, 2.2951]  w:  [1.32189825 1.29917876 2.12508525]
1.3974658835994611  -  34.1122  =  -32.71473411640054
training  [4.8842, -3.4563, -2.7572]  w:  [1.32189825 1.29917876 2.12508525]
-3.893221167002568  -  23.7819  =  -27.67512116700257
training  [0.3998, -1.1865, -2.3095]  w:  [1.32189825 1.29917876 2.12508525]
-5.920865061702119  -  11.4246  =  -17.345465061702118
training  [2.0692, -3.3887, 1.7303]  w:  [1.32189825 1.29917876 2.12508525]
2.009779789270002  -  42.6881  =  -40.67832021073
training  [4.9949, 2.5811, -0.2251]  w:  [1.32189825 1.29917876 2.12508525]
9.477703192387263  -  95.9901  =  -86.51239680761273
training  [-2.1215, 3.7111, 1.2372]  w:  [1.32189825 1.29917876 2.12508525]
4.646130638081125  -  71.3692  =  -66.72306936191887
training  [-0.8548, -1.4922, -2.6356]  w:  [1.32189825 1.29917876 2.12508525]
-8.669467854961324  -  4.7821  =  -13.451567854961324
training  [-0.3516, 1.8554, -3.2288]  w:  [1.32189825 1.29917876 2.12508525]
-4.915758394878791  -  20.3834  =  -25.299158394878795
training  [2.6396, -2.0585, 3.2964]  w:  [1.32189825 1.29917876 2.12508525]
7.820054149487676  -  80.826  =  -73.00594585051232
training  [3.182, 0.3063, 2.6692]  w:  [1.32189825 1.29917876 2.12508525]
10.276496233736673  -  92.9483  =  -82.67180376626334
training  [-3.9978, 3.3242, 4.3448]  w:  [1.32189825 1.29917876 2.12508525]
8.267115601423153  -  79.1768  =  -70.90968439857684
training  [-3.2188, 0.9749, -3.9211]  w:  [1.32189825 1.29917876 2.12508525]
-11.321028479042774  -  2.7053  =  -14.026328479042773
training  [-1.4037, -1.6469, -3.1777]  w:  [1.32189825 1.29917876 2.12508525]
-10.748049472544475  -  2.6234  =  -13.371449472544475
training  [-4.433, -2.0077, -4.009]  w:  [1.32189825 1.29917876 2.12508525]
-16.987802909217276  -  0.3253  =  -17.313102909217275
training  [0.2189, -0.4741, -0.1024]  w:  [1.32189825 1.29917876 2.12508525]
-0.5441858539943029  -  33.6531  =  -34.1972858539943
training  [-1.6415, -0.7735, -3.0675]  w:  [1.32189825 1.29917876 2.12508525]
-9.6935097502632  -  3.7641  =  -13.457609750263199
training  [-3.2433, -1.4039, 3.9589]  w:  [1.32189825 1.29917876 2.12508525]
2.301770322728699  -  30.0658  =  -27.7640296772713
training  [-2.9105, 0.5832, -4.0091]  w:  [1.32189825 1.29917876 2.12508525]
-11.609383071692832  -  2.4887  =  -14.098083071692832
training  [4.0515, 2.4255, -4.5583]  w:  [1.32189825 1.29917876 2.12508525]
-1.1799472286827886  -  61.2853  =  -62.465247228682784
training  [1.7539, -0.7567, 0.573]  w:  [1.32189825 1.29917876 2.12508525]
2.553062619296726  -  57.0797  =  -54.52663738070328
training  [-0.3153, -0.7064, 2.725]  w:  [1.32189825 1.29917876 2.12508525]
4.45632290273652  -  58.7004  =  -54.244077097263485
training  [4.1213, -3.7513, -1.8806]  w:  [1.32189825 1.29917876 2.12508525]
-3.4221053499838057  -  22.1789  =  -25.601005349983804
training  [-3.9599, -4.7557, -3.2102]  w:  [1.32189825 1.29917876 2.12508525]
-18.2350379930763  -  0.1558  =  -18.3908379930763
training  [2.4555, -2.0981, -1.6104]  w:  [1.32189825 1.29917876 2.12508525]
-2.9021230909399516  -  24.4796  =  -27.381723090939953
training  [2.3627, -1.8248, -2.8985]  w:  [1.32189825 1.29917876 2.12508525]
-5.407052000105152  -  15.7052  =  -21.11225200010515
training  [0.6186, 1.5369, 0.1015]  w:  [1.32189825 1.29917876 2.12508525]
3.030130252600226  -  65.2154  =  -62.18526974739978
training  [-3.1581, 4.5694, 4.0636]  w:  [1.32189825 1.29917876 2.12508525]
10.39727698773488  -  90.3564  =  -79.95912301226511
training  [0.9721, 4.3573, 1.2892]  w:  [1.32189825 1.29917876 2.12508525]
9.68558881791446  -  94.3178  =  -84.63221118208554
training  [-2.0006, -0.4211, -3.9847]  w:  [1.32189825 1.29917876 2.12508525]
-11.65950100515685  -  2.4051  =  -14.064601005156849
training  [-3.6588, -2.5952, -1.0915]  w:  [1.32189825 1.29917876 2.12508525]
-10.527720596625047  -  1.5176  =  -12.045320596625047
training  [-2.874, 2.639, -4.4538]  w:  [1.32189825 1.29917876 2.12508525]
-9.835307492974831  -  5.497  =  -15.33230749297483
training  [3.9494, 2.5933, 0.0128]  w:  [1.32189825 1.29917876 2.12508525]
8.617066332095346  -  94.1462  =  -85.52913366790465
training  [-4.2855, 2.4065, -0.6828]  w:  [1.32189825 1.29917876 2.12508525]
-3.9895294680606095  -  14.4193  =  -18.40882946806061
training  [-2.5751, 2.4369, 4.9756]  w:  [1.32189825 1.29917876 2.12508525]
10.335522700712591  -  87.1991  =  -76.86357729928741
training  [-4.4625, -3.9408, 3.116]  w:  [1.32189825 1.29917876 2.12508525]
-4.397008985770856  -  4.1344  =  -8.531408985770856
training  [-0.5828, 1.8156, -0.1435]  w:  [1.32189825 1.29917876 2.12508525]
1.283436929336127  -  51.1166  =  -49.83316307066387
training  [-4.8672, -0.3674, 3.9445]  w:  [1.32189825 1.29917876 2.12508525]
1.4711373134987475  -  24.1396  =  -22.668462686501254
training  [3.9719, -2.8784, -3.6245]  w:  [1.32189825 1.29917876 2.12508525]
-6.191479969411628  -  14.6104  =  -20.80187996941163
training  [-3.0334, -4.0148, -1.1]  w:  [1.32189825 1.29917876 2.12508525]
-11.563382827725246  -  1.021  =  -12.584382827725246
training  [-4.0663, 3.2357, 4.2736]  w:  [1.32189825 1.29917876 2.12508525]
7.910282181002588  -  77.2328  =  -69.32251781899741
training  [-1.9263, -3.2499, 4.1749]  w:  [1.32189825 1.29917876 2.12508525]
2.1034447354693473  -  26.8814  =  -24.777955264530654
training  [-0.4394, -3.3643, 2.1357]  w:  [1.32189825 1.29917876 2.12508525]
-0.41312464245301594  -  20.85  =  -21.26312464245302
training  [-3.9833, 1.6599, 1.1834]  w:  [1.32189825 1.29917876 2.12508525]
-0.5941845922153091  -  25.5397  =  -26.13388459221531
training  [4.9539, 3.9439, -1.5671]  w:  [1.32189825 1.29917876 2.12508525]
8.342161780718858  -  95.9509  =  -87.60873821928115
training  [-1.6791, 0.1656, 4.3603]  w:  [1.32189825 1.29917876 2.12508525]
7.261553855139931  -  71.5733  =  -64.31174614486007
training  [-2.0265, 2.027, -3.7523]  w:  [1.32189825 1.29917876 2.12508525]
-8.019348827148459  -  8.503  =  -16.52234882714846
training  [-4.3795, -3.4641, 2.3059]  w:  [1.32189825 1.29917876 2.12508525]
-5.389504473466179  -  3.6654  =  -9.054904473466179
training  [-2.0176, 4.5346, 1.4648]  w:  [1.32189825 1.29917876 2.12508525]
6.337018980573239  -  81.6212  =  -75.28418101942677
training  [-4.5365, 0.4088, 3.3315]  w:  [1.32189825 1.29917876 2.12508525]
1.6140343646412214  -  28.9449  =  -27.33086563535878
training  [0.0543, 1.7973, -1.0172]  w:  [1.32189825 1.29917876 2.12508525]
0.2451563529006502  -  47.9317  =  -47.68654364709935
training  [2.6143, -4.6344, 2.4982]  w:  [1.32189825 1.29917876 2.12508525]
2.743812501890087  -  43.5132  =  -40.76938749810991
training  [1.3107, 3.092, 3.3522]  w:  [1.32189825 1.29917876 2.12508525]
12.873383542172249  -  96.6993  =  -83.82591645782774
training  [-4.1011, 2.4862, -1.7754]  w:  [1.32189825 1.29917876 2.12508525]
-5.964095024701633  -  10.0187  =  -15.982795024701634
training  [-4.1914, -3.7981, 0.5226]  w:  [1.32189825 1.29917876 2.12508525]
-9.364445641652587  -  1.4295  =  -10.793945641652588
training  [2.7724, 0.2505, 4.7913]  w:  [1.32189825 1.29917876 2.12508525]
14.172195939148963  -  96.7925  =  -82.62030406085104
training  [4.0513, -1.7417, 0.4931]  w:  [1.32189825 1.29917876 2.12508525]
4.140506268179813  -  71.1234  =  -66.98289373182018
training  [0.3377, 0.4645, -1.6958]  w:  [1.32189825 1.29917876 2.12508525]
-2.553845987904907  -  27.9534  =  -30.507245987904906
training  [-3.9085, -1.0112, 1.1947]  w:  [1.32189825 1.29917876 2.12508525]
-3.941529535160235  -  8.608  =  -12.549529535160236
training  [3.2581, -0.8491, -1.3936]  w:  [1.32189825 1.29917876 2.12508525]
0.24222520290117844  -  50.1924  =  -49.95017479709882
training  [-1.619, -3.1926, 2.5651]  w:  [1.32189825 1.29917876 2.12508525]
-0.836855220506302  -  16.4754  =  -17.3122552205063
training  [-2.0603, -2.4461, -0.861]  w:  [1.32189825 1.29917876 2.12508525]
-7.7311265388347525  -  3.9784  =  -11.709526538834753
training  [2.4631, -4.7946, -0.0765]  w:  [1.32189825 1.29917876 2.12508525]
-3.1356439388350754  -  15.394  =  -18.529643938835076
training  [-4.8966, 4.2368, 1.9474]  w:  [1.32189825 1.29917876 2.12508525]
3.1699446200964445  -  53.5883  =  -50.41835537990355
training  [-4.5155, 1.537, 4.7273]  w:  [1.32189825 1.29917876 2.12508525]
6.073721697721636  -  59.2523  =  -53.17857830227836
training  [1.6792, 4.3261, -1.7225]  w:  [1.32189825 1.29917876 2.12508525]
4.179649453461305  -  83.7729  =  -79.5932505465387
training  [1.0347, -3.3649, 3.378]  w:  [1.32189825 1.29917876 2.12508525]
4.174699465585943  -  50.5979  =  -46.42320053441406
training  [0.261, 4.211, 2.3907]  w:  [1.32189825 1.29917876 2.12508525]
10.89629851869627  -  94.9375  =  -84.04120148130373
training  [2.2971, 2.9466, 4.5417]  w:  [1.32189825 1.29917876 2.12508525]
16.516192287053705  -  98.7784  =  -82.26220771294629
training  [2.0725, 0.7739, -4.6808]  w:  [1.32189825 1.29917876 2.12508525]
-6.202030456604308  -  19.5109  =  -25.712930456604308
training  [2.8138, -0.5996, -1.4313]  w:  [1.32189825 1.29917876 2.12508525]
-0.10106480242929994  -  47.2879  =  -47.3889648024293
training  [-2.1202, -2.4239, 1.6265]  w:  [1.32189825 1.29917876 2.12508525]
-2.4953169219124494  -  12.3599  =  -14.855216921912449
training  [1.9253, 2.5195, -2.185]  w:  [1.32189825 1.29917876 2.12508525]
1.1750203317202805  -  65.2467  =  -64.07167966827973
training  [0.5667, -2.7133, -2.6962]  w:  [1.32189825 1.29917876 2.12508525]
-8.50559684511045  -  5.1106  =  -13.61619684511045
training  [-1.0348, -4.3581, 2.1113]  w:  [1.32189825 1.29917876 2.12508525]
-2.5431587965213485  -  10.5192  =  -13.062358796521348
training  [-4.3841, 2.6733, 1.2457]  w:  [1.32189825 1.29917876 2.12508525]
0.3249791586588824  -  32.4639  =  -32.13892084134112
training  [2.8018, 1.712, 0.9061]  w:  [1.32189825 1.29917876 2.12508525]
7.853428306418212  -  90.1138  =  -82.26037169358179
training  [-1.6242, 2.1521, 1.6044]  w:  [1.32189825 1.29917876 2.12508525]
4.058422248912436  -  63.7879  =  -59.729477751087565
training  [1.0787, 1.4206, -4.5245]  w:  [1.32189825 1.29917876 2.12508525]
-6.343403208020327  -  18.0555  =  -24.398903208020325
training  [2.4125, -0.8095, -1.5122]  w:  [1.32189825 1.29917876 2.12508525]
-1.076159589652788  -  38.8276  =  -39.903759589652786
training  [-3.9519, -1.0924, -0.4866]  w:  [1.32189825 1.29917876 2.12508525]
-7.677299061799733  -  3.6777  =  -11.354999061799733
training  [-3.7211, 3.1614, -2.591]  w:  [1.32189825 1.29917876 2.12508525]
-6.317787716078865  -  11.1518  =  -17.469587716078863
training  [0.4954, -1.8257, 2.1505]  w:  [1.32189825 1.29917876 2.12508525]
2.8529535501011933  -  47.7531  =  -44.90014644989881
training  [-0.1477, 3.1454, 3.5618]  w:  [1.32189825 1.29917876 2.12508525]
11.460321146509395  -  94.1572  =  -82.6968788534906
training  [3.9048, 2.8907, -2.1849]  w:  [1.32189825 1.29917876 2.12508525]
4.274185585546011  -  85.8791  =  -81.60491441445399
training  [2.9896, 3.5226, 2.3105]  w:  [1.32189825 1.29917876 2.12508525]
13.438443589205264  -  98.038  =  -84.59955641079473
training  [2.3434, 0.0564, -3.6224]  w:  [1.32189825 1.29917876 2.12508525]
-4.526898757081391  -  24.7629  =  -29.28979875708139
training  [-4.4867, 1.3566, 3.3672]  w:  [1.32189825 1.29917876 2.12508525]
2.9870920730270774  -  40.5785  =  -37.59140792697292
training  [-4.2711, 4.5089, -3.614]  w:  [1.32189825 1.29917876 2.12508525]
-7.468150578680614  -  10.0825  =  -17.550650578680614
training  [-4.1147, -0.5604, 0.8821]  w:  [1.32189825 1.29917876 2.12508525]
-4.292736816356844  -  8.344  =  -12.636736816356844
training  [2.9835, -4.3998, -1.3384]  w:  [1.32189825 1.29917876 2.12508525]
-4.616457387097029  -  13.2692  =  -17.885657387097027
training  [4.4301, 3.6675, 3.0676]  w:  [1.32189825 1.29917876 2.12508525]
17.139791063929646  -  99.3834  =  -82.24360893607034
training  [1.8372, 1.3119, 0.0378]  w:  [1.32189825 1.29917876 2.12508525]
4.21331230942946  -  74.9026  =  -70.68928769057055
training  [-3.6792, -1.4493, -0.1041]  w:  [1.32189825 1.29917876 2.12508525]
-6.9676492021835505  -  4.2442  =  -11.21184920218355
training  [2.2272, 4.97, 3.7705]  w:  [1.32189825 1.29917876 2.12508525]
17.413684166534054  -  99.3199  =  -81.90621583346595
training  [-3.8965, -2.7583, -1.4686]  w:  [1.32189825 1.29917876 2.12508525]
-11.855201514180091  -  1.0337  =  -12.888901514180091
training  [-3.8251, 1.5245, -0.5056]  w:  [1.32189825 1.29917876 2.12508525]
-4.150238076806331  -  12.9762  =  -17.12643807680633
training  [1.4072, 1.0499, 4.6353]  w:  [1.32189825 1.29917876 2.12508525]
13.074590651584877  -  95.4618  =  -82.38720934841513
training  [-1.7119, -1.1275, -4.577]  w:  [1.32189825 1.29917876 2.12508525]
-13.45429685084102  -  1.4655  =  -14.91979685084102
training  [1.5381, -3.5781, 4.7296]  w:  [1.32189825 1.29917876 2.12508525]
7.435423353614828  -  69.9473  =  -62.51187664638517
training  [2.4913, -4.7487, -3.1079]  w:  [1.32189825 1.29917876 2.12508525]
-9.480717522735919  -  3.9825  =  -13.463217522735919
training  [0.8319, -0.7889, 1.6712]  w:  [1.32189825 1.29917876 2.12508525]
3.626207494508564  -  58.8336  =  -55.207392505491434
training  [2.4003, -3.159, 0.8644]  w:  [1.32189825 1.29917876 2.12508525]
0.90577034626964  -  39.0041  =  -38.09832965373036
training  [-2.6517, 2.2578, 1.7511]  w:  [1.32189825 1.29917876 2.12508525]
3.14924499694921  -  54.4525  =  -51.30325500305079
training  [2.3496, -1.2964, -1.3898]  w:  [1.32189825 1.29917876 2.12508525]
-1.5317666953302334  -  33.888  =  -35.41976669533023
training  [4.706, 3.4156, 1.2028]  w:  [1.32189825 1.29917876 2.12508525]
13.214380691003441  -  98.4665  =  -85.25211930899655
training  [3.6693, 2.3423, 3.1115]  w:  [1.32189825 1.29917876 2.12508525]
14.505710419274575  -  98.3069  =  -83.80118958072542
training  [-4.1377, 0.7103, -4.8074]  w:  [1.32189825 1.29917876 2.12508525]
-14.762946537943037  -  0.9782  =  -15.741146537943036
training  [-1.3356, -3.2314, -4.1613]  w:  [1.32189825 1.29917876 2.12508525]
-14.806810802174375  -  0.7659  =  -15.572710802174376
training  [-1.308, 4.5738, 4.748]  w:  [1.32189825 1.29917876 2.12508525]
14.303045672360199  -  97.0884  =  -82.7853543276398
training  [1.8503, -2.3468, 1.5135]  w:  [1.32189825 1.29917876 2.12508525]
2.6133121341713097  -  50.2125  =  -47.59918786582869
training  [0.9794, 4.2458, -2.6876]  w:  [1.32189825 1.29917876 2.12508525]
1.0993412300120955  -  68.3262  =  -67.2268587699879
training  [2.8936, -2.7623, -0.9651]  w:  [1.32189825 1.29917876 2.12508525]
-1.8145964915353336  -  28.5596  =  -30.374196491535333
training  [-1.3235, -1.2644, -3.7798]  w:  [1.32189825 1.29917876 2.12508525]
-11.424611183355065  -  2.4511  =  -13.875711183355065
training  [-2.9397, -4.125, -2.3156]  w:  [1.32189825 1.29917876 2.12508525]
-14.165944088421982  -  0.554  =  -14.719944088421983
training  [-4.1333, 1.4012, -2.4215]  w:  [1.32189825 1.29917876 2.12508525]
-8.789286685418508  -  4.4072  =  -13.196486685418508
training  [2.7193, -3.1938, -1.6833]  w:  [1.32189825 1.29917876 2.12508525]
-4.1318352180980575  -  17.0949  =  -21.226735218098057
training  [-2.9433, -4.5495, -3.4777]  w:  [1.32189825 1.29917876 2.12508525]
-17.191765873606876  -  0.2509  =  -17.442665873606877
training  [-1.1173, 2.2317, -1.5199]  w:  [1.32189825 1.29917876 2.12508525]
-1.8074967373147017  -  33.1206  =  -34.9280967373147
training  [0.5178, -1.5256, -3.7834]  w:  [1.32189825 1.29917876 2.12508525]
-9.337595733358263  -  5.237  =  -14.574595733358263
training  [-2.7105, 1.6062, 3.8415]  w:  [1.32189825 1.29917876 2.12508525]
6.667250699182867  -  70.4458  =  -63.77854930081714
training  [1.4194, -1.1613, -4.0572]  w:  [1.32189825 1.29917876 2.12508525]
-8.254329787313454  -  8.3206  =  -16.574929787313454
training  [-0.1552, 1.2735, 4.3004]  w:  [1.32189825 1.29917876 2.12508525]
10.588062145995801  -  90.1085  =  -79.5204378540042
training  [-3.4815, -4.7835, -1.0098]  w:  [1.32189825 1.29917876 2.12508525]
-12.962721460321887  -  0.5839  =  -13.546621460321887
training  [2.8193, 4.1057, -4.526]  w:  [1.32189825 1.29917876 2.12508525]
-0.5572698417249224  -  66.8081  =  -67.36536984172491
training  [-3.9939, 3.0056, -1.5763]  w:  [1.32189825 1.29917876 2.12508525]
-4.72448960954827  -  14.4018  =  -19.12628960954827
training  [-2.0593, 2.4585, 2.3597]  w:  [1.32189825 1.29917876 2.12508525]
5.486409580556034  -  70.6698  =  -65.18339041944397
training  [-2.6263, 3.1311, 2.9468]  w:  [1.32189825 1.29917876 2.12508525]
6.858358457433159  -  77.309  =  -70.45064154256684
training  [0.3087, -1.1669, 0.4491]  w:  [1.32189825 1.29917876 2.12508525]
-0.15356592435514638  -  33.0798  =  -33.23336592435515
training  [-4.085, 1.1728, 1.8622]  w:  [1.32189825 1.29917876 2.12508525]
0.0810562460200579  -  26.4056  =  -26.324543753979942
training  [-0.9468, 0.7549, 3.9363]  w:  [1.32189825 1.29917876 2.12508525]
8.094149844862281  -  79.7738  =  -71.67965015513771
training  [-3.9515, 0.3005, -4.4521]  w:  [1.32189825 1.29917876 2.12508525]
-14.294169752386985  -  1.0441  =  -15.338269752386985
training  [-3.8772, -2.2493, -1.9634]  w:  [1.32189825 1.29917876 2.12508525]
-12.219899067817725  -  1.0509  =  -13.270799067817725
training  [2.8443, -2.5137, -4.5381]  w:  [1.32189825 1.29917876 2.12508525]
-9.14971982467047  -  6.8897  =  -16.03941982467047
training  [-2.0843, -0.4836, -3.0452]  w:  [1.32189825 1.29917876 2.12508525]
-9.854824971306583  -  3.5346  =  -13.389424971306582
training  [1.0353, -2.7229, 2.2017]  w:  [1.32189825 1.29917876 2.12508525]
2.509827593911081  -  43.9562  =  -41.44637240608892
training  [4.6442, 3.0445, 2.2175]  w:  [1.32189825 1.29917876 2.12508525]
14.806886140736136  -  98.8492  =  -84.04231385926386
training  [-0.6752, 4.861, 3.778]  w:  [1.32189825 1.29917876 2.12508525]
13.451334336370156  -  97.017  =  -83.56566566362984
training  [1.9475, -4.7001, 0.8243]  w:  [1.32189825 1.29917876 2.12508525]
-1.7801654928804305  -  18.7839  =  -20.56406549288043
training  [2.581, 0.3566, -4.2932]  w:  [1.32189825 1.29917876 2.12508525]
-5.248309451912429  -  23.5455  =  -28.79380945191243
training  [-0.6736, -4.1292, 4.2274]  w:  [1.32189825 1.29917876 2.12508525]
2.728585763426625  -  31.2667  =  -28.538114236573374
training  [1.555, 3.0209, 3.0037]  w:  [1.32189825 1.29917876 2.12508525]
12.363359466031143  -  96.4078  =  -84.04444053396885
training  [-3.9024, 4.8914, -2.1405]  w:  [1.32189825 1.29917876 2.12508525]
-3.352517703923385  -  25.4308  =  -28.783317703923387
training  [4.3376, -4.3305, 0.4366]  w:  [1.32189825 1.29917876 2.12508525]
1.0355844378148427  -  43.0907  =  -42.05511556218516
training  [-3.1254, 4.394, 4.8478]  w:  [1.32189825 1.29917876 2.12508525]
11.87911895664989  -  92.8121  =  -80.93298104335011
training  [-2.3382, -4.8182, 2.1568]  w:  [1.32189825 1.29917876 2.12508525]
-4.767181747498102  -  4.7434  =  -9.510581747498103
training  [2.9783, 1.8384, 3.3897]  w:  [1.32189825 1.29917876 2.12508525]
13.528821264625202  -  97.3486  =  -83.8197787353748
training  [-0.124, 2.8374, -0.6674]  w:  [1.32189825 1.29917876 2.12508525]
2.1040925463648845  -  62.785  =  -60.680907453635115
training  [2.6896, 0.3414, -0.2938]  w:  [1.32189825 1.29917876 2.12508525]
3.374567120554732  -  70.4455  =  -67.07093287944527
training  [-1.0399, 3.8536, 0.6071]  w:  [1.32189825 1.29917876 2.12508525]
4.92201254582708  -  77.0369  =  -72.11488745417293
training  [-2.2706, 3.99, -2.3091]  w:  [1.32189825 1.29917876 2.12508525]
-2.7248132478739358  -  31.1134  =  -33.83821324787394
training  [-4.6277, 1.2594, 2.4902]  w:  [1.32189825 1.29917876 2.12508525]
0.8107244815661394  -  28.1093  =  -27.29857551843386
training  [1.7329, -3.6213, 0.0389]  w:  [1.32189825 1.29917876 2.12508525]
-2.3313327609563124  -  19.3919  =  -21.72323276095631
training  [-0.7044, -2.822, 1.4681]  w:  [1.32189825 1.29917876 2.12508525]
-1.4775899468798874  -  17.8122  =  -19.28978994687989
training  [-0.4826, -3.1786, -1.9225]  w:  [1.32189825 1.29917876 2.12508525]
-8.852994102662809  -  3.5851  =  -12.43809410266281
training  [1.0986, -4.5818, -3.6128]  w:  [1.32189825 1.29917876 2.12508525]
-12.177847823098205  -  1.7158  =  -13.893647823098204
training  [-4.406, -3.9306, -0.2443]  w:  [1.32189825 1.29917876 2.12508525]
-11.449994068986694  -  0.8241  =  -12.274094068986694
training  [-1.8419, 1.1644, -1.3754]  w:  [1.32189825 1.29917876 2.12508525]
-3.84488288622841  -  17.8517  =  -21.696582886228413
training  [2.7272, 4.3966, 2.8811]  w:  [1.32189825 1.29917876 2.12508525]
15.439633369799498  -  98.904  =  -83.4643666302005
training  [1.9643, -1.4554, 2.803]  w:  [1.32189825 1.29917876 2.12508525]
6.662393911565725  -  76.0591  =  -69.39670608843427
training  [-3.7467, -0.8937, 1.6851]  w:  [1.32189825 1.29917876 2.12508525]
-2.5328510879285413  -  12.1571  =  -14.689951087928542
training  [-3.6985, 4.8435, -3.665]  w:  [1.32189825 1.29917876 2.12508525]
-6.384905773375797  -  14.6793  =  -21.064205773375797
238007.3530412764
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.25689217 1.35440712 2.07982155]
9.376025316641842  -  87.3174  =  -77.94137468335816
training  [-4.1793, -4.9218, 1.7664]  w:  [1.25689217 1.35440712 2.07982155]
-8.24525361484385  -  1.5257  =  -9.770953614843851
training  [-3.9429, -0.7689, 4.883]  w:  [1.25689217 1.35440712 2.07982155]
4.158564844915039  -  39.7859  =  -35.62733515508496
training  [-3.5796, 1.5557, 2.6683]  w:  [1.25689217 1.35440712 2.07982155]
3.157467778908521  -  45.5674  =  -42.40993222109148
training  [-3.3354, 2.2292, -1.633]  w:  [1.25689217 1.35440712 2.07982155]
-4.569342374908993  -  13.3589  =  -17.928242374908994
training  [1.2096, 0.3121, 1.6238]  w:  [1.25689217 1.35440712 2.07982155]
5.320261454682231  -  74.5119  =  -69.19163854531777
training  [0.7371, -3.9118, -2.5583]  w:  [1.25689217 1.35440712 2.07982155]
-9.692522008587105  -  3.3358  =  -13.028322008587104
training  [-4.4792, 1.3177, -2.0449]  w:  [1.25689217 1.35440712 2.07982155]
-8.098196220069928  -  4.2974  =  -12.395596220069928
training  [4.312, -3.735, 1.8018]  w:  [1.25689217 1.35440712 2.07982155]
4.108430904888074  -  66.5833  =  -62.47486909511192
training  [2.2866, -3.657, 0.2785]  w:  [1.25689217 1.35440712 2.07982155]
-1.499826898562202  -  26.0005  =  -27.5003268985622
training  [2.3784, -4.0141, -0.8841]  w:  [1.25689217 1.35440712 2.07982155]
-4.286103508694821  -  14.6809  =  -18.96700350869482
training  [-4.366, -3.5797, 1.0264]  w:  [1.25689217 1.35440712 2.07982155]
-8.201233533316296  -  1.8713  =  -10.072533533316296
training  [3.6044, -3.3175, 2.5052]  w:  [1.25689217 1.35440712 2.07982155]
5.247465453805377  -  71.0139  =  -65.76643454619463
training  [4.3441, -3.0375, 0.8353]  w:  [1.25689217 1.35440712 2.07982155]
3.083328584310822  -  63.8979  =  -60.81457141568918
training  [4.844, -1.8252, 0.5179]  w:  [1.25689217 1.35440712 2.07982155]
4.69346136998961  -  78.0461  =  -73.35263863001039
training  [3.5894, -1.8357, 0.8357]  w:  [1.25689217 1.35440712 2.07982155]
3.763310468125141  -  68.8838  =  -65.12048953187485
training  [2.8556, -2.8244, 0.1182]  w:  [1.25689217 1.35440712 2.07982155]
0.009628718032586192  -  39.5252  =  -39.51557128196741
training  [0.1338, -2.4896, -4.1741]  w:  [1.25689217 1.35440712 2.07982155]
-11.885142904138002  -  2.2644  =  -14.149542904138002
training  [-3.224, 3.9292, 2.1957]  w:  [1.25689217 1.35440712 2.07982155]
5.836180266420809  -  72.1211  =  -66.28491973357919
training  [-1.0141, 2.0322, 4.9616]  w:  [1.25689217 1.35440712 2.07982155]
11.797054379880075  -  92.3427  =  -80.54564562011991
training  [-3.6607, 0.5574, -1.4547]  w:  [1.25689217 1.35440712 2.07982155]
-6.87167503584235  -  5.8471  =  -12.71877503584235
training  [-4.6911, -3.1557, 4.7126]  w:  [1.25689217 1.35440712 2.07982155]
-0.3689423765864479  -  11.2337  =  -11.602642376586449
training  [4.3914, -2.8797, -1.5355]  w:  [1.25689217 1.35440712 2.07982155]
-1.5743358939251122  -  37.475  =  -39.04933589392511
training  [-1.9869, -4.2265, 3.8654]  w:  [1.25689217 1.35440712 2.07982155]
-0.1823785307934891  -  15.7889  =  -15.971278530793489
training  [-2.0447, 4.138, -0.4531]  w:  [1.25689217 1.35440712 2.07982155]
2.0922020960237644  -  57.936  =  -55.84379790397624
training  [-1.6706, 2.0672, -0.8657]  w:  [1.25689217 1.35440712 2.07982155]
-1.1004351740054845  -  32.4185  =  -33.518935174005485
training  [-0.3293, 0.5779, -2.8227]  w:  [1.25689217 1.35440712 2.07982155]
-5.501894995080159  -  14.3434  =  -19.84529499508016
training  [1.482, -1.8657, -3.7435]  w:  [1.25689217 1.35440712 2.07982155]
-8.450015124051289  -  7.1519  =  -15.601915124051288
training  [-4.7477, -3.338, -1.9109]  w:  [1.25689217 1.35440712 2.07982155]
-14.462688900318176  -  0.4077  =  -14.870388900318176
training  [3.4221, 1.225, 2.261]  w:  [1.25689217 1.35440712 2.07982155]
10.662835924420767  -  95.0454  =  -84.38256407557924
training  [0.5903, 4.8793, 2.8287]  w:  [1.25689217 1.35440712 2.07982155]
13.233693305729917  -  97.4647  =  -84.23100669427008
training  [3.541, -3.2957, 1.9379]  w:  [1.25689217 1.35440712 2.07982155]
4.01742180251209  -  64.3732  =  -60.35577819748791
training  [-1.5212, -2.4221, -4.902]  w:  [1.25689217 1.35440712 2.07982155]
-15.387779065552468  -  0.7227  =  -16.110479065552468
training  [-0.5397, -1.032, 3.4321]  w:  [1.25689217 1.35440712 2.07982155]
5.062062678487544  -  60.5921  =  -55.53003732151246
training  [-4.4576, -4.2601, 4.2233]  w:  [1.25689217 1.35440712 2.07982155]
-2.5889219590302393  -  6.0247  =  -8.61362195903024
training  [-3.2289, 1.841, 2.7095]  w:  [1.25689217 1.35440712 2.07982155]
4.070360860863337  -  54.0111  =  -49.94073913913666
training  [1.6281, -0.9761, -4.5734]  w:  [1.25689217 1.35440712 2.07982155]
-8.787546506858686  -  7.8658  =  -16.653346506858686
training  [-1.6917, 4.8284, -1.2181]  w:  [1.25689217 1.35440712 2.07982155]
1.879904223232983  -  61.2837  =  -59.40379577676702
training  [3.9849, -0.9782, 2.0434]  w:  [1.25689217 1.35440712 2.07982155]
7.933615905563096  -  88.3402  =  -80.4065840944369
training  [-3.8184, 1.2067, 2.2951]  w:  [1.25689217 1.35440712 2.07982155]
1.6084444439198977  -  34.1122  =  -32.5037555560801
training  [4.8842, -3.4563, -2.7572]  w:  [1.25689217 1.35440712 2.07982155]
-4.27680856035663  -  23.7819  =  -28.05870856035663
training  [0.3998, -1.1865, -2.3095]  w:  [1.25689217 1.35440712 2.07982155]
-5.907846417121961  -  11.4246  =  -17.33244641712196
training  [2.0692, -3.3887, 1.7303]  w:  [1.25689217 1.35440712 2.07982155]
1.6097970942074076  -  42.6881  =  -41.07830290579259
training  [4.9949, 2.5811, -0.2251]  w:  [1.25689217 1.35440712 2.07982155]
9.3057430744998  -  95.9901  =  -86.6843569255002
training  [-2.1215, 3.7111, 1.2372]  w:  [1.25689217 1.35440712 2.07982155]
4.932998737792161  -  71.3692  =  -66.43620126220785
training  [-0.8548, -1.4922, -2.6356]  w:  [1.25689217 1.35440712 2.07982155]
-8.577015393692147  -  4.7821  =  -13.359115393692147
training  [-0.3516, 1.8554, -3.2288]  w:  [1.25689217 1.35440712 2.07982155]
-4.644284126730776  -  20.3834  =  -25.027684126730776
training  [2.6396, -2.0585, 3.2964]  w:  [1.25689217 1.35440712 2.07982155]
7.385569258717961  -  80.826  =  -73.44043074128203
training  [3.182, 0.3063, 2.6692]  w:  [1.25689217 1.35440712 2.07982155]
9.96574545035193  -  92.9483  =  -82.98255454964807
training  [-3.9978, 3.3242, 4.3448]  w:  [1.25689217 1.35440712 2.07982155]
8.513925284361507  -  79.1768  =  -70.6628747156385
training  [-3.2188, 0.9749, -3.9211]  w:  [1.25689217 1.35440712 2.07982155]
-10.880461275639611  -  2.7053  =  -13.58576127563961
training  [-1.4037, -1.6469, -3.1777]  w:  [1.25689217 1.35440712 2.07982155]
-10.60392154612546  -  2.6234  =  -13.22732154612546
training  [-4.433, -2.0077, -4.009]  w:  [1.25689217 1.35440712 2.07982155]
-16.629050731078188  -  0.3253  =  -16.954350731078186
training  [0.2189, -0.4741, -0.1024]  w:  [1.25689217 1.35440712 2.07982155]
-0.5799644453872645  -  33.6531  =  -34.233064445387264
training  [-1.6415, -0.7735, -3.0675]  w:  [1.25689217 1.35440712 2.07982155]
-9.490674992365154  -  3.7641  =  -13.254774992365153
training  [-3.2433, -1.4039, 3.9589]  w:  [1.25689217 1.35440712 2.07982155]
2.2558749952596635  -  30.0658  =  -27.809925004740336
training  [-2.9105, 0.5832, -4.0091]  w:  [1.25689217 1.35440712 2.07982155]
-11.20650698437547  -  2.4887  =  -13.695206984375469
training  [4.0515, 2.4255, -4.5583]  w:  [1.25689217 1.35440712 2.07982155]
-1.1030374674659207  -  61.2853  =  -62.38833746746592
training  [1.7539, -0.7567, 0.573]  w:  [1.25689217 1.35440712 2.07982155]
2.371321053539954  -  57.0797  =  -54.70837894646005
training  [-0.3153, -0.7064, 2.725]  w:  [1.25689217 1.35440712 2.07982155]
4.314462423636135  -  58.7004  =  -54.385937576363865
training  [4.1213, -3.7513, -1.8806]  w:  [1.25689217 1.35440712 2.07982155]
-3.8120701283136817  -  22.1789  =  -25.99097012831368
training  [-3.9599, -4.7557, -3.2102]  w:  [1.25689217 1.35440712 2.07982155]
-18.09496435616567  -  0.1558  =  -18.250764356165668
training  [2.4555, -2.0981, -1.6104]  w:  [1.25689217 1.35440712 2.07982155]
-3.1047274728426904  -  24.4796  =  -27.58432747284269
training  [2.3627, -1.8248, -2.8985]  w:  [1.25689217 1.35440712 2.07982155]
-5.530225733952692  -  15.7052  =  -21.23542573395269
training  [0.6186, 1.5369, 0.1015]  w:  [1.25689217 1.35440712 2.07982155]
3.0702036822124996  -  65.2154  =  -62.1451963177875
training  [-3.1581, 4.5694, 4.0636]  w:  [1.25689217 1.35440712 2.07982155]
10.670999562997135  -  90.3564  =  -79.68540043700285
training  [0.9721, 4.3573, 1.2892]  w:  [1.25689217 1.35440712 2.07982155]
9.804688949973787  -  94.3178  =  -84.51311105002623
training  [-2.0006, -0.4211, -3.9847]  w:  [1.25689217 1.35440712 2.07982155]
-11.372344223478635  -  2.4051  =  -13.777444223478636
training  [-3.6588, -2.5952, -1.0915]  w:  [1.25689217 1.35440712 2.07982155]
-10.383799636080319  -  1.5176  =  -11.901399636080319
training  [-2.874, 2.639, -4.4538]  w:  [1.25689217 1.35440712 2.07982155]
-9.301136908105118  -  5.497  =  -14.798136908105118
training  [3.9494, 2.5933, 0.0128]  w:  [1.25689217 1.35440712 2.07982155]
8.502975625102414  -  94.1462  =  -85.64322437489758
training  [-4.2855, 2.4065, -0.6828]  w:  [1.25689217 1.35440712 2.07982155]
-3.5471328090770715  -  14.4193  =  -17.96643280907707
training  [-2.5751, 2.4369, 4.9756]  w:  [1.25689217 1.35440712 2.07982155]
10.412291767460257  -  87.1991  =  -76.78680823253974
training  [-4.4625, -3.9408, 3.116]  w:  [1.25689217 1.35440712 2.07982155]
-4.465604935603859  -  4.1344  =  -8.60000493560386
training  [-0.5828, 1.8156, -0.1435]  w:  [1.25689217 1.35440712 2.07982155]
1.4280904162475647  -  51.1166  =  -49.688509583752435
training  [-4.8672, -0.3674, 3.9445]  w:  [1.25689217 1.35440712 2.07982155]
1.5887013508245555  -  24.1396  =  -22.550898649175444
training  [3.9719, -2.8784, -3.6245]  w:  [1.25689217 1.35440712 2.07982155]
-6.444588638707611  -  14.6104  =  -21.054988638707613
training  [-3.0334, -4.0148, -1.1]  w:  [1.25689217 1.35440712 2.07982155]
-11.538134102128158  -  1.021  =  -12.559134102128159
training  [-4.0663, 3.2357, 4.2736]  w:  [1.25689217 1.35440712 2.07982155]
8.159879846799782  -  77.2328  =  -69.07292015320022
training  [-1.9263, -3.2499, 4.1749]  w:  [1.25689217 1.35440712 2.07982155]
1.8602078947016771  -  26.8814  =  -25.021192105298322
training  [-0.4394, -3.3643, 2.1357]  w:  [1.25689217 1.35440712 2.07982155]
-0.667035410923484  -  20.85  =  -21.517035410923484
training  [-3.9833, 1.6599, 1.1834]  w:  [1.25689217 1.35440712 2.07982155]
-0.29713738126526223  -  25.5397  =  -25.836837381265262
training  [4.9539, 3.9439, -1.5671]  w:  [1.25689217 1.35440712 2.07982155]
8.308876001663291  -  95.9509  =  -87.64202399833671
training  [-1.6791, 0.1656, 4.3603]  w:  [1.25689217 1.35440712 2.07982155]
7.182488065538537  -  71.5733  =  -64.39081193446147
training  [-2.0265, 2.027, -3.7523]  w:  [1.25689217 1.35440712 2.07982155]
-7.605823137306321  -  8.503  =  -16.10882313730632
training  [-4.3795, -3.4641, 2.3059]  w:  [1.25689217 1.35440712 2.07982155]
-5.400500446729472  -  3.6654  =  -9.065900446729472
training  [-2.0176, 4.5346, 1.4648]  w:  [1.25689217 1.35440712 2.07982155]
6.652311479770461  -  81.6212  =  -74.96888852022954
training  [-4.5365, 0.4088, 3.3315]  w:  [1.25689217 1.35440712 2.07982155]
1.7807157883997675  -  28.9449  =  -27.164184211600233
training  [0.0543, 1.7973, -1.0172]  w:  [1.25689217 1.35440712 2.07982155]
0.38693068177738965  -  47.9317  =  -47.544769318222606
training  [2.6143, -4.6344, 2.4982]  w:  [1.25689217 1.35440712 2.07982155]
2.2048390331425867  -  43.5132  =  -41.308360966857414
training  [1.3107, 3.092, 3.3522]  w:  [1.25689217 1.35440712 2.07982155]
12.807213160739604  -  96.6993  =  -83.89208683926039
training  [-4.1011, 2.4862, -1.7754]  w:  [1.25689217 1.35440712 2.07982155]
-5.479828666977143  -  10.0187  =  -15.498528666977144
training  [-4.1914, -3.7981, 0.5226]  w:  [1.25689217 1.35440712 2.07982155]
-9.325396770167645  -  1.4295  =  -10.754896770167644
training  [2.7724, 0.2505, 4.7913]  w:  [1.25689217 1.35440712 2.07982155]
13.788935803581582  -  96.7925  =  -83.00356419641842
training  [4.0513, -1.7417, 0.4931]  w:  [1.25689217 1.35440712 2.07982155]
3.758636368167843  -  71.1234  =  -67.36476363183216
training  [0.3377, 0.4645, -1.6958]  w:  [1.25689217 1.35440712 2.07982155]
-2.4733867859035783  -  27.9534  =  -30.426786785903577
training  [-3.9085, -1.0112, 1.1947]  w:  [1.25689217 1.35440712 2.07982155]
-3.7973767170244663  -  8.608  =  -12.405376717024467
training  [3.2581, -0.8491, -1.3936]  w:  [1.25689217 1.35440712 2.07982155]
0.04661398326094934  -  50.1924  =  -50.14578601673905
training  [-1.619, -3.1926, 2.5651]  w:  [1.25689217 1.35440712 2.07982155]
-1.024038338701823  -  16.4754  =  -17.49943833870182
training  [-2.0603, -2.4461, -0.861]  w:  [1.25689217 1.35440712 2.07982155]
-7.693316537313063  -  3.9784  =  -11.671716537313063
training  [2.4631, -4.7946, -0.0765]  w:  [1.25689217 1.35440712 2.07982155]
-3.5570956173101322  -  15.394  =  -18.95109561731013
training  [-4.8966, 4.2368, 1.9474]  w:  [1.25689217 1.35440712 2.07982155]
3.6340983653427896  -  53.5883  =  -49.95420163465721
training  [-4.5155, 1.537, 4.7273]  w:  [1.25689217 1.35440712 2.07982155]
6.238167548472516  -  59.2523  =  -53.01413245152748
training  [1.6792, 4.3261, -1.7225]  w:  [1.25689217 1.35440712 2.07982155]
4.387381350301308  -  83.7729  =  -79.3855186496987
training  [1.0347, -3.3649, 3.378]  w:  [1.25689217 1.35440712 2.07982155]
3.7686989966612785  -  50.5979  =  -46.829201003338724
training  [0.261, 4.211, 2.3907]  w:  [1.25689217 1.35440712 2.07982155]
11.003686600489388  -  94.9375  =  -83.93381339951061
training  [2.2971, 2.9466, 4.5417]  w:  [1.25689217 1.35440712 2.07982155]
16.324028529479648  -  98.7784  =  -82.45437147052036
training  [2.0725, 0.7739, -4.6808]  w:  [1.25689217 1.35440712 2.07982155]
-6.082144004426207  -  19.5109  =  -25.593044004426208
training  [2.8138, -0.5996, -1.4313]  w:  [1.25689217 1.35440712 2.07982155]
-0.2523079034282225  -  47.2879  =  -47.540207903428225
training  [-2.1202, -2.4239, 1.6265]  w:  [1.25689217 1.35440712 2.07982155]
-2.564980444714528  -  12.3599  =  -14.924880444714528
training  [1.9253, 2.5195, -2.185]  w:  [1.25689217 1.35440712 2.07982155]
1.287913148210042  -  65.2467  =  -63.95878685178996
training  [0.5667, -2.7133, -2.6962]  w:  [1.25689217 1.35440712 2.07982155]
-8.570246894094483  -  5.1106  =  -13.680846894094483
training  [-1.0348, -4.3581, 2.1113]  w:  [1.25689217 1.35440712 2.07982155]
-2.8121464477465583  -  10.5192  =  -13.331346447746558
training  [-4.3841, 2.6733, 1.2457]  w:  [1.25689217 1.35440712 2.07982155]
0.70122929355224  -  32.4639  =  -31.762670706447764
training  [2.8018, 1.712, 0.9061]  w:  [1.25689217 1.35440712 2.07982155]
7.72483176639711  -  90.1138  =  -82.38896823360288
training  [-1.6242, 2.1521, 1.6044]  w:  [1.25689217 1.35440712 2.07982155]
4.210240987501056  -  63.7879  =  -59.57765901249894
training  [1.0787, 1.4206, -4.5245]  w:  [1.25689217 1.35440712 2.07982155]
-6.1302722503691705  -  18.0555  =  -24.18577225036917
training  [2.4125, -0.8095, -1.5122]  w:  [1.25689217 1.35440712 2.07982155]
-1.2092463477622182  -  38.8276  =  -40.036846347762214
training  [-3.9519, -1.0924, -0.4866]  w:  [1.25689217 1.35440712 2.07982155]
-7.45870766027237  -  3.6777  =  -11.13640766027237
training  [-3.7211, 3.1614, -2.591]  w:  [1.25689217 1.35440712 2.07982155]
-5.784016409642242  -  11.1518  =  -16.935816409642243
training  [0.4954, -1.8257, 2.1505]  w:  [1.25689217 1.35440712 2.07982155]
2.6225795389922264  -  47.7531  =  -45.13052046100778
training  [-0.1477, 3.1454, 3.5618]  w:  [1.25689217 1.35440712 2.07982155]
11.482417558550083  -  94.1572  =  -82.67478244144992
training  [3.9048, 2.8907, -2.1849]  w:  [1.25689217 1.35440712 2.07982155]
4.278895099893027  -  85.8791  =  -81.60020490010697
training  [2.9896, 3.5226, 2.3105]  w:  [1.25689217 1.35440712 2.07982155]
13.334067022904692  -  98.038  =  -84.7039329770953
training  [2.3434, 0.0564, -3.6224]  w:  [1.25689217 1.35440712 2.07982155]
-4.51215589913283  -  24.7629  =  -29.27505589913283
training  [-4.4867, 1.3566, 3.3672]  w:  [1.25689217 1.35440712 2.07982155]
3.2012657142016034  -  40.5785  =  -37.377234285798394
training  [-4.2711, 4.5089, -3.614]  w:  [1.25689217 1.35440712 2.07982155]
-6.77790095193214  -  10.0825  =  -16.86040095193214
training  [-4.1147, -0.5604, 0.8821]  w:  [1.25689217 1.35440712 2.07982155]
-4.096133368507094  -  8.344  =  -12.440133368507095
training  [2.9835, -4.3998, -1.3384]  w:  [1.25689217 1.35440712 2.07982155]
-4.992815811422545  -  13.2692  =  -18.262015811422543
training  [4.4301, 3.6675, 3.0676]  w:  [1.25689217 1.35440712 2.07982155]
16.915506675253717  -  99.3834  =  -82.46789332474629
training  [1.8372, 1.3119, 0.0378]  w:  [1.25689217 1.35440712 2.07982155]
4.164626244496994  -  74.9026  =  -70.737973755503
training  [-3.6792, -1.4493, -0.1041]  w:  [1.25689217 1.35440712 2.07982155]
-6.803809325136135  -  4.2442  =  -11.048009325136135
training  [2.2272, 4.97, 3.7705]  w:  [1.25689217 1.35440712 2.07982155]
17.372720753667068  -  99.3199  =  -81.94717924633294
training  [-3.8965, -2.7583, -1.4686]  w:  [1.25689217 1.35440712 2.07982155]
-11.687767410439664  -  1.0337  =  -12.721467410439663
training  [-3.8251, 1.5245, -0.5056]  w:  [1.25689217 1.35440712 2.07982155]
-3.7945023550832833  -  12.9762  =  -16.770702355083284
training  [1.4072, 1.0499, 4.6353]  w:  [1.25689217 1.35440712 2.07982155]
12.831287504472943  -  95.4618  =  -82.63051249552706
training  [-1.7119, -1.1275, -4.577]  w:  [1.25689217 1.35440712 2.07982155]
-13.198110944415323  -  1.4655  =  -14.663610944415323
training  [1.5381, -3.5781, 4.7296]  w:  [1.25689217 1.35440712 2.07982155]
6.923745718065884  -  69.9473  =  -63.02355428193411
training  [2.4913, -4.7487, -3.1079]  w:  [1.25689217 1.35440712 2.07982155]
-9.764255005718224  -  3.9825  =  -13.746755005718224
training  [0.8319, -0.7889, 1.6712]  w:  [1.25689217 1.35440712 2.07982155]
3.4529145868350626  -  58.8336  =  -55.38068541316493
training  [2.4003, -3.159, 0.8644]  w:  [1.25689217 1.35440712 2.07982155]
0.5361439295929062  -  39.0041  =  -38.4679560704071
training  [-2.6517, 2.2578, 1.7511]  w:  [1.25689217 1.35440712 2.07982155]
3.367054937698323  -  54.4525  =  -51.08544506230168
training  [2.3496, -1.2964, -1.3898]  w:  [1.25689217 1.35440712 2.07982155]
-1.6931955337827889  -  33.888  =  -35.58119553378279
training  [4.706, 3.4156, 1.2028]  w:  [1.25689217 1.35440712 2.07982155]
13.042656852609058  -  98.4665  =  -85.42384314739094
training  [3.6693, 2.3423, 3.1115]  w:  [1.25689217 1.35440712 2.07982155]
14.255706966399988  -  98.3069  =  -84.05119303360001
training  [-4.1377, 0.7103, -4.8074]  w:  [1.25689217 1.35440712 2.07982155]
-14.237141448756535  -  0.9782  =  -15.215341448756535
training  [-1.3356, -3.2314, -4.1613]  w:  [1.25689217 1.35440712 2.07982155]
-14.710097740806763  -  0.7659  =  -15.475997740806763
training  [-1.308, 4.5738, 4.748]  w:  [1.25689217 1.35440712 2.07982155]
14.425765021008372  -  97.0884  =  -82.66263497899162
training  [1.8503, -2.3468, 1.5135]  w:  [1.25689217 1.35440712 2.07982155]
2.2949148638524806  -  50.2125  =  -47.917585136147515
training  [0.9794, 4.2458, -2.6876]  w:  [1.25689217 1.35440712 2.07982155]
1.3918135453364133  -  68.3262  =  -66.93438645466358
training  [2.8936, -2.7623, -0.9651]  w:  [1.25689217 1.35440712 2.07982155]
-2.1115713782175414  -  28.5596  =  -30.67117137821754
training  [-1.3235, -1.2644, -3.7798]  w:  [1.25689217 1.35440712 2.07982155]
-11.237318624306859  -  2.4511  =  -13.688418624306859
training  [-2.9397, -4.125, -2.3156]  w:  [1.25689217 1.35440712 2.07982155]
-14.097850041591023  -  0.554  =  -14.651850041591024
training  [-4.1333, 1.4012, -2.4215]  w:  [1.25689217 1.35440712 2.07982155]
-8.333605018858204  -  4.4072  =  -12.740805018858204
training  [2.7193, -3.1938, -1.6833]  w:  [1.25689217 1.35440712 2.07982155]
-4.4088021889388695  -  17.0949  =  -21.503702188938867
training  [-2.9433, -4.5495, -3.4777]  w:  [1.25689217 1.35440712 2.07982155]
-17.094281293578078  -  0.2509  =  -17.34518129357808
training  [-1.1173, 2.2317, -1.5199]  w:  [1.25689217 1.35440712 2.07982155]
-1.5428160216489057  -  33.1206  =  -34.66341602164891
training  [0.5178, -1.5256, -3.7834]  w:  [1.25689217 1.35440712 2.07982155]
-9.284261571558922  -  5.237  =  -14.521261571558922
training  [-2.7105, 1.6062, 3.8415]  w:  [1.25689217 1.35440712 2.07982155]
6.7582769595576195  -  70.4458  =  -63.687523040442386
training  [1.4194, -1.1613, -4.0572]  w:  [1.25689217 1.35440712 2.07982155]
-8.227092218683849  -  8.3206  =  -16.54769221868385
training  [-0.1552, 1.2735, 4.3004]  w:  [1.25689217 1.35440712 2.07982155]
10.473832376542555  -  90.1085  =  -79.63466762345745
training  [-3.4815, -4.7835, -1.0098]  w:  [1.25689217 1.35440712 2.07982155]
-12.954880331084782  -  0.5839  =  -13.538780331084782
training  [2.8193, 4.1057, -4.526]  w:  [1.25689217 1.35440712 2.07982155]
-0.30892692137881106  -  66.8081  =  -67.11702692137881
training  [-3.9939, 3.0056, -1.5763]  w:  [1.25689217 1.35440712 2.07982155]
-4.227518299546055  -  14.4018  =  -18.629318299546057
training  [-2.0593, 2.4585, 2.3597]  w:  [1.25689217 1.35440712 2.07982155]
5.649246759695316  -  70.6698  =  -65.02055324030468
training  [-2.6263, 3.1311, 2.9468]  w:  [1.25689217 1.35440712 2.07982155]
7.068626357545743  -  77.309  =  -70.24037364245426
training  [0.3087, -1.1669, 0.4491]  w:  [1.25689217 1.35440712 2.07982155]
-0.25840719758628994  -  33.0798  =  -33.338207197586286
training  [-4.085, 1.1728, 1.8622]  w:  [1.25689217 1.35440712 2.07982155]
0.3270878433045086  -  26.4056  =  -26.078512156695492
training  [-0.9468, 0.7549, 3.9363]  w:  [1.25689217 1.35440712 2.07982155]
8.019217979710179  -  79.7738  =  -71.75458202028982
training  [-3.9515, 0.3005, -4.4521]  w:  [1.25689217 1.35440712 2.07982155]
-13.819183568784311  -  1.0441  =  -14.863283568784311
training  [-3.8772, -2.2493, -1.9634]  w:  [1.25689217 1.35440712 2.07982155]
-12.003211869345087  -  1.0509  =  -13.054111869345087
training  [2.8443, -2.5137, -4.5381]  w:  [1.25689217 1.35440712 2.07982155]
-9.268032936080557  -  6.8897  =  -16.157732936080556
training  [-2.0843, -0.4836, -3.0452]  w:  [1.25689217 1.35440712 2.07982155]
-9.608204200471782  -  3.5346  =  -13.142804200471783
training  [1.0353, -2.7229, 2.2017]  w:  [1.25689217 1.35440712 2.07982155]
2.1924884173883386  -  43.9562  =  -41.76371158261166
training  [4.6442, 3.0445, 2.2175]  w:  [1.25689217 1.35440712 2.07982155]
14.572755357679341  -  98.8492  =  -84.27644464232066
training  [-0.6752, 4.861, 3.778]  w:  [1.25689217 1.35440712 2.07982155]
13.592685209952577  -  97.017  =  -83.42431479004742
training  [1.9475, -4.7001, 0.8243]  w:  [1.25689217 1.35440712 2.07982155]
-2.203654498084185  -  18.7839  =  -20.987554498084183
training  [2.581, 0.3566, -4.2932]  w:  [1.25689217 1.35440712 2.07982155]
-5.202069596047597  -  23.5455  =  -28.747569596047597
training  [-0.6736, -4.1292, 4.2274]  w:  [1.25689217 1.35440712 2.07982155]
2.352977166124618  -  31.2667  =  -28.913722833875383
training  [1.555, 3.0209, 3.0037]  w:  [1.25689217 1.35440712 2.07982155]
12.293155762613381  -  96.4078  =  -84.11464423738661
training  [-3.9024, 4.8914, -2.1405]  w:  [1.25689217 1.35440712 2.07982155]
-2.7318070388467435  -  25.4308  =  -28.162607038846744
training  [4.3376, -4.3305, 0.4366]  w:  [1.25689217 1.35440712 2.07982155]
0.49468553102996293  -  43.0907  =  -42.59601446897003
training  [-3.1254, 4.394, 4.8478]  w:  [1.25689217 1.35440712 2.07982155]
12.10553298467523  -  92.8121  =  -80.70656701532477
training  [-2.3382, -4.8182, 2.1568]  w:  [1.25689217 1.35440712 2.07982155]
-4.978910534720915  -  4.7434  =  -9.722310534720915
training  [2.9783, 1.8384, 3.3897]  w:  [1.25689217 1.35440712 2.07982155]
13.283315085281338  -  97.3486  =  -84.06528491471866
training  [-0.124, 2.8374, -0.6674]  w:  [1.25689217 1.35440712 2.07982155]
2.2990672285591582  -  62.785  =  -60.48593277144084
training  [2.6896, 0.3414, -0.2938]  w:  [1.25689217 1.35440712 2.07982155]
3.231880195963638  -  70.4455  =  -67.21361980403636
training  [-1.0399, 3.8536, 0.6071]  w:  [1.25689217 1.35440712 2.07982155]
5.174960765345293  -  77.0369  =  -71.86193923465471
training  [-2.2706, 3.99, -2.3091]  w:  [1.25689217 1.35440712 2.07982155]
-2.252330887515094  -  31.1134  =  -33.36573088751509
training  [-4.6277, 1.2594, 2.4902]  w:  [1.25689217 1.35440712 2.07982155]
1.068392050809253  -  28.1093  =  -27.040907949190746
training  [1.7329, -3.6213, 0.0389]  w:  [1.25689217 1.35440712 2.07982155]
-2.645741000459846  -  19.3919  =  -22.037641000459846
training  [-0.7044, -2.822, 1.4681]  w:  [1.25689217 1.35440712 2.07982155]
-1.6541057193891744  -  17.8122  =  -19.466305719389176
training  [-0.4826, -3.1786, -1.9225]  w:  [1.25689217 1.35440712 2.07982155]
-8.910151548371289  -  3.5851  =  -12.49525154837129
training  [1.0986, -4.5818, -3.6128]  w:  [1.25689217 1.35440712 2.07982155]
-12.338780079086355  -  1.7158  =  -14.054580079086355
training  [-4.406, -3.9306, -0.2443]  w:  [1.25689217 1.35440712 2.07982155]
-11.369599916218096  -  0.8241  =  -12.193699916218096
training  [-1.8419, 1.1644, -1.3754]  w:  [1.25689217 1.35440712 2.07982155]
-3.598584590705962  -  17.8517  =  -21.450284590705962
training  [2.7272, 4.3966, 2.8811]  w:  [1.25689217 1.35440712 2.07982155]
15.37475651333284  -  98.904  =  -83.52924348666716
training  [1.9643, -1.4554, 2.803]  w:  [1.25689217 1.35440712 2.07982155]
6.327448959661945  -  76.0591  =  -69.73165104033805
training  [-3.7467, -0.8937, 1.6851]  w:  [1.25689217 1.35440712 2.07982155]
-2.4149242416809584  -  12.1571  =  -14.572024241680959
training  [-3.6985, 4.8435, -3.665]  w:  [1.25689217 1.35440712 2.07982155]
-5.711090773425978  -  14.6793  =  -20.390390773425977
238316.37353044612
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.26718367 1.31550476 2.09479373]
9.647422578109461  -  87.3174  =  -77.66997742189055
training  [-4.1793, -4.9218, 1.7664]  w:  [1.26718367 1.31550476 2.09479373]
-8.070348419657265  -  1.5257  =  -9.596048419657265
training  [-3.9429, -0.7689, 4.883]  w:  [1.26718367 1.31550476 2.09479373]
4.221007689718737  -  39.7859  =  -35.56489231028126
training  [-3.5796, 1.5557, 2.6683]  w:  [1.26718367 1.31550476 2.09479373]
3.1000582086087998  -  45.5674  =  -42.4673417913912
training  [-3.3354, 2.2292, -1.633]  w:  [1.26718367 1.31550476 2.09479373]
-4.714839371110449  -  13.3589  =  -18.07373937111045
training  [1.2096, 0.3121, 1.6238]  w:  [1.26718367 1.31550476 2.09479373]
5.344880474182082  -  74.5119  =  -69.16701952581792
training  [0.7371, -3.9118, -2.5583]  w:  [1.26718367 1.31550476 2.09479373]
-9.5710612630212  -  3.3358  =  -12.906861263021199
training  [-4.4792, 1.3177, -2.0449]  w:  [1.26718367 1.31550476 2.09479373]
-8.226172188125863  -  4.2974  =  -12.523572188125863
training  [4.312, -3.735, 1.8018]  w:  [1.26718367 1.31550476 2.09479373]
4.32508505454434  -  66.5833  =  -62.258214945455656
training  [2.2866, -3.657, 0.2785]  w:  [1.26718367 1.31550476 2.09479373]
-1.3298586811348652  -  26.0005  =  -27.330358681134864
training  [2.3784, -4.0141, -0.8841]  w:  [1.26718367 1.31550476 2.09479373]
-4.118705167302693  -  14.6809  =  -18.799605167302694
training  [-4.366, -3.5797, 1.0264]  w:  [1.26718367 1.31550476 2.09479373]
-8.091540031057253  -  1.8713  =  -9.962840031057253
training  [3.6044, -3.3175, 2.5052]  w:  [1.26718367 1.31550476 2.09479373]
5.451127039686274  -  71.0139  =  -65.56277296031374
training  [4.3441, -3.0375, 0.8353]  w:  [1.26718367 1.31550476 2.09479373]
3.2587080788373886  -  63.8979  =  -60.63919192116261
training  [4.844, -1.8252, 0.5179]  w:  [1.26718367 1.31550476 2.09479373]
4.822072091176327  -  78.0461  =  -73.22402790882367
training  [3.5894, -1.8357, 0.8357]  w:  [1.26718367 1.31550476 2.09479373]
3.884176104022588  -  68.8838  =  -64.99962389597741
training  [2.8556, -2.8244, 0.1182]  w:  [1.26718367 1.31550476 2.09479373]
0.1506626597597933  -  39.5252  =  -39.3745373402402
training  [0.1338, -2.4896, -4.1741]  w:  [1.26718367 1.31550476 2.09479373]
-11.849410013850795  -  2.2644  =  -14.113810013850795
training  [-3.224, 3.9292, 2.1957]  w:  [1.26718367 1.31550476 2.09479373]
5.683019761522804  -  72.1211  =  -66.4380802384772
training  [-1.0141, 2.0322, 4.9616]  w:  [1.26718367 1.31550476 2.09479373]
11.781846413558258  -  92.3427  =  -80.56085358644174
training  [-3.6607, 0.5574, -1.4547]  w:  [1.26718367 1.31550476 2.09479373]
-6.952813361823537  -  5.8471  =  -12.799913361823538
training  [-4.6911, -3.1557, 4.7126]  w:  [1.26718367 1.31550476 2.09479373]
-0.2238987579996632  -  11.2337  =  -11.457598757999664
training  [4.3914, -2.8797, -1.5355]  w:  [1.26718367 1.31550476 2.09479373]
-1.4401044680219885  -  37.475  =  -38.91510446802199
training  [-1.9869, -4.2265, 3.8654]  w:  [1.26718367 1.31550476 2.09479373]
0.019467576674353282  -  15.7889  =  -15.769432423325647
training  [-2.0447, 4.138, -0.4531]  w:  [1.26718367 1.31550476 2.09479373]
1.9033972171124818  -  57.936  =  -56.032602782887516
training  [-1.6706, 2.0672, -0.8657]  w:  [1.26718367 1.31550476 2.09479373]
-1.2110085315612469  -  32.4185  =  -33.62950853156125
training  [-0.3293, 0.5779, -2.8227]  w:  [1.26718367 1.31550476 2.09479373]
-5.570027655370547  -  14.3434  =  -19.913427655370548
training  [1.482, -1.8657, -3.7435]  w:  [1.26718367 1.31550476 2.09479373]
-8.41823138144129  -  7.1519  =  -15.57013138144129
training  [-4.7477, -3.338, -1.9109]  w:  [1.26718367 1.31550476 2.09479373]
-14.410304174623358  -  0.4077  =  -14.818004174623358
training  [3.4221, 1.225, 2.261]  w:  [1.26718367 1.31550476 2.09479373]
10.684251217553278  -  95.0454  =  -84.36114878244672
training  [0.5903, 4.8793, 2.8287]  w:  [1.26718367 1.31550476 2.09479373]
13.092303955710621  -  97.4647  =  -84.37239604428937
training  [3.541, -3.2957, 1.9379]  w:  [1.26718367 1.31550476 2.09479373]
4.211089112951037  -  64.3732  =  -60.16211088704896
training  [-1.5212, -2.4221, -4.902]  w:  [1.26718367 1.31550476 2.09479373]
-15.38260278047446  -  0.7227  =  -16.10530278047446
training  [-0.5397, -1.032, 3.4321]  w:  [1.26718367 1.31550476 2.09479373]
5.148041632142123  -  60.5921  =  -55.44405836785788
training  [-4.4576, -4.2601, 4.2233]  w:  [1.26718367 1.31550476 2.09479373]
-2.405837406399492  -  6.0247  =  -8.430537406399491
training  [-3.2289, 1.841, 2.7095]  w:  [1.26718367 1.31550476 2.09479373]
4.006078533804024  -  54.0111  =  -50.00502146619598
training  [1.6281, -0.9761, -4.5734]  w:  [1.26718367 1.31550476 2.09479373]
-8.801292129060428  -  7.8658  =  -16.66709212906043
training  [-1.6917, 4.8284, -1.2181]  w:  [1.26718367 1.31550476 2.09479373]
1.6564203357729288  -  61.2837  =  -59.627279664227075
training  [3.9849, -0.9782, 2.0434]  w:  [1.26718367 1.31550476 2.09479373]
8.043274975454985  -  88.3402  =  -80.296925024545
training  [-3.8184, 1.2067, 2.2951]  w:  [1.26718367 1.31550476 2.09479373]
1.5565665629896905  -  34.1122  =  -32.555633437010314
training  [4.8842, -3.4563, -2.7572]  w:  [1.26718367 1.31550476 2.09479373]
-4.133365906822214  -  23.7819  =  -27.915265906822214
training  [0.3998, -1.1865, -2.3095]  w:  [1.26718367 1.31550476 2.09479373]
-5.892152500756895  -  11.4246  =  -17.316752500756895
training  [2.0692, -3.3887, 1.7303]  w:  [1.26718367 1.31550476 2.09479373]
1.7888270607464252  -  42.6881  =  -40.89927293925357
training  [4.9949, 2.5811, -0.2251]  w:  [1.26718367 1.31550476 2.09479373]
9.25336700507048  -  95.9901  =  -86.73673299492953
training  [-2.1215, 3.7111, 1.2372]  w:  [1.26718367 1.31550476 2.09479373]
4.785318377061374  -  71.3692  =  -66.58388162293863
training  [-0.8548, -1.4922, -2.6356]  w:  [1.26718367 1.31550476 2.09479373]
-8.567223180123875  -  4.7821  =  -13.349323180123875
training  [-0.3516, 1.8554, -3.2288]  w:  [1.26718367 1.31550476 2.09479373]
-4.768424250673867  -  20.3834  =  -25.15182425067387
training  [2.6396, -2.0585, 3.2964]  w:  [1.26718367 1.31550476 2.09479373]
7.5421695331582015  -  80.826  =  -73.28383046684179
training  [3.182, 0.3063, 2.6692]  w:  [1.26718367 1.31550476 2.09479373]
10.026540993329075  -  92.9483  =  -82.92175900667092
training  [-3.9978, 3.3242, 4.3448]  w:  [1.26718367 1.31550476 2.09479373]
8.40851386845349  -  79.1768  =  -70.76828613154652
training  [-3.2188, 0.9749, -3.9211]  w:  [1.26718367 1.31550476 2.09479373]
-11.010220925126719  -  2.7053  =  -13.715520925126718
training  [-1.4037, -1.6469, -3.1777]  w:  [1.26718367 1.31550476 2.09479373]
-10.601876568827588  -  2.6234  =  -13.225276568827589
training  [-4.433, -2.0077, -4.009]  w:  [1.26718367 1.31550476 2.09479373]
-16.656592219827118  -  0.3253  =  -16.981892219827117
training  [0.2189, -0.4741, -0.1024]  w:  [1.26718367 1.31550476 2.09479373]
-0.560801181155776  -  33.6531  =  -34.21390118115578
training  [-1.6415, -0.7735, -3.0675]  w:  [1.26718367 1.31550476 2.09479373]
-9.523404715605702  -  3.7641  =  -13.287504715605703
training  [-3.2433, -1.4039, 3.9589]  w:  [1.26718367 1.31550476 2.09479373]
2.3363849717129073  -  30.0658  =  -27.729415028287093
training  [-2.9105, 0.5832, -4.0091]  w:  [1.26718367 1.31550476 2.09479373]
-11.319173263571638  -  2.4887  =  -13.807873263571638
training  [4.0515, 2.4255, -4.5583]  w:  [1.26718367 1.31550476 2.09479373]
-1.2239468247551972  -  61.2853  =  -62.509246824755195
training  [1.7539, -0.7567, 0.573]  w:  [1.26718367 1.31550476 2.09479373]
2.4273877988593133  -  57.0797  =  -54.65231220114069
training  [-0.3153, -0.7064, 2.725]  w:  [1.26718367 1.31550476 2.09479373]
4.379497349721326  -  58.7004  =  -54.320902650278676
training  [4.1213, -3.7513, -1.8806]  w:  [1.26718367 1.31550476 2.09479373]
-3.651878048437724  -  22.1789  =  -25.830778048437722
training  [-3.9599, -4.7557, -3.2102]  w:  [1.26718367 1.31550476 2.09479373]
-17.99877348091713  -  0.1558  =  -18.15457348091713
training  [2.4555, -2.0981, -1.6104]  w:  [1.26718367 1.31550476 2.09479373]
-3.021946867435867  -  24.4796  =  -27.50154686743587
training  [2.3627, -1.8248, -2.8985]  w:  [1.26718367 1.31550476 2.09479373]
-5.478317869972459  -  15.7052  =  -21.18351786997246
training  [0.6186, 1.5369, 0.1015]  w:  [1.26718367 1.31550476 2.09479373]
3.0183006562728947  -  65.2154  =  -62.19709934372711
training  [-3.1581, 4.5694, 4.0636]  w:  [1.26718367 1.31550476 2.09479373]
10.521578532789954  -  90.3564  =  -79.83482146721003
training  [0.9721, 4.3573, 1.2892]  w:  [1.26718367 1.31550476 2.09479373]
9.664486240434865  -  94.3178  =  -84.65331375956514
training  [-2.0006, -0.4211, -3.9847]  w:  [1.26718367 1.31550476 2.09479373]
-11.436211307164964  -  2.4051  =  -13.841311307164965
training  [-3.6588, -2.5952, -1.0915]  w:  [1.26718367 1.31550476 2.09479373]
-10.336836948057869  -  1.5176  =  -11.854436948057868
training  [-2.874, 2.639, -4.4538]  w:  [1.26718367 1.31550476 2.09479373]
-9.500061139077204  -  5.497  =  -14.997061139077204
training  [3.9494, 2.5933, 0.0128]  w:  [1.26718367 1.31550476 2.09479373]
8.442927062663086  -  94.1462  =  -85.7032729373369
training  [-4.2855, 2.4065, -0.6828]  w:  [1.26718367 1.31550476 2.09479373]
-3.695078577275652  -  14.4193  =  -18.11437857727565
training  [-2.5751, 2.4369, 4.9756]  w:  [1.26718367 1.31550476 2.09479373]
10.36548459050601  -  87.1991  =  -76.83361540949399
training  [-4.4625, -3.9408, 3.116]  w:  [1.26718367 1.31550476 2.09479373]
-4.3115710376872185  -  4.1344  =  -8.445971037687219
training  [-0.5828, 1.8156, -0.1435]  w:  [1.26718367 1.31550476 2.09479373]
1.3493129044045433  -  51.1166  =  -49.76728709559546
training  [-4.8672, -0.3674, 3.9445]  w:  [1.26718367 1.31550476 2.09479373]
1.6119610636011688  -  24.1396  =  -22.527638936398834
training  [3.9719, -2.8784, -3.6245]  w:  [1.26718367 1.31550476 2.09479373]
-6.346001974541115  -  14.6104  =  -20.956401974541116
training  [-3.0334, -4.0148, -1.1]  w:  [1.26718367 1.31550476 2.09479373]
-11.429636589049549  -  1.021  =  -12.450636589049548
training  [-4.0663, 3.2357, 4.2736]  w:  [1.26718367 1.31550476 2.09479373]
8.056140301310112  -  77.2328  =  -69.17665969868989
training  [-1.9263, -3.2499, 4.1749]  w:  [1.26718367 1.31550476 2.09479373]
2.029319520900044  -  26.8814  =  -24.852080479099953
training  [-0.4394, -3.3643, 2.1357]  w:  [1.26718367 1.31550476 2.09479373]
-0.5087022048047425  -  20.85  =  -21.358702204804743
training  [-3.9833, 1.6599, 1.1834]  w:  [1.26718367 1.31550476 2.09479373]
-0.38498746046820065  -  25.5397  =  -25.9246874604682
training  [4.9539, 3.9439, -1.5671]  w:  [1.26718367 1.31550476 2.09479373]
8.182969175104569  -  95.9509  =  -87.76793082489543
training  [-1.6791, 0.1656, 4.3603]  w:  [1.26718367 1.31550476 2.09479373]
7.224048605463036  -  71.5733  =  -64.34925139453696
training  [-2.0265, 2.027, -3.7523]  w:  [1.26718367 1.31550476 2.09479373]
-7.761714087047153  -  8.503  =  -16.264714087047153
training  [-4.3795, -3.4641, 2.3059]  w:  [1.26718367 1.31550476 2.09479373]
-5.276286076265276  -  3.6654  =  -8.941686076265276
training  [-2.0176, 4.5346, 1.4648]  w:  [1.26718367 1.31550476 2.09479373]
6.477071988044876  -  81.6212  =  -75.14412801195513
training  [-4.5365, 0.4088, 3.3315]  w:  [1.26718367 1.31550476 2.09479373]
1.7680049428100624  -  28.9449  =  -27.176895057189938
training  [0.0543, 1.7973, -1.0172]  w:  [1.26718367 1.31550476 2.09479373]
0.30234059916819067  -  47.9317  =  -47.62935940083181
training  [2.6143, -4.6344, 2.4982]  w:  [1.26718367 1.31550476 2.09479373]
2.4494367049895502  -  43.5132  =  -41.063763295010446
training  [1.3107, 3.092, 3.3522]  w:  [1.26718367 1.31550476 2.09479373]
12.750605928737368  -  96.6993  =  -83.94869407126262
training  [-4.1011, 2.4862, -1.7754]  w:  [1.26718367 1.31550476 2.09479373]
-5.645335812886795  -  10.0187  =  -15.664035812886796
training  [-4.1914, -3.7981, 0.5226]  w:  [1.26718367 1.31550476 2.09479373]
-9.21295308584697  -  1.4295  =  -10.64245308584697
training  [2.7724, 0.2505, 4.7913]  w:  [1.26718367 1.31550476 2.09479373]
13.879459179605952  -  96.7925  =  -82.91304082039406
training  [4.0513, -1.7417, 0.4931]  w:  [1.26718367 1.31550476 2.09479373]
3.8754693568475718  -  71.1234  =  -67.24793064315243
training  [0.3377, 0.4645, -1.6958]  w:  [1.26718367 1.31550476 2.09479373]
-2.5133713260921695  -  27.9534  =  -30.466771326092168
training  [-3.9085, -1.0112, 1.1947]  w:  [1.26718367 1.31550476 2.09479373]
-3.780375728239201  -  8.608  =  -12.388375728239202
training  [3.2581, -0.8491, -1.3936]  w:  [1.26718367 1.31550476 2.09479373]
0.09231148065275763  -  50.1924  =  -50.10008851934724
training  [-1.619, -3.1926, 2.5651]  w:  [1.26718367 1.31550476 2.09479373]
-0.8780954676492279  -  16.4754  =  -17.35349546764923
training  [-2.0603, -2.4461, -0.861]  w:  [1.26718367 1.31550476 2.09479373]
-7.632252130696184  -  3.9784  =  -11.610652130696185
training  [2.4631, -4.7946, -0.0765]  w:  [1.26718367 1.31550476 2.09479373]
-3.3463707584838818  -  15.394  =  -18.74037075848388
training  [-4.8966, 4.2368, 1.9474]  w:  [1.26718367 1.31550476 2.09479373]
3.4480403313386  -  53.5883  =  -50.1402596686614
training  [-4.5155, 1.537, 4.7273]  w:  [1.26718367 1.31550476 2.09479373]
6.202681369919887  -  59.2523  =  -53.04961863008011
training  [1.6792, 4.3261, -1.7225]  w:  [1.26718367 1.31550476 2.09479373]
4.21057777591536  -  83.7729  =  -79.56232222408465
training  [1.0347, -3.3649, 3.378]  w:  [1.26718367 1.31550476 2.09479373]
3.960826201278479  -  50.5979  =  -46.637073798721524
training  [0.261, 4.211, 2.3907]  w:  [1.26718367 1.31550476 2.09479373]
10.878348882464568  -  94.9375  =  -84.05915111753544
training  [2.2971, 2.9466, 4.5417]  w:  [1.26718367 1.31550476 2.09479373]
16.301038658485766  -  98.7784  =  -82.47736134151424
training  [2.0725, 0.7739, -4.6808]  w:  [1.26718367 1.31550476 2.09479373]
-6.161003214546406  -  19.5109  =  -25.671903214546404
training  [2.8138, -0.5996, -1.4313]  w:  [1.26718367 1.31550476 2.09479373]
-0.22145351035072736  -  47.2879  =  -47.50935351035073
training  [-2.1202, -2.4239, 1.6265]  w:  [1.26718367 1.31550476 2.09479373]
-2.4681528117088027  -  12.3599  =  -14.828052811708803
training  [1.9253, 2.5195, -2.185]  w:  [1.26718367 1.31550476 2.09479373]
1.1769986684507394  -  65.2467  =  -64.06970133154927
training  [0.5667, -2.7133, -2.6962]  w:  [1.26718367 1.31550476 2.09479373]
-8.499228956992344  -  5.1106  =  -13.609828956992343
training  [-1.0348, -4.3581, 2.1113]  w:  [1.26718367 1.31550476 2.09479373]
-2.621644965467773  -  10.5192  =  -13.140844965467773
training  [-4.3841, 2.6733, 1.2457]  w:  [1.26718367 1.31550476 2.09479373]
0.5707635011642198  -  32.4639  =  -31.893136498835783
training  [2.8018, 1.712, 0.9061]  w:  [1.26718367 1.31550476 2.09479373]
7.700631974186006  -  90.1138  =  -82.41316802581399
training  [-1.6242, 2.1521, 1.6044]  w:  [1.26718367 1.31550476 2.09479373]
4.133825149588562  -  63.7879  =  -59.65407485041144
training  [1.0787, 1.4206, -4.5245]  w:  [1.26718367 1.31550476 2.09479373]
-6.242177156923476  -  18.0555  =  -24.297677156923474
training  [2.4125, -0.8095, -1.5122]  w:  [1.26718367 1.31550476 2.09479373]
-1.1755675814434103  -  38.8276  =  -40.00316758144341
training  [-3.9519, -1.0924, -0.4866]  w:  [1.26718367 1.31550476 2.09479373]
-7.464167192759607  -  3.6777  =  -11.141867192759607
training  [-3.7211, 3.1614, -2.591]  w:  [1.26718367 1.31550476 2.09479373]
-5.984090970452951  -  11.1518  =  -17.13589097045295
training  [0.4954, -1.8257, 2.1505]  w:  [1.26718367 1.31550476 2.09479373]
2.730899670138565  -  47.7531  =  -45.02220032986144
training  [-0.1477, 3.1454, 3.5618]  w:  [1.26718367 1.31550476 2.09479373]
11.41186198137578  -  94.1572  =  -82.74533801862422
training  [3.9048, 2.8907, -2.1849]  w:  [1.26718367 1.31550476 2.09479373]
4.1739135968359244  -  85.8791  =  -81.70518640316406
training  [2.9896, 3.5226, 2.3105]  w:  [1.26718367 1.31550476 2.09479373]
13.262390315160541  -  98.038  =  -84.77560968483945
training  [2.3434, 0.0564, -3.6224]  w:  [1.26718367 1.31550476 2.09479373]
-4.544468137005958  -  24.7629  =  -29.307368137005955
training  [-4.4867, 1.3566, 3.3672]  w:  [1.26718367 1.31550476 2.09479373]
3.1527302415799463  -  40.5785  =  -37.42576975842005
training  [-4.2711, 4.5089, -3.614]  w:  [1.26718367 1.31550476 2.09479373]
-7.0513733114344515  -  10.0825  =  -17.13387331143445
training  [-4.1147, -0.5604, 0.8821]  w:  [1.26718367 1.31550476 2.09479373]
-4.103471975371434  -  8.344  =  -12.447471975371434
training  [2.9835, -4.3998, -1.3384]  w:  [1.26718367 1.31550476 2.09479373]
-4.810987308086028  -  13.2692  =  -18.08018730808603
training  [4.4301, 3.6675, 3.0676]  w:  [1.26718367 1.31550476 2.09479373]
16.864353372919616  -  99.3834  =  -82.51904662708037
training  [1.8372, 1.3119, 0.0378]  w:  [1.26718367 1.31550476 2.09479373]
4.1330637472318585  -  74.9026  =  -70.76953625276815
training  [-3.6792, -1.4493, -0.1041]  w:  [1.26718367 1.31550476 2.09479373]
-6.786851251958231  -  4.2442  =  -11.031051251958232
training  [2.2272, 4.97, 3.7705]  w:  [1.26718367 1.31550476 2.09479373]
17.25874993142048  -  99.3199  =  -82.06115006857952
training  [-3.8965, -2.7583, -1.4686]  w:  [1.26718367 1.31550476 2.09479373]
-11.642552051533876  -  1.0337  =  -12.676252051533876
training  [-3.8251, 1.5245, -0.5056]  w:  [1.26718367 1.31550476 2.09479373]
-3.900744966507557  -  12.9762  =  -16.87694496650756
training  [1.4072, 1.0499, 4.6353]  w:  [1.26718367 1.31550476 2.09479373]
12.874326715237729  -  95.4618  =  -82.58747328476227
training  [-1.7119, -1.1275, -4.577]  w:  [1.26718367 1.31550476 2.09479373]
-13.240394275341263  -  1.4655  =  -14.705894275341263
training  [1.5381, -3.5781, 4.7296]  w:  [1.26718367 1.31550476 2.09479373]
7.149584058400789  -  69.9473  =  -62.79771594159921
training  [2.4913, -4.7487, -3.1079]  w:  [1.26718367 1.31550476 2.09479373]
-9.600412237798231  -  3.9825  =  -13.582912237798231
training  [0.8319, -0.7889, 1.6712]  w:  [1.26718367 1.31550476 2.09479373]
3.5171876785442198  -  58.8336  =  -55.31641232145578
training  [2.4003, -3.159, 0.8644]  w:  [1.26718367 1.31550476 2.09479373]
0.6966811242560986  -  39.0041  =  -38.307418875743906
training  [-2.6517, 2.2578, 1.7511]  w:  [1.26718367 1.31550476 2.09479373]
3.2781490201375685  -  54.4525  =  -51.17435097986243
training  [2.3496, -1.2964, -1.3898]  w:  [1.26718367 1.31550476 2.09479373]
-1.6393899510330772  -  33.888  =  -35.52738995103307
training  [4.706, 3.4156, 1.2028]  w:  [1.26718367 1.31550476 2.09479373]
12.97622234157884  -  98.4665  =  -85.49027765842115
training  [3.6693, 2.3423, 3.1115]  w:  [1.26718367 1.31550476 2.09479373]
14.248934565978614  -  98.3069  =  -84.05796543402138
training  [-4.1377, 0.7103, -4.8074]  w:  [1.26718367 1.31550476 2.09479373]
-14.379334249902676  -  0.9782  =  -15.357534249902676
training  [-1.3356, -3.2314, -4.1613]  w:  [1.26718367 1.31550476 2.09479373]
-14.660437777123972  -  0.7659  =  -15.426337777123972
training  [-1.308, 4.5738, 4.748]  w:  [1.26718367 1.31550476 2.09479373]
14.305460099084256  -  97.0884  =  -82.78293990091574
training  [1.8503, -2.3468, 1.5135]  w:  [1.26718367 1.31550476 2.09479373]
2.4279136868891142  -  50.2125  =  -47.784586313110886
training  [0.9794, 4.2458, -2.6876]  w:  [1.26718367 1.31550476 2.09479373]
1.1964821756210675  -  68.3262  =  -67.12971782437893
training  [2.8936, -2.7623, -0.9651]  w:  [1.26718367 1.31550476 2.09479373]
-1.9887815676829135  -  28.5596  =  -30.548381567682913
training  [-1.3235, -1.2644, -3.7798]  w:  [1.26718367 1.31550476 2.09479373]
-11.25834317364809  -  2.4511  =  -13.70944317364809
training  [-2.9397, -4.125, -2.3156]  w:  [1.26718367 1.31550476 2.09479373]
-14.002301367895514  -  0.554  =  -14.556301367895514
training  [-4.1333, 1.4012, -2.4215]  w:  [1.26718367 1.31550476 2.09479373]
-8.466908028365244  -  4.4072  =  -12.874108028365244
training  [2.7193, -3.1938, -1.6833]  w:  [1.26718367 1.31550476 2.09479373]
-4.28177284794132  -  17.0949  =  -21.376672847941318
training  [-2.9433, -4.5495, -3.4777]  w:  [1.26718367 1.31550476 2.09479373]
-16.999654800700377  -  0.2509  =  -17.250554800700378
training  [-1.1173, 2.2317, -1.5199]  w:  [1.26718367 1.31550476 2.09479373]
-1.6638893329073583  -  33.1206  =  -34.78448933290736
training  [0.5178, -1.5256, -3.7834]  w:  [1.26718367 1.31550476 2.09479373]
-9.276228978570927  -  5.237  =  -14.513228978570927
training  [-2.7105, 1.6062, 3.8415]  w:  [1.26718367 1.31550476 2.09479373]
6.725412538958386  -  70.4458  =  -63.72038746104162
training  [1.4194, -1.1613, -4.0572]  w:  [1.26718367 1.31550476 2.09479373]
-8.228052318045144  -  8.3206  =  -16.548652318045143
training  [-0.1552, 1.2735, 4.3004]  w:  [1.26718367 1.31550476 2.09479373]
10.487079388183481  -  90.1085  =  -79.62142061181652
training  [-3.4815, -4.7835, -1.0098]  w:  [1.26718367 1.31550476 2.09479373]
-12.819739710262315  -  0.5839  =  -13.403639710262315
training  [2.8193, 4.1057, -4.526]  w:  [1.26718367 1.31550476 2.09479373]
-0.5073976040446073  -  66.8081  =  -67.31549760404461
training  [-3.9939, 3.0056, -1.5763]  w:  [1.26718367 1.31550476 2.09479373]
-4.409147116022774  -  14.4018  =  -18.810947116022774
training  [-2.0593, 2.4585, 2.3597]  w:  [1.26718367 1.31550476 2.09479373]
5.567741901129063  -  70.6698  =  -65.10205809887093
training  [-2.6263, 3.1311, 2.9468]  w:  [1.26718367 1.31550476 2.09479373]
6.963910664681977  -  77.309  =  -70.34508933531802
training  [0.3087, -1.1669, 0.4491]  w:  [1.26718367 1.31550476 2.09479373]
-0.20311104325646756  -  33.0798  =  -33.28291104325647
training  [-4.085, 1.1728, 1.8622]  w:  [1.26718367 1.31550476 2.09479373]
0.26730357650376346  -  26.4056  =  -26.138296423496236
training  [-0.9468, 0.7549, 3.9363]  w:  [1.26718367 1.31550476 2.09479373]
8.039041623152178  -  79.7738  =  -71.73475837684782
training  [-3.9515, 0.3005, -4.4521]  w:  [1.26718367 1.31550476 2.09479373]
-13.938198288421216  -  1.0441  =  -14.982298288421216
training  [-3.8772, -2.2493, -1.9634]  w:  [1.26718367 1.31550476 2.09479373]
-11.985007421620681  -  1.0509  =  -13.035907421620681
training  [2.8443, -2.5137, -4.5381]  w:  [1.26718367 1.31550476 2.09479373]
-9.208917252689732  -  6.8897  =  -16.09861725268973
training  [-2.0843, -0.4836, -3.0452]  w:  [1.26718367 1.31550476 2.09479373]
-9.6564349145394  -  3.5346  =  -13.1910349145394
training  [1.0353, -2.7229, 2.2017]  w:  [1.26718367 1.31550476 2.09479373]
2.3420346999067236  -  43.9562  =  -41.614165300093276
training  [4.6442, 3.0445, 2.2175]  w:  [1.26718367 1.31550476 2.09479373]
14.535313775257322  -  98.8492  =  -84.31388622474267
training  [-0.6752, 4.861, 3.778]  w:  [1.26718367 1.31550476 2.09479373]
13.453196972865637  -  97.017  =  -83.56380302713436
training  [1.9475, -4.7001, 0.8243]  w:  [1.26718367 1.31550476 2.09479373]
-1.9884252637427744  -  18.7839  =  -20.772325263742772
training  [2.581, 0.3566, -4.2932]  w:  [1.26718367 1.31550476 2.09479373]
-5.253658403383487  -  23.5455  =  -28.799158403383487
training  [-0.6736, -4.1292, 4.2274]  w:  [1.26718367 1.31550476 2.09479373]
2.5699738398560372  -  31.2667  =  -28.696726160143964
training  [1.555, 3.0209, 3.0037]  w:  [1.26718367 1.31550476 2.09479373]
12.23661089472844  -  96.4078  =  -84.17118910527155
training  [-3.9024, 4.8914, -2.1405]  w:  [1.26718367 1.31550476 2.09479373]
-2.994303550739935  -  25.4308  =  -28.425103550739937
training  [4.3376, -4.3305, 0.4366]  w:  [1.26718367 1.31550476 2.09479373]
0.7143294627760804  -  43.0907  =  -42.37637053722392
training  [-3.1254, 4.394, 4.8478]  w:  [1.26718367 1.31550476 2.09479373]
11.975013150053197  -  92.8121  =  -80.8370868499468
training  [-2.3382, -4.8182, 2.1568]  w:  [1.26718367 1.31550476 2.09479373]
-4.783242791829641  -  4.7434  =  -9.52664279182964
training  [2.9783, 1.8384, 3.3897]  w:  [1.26718367 1.31550476 2.09479373]
13.293199414316389  -  97.3486  =  -84.05540058568361
training  [-0.124, 2.8374, -0.6674]  w:  [1.26718367 1.31550476 2.09479373]
2.17741710397374  -  62.785  =  -60.60758289602626
training  [2.6896, 0.3414, -0.2938]  w:  [1.26718367 1.31550476 2.09479373]
3.241880133900081  -  70.4455  =  -67.20361986609991
training  [-1.0399, 3.8536, 0.6071]  w:  [1.26718367 1.31550476 2.09479373]
5.023434134310744  -  77.0369  =  -72.01346586568926
training  [-2.2706, 3.99, -2.3091]  w:  [1.26718367 1.31550476 2.09479373]
-2.4654914514281585  -  31.1134  =  -33.578891451428156
training  [-4.6277, 1.2594, 2.4902]  w:  [1.26718367 1.31550476 2.09479373]
1.0090561752275278  -  28.1093  =  -27.100243824772473
training  [1.7329, -3.6213, 0.0389]  w:  [1.26718367 1.31550476 2.09479373]
-2.4864473395945197  -  19.3919  =  -21.87834733959452
training  [-0.7044, -2.822, 1.4681]  w:  [1.26718367 1.31550476 2.09479373]
-1.5295919418199597  -  17.8122  =  -19.34179194181996
training  [-0.4826, -3.1786, -1.9225]  w:  [1.26718367 1.31550476 2.09479373]
-8.82024723918445  -  3.5851  =  -12.40534723918445
training  [1.0986, -4.5818, -3.6128]  w:  [1.26718367 1.31550476 2.09479373]
-12.20332255060038  -  1.7158  =  -13.91912255060038
training  [-4.406, -3.9306, -0.2443]  w:  [1.26718367 1.31550476 2.09479373]
-11.265692398505134  -  0.8241  =  -12.089792398505134
training  [-1.8419, 1.1644, -1.3754]  w:  [1.26718367 1.31550476 2.09479373]
-3.683431162479146  -  17.8517  =  -21.535131162479146
training  [2.7272, 4.3966, 2.8811]  w:  [1.26718367 1.31550476 2.09479373]
15.274921788373325  -  98.904  =  -83.62907821162668
training  [1.9643, -1.4554, 2.803]  w:  [1.26718367 1.31550476 2.09479373]
6.446250093407092  -  76.0591  =  -69.61284990659291
training  [-3.7467, -0.8937, 1.6851]  w:  [1.26718367 1.31550476 2.09479373]
-2.3934867526368593  -  12.1571  =  -14.550586752636859
training  [-3.6985, 4.8435, -3.665]  w:  [1.26718367 1.31550476 2.09479373]
-5.99245052668895  -  14.6793  =  -20.67175052668895
238414.13718042008
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.35181245 1.1769094  2.16556175]
10.90681237057544  -  87.3174  =  -76.41058762942457
training  [-4.1793, -4.9218, 1.7664]  w:  [1.35181245 1.1769094  2.16556175]
-7.616894171633026  -  1.5257  =  -9.142594171633027
training  [-3.9429, -0.7689, 4.883]  w:  [1.35181245 1.1769094  2.16556175]
4.339451070052066  -  39.7859  =  -35.446448929947934
training  [-3.5796, 1.5557, 2.6683]  w:  [1.35181245 1.1769094  2.16556175]
2.770338518712351  -  45.5674  =  -42.79706148128765
training  [-3.3354, 2.2292, -1.633]  w:  [1.35181245 1.1769094  2.16556175]
-5.421631143028388  -  13.3589  =  -18.780531143028387
training  [1.2096, 0.3121, 1.6238]  w:  [1.35181245 1.1769094  2.16556175]
5.5189049251443665  -  74.5119  =  -68.99299507485563
training  [0.7371, -3.9118, -2.5583]  w:  [1.35181245 1.1769094  2.16556175]
-9.147569844028876  -  3.3358  =  -12.483369844028875
training  [-4.4792, 1.3177, -2.0449]  w:  [1.35181245 1.1769094  2.16556175]
-8.932582021365475  -  4.2974  =  -13.229982021365474
training  [4.312, -3.735, 1.8018]  w:  [1.35181245 1.1769094  2.16556175]
5.335167831537821  -  66.5833  =  -61.24813216846217
training  [2.2866, -3.657, 0.2785]  w:  [1.35181245 1.1769094  2.16556175]
-0.6097943773658968  -  26.0005  =  -26.610294377365896
training  [2.3784, -4.0141, -0.8841]  w:  [1.35181245 1.1769094  2.16556175]
-3.423654427376043  -  14.6809  =  -18.104554427376044
training  [-4.366, -3.5797, 1.0264]  w:  [1.35181245 1.1769094  2.16556175]
-7.892263145276024  -  1.8713  =  -9.763563145276024
training  [3.6044, -3.3175, 2.5052]  w:  [1.35181245 1.1769094  2.16556175]
6.393241149314402  -  71.0139  =  -64.6206588506856
training  [4.3441, -3.0375, 0.8353]  w:  [1.35181245 1.1769094  2.16556175]
4.106439888029682  -  63.8979  =  -59.791460111970316
training  [4.844, -1.8252, 0.5179]  w:  [1.35181245 1.1769094  2.16556175]
5.5216288958202835  -  78.0461  =  -72.52447110417971
training  [3.5894, -1.8357, 0.8357]  w:  [1.35181245 1.1769094  2.16556175]
4.501502972389806  -  68.8838  =  -64.38229702761019
training  [2.8556, -2.8244, 0.1182]  w:  [1.35181245 1.1769094  2.16556175]
0.7921421226016634  -  39.5252  =  -38.73305787739834
training  [0.1338, -2.4896, -4.1741]  w:  [1.35181245 1.1769094  2.16556175]
-11.788432418716113  -  2.2644  =  -14.052832418716113
training  [-3.224, 3.9292, 2.1957]  w:  [1.35181245 1.1769094  2.16556175]
5.020993000064432  -  72.1211  =  -67.10010699993556
training  [-1.0141, 2.0322, 4.9616]  w:  [1.35181245 1.1769094  2.16556175]
11.765493437220869  -  92.3427  =  -80.57720656277912
training  [-3.6607, 0.5574, -1.4547]  w:  [1.35181245 1.1769094  2.16556175]
-7.442813204670765  -  5.8471  =  -13.289913204670764
training  [-4.6911, -3.1557, 4.7126]  w:  [1.35181245 1.1769094  2.16556175]
0.14996592328434843  -  11.2337  =  -11.083734076715652
training  [4.3914, -2.8797, -1.5355]  w:  [1.35181245 1.1769094  2.16556175]
-0.7780168693041141  -  37.475  =  -38.25301686930412
training  [-1.9869, -4.2265, 3.8654]  w:  [1.35181245 1.1769094  2.16556175]
0.7106386512422809  -  15.7889  =  -15.078261348757719
training  [-2.0447, 4.138, -0.4531]  w:  [1.35181245 1.1769094  2.16556175]
1.1247841481168557  -  57.936  =  -56.81121585188315
training  [-1.6706, 2.0672, -0.8657]  w:  [1.35181245 1.1769094  2.16556175]
-1.700157573009054  -  32.4185  =  -34.11865757300905
training  [-0.3293, 0.5779, -2.8227]  w:  [1.35181245 1.1769094  2.16556175]
-5.877747040675383  -  14.3434  =  -20.221147040675383
training  [1.482, -1.8657, -3.7435]  w:  [1.35181245 1.1769094  2.16556175]
-8.299154214113706  -  7.1519  =  -15.451054214113707
training  [-4.7477, -3.338, -1.9109]  w:  [1.35181245 1.1769094  2.16556175]
-14.484695474038466  -  0.4077  =  -14.892395474038466
training  [3.4221, 1.225, 2.261]  w:  [1.35181245 1.1769094  2.16556175]
10.96408650186794  -  95.0454  =  -84.08131349813206
training  [0.5903, 4.8793, 2.8287]  w:  [1.35181245 1.1769094  2.16556175]
12.666193427032848  -  97.4647  =  -84.79850657296714
training  [3.541, -3.2957, 1.9379]  w:  [1.35181245 1.1769094  2.16556175]
5.104669686036164  -  64.3732  =  -59.268530313963836
training  [-1.5212, -2.4221, -4.902]  w:  [1.35181245 1.1769094  2.16556175]
-15.522553032031098  -  0.7227  =  -16.245253032031098
training  [-0.5397, -1.032, 3.4321]  w:  [1.35181245 1.1769094  2.16556175]
5.4882807937683715  -  60.5921  =  -55.103819206231634
training  [-4.4576, -4.2601, 4.2233]  w:  [1.35181245 1.1769094  2.16556175]
-1.8937739718346975  -  6.0247  =  -7.918473971834698
training  [-3.2289, 1.841, 2.7095]  w:  [1.35181245 1.1769094  2.16556175]
3.66941253961207  -  54.0111  =  -50.34168746038793
training  [1.6281, -0.9761, -4.5734]  w:  [1.35181245 1.1769094  2.16556175]
-8.851875508533652  -  7.8658  =  -16.717675508533652
training  [-1.6917, 4.8284, -1.2181]  w:  [1.35181245 1.1769094  2.16556175]
0.7578574545666066  -  61.2837  =  -60.5258425454334
training  [3.9849, -0.9782, 2.0434]  w:  [1.35181245 1.1769094  2.16556175]
8.66069352608638  -  88.3402  =  -79.67950647391362
training  [-3.8184, 1.2067, 2.2951]  w:  [1.35181245 1.1769094  2.16556175]
1.2285966822291248  -  34.1122  =  -32.88360331777088
training  [4.8842, -3.4563, -2.7572]  w:  [1.35181245 1.1769094  2.16556175]
-3.4361164395690382  -  23.7819  =  -27.218016439569038
training  [0.3998, -1.1865, -2.3095]  w:  [1.35181245 1.1769094  2.16556175]
-5.857313237915676  -  11.4246  =  -17.281913237915674
training  [2.0692, -3.3887, 1.7303]  w:  [1.35181245 1.1769094  2.16556175]
2.5560489317268114  -  42.6881  =  -40.132051068273185
training  [4.9949, 2.5811, -0.2251]  w:  [1.35181245 1.1769094  2.16556175]
9.302420896928195  -  95.9901  =  -86.6876791030718
training  [-2.1215, 3.7111, 1.2372]  w:  [1.35181245 1.1769094  2.16556175]
4.1789913505644805  -  71.3692  =  -67.19020864943553
training  [-0.8548, -1.4922, -2.6356]  w:  [1.35181245 1.1769094  2.16556175]
-8.619268024359842  -  4.7821  =  -13.401368024359842
training  [-0.3516, 1.8554, -3.2288]  w:  [1.35181245 1.1769094  2.16556175]
-5.283825327665852  -  20.3834  =  -25.667225327665854
training  [2.6396, -2.0585, 3.2964]  w:  [1.35181245 1.1769094  2.16556175]
8.284133885131025  -  80.826  =  -72.54186611486897
training  [3.182, 0.3063, 2.6692]  w:  [1.35181245 1.1769094  2.16556175]
10.442271974051645  -  92.9483  =  -82.50602802594835
training  [-3.9978, 3.3242, 4.3448]  w:  [1.35181245 1.1769094  2.16556175]
7.916939091536648  -  79.1768  =  -71.25986090846335
training  [-3.2188, 0.9749, -3.9211]  w:  [1.35181245 1.1769094  2.16556175]
-11.695229102158628  -  2.7053  =  -14.400529102158627
training  [-1.4037, -1.6469, -3.1777]  w:  [1.35181245 1.1769094  2.16556175]
-10.717296784106304  -  2.6234  =  -13.340696784106305
training  [-4.433, -2.0077, -4.009]  w:  [1.35181245 1.1769094  2.16556175]
-17.037202625147323  -  0.3253  =  -17.36250262514732
training  [0.2189, -0.4741, -0.1024]  w:  [1.35181245 1.1769094  2.16556175]
-0.48381452348999443  -  33.6531  =  -34.13691452349
training  [-1.6415, -0.7735, -3.0675]  w:  [1.35181245 1.1769094  2.16556175]
-9.772200211642408  -  3.7641  =  -13.53630021164241
training  [-3.2433, -1.4039, 3.9589]  w:  [1.35181245 1.1769094  2.16556175]
2.536645981116502  -  30.0658  =  -27.529154018883496
training  [-2.9105, 0.5832, -4.0091]  w:  [1.35181245 1.1769094  2.16556175]
-11.930030169205493  -  2.4887  =  -14.418730169205492
training  [4.0515, 2.4255, -4.5583]  w:  [1.35181245 1.1769094  2.16556175]
-1.5398182302386907  -  61.2853  =  -62.82511823023869
training  [1.7539, -0.7567, 0.573]  w:  [1.35181245 1.1769094  2.16556175]
2.7212433927918607  -  57.0797  =  -54.35845660720814
training  [-0.3153, -0.7064, 2.725]  w:  [1.35181245 1.1769094  2.16556175]
4.643560496085113  -  58.7004  =  -54.05683950391489
training  [4.1213, -3.7513, -1.8806]  w:  [1.35181245 1.1769094  2.16556175]
-2.9162710017419586  -  22.1789  =  -25.095171001741956
training  [-3.9599, -4.7557, -3.2102]  w:  [1.35181245 1.1769094  2.16556175]
-17.901956458215015  -  0.1558  =  -18.057756458215014
training  [2.4555, -2.0981, -1.6104]  w:  [1.35181245 1.1769094  2.16556175]
-2.637318777661486  -  24.4796  =  -27.11691877766149
training  [2.3627, -1.8248, -2.8985]  w:  [1.35181245 1.1769094  2.16556175]
-5.230577720370004  -  15.7052  =  -20.935777720370005
training  [0.6186, 1.5369, 0.1015]  w:  [1.35181245 1.1769094  2.16556175]
2.864827751725598  -  65.2154  =  -62.3505722482744
training  [-3.1581, 4.5694, 4.0636]  w:  [1.35181245 1.1769094  2.16556175]
9.908587623746984  -  90.3564  =  -80.44781237625301
training  [0.9721, 4.3573, 1.2892]  w:  [1.35181245 1.1769094  2.16556175]
9.234086405006508  -  94.3178  =  -85.0837135949935
training  [-2.0006, -0.4211, -3.9847]  w:  [1.35181245 1.1769094  2.16556175]
-11.829146424135466  -  2.4051  =  -14.234246424135467
training  [-3.6588, -2.5952, -1.0915]  w:  [1.35181245 1.1769094  2.16556175]
-10.364037302773905  -  1.5176  =  -11.881637302773905
training  [-2.874, 2.639, -4.4538]  w:  [1.35181245 1.1769094  2.16556175]
-10.424223983177509  -  5.497  =  -15.921223983177509
training  [3.9494, 2.5933, 0.0128]  w:  [1.35181245 1.1769094  2.16556175]
8.418646416245796  -  94.1462  =  -85.7275535837542
training  [-4.2855, 2.4065, -0.6828]  w:  [1.35181245 1.1769094  2.16556175]
-4.4396053423168125  -  14.4193  =  -18.858905342316813
training  [-2.5751, 2.4369, 4.9756]  w:  [1.35181245 1.1769094  2.16556175]
10.161927302972897  -  87.1991  =  -77.0371726970271
training  [-4.4625, -3.9408, 3.116]  w:  [1.35181245 1.1769094  2.16556175]
-3.922537204204138  -  4.1344  =  -8.05693720420414
training  [-0.5828, 1.8156, -0.1435]  w:  [1.35181245 1.1769094  2.16556175]
1.0382022973979887  -  51.1166  =  -50.07839770260201
training  [-4.8672, -0.3674, 3.9445]  w:  [1.35181245 1.1769094  2.16556175]
1.5301202479150868  -  24.1396  =  -22.609479752084916
training  [3.9719, -2.8784, -3.6245]  w:  [1.35181245 1.1769094  2.16556175]
-5.8674306981478335  -  14.6104  =  -20.477830698147834
training  [-3.0334, -4.0148, -1.1]  w:  [1.35181245 1.1769094  2.16556175]
-11.20776165375774  -  1.021  =  -12.22876165375774
training  [-4.0663, 3.2357, 4.2736]  w:  [1.35181245 1.1769094  2.16556175]
7.565995460724489  -  77.2328  =  -69.6668045392755
training  [-1.9263, -3.2499, 4.1749]  w:  [1.35181245 1.1769094  2.16556175]
2.612169564331033  -  26.8814  =  -24.269230435668966
training  [-0.4394, -3.3643, 2.1357]  w:  [1.35181245 1.1769094  2.16556175]
0.0715275449068491  -  20.85  =  -20.77847245509315
training  [-3.9833, 1.6599, 1.1834]  w:  [1.35181245 1.1769094  2.16556175]
-0.8683968451890967  -  25.5397  =  -26.408096845189096
training  [4.9539, 3.9439, -1.5671]  w:  [1.35181245 1.1769094  2.16556175]
7.944704850034686  -  95.9509  =  -88.00619514996532
training  [-1.6791, 0.1656, 4.3603]  w:  [1.35181245 1.1769094  2.16556175]
7.367566798344873  -  71.5733  =  -64.20573320165514
training  [-2.0265, 2.027, -3.7523]  w:  [1.35181245 1.1769094  2.16556175]
-8.479689919340592  -  8.503  =  -16.982689919340594
training  [-4.3795, -3.4641, 2.3059]  w:  [1.35181245 1.1769094  2.16556175]
-5.003625631976472  -  3.6654  =  -8.66902563197647
training  [-2.0176, 4.5346, 1.4648]  w:  [1.35181245 1.1769094  2.16556175]
5.781511406779606  -  81.6212  =  -75.8396885932204
training  [-4.5365, 0.4088, 3.3315]  w:  [1.35181245 1.1769094  2.16556175]
1.5631923486163632  -  28.9449  =  -27.381707651383635
training  [0.0543, 1.7973, -1.0172]  w:  [1.35181245 1.1769094  2.16556175]
-0.014146731779081989  -  47.9317  =  -47.945846731779085
training  [2.6143, -4.6344, 2.4982]  w:  [1.35181245 1.1769094  2.16556175]
3.489780725607069  -  43.5132  =  -40.02341927439293
training  [1.3107, 3.092, 3.3522]  w:  [1.35181245 1.1769094  2.16556175]
12.670220522267677  -  96.6993  =  -84.02907947773232
training  [-4.1011, 2.4862, -1.7754]  w:  [1.35181245 1.1769094  2.16556175]
-6.462624212275395  -  10.0187  =  -16.481324212275396
training  [-4.1914, -3.7981, 0.5226]  w:  [1.35181245 1.1769094  2.16556175]
-9.004283712300705  -  1.4295  =  -10.433783712300706
training  [2.7724, 0.2505, 4.7913]  w:  [1.35181245 1.1769094  2.16556175]
14.418436633485928  -  96.7925  =  -82.37406336651408
training  [4.0513, -1.7417, 0.4931]  w:  [1.35181245 1.1769094  2.16556175]
4.494613171325188  -  71.1234  =  -66.62878682867482
training  [0.3377, 0.4645, -1.6958]  w:  [1.35181245 1.1769094  2.16556175]
-2.6691781308810434  -  27.9534  =  -30.622578130881042
training  [-3.9085, -1.0112, 1.1947]  w:  [1.35181245 1.1769094  2.16556175]
-3.886453119331017  -  8.608  =  -12.494453119331018
training  [3.2581, -0.8491, -1.3936]  w:  [1.35181245 1.1769094  2.16556175]
0.38709951829538136  -  50.1924  =  -49.80530048170462
training  [-1.619, -3.1926, 2.5651]  w:  [1.35181245 1.1769094  2.16556175]
-0.3911028616347645  -  16.4754  =  -16.866502861634764
training  [-2.0603, -2.4461, -0.861]  w:  [1.35181245 1.1769094  2.16556175]
-7.528525930013578  -  3.9784  =  -11.506925930013578
training  [2.4631, -4.7946, -0.0765]  w:  [1.35181245 1.1769094  2.16556175]
-2.478826031476101  -  15.394  =  -17.8728260314761
training  [-4.8966, 4.2368, 1.9474]  w:  [1.35181245 1.1769094  2.16556175]
2.5842598478513796  -  53.5883  =  -51.00404015214862
training  [-4.5155, 1.537, 4.7273]  w:  [1.35181245 1.1769094  2.16556175]
5.942060678959043  -  59.2523  =  -53.31023932104095
training  [1.6792, 4.3261, -1.7225]  w:  [1.35181245 1.1769094  2.16556175]
3.6312111014749977  -  83.7729  =  -80.141688898525
training  [1.0347, -3.3649, 3.378]  w:  [1.35181245 1.1769094  2.16556175]
4.7538054875378375  -  50.5979  =  -45.84409451246216
training  [0.261, 4.211, 2.3907]  w:  [1.35181245 1.1769094  2.16556175]
10.48599699198913  -  94.9375  =  -84.45150300801087
training  [2.2971, 2.9466, 4.5417]  w:  [1.35181245 1.1769094  2.16556175]
16.4084613927156  -  98.7784  =  -82.36993860728441
training  [2.0725, 0.7739, -4.6808]  w:  [1.35181245 1.1769094  2.16556175]
-6.424119941509561  -  19.5109  =  -25.93501994150956
training  [2.8138, -0.5996, -1.4313]  w:  [1.35181245 1.1769094  2.16556175]
-0.0015135356123900934  -  47.2879  =  -47.28941353561239
training  [-2.1202, -2.4239, 1.6265]  w:  [1.35181245 1.1769094  2.16556175]
-2.196537262045049  -  12.3599  =  -14.556437262045048
training  [1.9253, 2.5195, -2.185]  w:  [1.35181245 1.1769094  2.16556175]
0.8361153187361348  -  65.2467  =  -64.41058468126387
training  [0.5667, -2.7133, -2.6962]  w:  [1.35181245 1.1769094  2.16556175]
-8.266023736608453  -  5.1106  =  -13.376623736608453
training  [-1.0348, -4.3581, 2.1113]  w:  [1.35181245 1.1769094  2.16556175]
-1.9557938532813601  -  10.5192  =  -12.47499385328136
training  [-4.3841, 2.6733, 1.2457]  w:  [1.35181245 1.1769094  2.16556175]
-0.08260879377441066  -  32.4639  =  -32.546508793774414
training  [2.8018, 1.712, 0.9061]  w:  [1.35181245 1.1769094  2.16556175]
7.764592506259429  -  90.1138  =  -82.34920749374056
training  [-1.6242, 2.1521, 1.6044]  w:  [1.35181245 1.1769094  2.16556175]
3.811640203095017  -  63.7879  =  -59.97625979690498
training  [1.0787, 1.4206, -4.5245]  w:  [1.35181245 1.1769094  2.16556175]
-6.667966544101137  -  18.0555  =  -24.723466544101136
training  [2.4125, -0.8095, -1.5122]  w:  [1.35181245 1.1769094  2.16556175]
-0.9662230991404614  -  38.8276  =  -39.79382309914046
training  [-3.9519, -1.0924, -0.4866]  w:  [1.35181245 1.1769094  2.16556175]
-7.681645787494558  -  3.6777  =  -11.359345787494558
training  [-3.7211, 3.1614, -2.591]  w:  [1.35181245 1.1769094  2.16556175]
-6.920518416951107  -  11.1518  =  -18.072318416951106
training  [0.4954, -1.8257, 2.1505]  w:  [1.35181245 1.1769094  2.16556175]
3.178044935376721  -  47.7531  =  -44.575055064623285
training  [-0.1477, 3.1454, 3.5618]  w:  [1.35181245 1.1769094  2.16556175]
11.21548595137344  -  94.1572  =  -82.94171404862657
training  [3.9048, 2.8907, -2.1849]  w:  [1.35181245 1.1769094  2.16556175]
3.9491133852183493  -  85.8791  =  -81.92998661478164
training  [2.9896, 3.5226, 2.3105]  w:  [1.35181245 1.1769094  2.16556175]
13.190689957232939  -  98.038  =  -84.84731004276706
training  [2.3434, 0.0564, -3.6224]  w:  [1.35181245 1.1769094  2.16556175]
-4.610315889547523  -  24.7629  =  -29.37321588954752
training  [-4.4867, 1.3566, 3.3672]  w:  [1.35181245 1.1769094  2.16556175]
2.8232978903435164  -  40.5785  =  -37.75520210965648
training  [-4.2711, 4.5089, -3.614]  w:  [1.35181245 1.1769094  2.16556175]
-8.293499516702841  -  10.0825  =  -18.37599951670284
training  [-4.1147, -0.5604, 0.8821]  w:  [1.35181245 1.1769094  2.16556175]
-4.311600691612889  -  8.344  =  -12.65560069161289
training  [2.9835, -4.3998, -1.3384]  w:  [1.35181245 1.1769094  2.16556175]
-4.043421371154055  -  13.2692  =  -17.312621371154055
training  [4.4301, 3.6675, 3.0676]  w:  [1.35181245 1.1769094  2.16556175]
16.948056759491035  -  99.3834  =  -82.43534324050896
training  [1.8372, 1.3119, 0.0378]  w:  [1.35181245 1.1769094  2.16556175]
4.1093955036239675  -  74.9026  =  -70.79320449637603
training  [-3.6792, -1.4493, -0.1041]  w:  [1.35181245 1.1769094  2.16556175]
-6.904718128818981  -  4.2442  =  -11.14891812881898
training  [2.2272, 4.97, 3.7705]  w:  [1.35181245 1.1769094  2.16556175]
17.02524695942168  -  99.3199  =  -82.29465304057832
training  [-3.8965, -2.7583, -1.4686]  w:  [1.35181245 1.1769094  2.16556175]
-11.693950379285877  -  1.0337  =  -12.727650379285876
training  [-3.8251, 1.5245, -0.5056]  w:  [1.35181245 1.1769094  2.16556175]
-4.471527438561104  -  12.9762  =  -17.447727438561103
training  [1.4072, 1.0499, 4.6353]  w:  [1.35181245 1.1769094  2.16556175]
13.175936019100643  -  95.4618  =  -82.28586398089935
training  [-1.7119, -1.1275, -4.577]  w:  [1.35181245 1.1769094  2.16556175]
-13.552909191603604  -  1.4655  =  -15.018409191603604
training  [1.5381, -3.5781, 4.7296]  w:  [1.35181245 1.1769094  2.16556175]
8.11036404733015  -  69.9473  =  -61.83693595266985
training  [2.4913, -4.7487, -3.1079]  w:  [1.35181245 1.1769094  2.16556175]
-8.951368658104627  -  3.9825  =  -12.933868658104627
training  [0.8319, -0.7889, 1.6712]  w:  [1.35181245 1.1769094  2.16556175]
3.815195742938871  -  58.8336  =  -55.01840425706113
training  [2.4003, -3.159, 0.8644]  w:  [1.35181245 1.1769094  2.16556175]
1.3988102056460463  -  39.0041  =  -37.60528979435396
training  [-2.6517, 2.2578, 1.7511]  w:  [1.35181245 1.1769094  2.16556175]
2.864740143897268  -  54.4525  =  -51.587759856102736
training  [2.3496, -1.2964, -1.3898]  w:  [1.35181245 1.1769094  2.16556175]
-1.359224530241206  -  33.888  =  -35.247224530241205
training  [4.706, 3.4156, 1.2028]  w:  [1.35181245 1.1769094  2.16556175]
12.986218791361328  -  98.4665  =  -85.48028120863867
training  [3.6693, 2.3423, 3.1115]  w:  [1.35181245 1.1769094  2.16556175]
14.455025675125327  -  98.3069  =  -83.85187432487467
training  [-4.1377, 0.7103, -4.8074]  w:  [1.35181245 1.1769094  2.16556175]
-15.168157163909292  -  0.9782  =  -16.146357163909293
training  [-1.3356, -3.2314, -4.1613]  w:  [1.35181245 1.1769094  2.16556175]
-14.620097831598631  -  0.7659  =  -15.385997831598631
training  [-1.308, 4.5738, 4.748]  w:  [1.35181245 1.1769094  2.16556175]
13.896864695494513  -  97.0884  =  -83.19153530450548
training  [1.8503, -2.3468, 1.5135]  w:  [1.35181245 1.1769094  2.16556175]
3.0168653018503067  -  50.2125  =  -47.19563469814969
training  [0.9794, 4.2458, -2.6876]  w:  [1.35181245 1.1769094  2.16556175]
0.5007232835971394  -  68.3262  =  -67.82547671640286
training  [2.8936, -2.7623, -0.9651]  w:  [1.35181245 1.1769094  2.16556175]
-1.4293559709747576  -  28.5596  =  -29.988955970974757
training  [-1.3235, -1.2644, -3.7798]  w:  [1.35181245 1.1769094  2.16556175]
-11.462598308706664  -  2.4511  =  -13.913698308706664
training  [-2.9397, -4.125, -2.3156]  w:  [1.35181245 1.1769094  2.16556175]
-13.84324910232375  -  0.554  =  -14.39724910232375
training  [-4.1333, 1.4012, -2.4215]  w:  [1.35181245 1.1769094  2.16556175]
-9.182268714521776  -  4.4072  =  -13.589468714521775
training  [2.7193, -3.1938, -1.6833]  w:  [1.35181245 1.1769094  2.16556175]
-3.728119732489559  -  17.0949  =  -20.82301973248956
training  [-2.9433, -4.5495, -3.4777]  w:  [1.35181245 1.1769094  2.16556175]
-16.864312972471435  -  0.2509  =  -17.115212972471436
training  [-1.1173, 2.2317, -1.5199]  w:  [1.35181245 1.1769094  2.16556175]
-2.175308644004647  -  33.1206  =  -35.29590864400465
training  [0.5178, -1.5256, -3.7834]  w:  [1.35181245 1.1769094  2.16556175]
-9.288710804369227  -  5.237  =  -14.525710804369227
training  [-2.7105, 1.6062, 3.8415]  w:  [1.35181245 1.1769094  2.16556175]
6.545269683552133  -  70.4458  =  -63.90053031644787
training  [1.4194, -1.1613, -4.0572]  w:  [1.35181245 1.1769094  2.16556175]
-8.234099413379763  -  8.3206  =  -16.554699413379765
training  [-0.1552, 1.2735, 4.3004]  w:  [1.35181245 1.1769094  2.16556175]
10.60177456201016  -  90.1085  =  -79.50672543798984
training  [-3.4815, -4.7835, -1.0098]  w:  [1.35181245 1.1769094  2.16556175]
-12.522865396617131  -  0.5839  =  -13.106765396617131
training  [2.8193, 4.1057, -4.526]  w:  [1.35181245 1.1769094  2.16556175]
-1.158130714298661  -  66.8081  =  -67.96623071429866
training  [-3.9939, 3.0056, -1.5763]  w:  [1.35181245 1.1769094  2.16556175]
-5.275259832697205  -  14.4018  =  -19.677059832697203
training  [-2.0593, 2.4585, 2.3597]  w:  [1.35181245 1.1769094  2.16556175]
5.219720433618797  -  70.6698  =  -65.45007956638119
training  [-2.6263, 3.1311, 2.9468]  w:  [1.35181245 1.1769094  2.16556175]
6.516233337939205  -  77.309  =  -70.79276666206079
training  [0.3087, -1.1669, 0.4491]  w:  [1.35181245 1.1769094  2.16556175]
0.016522706764584227  -  33.0798  =  -33.063277293235416
training  [-4.085, 1.1728, 1.8622]  w:  [1.35181245 1.1769094  2.16556175]
-0.10916542528860251  -  26.4056  =  -26.5147654252886
training  [-0.9468, 0.7549, 3.9363]  w:  [1.35181245 1.1769094  2.16556175]
8.132853581999896  -  79.7738  =  -71.6409464180001
training  [-3.9515, 0.3005, -4.4521]  w:  [1.35181245 1.1769094  2.16556175]
-14.629323068693111  -  1.0441  =  -15.673423068693111
training  [-3.8772, -2.2493, -1.9634]  w:  [1.35181245 1.1769094  2.16556175]
-12.140333467725934  -  1.0509  =  -13.191233467725935
training  [2.8443, -2.5137, -4.5381]  w:  [1.35181245 1.1769094  2.16556175]
-8.940972769413937  -  6.8897  =  -15.830672769413937
training  [-2.0843, -0.4836, -3.0452]  w:  [1.35181245 1.1769094  2.16556175]
-9.98130470239389  -  3.5346  =  -13.51590470239389
training  [1.0353, -2.7229, 2.2017]  w:  [1.35181245 1.1769094  2.16556175]
2.9628421258485487  -  43.9562  =  -40.99335787415146
training  [4.6442, 3.0445, 2.2175]  w:  [1.35181245 1.1769094  2.16556175]
14.663321208852793  -  98.8492  =  -84.1858787911472
training  [-0.6752, 4.861, 3.778]  w:  [1.35181245 1.1769094  2.16556175]
12.989705097670916  -  97.017  =  -84.02729490232907
training  [1.9475, -4.7001, 0.8243]  w:  [1.35181245 1.1769094  2.16556175]
-1.1138645703438632  -  18.7839  =  -19.897764570343863
training  [2.581, 0.3566, -4.2932]  w:  [1.35181245 1.1769094  2.16556175]
-5.388475870213933  -  23.5455  =  -28.933975870213935
training  [-0.6736, -4.1292, 4.2274]  w:  [1.35181245 1.1769094  2.16556175]
3.3844205765744837  -  31.2667  =  -27.882279423425516
training  [1.555, 3.0209, 3.0037]  w:  [1.35181245 1.1769094  2.16556175]
12.162091776496549  -  96.4078  =  -84.24570822350344
training  [-3.9024, 4.8914, -2.1405]  w:  [1.35181245 1.1769094  2.16556175]
-4.15396318839915  -  25.4308  =  -29.58476318839915
training  [4.3376, -4.3305, 0.4366]  w:  [1.35181245 1.1769094  2.16556175]
1.7124997870645946  -  43.0907  =  -41.378200212935404
training  [-3.1254, 4.394, 4.8478]  w:  [1.35181245 1.1769094  2.16556175]
11.44459550418869  -  92.8121  =  -81.36750449581132
training  [-2.3382, -4.8182, 2.1568]  w:  [1.35181245 1.1769094  2.16556175]
-4.160709153178462  -  4.7434  =  -8.904109153178462
training  [2.9783, 1.8384, 3.3897]  w:  [1.35181245 1.1769094  2.16556175]
13.530337905509064  -  97.3486  =  -83.81826209449093
training  [-0.124, 2.8374, -0.6674]  w:  [1.35181245 1.1769094  2.16556175]
1.7264420725348106  -  62.785  =  -61.05855792746519
training  [2.6896, 0.3414, -0.2938]  w:  [1.35181245 1.1769094  2.16556175]
3.401389588722455  -  70.4455  =  -67.04411041127754
training  [-1.0399, 3.8536, 0.6071]  w:  [1.35181245 1.1769094  2.16556175]
4.4443008274408395  -  77.0369  =  -72.59259917255916
training  [-2.2706, 3.99, -2.3091]  w:  [1.35181245 1.1769094  2.16556175]
-3.3740554768355153  -  31.1134  =  -34.487455476835514
training  [-4.6277, 1.2594, 2.4902]  w:  [1.35181245 1.1769094  2.16556175]
0.619099089736971  -  28.1093  =  -27.49020091026303
training  [1.7329, -3.6213, 0.0389]  w:  [1.35181245 1.1769094  2.16556175]
-1.835145859097306  -  19.3919  =  -21.227045859097306
training  [-0.7044, -2.822, 1.4681]  w:  [1.35181245 1.1769094  2.16556175]
-1.0941938095176371  -  17.8122  =  -18.90639380951764
training  [-0.4826, -3.1786, -1.9225]  w:  [1.35181245 1.1769094  2.16556175]
-8.556601358245993  -  3.5851  =  -12.141701358245994
training  [1.0986, -4.5818, -3.6128]  w:  [1.35181245 1.1769094  2.16556175]
-11.731003802499764  -  1.7158  =  -13.446803802499764
training  [-4.406, -3.9306, -0.2443]  w:  [1.35181245 1.1769094  2.16556175]
-11.11109246254992  -  0.8241  =  -11.935192462549919
training  [-1.8419, 1.1644, -1.3754]  w:  [1.35181245 1.1769094  2.16556175]
-4.098023672267155  -  17.8517  =  -21.949723672267154
training  [2.7272, 4.3966, 2.8811]  w:  [1.35181245 1.1769094  2.16556175]
15.100262717298593  -  98.904  =  -83.8037372827014
training  [1.9643, -1.4554, 2.803]  w:  [1.35181245 1.1769094  2.16556175]
7.012560830775049  -  76.0591  =  -69.04653916922496
training  [-3.7467, -0.8937, 1.6851]  w:  [1.35181245 1.1769094  2.16556175]
-2.467451530303186  -  12.1571  =  -14.624551530303187
training  [-3.6985, 4.8435, -3.665]  w:  [1.35181245 1.1769094  2.16556175]
-7.236101473212226  -  14.6793  =  -21.915401473212228
238415.64057427357
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.5801863 1.1975441 2.5602406]
13.604260024271891  -  87.3174  =  -73.71313997572811
training  [-4.1793, -4.9218, 1.7664]  w:  [1.5801863 1.1975441 2.5602406]
-7.975736176935998  -  1.5257  =  -9.501436176935998
training  [-3.9429, -0.7689, 4.883]  w:  [1.5801863 1.1975441 2.5602406]
5.350346604537979  -  39.7859  =  -34.43555339546202
training  [-3.5796, 1.5557, 2.6683]  w:  [1.5801863 1.1975441 2.5602406]
3.0380744557234842  -  45.5674  =  -42.52932554427652
training  [-3.3354, 2.2292, -1.633]  w:  [1.5801863 1.1975441 2.5602406]
-6.781860975340816  -  13.3589  =  -20.140760975340818
training  [1.2096, 0.3121, 1.6238]  w:  [1.5801863 1.1975441 2.5602406]
6.442465545153573  -  74.5119  =  -68.06943445484643
training  [0.7371, -3.9118, -2.5583]  w:  [1.5801863 1.1975441 2.5602406]
-10.069661208941733  -  3.3358  =  -13.405461208941734
training  [-4.4792, 1.3177, -2.0449]  w:  [1.5801863 1.1975441 2.5602406]
-10.735402616961437  -  4.2974  =  -15.032802616961437
training  [4.312, -3.735, 1.8018]  w:  [1.5801863 1.1975441 2.5602406]
6.953977623221838  -  66.5833  =  -59.629322376778156
training  [2.2866, -3.657, 0.2785]  w:  [1.5801863 1.1975441 2.5602406]
-0.05313777319814805  -  26.0005  =  -26.053637773198147
training  [2.3784, -4.0141, -0.8841]  w:  [1.5801863 1.1975441 2.5602406]
-3.3122553866602513  -  14.6809  =  -17.993155386660252
training  [-4.366, -3.5797, 1.0264]  w:  [1.5801863 1.1975441 2.5602406]
-8.558111063117504  -  1.8713  =  -10.429411063117504
training  [3.6044, -3.3175, 2.5052]  w:  [1.5801863 1.1975441 2.5602406]
8.136685693823924  -  71.0139  =  -62.877214306176086
training  [4.3441, -3.0375, 0.8353]  w:  [1.5801863 1.1975441 2.5602406]
5.365516077318624  -  63.8979  =  -58.532383922681376
training  [4.844, -1.8252, 0.5179]  w:  [1.5801863 1.1975441 2.5602406]
6.794613557726823  -  78.0461  =  -71.25148644227318
training  [3.5894, -1.8357, 0.8357]  w:  [1.5801863 1.1975441 2.5602406]
5.613182072063421  -  68.8838  =  -63.27061792793657
training  [2.8556, -2.8244, 0.1182]  w:  [1.5801863 1.1975441 2.5602406]
1.4326568832723097  -  39.5252  =  -38.09254311672769
training  [0.1338, -2.4896, -4.1741]  w:  [1.5801863 1.1975441 2.5602406]
-13.456677140404489  -  2.2644  =  -15.72107714040449
training  [-3.224, 3.9292, 2.1957]  w:  [1.5801863 1.1975441 2.5602406]
5.232389922151537  -  72.1211  =  -66.88871007784846
training  [-1.0141, 2.0322, 4.9616]  w:  [1.5801863 1.1975441 2.5602406]
13.534071936998746  -  92.3427  =  -78.80862806300125
training  [-3.6607, 0.5574, -1.4547]  w:  [1.5801863 1.1975441 2.5602406]
-8.841458908797147  -  5.8471  =  -14.688558908797148
training  [-4.6911, -3.1557, 4.7126]  w:  [1.5801863 1.1975441 2.5602406]
0.873487955922867  -  11.2337  =  -10.360212044077134
training  [4.3914, -2.8797, -1.5355]  w:  [1.5801863 1.1975441 2.5602406]
-0.440587057766503  -  37.475  =  -37.9155870577665
training  [-1.9869, -4.2265, 3.8654]  w:  [1.5801863 1.1975441 2.5602406]
1.6952616965192764  -  15.7889  =  -14.093638303480724
training  [-2.0447, 4.138, -0.4531]  w:  [1.5801863 1.1975441 2.5602406]
0.5643855439624805  -  57.936  =  -57.37161445603752
training  [-1.6706, 2.0672, -0.8657]  w:  [1.5801863 1.1975441 2.5602406]
-2.380696354793208  -  32.4185  =  -34.79919635479321
training  [-0.3293, 0.5779, -2.8227]  w:  [1.5801863 1.1975441 2.5602406]
-7.055085745122102  -  14.3434  =  -21.3984857451221
training  [1.482, -1.8657, -3.7435]  w:  [1.5801863 1.1975441 2.5602406]
-9.476682602963619  -  7.1519  =  -16.62858260296362
training  [-4.7477, -3.338, -1.9109]  w:  [1.5801863 1.1975441 2.5602406]
-16.392016469532397  -  0.4077  =  -16.799716469532395
training  [3.4221, 1.225, 2.261]  w:  [1.5801863 1.1975441 2.5602406]
12.663251055603917  -  95.0454  =  -82.38214894439608
training  [0.5903, 4.8793, 2.8287]  w:  [1.5801863 1.1975441 2.5602406]
14.018113480804033  -  97.4647  =  -83.44658651919596
training  [3.541, -3.2957, 1.9379]  w:  [1.5801863 1.1975441 2.5602406]
6.610183853274476  -  64.3732  =  -57.76301614672552
training  [-1.5212, -2.4221, -4.902]  w:  [1.5801863 1.1975441 2.5602406]
-17.854650373224725  -  0.7227  =  -18.577350373224725
training  [-0.5397, -1.032, 3.4321]  w:  [1.5801863 1.1975441 2.5602406]
6.6983096922153065  -  60.5921  =  -53.8937903077847
training  [-4.4576, -4.2601, 4.2233]  w:  [1.5801863 1.1975441 2.5602406]
-1.3328319715202532  -  6.0247  =  -7.357531971520253
training  [-3.2289, 1.841, 2.7095]  w:  [1.5801863 1.1975441 2.5602406]
4.039387036309407  -  54.0111  =  -49.97171296369059
training  [1.6281, -0.9761, -4.5734]  w:  [1.5801863 1.1975441 2.5602406]
-10.305225823199292  -  7.8658  =  -18.171025823199294
training  [-1.6917, 4.8284, -1.2181]  w:  [1.5801863 1.1975441 2.5602406]
-0.009608300620242538  -  61.2837  =  -61.29330830062025
training  [3.9849, -0.9782, 2.0434]  w:  [1.5801863 1.1975441 2.5602406]
10.357042389358135  -  88.3402  =  -77.98315761064185
training  [-3.8184, 1.2067, 2.2951]  w:  [1.5801863 1.1975441 2.5602406]
1.2873012850265102  -  34.1122  =  -32.82489871497349
training  [4.8842, -3.4563, -2.7572]  w:  [1.5801863 1.1975441 2.5602406]
-3.4802211136235215  -  23.7819  =  -27.26212111362352
training  [0.3998, -1.1865, -2.3095]  w:  [1.5801863 1.1975441 2.5602406]
-6.702003249966113  -  11.4246  =  -18.126603249966113
training  [2.0692, -3.3887, 1.7303]  w:  [1.5801863 1.1975441 2.5602406]
3.641588105124203  -  42.6881  =  -39.04651189487579
training  [4.9949, 2.5811, -0.2251]  w:  [1.5801863 1.1975441 2.5602406]
10.407543479157628  -  95.9901  =  -85.58255652084237
training  [-2.1215, 3.7111, 1.2372]  w:  [1.5801863 1.1975441 2.5602406]
4.259370339652218  -  71.3692  =  -67.10982966034778
training  [-0.8548, -1.4922, -2.6356]  w:  [1.5801863 1.1975441 2.5602406]
-9.885488674322763  -  4.7821  =  -14.667588674322763
training  [-0.3516, 1.8554, -3.2288]  w:  [1.5801863 1.1975441 2.5602406]
-6.600175017027018  -  20.3834  =  -26.98357501702702
training  [2.6396, -2.0585, 3.2964]  w:  [1.5801863 1.1975441 2.5602406]
10.145492332884158  -  80.826  =  -70.68050766711583
training  [3.182, 0.3063, 2.6692]  w:  [1.5801863 1.1975441 2.5602406]
12.228754770577641  -  92.9483  =  -80.71954522942237
training  [-3.9978, 3.3242, 4.3448]  w:  [1.5801863 1.1975441 2.5602406]
8.787340646841734  -  79.1768  =  -70.38945935315826
training  [-3.2188, 0.9749, -3.9211]  w:  [1.5801863 1.1975441 2.5602406]
-13.957777327238551  -  2.7053  =  -16.66307732723855
training  [-1.4037, -1.6469, -3.1777]  w:  [1.5801863 1.1975441 2.5602406]
-12.326019435148556  -  2.6234  =  -14.949419435148556
training  [-4.433, -2.0077, -4.009]  w:  [1.5801863 1.1975441 2.5602406]
-19.673279718564636  -  0.3253  =  -19.998579718564635
training  [0.2189, -0.4741, -0.1024]  w:  [1.5801863 1.1975441 2.5602406]
-0.4840215138601624  -  33.6531  =  -34.137121513860166
training  [-1.6415, -0.7735, -3.0675]  w:  [1.5801863 1.1975441 2.5602406]
-11.373714206255617  -  3.7641  =  -15.137814206255616
training  [-3.2433, -1.4039, 3.9589]  w:  [1.5801863 1.1975441 2.5602406]
3.3294861019231243  -  30.0658  =  -26.736313898076876
training  [-2.9105, 0.5832, -4.0091]  w:  [1.5801863 1.1975441 2.5602406]
-14.164985087218597  -  2.4887  =  -16.653685087218598
training  [4.0515, 2.4255, -4.5583]  w:  [1.5801863 1.1975441 2.5602406]
-2.3635766929461077  -  61.2853  =  -63.648876692946104
training  [1.7539, -0.7567, 0.573]  w:  [1.5801863 1.1975441 2.5602406]
3.332324995330696  -  57.0797  =  -53.74737500466931
training  [-0.3153, -0.7064, 2.725]  w:  [1.5801863 1.1975441 2.5602406]
5.63247773176381  -  58.7004  =  -53.06792226823619
training  [4.1213, -3.7513, -1.8806]  w:  [1.5801863 1.1975441 2.5602406]
-2.7947138460676646  -  22.1789  =  -24.973613846067664
training  [-3.9599, -4.7557, -3.2102]  w:  [1.5801863 1.1975441 2.5602406]
-20.17142457991607  -  0.1558  =  -20.32722457991607
training  [2.4555, -2.0981, -1.6104]  w:  [1.5801863 1.1975441 2.5602406]
-2.755431270768283  -  24.4796  =  -27.235031270768285
training  [2.3627, -1.8248, -2.8985]  w:  [1.5801863 1.1975441 2.5602406]
-5.872629669203318  -  15.7052  =  -21.577829669203318
training  [0.6186, 1.5369, 0.1015]  w:  [1.5801863 1.1975441 2.5602406]
3.077873195464453  -  65.2154  =  -62.13752680453555
training  [-3.1581, 4.5694, 4.0636]  w:  [1.5801863 1.1975441 2.5602406]
10.885465343100883  -  90.3564  =  -79.47093465689912
training  [0.9721, 4.3573, 1.2892]  w:  [1.5801863 1.1975441 2.5602406]
10.054820191779722  -  94.3178  =  -84.26297980822028
training  [-2.0006, -0.4211, -3.9847]  w:  [1.5801863 1.1975441 2.5602406]
-13.867397241211886  -  2.4051  =  -16.272497241211887
training  [-3.6588, -2.5952, -1.0915]  w:  [1.5801863 1.1975441 2.5602406]
-11.683954702607206  -  1.5176  =  -13.201554702607206
training  [-2.874, 2.639, -4.4538]  w:  [1.5801863 1.1975441 2.5602406]
-12.783936117888643  -  5.497  =  -18.280936117888643
training  [3.9494, 2.5933, 0.0128]  w:  [1.5801863 1.1975441 2.5602406]
9.379149976618159  -  94.1462  =  -84.76705002338184
training  [-4.2855, 2.4065, -0.6828]  w:  [1.5801863 1.1975441 2.5602406]
-5.638130796721045  -  14.4193  =  -20.057430796721043
training  [-2.5751, 2.4369, 4.9756]  w:  [1.5801863 1.1975441 2.5602406]
11.587890585935014  -  87.1991  =  -75.61120941406499
training  [-4.4625, -3.9408, 3.116]  w:  [1.5801863 1.1975441 2.5602406]
-3.7931534655356804  -  4.1344  =  -7.927553465535681
training  [-0.5828, 1.8156, -0.1435]  w:  [1.5801863 1.1975441 2.5602406]
0.8859339672973043  -  51.1166  =  -50.23066603270269
training  [-4.8672, -0.3674, 3.9445]  w:  [1.5801863 1.1975441 2.5602406]
1.967808562475616  -  24.1396  =  -22.171791437524384
training  [3.9719, -2.8784, -3.6245]  w:  [1.5801863 1.1975441 2.5602406]
-6.4502610101951925  -  14.6104  =  -21.060661010195194
training  [-3.0334, -4.0148, -1.1]  w:  [1.5801863 1.1975441 2.5602406]
-12.417501840173719  -  1.021  =  -13.438501840173718
training  [-4.0663, 3.2357, 4.2736]  w:  [1.5801863 1.1975441 2.5602406]
8.390826101769463  -  77.2328  =  -68.84197389823053
training  [-1.9263, -3.2499, 4.1749]  w:  [1.5801863 1.1975441 2.5602406]
3.7529370199582806  -  26.8814  =  -23.128462980041718
training  [-0.4394, -3.3643, 2.1357]  w:  [1.5801863 1.1975441 2.5602406]
0.7446743624350116  -  20.85  =  -20.105325637564988
training  [-3.9833, 1.6599, 1.1834]  w:  [1.5801863 1.1975441 2.5602406]
-1.2767639207864865  -  25.5397  =  -26.816463920786486
training  [4.9539, 3.9439, -1.5671]  w:  [1.5801863 1.1975441 2.5602406]
8.538926060913191  -  95.9509  =  -87.4119739390868
training  [-1.6791, 0.1656, 4.3603]  w:  [1.5801863 1.1975441 2.5602406]
8.70843955692047  -  71.5733  =  -62.864860443079536
training  [-2.0265, 2.027, -3.7523]  w:  [1.5801863 1.1975441 2.5602406]
-10.381616438417362  -  8.503  =  -18.88461643841736
training  [-4.3795, -3.4641, 2.3059]  w:  [1.5801863 1.1975441 2.5602406]
-5.165179636855732  -  3.6654  =  -8.830579636855731
training  [-2.0176, 4.5346, 1.4648]  w:  [1.5801863 1.1975441 2.5602406]
5.992440023255325  -  81.6212  =  -75.62875997674467
training  [-4.5365, 0.4088, 3.3315]  w:  [1.5801863 1.1975441 2.5602406]
1.8504824178936765  -  28.9449  =  -27.094417582106324
training  [0.0543, 1.7973, -1.0172]  w:  [1.5801863 1.1975441 2.5602406]
-0.3661266060965964  -  47.9317  =  -48.29782660609659
training  [2.6143, -4.6344, 2.4982]  w:  [1.5801863 1.1975441 2.5602406]
4.9771757258241935  -  43.5132  =  -38.5360242741758
training  [1.3107, 3.092, 3.3522]  w:  [1.5801863 1.1975441 2.5602406]
14.356395073368851  -  96.6993  =  -82.34290492663115
training  [-4.1011, 2.4862, -1.7754]  w:  [1.5801863 1.1975441 2.5602406]
-8.048619053616486  -  10.0187  =  -18.067319053616487
training  [-4.1914, -3.7981, 0.5226]  w:  [1.5801863 1.1975441 2.5602406]
-9.833603379000754  -  1.4295  =  -11.263103379000754
training  [2.7724, 0.2505, 4.7913]  w:  [1.5801863 1.1975441 2.5602406]
16.947774070466714  -  96.7925  =  -79.8447259295333
training  [4.0513, -1.7417, 0.4931]  w:  [1.5801863 1.1975441 2.5602406]
5.578500841953477  -  71.1234  =  -65.54489915804653
training  [0.3377, 0.4645, -1.6958]  w:  [1.5801863 1.1975441 2.5602406]
-3.2517678546490085  -  27.9534  =  -31.205167854649005
training  [-3.9085, -1.0112, 1.1947]  w:  [1.5801863 1.1975441 2.5602406]
-4.328395314545338  -  8.608  =  -12.936395314545338
training  [3.2581, -0.8491, -1.3936]  w:  [1.5801863 1.1975441 2.5602406]
0.5636189983561009  -  50.1924  =  -49.6287810016439
training  [-1.619, -3.1926, 2.5651]  w:  [1.5801863 1.1975441 2.5602406]
0.18567223515836062  -  16.4754  =  -16.28972776484164
training  [-2.0603, -2.4461, -0.861]  w:  [1.5801863 1.1975441 2.5602406]
-8.389337616303926  -  3.9784  =  -12.367737616303927
training  [2.4631, -4.7946, -0.0765]  w:  [1.5801863 1.1975441 2.5602406]
-2.045446471875417  -  15.394  =  -17.439446471875417
training  [-4.8966, 4.2368, 1.9474]  w:  [1.5801863 1.1975441 2.5602406]
2.3220271391433425  -  53.5883  =  -51.26627286085665
training  [-4.5155, 1.537, 4.7273]  w:  [1.5801863 1.1975441 2.5602406]
6.808319409498828  -  59.2523  =  -52.44398059050117
training  [1.6792, 4.3261, -1.7225]  w:  [1.5801863 1.1975441 2.5602406]
3.4241299452042693  -  83.7729  =  -80.34877005479574
training  [1.0347, -3.3649, 3.378]  w:  [1.5801863 1.1975441 2.5602406]
6.253895356476829  -  50.5979  =  -44.34400464352317
training  [0.261, 4.211, 2.3907]  w:  [1.5801863 1.1975441 2.5602406]
11.576054027729962  -  94.9375  =  -83.36144597227003
training  [2.2971, 2.9466, 4.5417]  w:  [1.5801863 1.1975441 2.5602406]
18.78637411873834  -  98.7784  =  -79.99202588126167
training  [2.0725, 0.7739, -4.6808]  w:  [1.5801863 1.1975441 2.5602406]
-7.7822586942198395  -  19.5109  =  -27.29315869421984
training  [2.8138, -0.5996, -1.4313]  w:  [1.5801863 1.1975441 2.5602406]
0.0638084071663445  -  47.2879  =  -47.22409159283366
training  [-2.1202, -2.4239, 1.6265]  w:  [1.5801863 1.1975441 2.5602406]
-2.088806812845573  -  12.3599  =  -14.448706812845572
training  [1.9253, 2.5195, -2.185]  w:  [1.5801863 1.1975441 2.5602406]
0.4654193455098401  -  65.2467  =  -64.78128065449016
training  [0.5667, -2.7133, -2.6962]  w:  [1.5801863 1.1975441 2.5602406]
-9.256725528114623  -  5.1106  =  -14.367325528114623
training  [-1.0348, -4.3581, 2.1113]  w:  [1.5801863 1.1975441 2.5602406]
-1.4487577596453285  -  10.5192  =  -11.967957759645328
training  [-4.3841, 2.6733, 1.2457]  w:  [1.5801863 1.1975441 2.5602406]
-0.5370084095305012  -  32.4639  =  -33.0009084095305
training  [2.8018, 1.712, 0.9061]  w:  [1.5801863 1.1975441 2.5602406]
8.797395485501955  -  90.1138  =  -81.31640451449805
training  [-1.6242, 2.1521, 1.6044]  w:  [1.5801863 1.1975441 2.5602406]
4.118346081287564  -  63.7879  =  -59.66955391871244
training  [1.0787, 1.4206, -4.5245]  w:  [1.5801863 1.1975441 2.5602406]
-8.178030465625262  -  18.0555  =  -26.23353046562526
training  [2.4125, -0.8095, -1.5122]  w:  [1.5801863 1.1975441 2.5602406]
-1.0288083267644903  -  38.8276  =  -39.85640832676449
training  [-3.9519, -1.0924, -0.4866]  w:  [1.5801863 1.1975441 2.5602406]
-8.79874849599658  -  3.6777  =  -12.47644849599658
training  [-3.7211, 3.1614, -2.591]  w:  [1.5801863 1.1975441 2.5602406]
-8.727698712570142  -  11.1518  =  -19.87949871257014
training  [0.4954, -1.8257, 2.1505]  w:  [1.5801863 1.1975441 2.5602406]
4.102265431766561  -  47.7531  =  -43.65083456823344
training  [-0.1477, 3.1454, 3.5618]  w:  [1.5801863 1.1975441 2.5602406]
12.652426654908153  -  94.1572  =  -81.50477334509185
training  [3.9048, 2.8907, -2.1849]  w:  [1.5801863 1.1975441 2.5602406]
4.038182524146072  -  85.8791  =  -81.84091747585393
training  [2.9896, 3.5226, 2.3105]  w:  [1.5801863 1.1975441 2.5602406]
14.85802971581369  -  98.038  =  -83.17997028418631
training  [2.3434, 0.0564, -3.6224]  w:  [1.5801863 1.1975441 2.5602406]
-5.503665470079811  -  24.7629  =  -30.26656547007981
training  [-4.4867, 1.3566, 3.3672]  w:  [1.5801863 1.1975441 2.5602406]
3.1556085838355106  -  40.5785  =  -37.42289141616449
training  [-4.2711, 4.5089, -3.614]  w:  [1.5801863 1.1975441 2.5602406]
-10.60223663285618  -  10.0825  =  -20.68473663285618
training  [-4.1147, -0.5604, 0.8821]  w:  [1.5801863 1.1975441 2.5602406]
-4.914708059767678  -  8.344  =  -13.258708059767677
training  [2.9835, -4.3998, -1.3384]  w:  [1.5801863 1.1975441 2.5602406]
-3.9810947181861565  -  13.2692  =  -17.250294718186154
training  [4.4301, 3.6675, 3.0676]  w:  [1.5801863 1.1975441 2.5602406]
19.24617037935373  -  99.3834  =  -80.13722962064627
training  [1.8372, 1.3119, 0.0378]  w:  [1.5801863 1.1975441 2.5602406]
4.570953474087307  -  74.9026  =  -70.3316465259127
training  [-3.6792, -1.4493, -0.1041]  w:  [1.5801863 1.1975441 2.5602406]
-7.815943152936212  -  4.2442  =  -12.060143152936213
training  [2.2272, 4.97, 3.7705]  w:  [1.5801863 1.1975441 2.5602406]
19.124572281922276  -  99.3199  =  -80.19532771807772
training  [-3.8965, -2.7583, -1.4686]  w:  [1.5801863 1.1975441 2.5602406]
-13.220351158344423  -  1.0337  =  -14.254051158344422
training  [-3.8251, 1.5245, -0.5056]  w:  [1.5801863 1.1975441 2.5602406]
-5.513172286664744  -  12.9762  =  -18.489372286664747
training  [1.4072, 1.0499, 4.6353]  w:  [1.5801863 1.1975441 2.5602406]
15.348422952494106  -  95.4618  =  -80.11337704750589
training  [-1.7119, -1.1275, -4.577]  w:  [1.5801863 1.1975441 2.5602406]
-15.773573114089833  -  1.4655  =  -17.239073114089834
training  [1.5381, -3.5781, 4.7296]  w:  [1.5801863 1.1975441 2.5602406]
10.25446592875682  -  69.9473  =  -59.692834071243176
training  [2.4913, -4.7487, -3.1079]  w:  [1.5801863 1.1975441 2.5602406]
-9.707031288287544  -  3.9825  =  -13.689531288287544
training  [0.8319, -0.7889, 1.6712]  w:  [1.5801863 1.1975441 2.5602406]
4.6484885281826145  -  58.8336  =  -54.18511147181738
training  [2.4003, -3.159, 0.8644]  w:  [1.5801863 1.1975441 2.5602406]
2.222951337064831  -  39.0041  =  -36.78114866293517
training  [-2.6517, 2.2578, 1.7511]  w:  [1.5801863 1.1975441 2.5602406]
2.996872363207905  -  54.4525  =  -51.455627636792094
training  [2.3496, -1.2964, -1.3898]  w:  [1.5801863 1.1975441 2.5602406]
-1.3979128188488974  -  33.888  =  -35.28591281884889
training  [4.706, 3.4156, 1.2028]  w:  [1.5801863 1.1975441 2.5602406]
14.606145756567534  -  98.4665  =  -83.86035424343247
training  [3.6693, 2.3423, 3.1115]  w:  [1.5801863 1.1975441 2.5602406]
16.569373760673496  -  98.3069  =  -81.7375262393265
training  [-4.1377, 0.7103, -4.8074]  w:  [1.5801863 1.1975441 2.5602406]
-17.995821929730837  -  0.9782  =  -18.97402192973084
training  [-1.3356, -3.2314, -4.1613]  w:  [1.5801863 1.1975441 2.5602406]
-16.634170026606586  -  0.7659  =  -17.400070026606585
training  [-1.308, 4.5738, 4.748]  w:  [1.5801863 1.1975441 2.5602406]
15.566465878298011  -  97.0884  =  -81.52193412170197
training  [1.8503, -2.3468, 1.5135]  w:  [1.5801863 1.1975441 2.5602406]
3.988346361050627  -  50.2125  =  -46.224153638949375
training  [0.9794, 4.2458, -2.6876]  w:  [1.5801863 1.1975441 2.5602406]
-0.24873541978746694  -  68.3262  =  -68.57493541978747
training  [2.8936, -2.7623, -0.9651]  w:  [1.5801863 1.1975441 2.5602406]
-1.2064371868281234  -  28.5596  =  -29.76603718682812
training  [-1.3235, -1.2644, -3.7798]  w:  [1.5801863 1.1975441 2.5602406]
-13.282748738336416  -  2.4511  =  -15.733848738336416
training  [-2.9397, -4.125, -2.3156]  w:  [1.5801863 1.1975441 2.5602406]
-15.513636212770868  -  0.554  =  -16.067636212770868
training  [-4.1333, 1.4012, -2.4215]  w:  [1.5801863 1.1975441 2.5602406]
-11.053007851416872  -  4.4072  =  -15.460207851416872
training  [2.7193, -3.1938, -1.6833]  w:  [1.5801863 1.1975441 2.5602406]
-3.837368735191087  -  17.0949  =  -20.932268735191087
training  [-2.9433, -4.5495, -3.4777]  w:  [1.5801863 1.1975441 2.5602406]
-19.002937951521922  -  0.2509  =  -19.253837951521923
training  [-1.1173, 2.2317, -1.5199]  w:  [1.5801863 1.1975441 2.5602406]
-2.9842926676921775  -  33.1206  =  -36.104892667692184
training  [0.5178, -1.5256, -3.7834]  w:  [1.5801863 1.1975441 2.5602406]
-10.69516708620926  -  5.237  =  -15.93216708620926
training  [-2.7105, 1.6062, 3.8415]  w:  [1.5801863 1.1975441 2.5602406]
7.475564615536415  -  70.4458  =  -62.97023538446359
training  [1.4194, -1.1613, -4.0572]  w:  [1.5801863 1.1975441 2.5602406]
-9.535199675925638  -  8.3206  =  -17.85579967592564
training  [-0.1552, 1.2735, 4.3004]  w:  [1.5801863 1.1975441 2.5602406]
12.289886159804915  -  90.1085  =  -77.8186138401951
training  [-3.4815, -4.7835, -1.0098]  w:  [1.5801863 1.1975441 2.5602406]
-13.815201770532717  -  0.5839  =  -14.399101770532717
training  [2.8193, 4.1057, -4.526]  w:  [1.5801863 1.1975441 2.5602406]
-2.2158728843978572  -  66.8081  =  -69.02397288439785
training  [-3.9939, 3.0056, -1.5763]  w:  [1.5801863 1.1975441 2.5602406]
-6.7474747732977995  -  14.4018  =  -21.149274773297797
training  [-2.0593, 2.4585, 2.3597]  w:  [1.5801863 1.1975441 2.5602406]
5.731484256470729  -  70.6698  =  -64.93831574352927
training  [-2.6263, 3.1311, 2.9468]  w:  [1.5801863 1.1975441 2.5602406]
7.1441040398577496  -  77.309  =  -70.16489596014225
training  [0.3087, -1.1669, 0.4491]  w:  [1.5801863 1.1975441 2.5602406]
0.24019335193718971  -  33.0798  =  -32.83960664806281
training  [-4.085, 1.1728, 1.8622]  w:  [1.5801863 1.1975441 2.5602406]
-0.2829012822842296  -  26.4056  =  -26.68850128228423
training  [-0.9468, 0.7549, 3.9363]  w:  [1.5801863 1.1975441 2.5602406]
9.485780711415137  -  79.7738  =  -70.28801928858486
training  [-3.9515, 0.3005, -4.4521]  w:  [1.5801863 1.1975441 2.5602406]
-17.28269132893513  -  1.0441  =  -18.32679132893513
training  [-3.8772, -2.2493, -1.9634]  w:  [1.5801863 1.1975441 2.5602406]
-13.8471106625387  -  1.0509  =  -14.8980106625387
training  [2.8443, -2.5137, -4.5381]  w:  [1.5801863 1.1975441 2.5602406]
-10.134370559463477  -  6.8897  =  -17.02407055946348
training  [-2.0843, -0.4836, -3.0452]  w:  [1.5801863 1.1975441 2.5602406]
-11.669159300524607  -  3.5346  =  -15.203759300524606
training  [1.0353, -2.7229, 2.2017]  w:  [1.5801863 1.1975441 2.5602406]
4.012055767315049  -  43.9562  =  -39.944144232684955
training  [4.6442, 3.0445, 2.2175]  w:  [1.5801863 1.1975441 2.5602406]
16.661957760590326  -  98.8492  =  -82.18724223940967
training  [-0.6752, 4.861, 3.778]  w:  [1.5801863 1.1975441 2.5602406]
14.42690905717978  -  97.017  =  -82.59009094282021
training  [1.9475, -4.7001, 0.8243]  w:  [1.5801863 1.1975441 2.5602406]
-0.4407578821644109  -  18.7839  =  -19.22465788216441
training  [2.581, 0.3566, -4.2932]  w:  [1.5801863 1.1975441 2.5602406]
-6.486119857856153  -  23.5455  =  -30.031619857856153
training  [-0.6736, -4.1292, 4.2274]  w:  [1.5801863 1.1975441 2.5602406]
4.81384850358065  -  31.2667  =  -26.45285149641935
training  [1.555, 3.0209, 3.0037]  w:  [1.5801863 1.1975441 2.5602406]
13.765045353421002  -  96.4078  =  -82.642754646579
training  [-3.9024, 4.8914, -2.1405]  w:  [1.5801863 1.1975441 2.5602406]
-5.789046805808039  -  25.4308  =  -31.21984680580804
training  [4.3376, -4.3305, 0.4366]  w:  [1.5801863 1.1975441 2.5602406]
2.786052418073601  -  43.0907  =  -40.304647581926396
training  [-3.1254, 4.394, 4.8478]  w:  [1.5801863 1.1975441 2.5602406]
12.734828875680195  -  92.8121  =  -80.07727112431981
training  [-2.3382, -4.8182, 2.1568]  w:  [1.5801863 1.1975441 2.5602406]
-3.9428716790298424  -  4.7434  =  -8.686271679029844
training  [2.9783, 1.8384, 3.3897]  w:  [1.5801863 1.1975441 2.5602406]
15.586281487681322  -  97.3486  =  -81.76231851231869
training  [-0.124, 2.8374, -0.6674]  w:  [1.5801863 1.1975441 2.5602406]
1.4932639562993124  -  62.785  =  -61.29173604370068
training  [2.6896, 0.3414, -0.2938]  w:  [1.5801863 1.1975441 2.5602406]
3.906711945984508  -  70.4455  =  -66.53878805401548
training  [-1.0399, 3.8536, 0.6071]  w:  [1.5801863 1.1975441 2.5602406]
4.525942278128769  -  77.0369  =  -72.51095772187124
training  [-2.2706, 3.99, -2.3091]  w:  [1.5801863 1.1975441 2.5602406]
-4.721621615714097  -  31.1134  =  -35.8350216157141
training  [-4.6277, 1.2594, 2.4902]  w:  [1.5801863 1.1975441 2.5602406]
0.5710700255159784  -  28.1093  =  -27.53822997448402
training  [1.7329, -3.6213, 0.0389]  w:  [1.5801863 1.1975441 2.5602406]
-1.4987682510106262  -  19.3919  =  -20.890668251010627
training  [-0.7044, -2.822, 1.4681]  w:  [1.5801863 1.1975441 2.5602406]
-0.7338634638715757  -  17.8122  =  -18.546063463871576
training  [-0.4826, -3.1786, -1.9225]  w:  [1.5801863 1.1975441 2.5602406]
-9.49117413514658  -  3.5851  =  -13.07627413514658
training  [1.0986, -4.5818, -3.6128]  w:  [1.5801863 1.1975441 2.5602406]
-13.000552117500504  -  1.7158  =  -14.716352117500504
training  [-4.406, -3.9306, -0.2443]  w:  [1.5801863 1.1975441 2.5602406]
-12.294834466211737  -  0.8241  =  -13.118934466211737
training  [-1.8419, 1.1644, -1.3754]  w:  [1.5801863 1.1975441 2.5602406]
-5.0374797146188675  -  17.8517  =  -22.88917971461887
training  [2.7272, 4.3966, 2.8811]  w:  [1.5801863 1.1975441 2.5602406]
16.950915658791082  -  98.904  =  -81.95308434120892
training  [1.9643, -1.4554, 2.803]  w:  [1.5801863 1.1975441 2.5602406]
8.537408660217642  -  76.0591  =  -67.52169133978236
training  [-3.7467, -0.8937, 1.6851]  w:  [1.5801863 1.1975441 2.5602406]
-2.6764677505237877  -  12.1571  =  -14.833567750523788
training  [-3.6985, 4.8435, -3.665]  w:  [1.5801863 1.1975441 2.5602406]
-9.427295970737765  -  14.6793  =  -24.106595970737764
233708.76248673865
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.45484771 1.23715391 2.63557702]
13.21704553498779  -  87.3174  =  -74.10035446501222
training  [-4.1793, -4.9218, 1.7664]  w:  [1.45484771 1.23715391 2.63557702]
-7.513785872584663  -  1.5257  =  -9.039485872584663
training  [-3.9429, -0.7689, 4.883]  w:  [1.45484771 1.23715391 2.63557702]
6.181955928070849  -  39.7859  =  -33.60394407192915
training  [-3.5796, 1.5557, 2.6683]  w:  [1.45484771 1.23715391 2.63557702]
3.749377641142128  -  45.5674  =  -41.818022358857874
training  [-3.3354, 2.2292, -1.633]  w:  [1.45484771 1.23715391 2.63557702]
-6.3985328355666855  -  13.3589  =  -19.757432835566686
training  [1.2096, 0.3121, 1.6238]  w:  [1.45484771 1.23715391 2.63557702]
6.42554948996327  -  74.5119  =  -68.08635051003672
training  [0.7371, -3.9118, -2.5583]  w:  [1.45484771 1.23715391 2.63557702]
-10.509727098502216  -  3.3358  =  -13.845527098502217
training  [-4.4792, 1.3177, -2.0449]  w:  [1.45484771 1.23715391 2.63557702]
-10.275847605210647  -  4.2974  =  -14.573247605210646
training  [4.312, -3.735, 1.8018]  w:  [1.45484771 1.23715391 2.63557702]
6.401316157033797  -  66.5833  =  -60.1819838429662
training  [2.2866, -3.657, 0.2785]  w:  [1.45484771 1.23715391 2.63557702]
-0.4636088640638091  -  26.0005  =  -26.464108864063807
training  [2.3784, -4.0141, -0.8841]  w:  [1.45484771 1.23715391 2.63557702]
-3.83596334960418  -  14.6809  =  -18.51686334960418
training  [-4.366, -3.5797, 1.0264]  w:  [1.45484771 1.23715391 2.63557702]
-8.075348678270501  -  1.8713  =  -9.9466486782705
training  [3.6044, -3.3175, 2.5052]  w:  [1.45484771 1.23715391 2.63557702]
7.742242551299672  -  71.0139  =  -63.27165744870034
training  [4.3441, -3.0375, 0.8353]  w:  [1.45484771 1.23715391 2.63557702]
4.763646426667634  -  63.8979  =  -59.134253573332366
training  [4.844, -1.8252, 0.5179]  w:  [1.45484771 1.23715391 2.63557702]
6.15419432994077  -  78.0461  =  -71.89190567005923
training  [3.5894, -1.8357, 0.8357]  w:  [1.45484771 1.23715391 2.63557702]
5.153538656295413  -  68.8838  =  -63.73026134370458
training  [2.8556, -2.8244, 0.1182]  w:  [1.45484771 1.23715391 2.63557702]
0.9717708277871102  -  39.5252  =  -38.55342917221289
training  [0.1338, -2.4896, -4.1741]  w:  [1.45484771 1.23715391 2.63557702]
-13.8865217871678  -  2.2644  =  -16.1509217871678
training  [-3.224, 3.9292, 2.1957]  w:  [1.45484771 1.23715391 2.63557702]
5.957532582165629  -  72.1211  =  -66.16356741783437
training  [-1.0141, 2.0322, 4.9616]  w:  [1.45484771 1.23715391 2.63557702]
14.115462057187699  -  92.3427  =  -78.2272379428123
training  [-3.6607, 0.5574, -1.4547]  w:  [1.45484771 1.23715391 2.63557702]
-8.470145312519001  -  5.8471  =  -14.317245312519002
training  [-4.6911, -3.1557, 4.7126]  w:  [1.45484771 1.23715391 2.63557702]
1.6914976048601087  -  11.2337  =  -9.542202395139892
training  [4.3914, -2.8797, -1.5355]  w:  [1.45484771 1.23715391 2.63557702]
-1.2207423930918635  -  37.475  =  -38.69574239309186
training  [-1.9869, -4.2265, 3.8654]  w:  [1.45484771 1.23715391 2.63557702]
2.0680915227934182  -  15.7889  =  -13.720808477206582
training  [-2.0447, 4.138, -0.4531]  w:  [1.45484771 1.23715391 2.63557702]
0.9504358056474391  -  57.936  =  -56.98556419435256
training  [-1.6706, 2.0672, -0.8657]  w:  [1.45484771 1.23715391 2.63557702]
-2.154643054588596  -  32.4185  =  -34.5731430545886
training  [-0.3293, 0.5779, -2.8227]  w:  [1.45484771 1.23715391 2.63557702]
-7.203573366855347  -  14.3434  =  -21.546973366855347
training  [1.482, -1.8657, -3.7435]  w:  [1.45484771 1.23715391 2.63557702]
-10.018356319014636  -  7.1519  =  -17.170256319014637
training  [-4.7477, -3.338, -1.9109]  w:  [1.45484771 1.23715391 2.63557702]
-16.07312433497676  -  0.4077  =  -16.48082433497676
training  [3.4221, 1.225, 2.261]  w:  [1.45484771 1.23715391 2.63557702]
12.45318752411627  -  95.0454  =  -82.59221247588373
training  [0.5903, 4.8793, 2.8287]  w:  [1.45484771 1.23715391 2.63557702]
14.35049837761894  -  97.4647  =  -83.11420162238105
training  [3.541, -3.2957, 1.9379]  w:  [1.45484771 1.23715391 2.63557702]
6.18181231739196  -  64.3732  =  -58.19138768260804
training  [-1.5212, -2.4221, -4.902]  w:  [1.45484771 1.23715391 2.63557702]
-18.129223370084695  -  0.7227  =  -18.851923370084695
training  [-0.5397, -1.032, 3.4321]  w:  [1.45484771 1.23715391 2.63557702]
6.983639756328099  -  60.5921  =  -53.6084602436719
training  [-4.4576, -4.2601, 4.2233]  w:  [1.45484771 1.23715391 2.63557702]
-0.6246960658306033  -  6.0247  =  -6.6493960658306035
training  [-3.2289, 1.841, 2.7095]  w:  [1.45484771 1.23715391 2.63557702]
4.7211385152320124  -  54.0111  =  -49.289961484767986
training  [1.6281, -0.9761, -4.5734]  w:  [1.45484771 1.23715391 2.63557702]
-10.892496324089398  -  7.8658  =  -18.7582963240894
training  [-1.6917, 4.8284, -1.2181]  w:  [1.45484771 1.23715391 2.63557702]
0.30191168205502406  -  61.2837  =  -60.98178831794498
training  [3.9849, -0.9782, 2.0434]  w:  [1.45484771 1.23715391 2.63557702]
9.972776768507213  -  88.3402  =  -78.36742323149278
training  [-3.8184, 1.2067, 2.2951]  w:  [1.45484771 1.23715391 2.63557702]
1.9865959506463318  -  34.1122  =  -32.12560404935367
training  [4.8842, -3.4563, -2.7572]  w:  [1.45484771 1.23715391 2.63557702]
-4.437020831900431  -  23.7819  =  -28.21892083190043
training  [0.3998, -1.1865, -2.3095]  w:  [1.45484771 1.23715391 2.63557702]
-6.973100127144303  -  11.4246  =  -18.397700127144304
training  [2.0692, -3.3887, 1.7303]  w:  [1.45484771 1.23715391 2.63557702]
3.3783663570623905  -  42.6881  =  -39.30973364293761
training  [4.9949, 2.5811, -0.2251]  w:  [1.45484771 1.23715391 2.63557702]
9.86676837884683  -  95.9901  =  -86.12333162115317
training  [-2.1215, 3.7111, 1.2372]  w:  [1.45484771 1.23715391 2.63557702]
4.765478338671624  -  71.3692  =  -66.60372166132838
training  [-0.8548, -1.4922, -2.6356]  w:  [1.45484771 1.23715391 2.63557702]
-10.036011678085103  -  4.7821  =  -14.818111678085103
training  [-0.3516, 1.8554, -3.2288]  w:  [1.45484771 1.23715391 2.63557702]
-6.725860184095379  -  20.3834  =  -27.10926018409538
training  [2.6396, -2.0585, 3.2964]  w:  [1.45484771 1.23715391 2.63557702]
9.981450789469587  -  80.826  =  -70.8445492105304
training  [3.182, 0.3063, 2.6692]  w:  [1.45484771 1.23715391 2.63557702]
12.043147835921584  -  92.9483  =  -80.90515216407842
training  [-3.9978, 3.3242, 4.3448]  w:  [1.45484771 1.23715391 2.63557702]
9.747411889176227  -  79.1768  =  -69.42938811082377
training  [-3.2188, 0.9749, -3.9211]  w:  [1.45484771 1.23715391 2.63557702]
-13.811123520335356  -  2.7053  =  -16.516423520335355
training  [-1.4037, -1.6469, -3.1777]  w:  [1.45484771 1.23715391 2.63557702]
-12.454711597965483  -  2.6234  =  -15.078111597965483
training  [-4.433, -2.0077, -4.009]  w:  [1.45484771 1.23715391 2.63557702]
-19.49920206872063  -  0.3253  =  -19.82450206872063
training  [0.2189, -0.4741, -0.1024]  w:  [1.45484771 1.23715391 2.63557702]
-0.5379515905304151  -  33.6531  =  -34.191051590530414
training  [-1.6415, -0.7735, -3.0675]  w:  [1.45484771 1.23715391 2.63557702]
-11.42970357362644  -  3.7641  =  -15.19380357362644
training  [-3.2433, -1.4039, 3.9589]  w:  [1.45484771 1.23715391 2.63557702]
3.9786379288834812  -  30.0658  =  -26.087162071116516
training  [-2.9105, 0.5832, -4.0091]  w:  [1.45484771 1.23715391 2.63557702]
-14.07911793474689  -  2.4887  =  -16.56781793474689
training  [4.0515, 2.4255, -4.5583]  w:  [1.45484771 1.23715391 2.63557702]
-3.118718447069771  -  61.2853  =  -64.40401844706977
training  [1.7539, -0.7567, 0.573]  w:  [1.45484771 1.23715391 2.63557702]
3.125688668517263  -  57.0797  =  -53.95401133148274
training  [-0.3153, -0.7064, 2.725]  w:  [1.45484771 1.23715391 2.63557702]
5.849308382003226  -  58.7004  =  -52.85109161799677
training  [4.1213, -3.7513, -1.8806]  w:  [1.45484771 1.23715391 2.63557702]
-3.601537733918369  -  22.1789  =  -25.78043773391837
training  [-3.9599, -4.7557, -3.2102]  w:  [1.45484771 1.23715391 2.63557702]
-20.105313627125323  -  0.1558  =  -20.261113627125322
training  [2.4555, -2.0981, -1.6104]  w:  [1.45484771 1.23715391 2.63557702]
-3.2676272978438727  -  24.4796  =  -27.747227297843875
training  [2.3627, -1.8248, -2.8985]  w:  [1.45484771 1.23715391 2.63557702]
-6.459409764137129  -  15.7052  =  -22.16460976413713
training  [0.6186, 1.5369, 0.1015]  w:  [1.45484771 1.23715391 2.63557702]
3.0688616985534707  -  65.2154  =  -62.14653830144653
training  [-3.1581, 4.5694, 4.0636]  w:  [1.45484771 1.23715391 2.63557702]
11.768427295493021  -  90.3564  =  -78.58797270450697
training  [0.9721, 4.3573, 1.2892]  w:  [1.45484771 1.23715391 2.63557702]
10.202694068984497  -  94.3178  =  -84.1151059310155
training  [-2.0006, -0.4211, -3.9847]  w:  [1.45484771 1.23715391 2.63557702]
-13.933517593412382  -  2.4051  =  -16.338617593412383
training  [-3.6588, -2.5952, -1.0915]  w:  [1.45484771 1.23715391 2.63557702]
-11.410390932205152  -  1.5176  =  -12.927990932205152
training  [-2.874, 2.639, -4.4538]  w:  [1.45484771 1.23715391 2.63557702]
-12.65471609459299  -  5.497  =  -18.15171609459299
training  [3.9494, 2.5933, 0.0128]  w:  [1.45484771 1.23715391 2.63557702]
8.987822150695239  -  94.1462  =  -85.15837784930476
training  [-4.2855, 2.4065, -0.6828]  w:  [1.45484771 1.23715391 2.63557702]
-5.05711096994726  -  14.4193  =  -19.47641096994726
training  [-2.5751, 2.4369, 4.9756]  w:  [1.45484771 1.23715391 2.63557702]
12.382019048339425  -  87.1991  =  -74.81708095166057
training  [-4.4625, -3.9408, 3.116]  w:  [1.45484771 1.23715391 2.63557702]
-3.155176013360995  -  4.1344  =  -7.289576013360995
training  [-0.5828, 1.8156, -0.1435]  w:  [1.45484771 1.23715391 2.63557702]
1.0200860849171591  -  51.1166  =  -50.09651391508284
training  [-4.8672, -0.3674, 3.9445]  w:  [1.45484771 1.23715391 2.63557702]
2.8604684496714023  -  24.1396  =  -21.2791315503286
training  [3.9719, -2.8784, -3.6245]  w:  [1.45484771 1.23715391 2.63557702]
-7.335163104814046  -  14.6104  =  -21.945563104814045
training  [-3.0334, -4.0148, -1.1]  w:  [1.45484771 1.23715391 2.63557702]
-12.279195265179677  -  1.021  =  -13.300195265179678
training  [-4.0663, 3.2357, 4.2736]  w:  [1.45484771 1.23715391 2.63557702]
9.350613616511678  -  77.2328  =  -67.88218638348832
training  [-1.9263, -3.2499, 4.1749]  w:  [1.45484771 1.23715391 2.63557702]
4.180170886867204  -  26.8814  =  -22.701229113132797
training  [-0.4394, -3.3643, 2.1357]  w:  [1.45484771 1.23715391 2.63557702]
0.8273848753686437  -  20.85  =  -20.022615124631358
training  [-3.9833, 1.6599, 1.1834]  w:  [1.45484771 1.23715391 2.63557702]
-0.6226012611043834  -  25.5397  =  -26.162301261104382
training  [4.9539, 3.9439, -1.5671]  w:  [1.45484771 1.23715391 2.63557702]
7.956168603155818  -  95.9509  =  -87.99473139684419
training  [-1.6791, 0.1656, 4.3603]  w:  [1.45484771 1.23715391 2.63557702]
9.25394438671139  -  71.5733  =  -62.319355613288614
training  [-2.0265, 2.027, -3.7523]  w:  [1.45484771 1.23715391 2.63557702]
-10.330013571568735  -  8.503  =  -18.833013571568735
training  [-4.3795, -3.4641, 2.3059]  w:  [1.45484771 1.23715391 2.63557702]
-4.579753331669895  -  3.6654  =  -8.245153331669895
training  [-2.0176, 4.5346, 1.4648]  w:  [1.45484771 1.23715391 2.63557702]
6.535290587422539  -  81.6212  =  -75.08590941257746
training  [-4.5365, 0.4088, 3.3315]  w:  [1.45484771 1.23715391 2.63557702]
2.6862567346084774  -  28.9449  =  -26.258643265391523
training  [0.0543, 1.7973, -1.0172]  w:  [1.45484771 1.23715391 2.63557702]
-0.3783740002330931  -  47.9317  =  -48.310074000233094
training  [2.6143, -4.6344, 2.4982]  w:  [1.45484771 1.23715391 2.63557702]
4.6541408169323155  -  43.5132  =  -38.859059183067686
training  [1.3107, 3.092, 3.3522]  w:  [1.45484771 1.23715391 2.63557702]
14.567130061137142  -  96.6993  =  -82.13216993886286
training  [-4.1011, 2.4862, -1.7754]  w:  [1.45484771 1.23715391 2.63557702]
-7.569867339957343  -  10.0187  =  -17.588567339957343
training  [-4.1914, -3.7981, 0.5226]  w:  [1.45484771 1.23715391 2.63557702]
-9.419330384944306  -  1.4295  =  -10.848830384944307
training  [2.7724, 0.2505, 4.7913]  w:  [1.45484771 1.23715391 2.63557702]
16.971167024051546  -  96.7925  =  -79.82133297594845
training  [4.0513, -1.7417, 0.4931]  w:  [1.45484771 1.23715391 2.63557702]
5.038876592439094  -  71.1234  =  -66.08452340756091
training  [0.3377, 0.4645, -1.6958]  w:  [1.45484771 1.23715391 2.63557702]
-3.4034514526224497  -  27.9534  =  -31.356851452622447
training  [-3.9085, -1.0112, 1.1947]  w:  [1.45484771 1.23715391 2.63557702]
-3.7885584309173126  -  8.608  =  -12.396558430917313
training  [3.2581, -0.8491, -1.3936]  w:  [1.45484771 1.23715391 2.63557702]
0.016631800078199532  -  50.1924  =  -50.1757681999218
training  [-1.619, -3.1926, 2.5651]  w:  [1.45484771 1.23715391 2.63557702]
0.4553826171724902  -  16.4754  =  -16.02001738282751
training  [-2.0603, -2.4461, -0.861]  w:  [1.45484771 1.23715391 2.63557702]
-8.29285671927816  -  3.9784  =  -12.27125671927816
training  [2.4631, -4.7946, -0.0765]  w:  [1.45484771 1.23715391 2.63557702]
-2.549844369825537  -  15.394  =  -17.943844369825538
training  [-4.8966, 4.2368, 1.9474]  w:  [1.45484771 1.23715391 2.63557702]
3.2502890719991457  -  53.5883  =  -50.33801092800085
training  [-4.5155, 1.537, 4.7273]  w:  [1.45484771 1.23715391 2.63557702]
7.7913039801433435  -  59.2523  =  -51.46099601985665
training  [1.6792, 4.3261, -1.7225]  w:  [1.45484771 1.23715391 2.63557702]
3.255250365899771  -  83.7729  =  -80.51764963410024
training  [1.0347, -3.3649, 3.378]  w:  [1.45484771 1.23715391 2.63557702]
6.245410924040779  -  50.5979  =  -44.35248907595923
training  [0.261, 4.211, 2.3907]  w:  [1.45484771 1.23715391 2.63557702]
11.890244336267127  -  94.9375  =  -83.04725566373287
training  [2.2971, 2.9466, 4.5417]  w:  [1.45484771 1.23715391 2.63557702]
18.957328530019957  -  98.7784  =  -79.82107146998004
training  [2.0725, 0.7739, -4.6808]  w:  [1.45484771 1.23715391 2.63557702]
-8.364003638762188  -  19.5109  =  -27.874903638762188
training  [2.8138, -0.5996, -1.4313]  w:  [1.45484771 1.23715391 2.63557702]
-0.4204483909359711  -  47.2879  =  -47.708348390935974
training  [-2.1202, -2.4239, 1.6265]  w:  [1.45484771 1.23715391 2.63557702]
-1.796539439117904  -  12.3599  =  -14.156439439117904
training  [1.9253, 2.5195, -2.185]  w:  [1.45484771 1.23715391 2.63557702]
0.15929176760668629  -  65.2467  =  -65.08740823239332
training  [0.5667, -2.7133, -2.6962]  w:  [1.45484771 1.23715391 2.63557702]
-9.638350262770558  -  5.1106  =  -14.748950262770558
training  [-1.0348, -4.3581, 2.1113]  w:  [1.45484771 1.23715391 2.63557702]
-1.3326230815463278  -  10.5192  =  -11.851823081546328
training  [-4.3841, 2.6733, 1.2457]  w:  [1.45484771 1.23715391 2.63557702]
0.21222399427764627  -  32.4639  =  -32.25167600572236
training  [2.8018, 1.712, 0.9061]  w:  [1.45484771 1.23715391 2.63557702]
8.582296136292658  -  90.1138  =  -81.53150386370734
training  [-1.6242, 2.1521, 1.6044]  w:  [1.45484771 1.23715391 2.63557702]
4.528035046726564  -  63.7879  =  -59.259864953273436
training  [1.0787, 1.4206, -4.5245]  w:  [1.45484771 1.23715391 2.63557702]
-8.5978231718845  -  18.0555  =  -26.653323171884498
training  [2.4125, -0.8095, -1.5122]  w:  [1.45484771 1.23715391 2.63557702]
-1.4771755623082083  -  38.8276  =  -40.30477556230821
training  [-3.9519, -1.0924, -0.4866]  w:  [1.45484771 1.23715391 2.63557702]
-8.383351365031038  -  3.6777  =  -12.061051365031037
training  [-3.7211, 3.1614, -2.591]  w:  [1.45484771 1.23715391 2.63557702]
-8.331275512085835  -  11.1518  =  -19.483075512085833
training  [0.4954, -1.8257, 2.1505]  w:  [1.45484771 1.23715391 2.63557702]
4.129868053220475  -  47.7531  =  -43.623231946779526
training  [-0.1477, 3.1454, 3.5618]  w:  [1.45484771 1.23715391 2.63557702]
13.063861125367445  -  94.1572  =  -81.09333887463256
training  [3.9048, 2.8907, -2.1849]  w:  [1.45484771 1.23715391 2.63557702]
3.498657894260303  -  85.8791  =  -82.38044210573969
training  [2.9896, 3.5226, 2.3105]  w:  [1.45484771 1.23715391 2.63557702]
14.796911767557447  -  98.038  =  -83.24108823244255
training  [2.3434, 0.0564, -3.6224]  w:  [1.45484771 1.23715391 2.63557702]
-6.068048602559292  -  24.7629  =  -30.83094860255929
training  [-4.4867, 1.3566, 3.3672]  w:  [1.45484771 1.23715391 2.63557702]
4.025372722424031  -  40.5785  =  -36.55312727757597
training  [-4.2711, 4.5089, -3.614]  w:  [1.45484771 1.23715391 2.63557702]
-10.160572156285323  -  10.0825  =  -20.243072156285322
training  [-4.1147, -0.5604, 0.8821]  w:  [1.45484771 1.23715391 2.63557702]
-4.35472042445863  -  8.344  =  -12.69872042445863
training  [2.9835, -4.3998, -1.3384]  w:  [1.45484771 1.23715391 2.63557702]
-4.630147903699886  -  13.2692  =  -17.899347903699883
training  [4.4301, 3.6675, 3.0676]  w:  [1.45484771 1.23715391 2.63557702]
19.067278855699495  -  99.3834  =  -80.3161211443005
training  [1.8372, 1.3119, 0.0378]  w:  [1.45484771 1.23715391 2.63557702]
4.3954932309749575  -  74.9026  =  -70.50710676902504
training  [-3.6792, -1.4493, -0.1041]  w:  [1.45484771 1.23715391 2.63557702]
-7.4200464132769515  -  4.2442  =  -11.664246413276953
training  [2.2272, 4.97, 3.7705]  w:  [1.45484771 1.23715391 2.63557702]
19.326334889883135  -  99.3199  =  -79.99356511011686
training  [-3.8965, -2.7583, -1.4686]  w:  [1.45484771 1.23715391 2.63557702]
-12.951864129449994  -  1.0337  =  -13.985564129449994
training  [-3.8251, 1.5245, -0.5056]  w:  [1.45484771 1.23715391 2.63557702]
-5.011444581963934  -  12.9762  =  -17.987644581963934
training  [1.4072, 1.0499, 4.6353]  w:  [1.45484771 1.23715391 2.63557702]
15.562839749622247  -  95.4618  =  -79.89896025037775
training  [-1.7119, -1.1275, -4.577]  w:  [1.45484771 1.23715391 2.63557702]
-15.94848084916351  -  1.4655  =  -17.413980849163508
training  [1.5381, -3.5781, 4.7296]  w:  [1.45484771 1.23715391 2.63557702]
10.276265950076581  -  69.9473  =  -59.67103404992342
training  [2.4913, -4.7487, -3.1079]  w:  [1.45484771 1.23715391 2.63557702]
-10.44152048337357  -  3.9825  =  -14.42402048337357
training  [0.8319, -0.7889, 1.6712]  w:  [1.45484771 1.23715391 2.63557702]
4.638873410598424  -  58.8336  =  -54.194726589401576
training  [2.4003, -3.159, 0.8644]  w:  [1.45484771 1.23715391 2.63557702]
1.862094542606762  -  39.0041  =  -37.14200545739324
training  [-2.6517, 2.2578, 1.7511]  w:  [1.45484771 1.23715391 2.63557702]
3.5505853431861274  -  54.4525  =  -50.90191465681387
training  [2.3496, -1.2964, -1.3898]  w:  [1.45484771 1.23715391 2.63557702]
-1.8484610926425191  -  33.888  =  -35.736461092642514
training  [4.706, 3.4156, 1.2028]  w:  [1.45484771 1.23715391 2.63557702]
14.24220823966889  -  98.4665  =  -84.22429176033111
training  [3.6693, 2.3423, 3.1115]  w:  [1.45484771 1.23715391 2.63557702]
16.436656193869418  -  98.3069  =  -81.87024380613059
training  [-4.1377, 0.7103, -4.8074]  w:  [1.45484771 1.23715391 2.63557702]
-17.81124591747775  -  0.9782  =  -18.78944591747775
training  [-1.3356, -3.2314, -4.1613]  w:  [1.45484771 1.23715391 2.63557702]
-16.908260391759274  -  0.7659  =  -17.674160391759273
training  [-1.308, 4.5738, 4.748]  w:  [1.45484771 1.23715391 2.63557702]
16.269273431753412  -  97.0884  =  -80.81912656824659
training  [1.8503, -2.3468, 1.5135]  w:  [1.45484771 1.23715391 2.63557702]
3.777497750223684  -  50.2125  =  -46.43500224977632
training  [0.9794, 4.2458, -2.6876]  w:  [1.45484771 1.23715391 2.63557702]
-0.40579090270408447  -  68.3262  =  -68.73199090270408
training  [2.8936, -2.7623, -0.9651]  w:  [1.45484771 1.23715391 2.63557702]
-1.7512382891957277  -  28.5596  =  -30.31083828919573
training  [-1.3235, -1.2644, -3.7798]  w:  [1.45484771 1.23715391 2.63557702]
-13.451702367329926  -  2.4511  =  -15.902802367329926
training  [-2.9397, -4.125, -2.3156]  w:  [1.45484771 1.23715391 2.63557702]
-15.483017822785955  -  0.554  =  -16.037017822785955
training  [-4.1333, 1.4012, -2.4215]  w:  [1.45484771 1.23715391 2.63557702]
-10.6618717380019  -  4.4072  =  -15.069071738001899
training  [2.7193, -3.1938, -1.6833]  w:  [1.45484771 1.23715391 2.63557702]
-4.431521572196948  -  17.0949  =  -21.526421572196945
training  [-2.9433, -4.5495, -3.4777]  w:  [1.45484771 1.23715391 2.63557702]
-19.076231164482223  -  0.2509  =  -19.327131164482225
training  [-1.1173, 2.2317, -1.5199]  w:  [1.45484771 1.23715391 2.63557702]
-2.8703584874277857  -  33.1206  =  -35.99095848742779
training  [0.5178, -1.5256, -3.7834]  w:  [1.45484771 1.23715391 2.63557702]
-11.105523959229105  -  5.237  =  -16.342523959229105
training  [-2.7105, 1.6062, 3.8415]  w:  [1.45484771 1.23715391 2.63557702]
8.16832101858305  -  70.4458  =  -62.277478981416955
training  [1.4194, -1.1613, -4.0572]  w:  [1.45484771 1.23715391 2.63557702]
-10.0647590857355  -  8.3206  =  -18.3853590857355
training  [-0.1552, 1.2735, 4.3004]  w:  [1.45484771 1.23715391 2.63557702]
12.683758558746263  -  90.1085  =  -77.42474144125374
training  [-3.4815, -4.7835, -1.0098]  w:  [1.45484771 1.23715391 2.63557702]
-13.644383683681458  -  0.5839  =  -14.228283683681457
training  [2.8193, 4.1057, -4.526]  w:  [1.45484771 1.23715391 2.63557702]
-2.7475866625556655  -  66.8081  =  -69.55568666255566
training  [-3.9939, 3.0056, -1.5763]  w:  [1.45484771 1.23715391 2.63557702]
-6.246586541747696  -  14.4018  =  -20.648386541747698
training  [-2.0593, 2.4585, 2.3597]  w:  [1.45484771 1.23715391 2.63557702]
6.264746090005083  -  70.6698  =  -64.4050539099949
training  [-2.6263, 3.1311, 2.9468]  w:  [1.45484771 1.23715391 2.63557702]
7.819304425939012  -  77.309  =  -69.48969557406099
training  [0.3087, -1.1669, 0.4491]  w:  [1.45484771 1.23715391 2.63557702]
0.18911423490522083  -  33.0798  =  -32.89068576509478
training  [-4.085, 1.1728, 1.8622]  w:  [1.45484771 1.23715391 2.63557702]
0.4158527414978046  -  26.4056  =  -25.989747258502195
training  [-0.9468, 0.7549, 3.9363]  w:  [1.45484771 1.23715391 2.63557702]
9.930899503400553  -  79.7738  =  -69.84290049659944
training  [-3.9515, 0.3005, -4.4521]  w:  [1.45484771 1.23715391 2.63557702]
-17.110918429132305  -  1.0441  =  -18.155018429132305
training  [-3.8772, -2.2493, -1.9634]  w:  [1.45484771 1.23715391 2.63557702]
-13.598157740717024  -  1.0509  =  -14.649057740717025
training  [2.8443, -2.5137, -4.5381]  w:  [1.45484771 1.23715391 2.63557702]
-10.932322518261795  -  6.8897  =  -17.822022518261797
training  [-2.0843, -0.4836, -3.0452]  w:  [1.45484771 1.23715391 2.63557702]
-11.656485853973994  -  3.5346  =  -15.191085853973995
training  [1.0353, -2.7229, 2.2017]  w:  [1.45484771 1.23715391 2.63557702]
3.940307389936976  -  43.9562  =  -40.01589261006303
training  [4.6442, 3.0445, 2.2175]  w:  [1.45484771 1.23715391 2.63557702]
16.3675108405044  -  98.8492  =  -82.4816891594956
training  [-0.6752, 4.861, 3.778]  w:  [1.45484771 1.23715391 2.63557702]
14.988701952611237  -  97.017  =  -82.02829804738876
training  [1.9475, -4.7001, 0.8243]  w:  [1.45484771 1.23715391 2.63557702]
-0.8089250231575593  -  18.7839  =  -19.59282502315756
training  [2.581, 0.3566, -4.2932]  w:  [1.45484771 1.23715391 2.63557702]
-7.118928250465069  -  23.5455  =  -30.66442825046507
training  [-0.6736, -4.1292, 4.2274]  w:  [1.45484771 1.23715391 2.63557702]
5.05319697525372  -  31.2667  =  -26.21350302474628
training  [1.555, 3.0209, 3.0037]  w:  [1.45484771 1.23715391 2.63557702]
13.91608912157546  -  96.4078  =  -82.49171087842453
training  [-3.9024, 4.8914, -2.1405]  w:  [1.45484771 1.23715391 2.63557702]
-5.267435695752777  -  25.4308  =  -30.69823569575278
training  [4.3376, -4.3305, 0.4366]  w:  [1.45484771 1.23715391 2.63557702]
2.1037453573888065  -  43.0907  =  -40.986954642611195
training  [-3.1254, 4.394, 4.8478]  w:  [1.45484771 1.23715391 2.63557702]
13.665823520743897  -  92.8121  =  -79.1462764792561
training  [-2.3382, -4.8182, 2.1568]  w:  [1.45484771 1.23715391 2.63557702]
-3.6781673425542296  -  4.7434  =  -8.42156734255423
training  [2.9783, 1.8384, 3.3897]  w:  [1.45484771 1.23715391 2.63557702]
15.541172101381306  -  97.3486  =  -81.8074278986187
training  [-0.124, 2.8374, -0.6674]  w:  [1.45484771 1.23715391 2.63557702]
1.5709152732901808  -  62.785  =  -61.214084726709814
training  [2.6896, 0.3414, -0.2938]  w:  [1.45484771 1.23715391 2.63557702]
3.5609902114159593  -  70.4455  =  -66.88450978858404
training  [-1.0399, 3.8536, 0.6071]  w:  [1.45484771 1.23715391 2.63557702]
4.854658970519595  -  77.0369  =  -72.18224102948041
training  [-2.2706, 3.99, -2.3091]  w:  [1.45484771 1.23715391 2.63557702]
-4.452944021870179  -  31.1134  =  -35.56634402187018
training  [-4.6277, 1.2594, 2.4902]  w:  [1.45484771 1.23715391 2.63557702]
1.388586787919328  -  28.1093  =  -26.720713212080675
training  [1.7329, -3.6213, 0.0389]  w:  [1.45484771 1.23715391 2.63557702]
-1.8564759001832474  -  19.3919  =  -21.248375900183248
training  [-0.7044, -2.822, 1.4681]  w:  [1.45484771 1.23715391 2.63557702]
-0.6467524236800295  -  17.8122  =  -18.45895242368003
training  [-0.4826, -3.1786, -1.9225]  w:  [1.45484771 1.23715391 2.63557702]
-9.70142373424434  -  3.5851  =  -13.28652373424434
training  [1.0986, -4.5818, -3.6128]  w:  [1.45484771 1.23715391 2.63557702]
-13.591908738264664  -  1.7158  =  -15.307708738264663
training  [-4.406, -3.9306, -0.2443]  w:  [1.45484771 1.23715391 2.63557702]
-11.916687613606396  -  0.8241  =  -12.740787613606395
training  [-1.8419, 1.1644, -1.3754]  w:  [1.45484771 1.23715391 2.63557702]
-4.864114621439441  -  17.8517  =  -22.715814621439442
training  [2.7272, 4.3966, 2.8811]  w:  [1.45484771 1.23715391 2.63557702]
17.000292491346897  -  98.904  =  -81.9037075086531
training  [1.9643, -1.4554, 2.803]  w:  [1.45484771 1.23715391 2.63557702]
8.444725950275878  -  76.0591  =  -67.61437404972412
training  [-3.7467, -0.8937, 1.6851]  w:  [1.45484771 1.23715391 2.63557702]
-2.115311516323837  -  12.1571  =  -14.272411516323837
training  [-3.6985, 4.8435, -3.665]  w:  [1.45484771 1.23715391 2.63557702]
-9.047989089494324  -  14.6793  =  -23.727289089494324
233248.62780876237
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.42617016 1.19149266 2.54316489]
12.862958301915448  -  87.3174  =  -74.45444169808457
training  [-4.1793, -4.9218, 1.7664]  w:  [1.42617016 1.19149266 2.54316489]
-7.332435080106022  -  1.5257  =  -8.858135080106022
training  [-3.9429, -0.7689, 4.883]  w:  [1.42617016 1.19149266 2.54316489]
5.878889130943528  -  39.7859  =  -33.90701086905647
training  [-3.5796, 1.5557, 2.6683]  w:  [1.42617016 1.19149266 2.54316489]
3.5344133054335964  -  45.5674  =  -42.032986694566404
training  [-3.3354, 2.2292, -1.633]  w:  [1.42617016 1.19149266 2.54316489]
-6.253760787812524  -  13.3589  =  -19.612660787812523
training  [1.2096, 0.3121, 1.6238]  w:  [1.42617016 1.19149266 2.54316489]
6.226551442369489  -  74.5119  =  -68.28534855763051
training  [0.7371, -3.9118, -2.5583]  w:  [1.42617016 1.19149266 2.54316489]
-10.115829716856469  -  3.3358  =  -13.45162971685647
training  [-4.4792, 1.3177, -2.0449]  w:  [1.42617016 1.19149266 2.54316489]
-10.018589401327375  -  4.2974  =  -14.315989401327375
training  [4.312, -3.735, 1.8018]  w:  [1.42617016 1.19149266 2.54316489]
6.281695151359178  -  66.5833  =  -60.301604848640814
training  [2.2866, -3.657, 0.2785]  w:  [1.42617016 1.19149266 2.54316489]
-0.3879365502825477  -  26.0005  =  -26.388436550282545
training  [2.3784, -4.0141, -0.8841]  w:  [1.42617016 1.19149266 2.54316489]
-3.6391796640109875  -  14.6809  =  -18.320079664010986
training  [-4.366, -3.5797, 1.0264]  w:  [1.42617016 1.19149266 2.54316489]
-7.8815407680272  -  1.8713  =  -9.7528407680272
training  [3.6044, -3.3175, 2.5052]  w:  [1.42617016 1.19149266 2.54316489]
7.558847516765452  -  71.0139  =  -63.45505248323455
training  [4.3441, -3.0375, 0.8353]  w:  [1.42617016 1.19149266 2.54316489]
4.700572476424653  -  63.8979  =  -59.197327523575346
training  [4.844, -1.8252, 0.5179]  w:  [1.42617016 1.19149266 2.54316489]
6.050760958468764  -  78.0461  =  -71.99533904153122
training  [3.5894, -1.8357, 0.8357]  w:  [1.42617016 1.19149266 2.54316489]
5.057195002487331  -  68.8838  =  -63.82660499751266
training  [2.8556, -2.8244, 0.1182]  w:  [1.42617016 1.19149266 2.54316489]
1.007921730749977  -  39.5252  =  -38.51727826925002
training  [0.1338, -2.4896, -4.1741]  w:  [1.42617016 1.19149266 2.54316489]
-13.390943145758484  -  2.2644  =  -15.655343145758485
training  [-3.224, 3.9292, 2.1957]  w:  [1.42617016 1.19149266 2.54316489]
5.6676675213507774  -  72.1211  =  -66.45343247864922
training  [-1.0141, 2.0322, 4.9616]  w:  [1.42617016 1.19149266 2.54316489]
13.593239161109622  -  92.3427  =  -78.74946083889037
training  [-3.6607, 0.5574, -1.4547]  w:  [1.42617016 1.19149266 2.54316489]
-8.25618507455118  -  5.8471  =  -14.10328507455118
training  [-4.6911, -3.1557, 4.7126]  w:  [1.42617016 1.19149266 2.54316489]
1.5346186304075804  -  11.2337  =  -9.69908136959242
training  [4.3914, -2.8797, -1.5355]  w:  [1.42617016 1.19149266 2.54316489]
-1.073287461575617  -  37.475  =  -38.54828746157562
training  [-1.9869, -4.2265, 3.8654]  w:  [1.42617016 1.19149266 2.54316489]
1.9608483436937636  -  15.7889  =  -13.828051656306236
training  [-2.0447, 4.138, -0.4531]  w:  [1.42617016 1.19149266 2.54316489]
0.8619984929724027  -  57.936  =  -57.074001507027596
training  [-1.6706, 2.0672, -0.8657]  w:  [1.42617016 1.19149266 2.54316489]
-2.121124089761581  -  32.4185  =  -34.53962408976158
training  [-0.3293, 0.5779, -2.8227]  w:  [1.42617016 1.19149266 2.54316489]
-6.959665768964496  -  14.3434  =  -21.303065768964498
training  [1.482, -1.8657, -3.7435]  w:  [1.42617016 1.19149266 2.54316489]
-9.629721457244704  -  7.1519  =  -16.781621457244704
training  [-4.7477, -3.338, -1.9109]  w:  [1.42617016 1.19149266 2.54316489]
-15.607964383434481  -  0.4077  =  -16.01566438343448
training  [3.4221, 1.225, 2.261]  w:  [1.42617016 1.19149266 2.54316489]
12.09017124890367  -  95.0454  =  -82.95522875109633
training  [0.5903, 4.8793, 2.8287]  w:  [1.42617016 1.19149266 2.54316489]
13.849368928951247  -  97.4647  =  -83.61533107104874
training  [3.541, -3.2957, 1.9379]  w:  [1.42617016 1.19149266 2.54316489]
6.051665424571752  -  64.3732  =  -58.321534575428245
training  [-1.5212, -2.4221, -4.902]  w:  [1.42617016 1.19149266 2.54316489]
-17.521998736035066  -  0.7227  =  -18.244698736035065
training  [-0.5397, -1.032, 3.4321]  w:  [1.42617016 1.19149266 2.54316489]
6.729071765457681  -  60.5921  =  -53.86302823454232
training  [-4.4576, -4.2601, 4.2233]  w:  [1.42617016 1.19149266 2.54316489]
-0.692625715401979  -  6.0247  =  -6.717325715401979
training  [-3.2289, 1.841, 2.7095]  w:  [1.42617016 1.19149266 2.54316489]
4.479282431714697  -  54.0111  =  -49.531817568285305
training  [1.6281, -0.9761, -4.5734]  w:  [1.42617016 1.19149266 2.54316489]
-10.47197866874105  -  7.8658  =  -18.337778668741052
training  [-1.6917, 4.8284, -1.2181]  w:  [1.42617016 1.19149266 2.54316489]
0.24252195131954535  -  61.2837  =  -61.04117804868046
training  [3.9849, -0.9782, 2.0434]  w:  [1.42617016 1.19149266 2.54316489]
9.714330501520141  -  88.3402  =  -78.62586949847986
training  [-3.8184, 1.2067, 2.2951]  w:  [1.42617016 1.19149266 2.54316489]
1.8289037932006957  -  34.1122  =  -32.28329620679931
training  [4.8842, -3.4563, -2.7572]  w:  [1.42617016 1.19149266 2.54316489]
-4.164470024695194  -  23.7819  =  -27.946370024695195
training  [0.3998, -1.1865, -2.3095]  w:  [1.42617016 1.19149266 2.54316489]
-6.716962533994497  -  11.4246  =  -18.141562533994495
training  [2.0692, -3.3887, 1.7303]  w:  [1.42617016 1.19149266 2.54316489]
3.3138583296974917  -  42.6881  =  -39.37424167030251
training  [4.9949, 2.5811, -0.2251]  w:  [1.42617016 1.19149266 2.54316489]
9.626472639429338  -  95.9901  =  -86.36362736057066
training  [-2.1215, 3.7111, 1.2372]  w:  [1.42617016 1.19149266 2.54316489]
4.542532025839774  -  71.3692  =  -66.82666797416023
training  [-0.8548, -1.4922, -2.6356]  w:  [1.42617016 1.19149266 2.54316489]
-9.699800998711119  -  4.7821  =  -14.481900998711119
training  [-0.3516, 1.8554, -3.2288]  w:  [1.42617016 1.19149266 2.54316489]
-6.502116750297653  -  20.3834  =  -26.885516750297654
training  [2.6396, -2.0585, 3.2964]  w:  [1.42617016 1.19149266 2.54316489]
9.695119869508446  -  80.826  =  -71.13088013049155
training  [3.182, 0.3063, 2.6692]  w:  [1.42617016 1.19149266 2.54316489]
11.691243393156723  -  92.9483  =  -81.25705660684328
training  [-3.9978, 3.3242, 4.3448]  w:  [1.42617016 1.19149266 2.54316489]
9.308759660641046  -  79.1768  =  -69.86804033935896
training  [-3.2188, 0.9749, -3.9211]  w:  [1.42617016 1.19149266 2.54316489]
-13.40097418568336  -  2.7053  =  -16.10627418568336
training  [-1.4037, -1.6469, -3.1777]  w:  [1.42617016 1.19149266 2.54316489]
-12.04559940451696  -  2.6234  =  -14.66899940451696
training  [-4.433, -2.0077, -4.009]  w:  [1.42617016 1.19149266 2.54316489]
-18.909920206692796  -  0.3253  =  -19.235220206692794
training  [0.2189, -0.4741, -0.1024]  w:  [1.42617016 1.19149266 2.54316489]
-0.5131181077804088  -  33.6531  =  -34.16621810778041
training  [-1.6415, -0.7735, -3.0675]  w:  [1.42617016 1.19149266 2.54316489]
-11.063836206480293  -  3.7641  =  -14.827936206480292
training  [-3.2433, -1.4039, 3.9589]  w:  [1.42617016 1.19149266 2.54316489]
3.7699012581933333  -  30.0658  =  -26.295898741806667
training  [-2.9105, 0.5832, -4.0091]  w:  [1.42617016 1.19149266 2.54316489]
-13.651792111062727  -  2.4887  =  -16.140492111062727
training  [4.0515, 2.4255, -4.5583]  w:  [1.42617016 1.19149266 2.54316489]
-2.9244146656371406  -  61.2853  =  -64.20971466563714
training  [1.7539, -0.7567, 0.573]  w:  [1.42617016 1.19149266 2.54316489]
3.0569908343627485  -  57.0797  =  -54.02270916563725
training  [-0.3153, -0.7064, 2.725]  w:  [1.42617016 1.19149266 2.54316489]
5.638782464897466  -  58.7004  =  -53.061617535102535
training  [4.1213, -3.7513, -1.8806]  w:  [1.42617016 1.19149266 2.54316489]
-3.3746472318590692  -  22.1789  =  -25.553547231859067
training  [-3.9599, -4.7557, -3.2102]  w:  [1.42617016 1.19149266 2.54316489]
-19.477940822765838  -  0.1558  =  -19.633740822765837
training  [2.4555, -2.0981, -1.6104]  w:  [1.42617016 1.19149266 2.54316489]
-3.093422664933647  -  24.4796  =  -27.57302266493365
training  [2.3627, -1.8248, -2.8985]  w:  [1.42617016 1.19149266 2.54316489]
-6.175987010307536  -  15.7052  =  -21.881187010307535
training  [0.6186, 1.5369, 0.1015]  w:  [1.42617016 1.19149266 2.54316489]
2.971565172393455  -  65.2154  =  -62.24383482760655
training  [-3.1581, 4.5694, 4.0636]  w:  [1.42617016 1.19149266 2.54316489]
11.274823441694686  -  90.3564  =  -79.0815765583053
training  [0.9721, 4.3573, 1.2892]  w:  [1.42617016 1.19149266 2.54316489]
9.856719174085576  -  94.3178  =  -84.46108082591442
training  [-2.0006, -0.4211, -3.9847]  w:  [1.42617016 1.19149266 2.54316489]
-13.488682737669308  -  2.4051  =  -15.893782737669309
training  [-3.6588, -2.5952, -1.0915]  w:  [1.42617016 1.19149266 2.54316489]
-11.086097630038223  -  1.5176  =  -12.603697630038223
training  [-2.874, 2.639, -4.4538]  w:  [1.42617016 1.19149266 2.54316489]
-12.28121171243183  -  5.497  =  -17.77821171243183
training  [3.9494, 2.5933, 0.0128]  w:  [1.42617016 1.19149266 2.54316489]
8.754966872934874  -  94.1462  =  -85.39123312706512
training  [-4.2855, 2.4065, -0.6828]  w:  [1.42617016 1.19149266 2.54316489]
-4.980998128756628  -  14.4193  =  -19.400298128756628
training  [-2.5751, 2.4369, 4.9756]  w:  [1.42617016 1.19149266 2.54316489]
11.884788926223063  -  87.1991  =  -75.31431107377693
training  [-4.4625, -3.9408, 3.116]  w:  [1.42617016 1.19149266 2.54316489]
-3.135216828304383  -  4.1344  =  -7.269616828304383
training  [-0.5828, 1.8156, -0.1435]  w:  [1.42617016 1.19149266 2.54316489]
0.9671579451763943  -  51.1166  =  -50.1494420548236
training  [-4.8672, -0.3674, 3.9445]  w:  [1.42617016 1.19149266 2.54316489]
2.652304101318019  -  24.1396  =  -21.48729589868198
training  [3.9719, -2.8784, -3.6245]  w:  [1.42617016 1.19149266 2.54316489]
-6.982688366294182  -  14.6104  =  -21.593088366294182
training  [-3.0334, -4.0148, -1.1]  w:  [1.42617016 1.19149266 2.54316489]
-11.907230695677114  -  1.021  =  -12.928230695677115
training  [-4.0663, 3.2357, 4.2736]  w:  [1.42617016 1.19149266 2.54316489]
8.924546563463265  -  77.2328  =  -68.30825343653673
training  [-1.9263, -3.2499, 4.1749]  w:  [1.42617016 1.19149266 2.54316489]
3.9979955242681804  -  26.8814  =  -22.88340447573182
training  [-0.4394, -3.3643, 2.1357]  w:  [1.42617016 1.19149266 2.54316489]
0.796239328293403  -  20.85  =  -20.0537606717066
training  [-3.9833, 1.6599, 1.1834]  w:  [1.42617016 1.19149266 2.54316489]
-0.6935236037416836  -  25.5397  =  -26.233223603741685
training  [4.9539, 3.9439, -1.5671]  w:  [1.42617016 1.19149266 2.54316489]
7.778838576605876  -  95.9509  =  -88.17206142339413
training  [-1.6791, 0.1656, 4.3603]  w:  [1.42617016 1.19149266 2.54316489]
8.89159074868744  -  71.5733  =  -62.68170925131256
training  [-2.0265, 2.027, -3.7523]  w:  [1.42617016 1.19149266 2.54316489]
-10.01769583646369  -  8.503  =  -18.520695836463688
training  [-4.3795, -3.4641, 2.3059]  w:  [1.42617016 1.19149266 2.54316489]
-4.509078032554247  -  3.6654  =  -8.174478032554248
training  [-2.0176, 4.5346, 1.4648]  w:  [1.42617016 1.19149266 2.54316489]
6.250729643063901  -  81.6212  =  -75.3704703569361
training  [-4.5365, 0.4088, 3.3315]  w:  [1.42617016 1.19149266 2.54316489]
2.489815099255509  -  28.9449  =  -26.45508490074449
training  [0.0543, 1.7973, -1.0172]  w:  [1.42617016 1.19149266 2.54316489]
-0.3679965271164658  -  47.9317  =  -48.29969652711647
training  [2.6143, -4.6344, 2.4982]  w:  [1.42617016 1.19149266 2.54316489]
4.559917597113304  -  43.5132  =  -38.95328240288669
training  [1.3107, 3.092, 3.3522]  w:  [1.42617016 1.19149266 2.54316489]
14.078573899933339  -  96.6993  =  -82.62072610006666
training  [-4.1011, 2.4862, -1.7754]  w:  [1.42617016 1.19149266 2.54316489]
-7.401712347886061  -  10.0187  =  -17.420412347886064
training  [-4.1914, -3.7981, 0.5226]  w:  [1.42617016 1.19149266 2.54316489]
-9.173999928334098  -  1.4295  =  -10.603499928334099
training  [2.7724, 0.2505, 4.7913]  w:  [1.42617016 1.19149266 2.54316489]
16.437449023858388  -  96.7925  =  -80.35505097614161
training  [4.0513, -1.7417, 0.4931]  w:  [1.42617016 1.19149266 2.54316489]
4.95665501849016  -  71.1234  =  -66.16674498150985
training  [0.3377, 0.4645, -1.6958]  w:  [1.42617016 1.19149266 2.54316489]
-3.2776330202260127  -  27.9534  =  -31.23103302022601
training  [-3.9085, -1.0112, 1.1947]  w:  [1.42617016 1.19149266 2.54316489]
-3.740704363267453  -  8.608  =  -12.348704363267453
training  [3.2581, -0.8491, -1.3936]  w:  [1.42617016 1.19149266 2.54316489]
0.09075399202656742  -  50.1924  =  -50.10164600797343
training  [-1.619, -3.1926, 2.5651]  w:  [1.42617016 1.19149266 2.54316489]
0.41054329971593617  -  16.4754  =  -16.064856700284064
training  [-2.0603, -2.4461, -0.861]  w:  [1.42617016 1.19149266 2.54316489]
-8.042513561128384  -  3.9784  =  -12.020913561128385
training  [2.4631, -4.7946, -0.0765]  w:  [1.42617016 1.19149266 2.54316489]
-2.394483106602206  -  15.394  =  -17.788483106602207
training  [-4.8966, 4.2368, 1.9474]  w:  [1.42617016 1.19149266 2.54316489]
3.017290607282612  -  53.5883  =  -50.571009392717386
training  [-4.5155, 1.537, 4.7273]  w:  [1.42617016 1.19149266 2.54316489]
7.413756252539306  -  59.2523  =  -51.83854374746069
training  [1.6792, 4.3261, -1.7225]  w:  [1.42617016 1.19149266 2.54316489]
3.168739816126486  -  83.7729  =  -80.60416018387352
training  [1.0347, -3.3649, 3.378]  w:  [1.42617016 1.19149266 2.54316489]
6.0572156163410265  -  50.5979  =  -44.54068438365898
training  [0.261, 4.211, 2.3907]  w:  [1.42617016 1.19149266 2.54316489]
11.469550324757519  -  94.9375  =  -83.46794967524248
training  [2.2971, 2.9466, 4.5417]  w:  [1.42617016 1.19149266 2.54316489]
18.337199755743136  -  98.7784  =  -80.44120024425686
training  [2.0725, 0.7739, -4.6808]  w:  [1.42617016 1.19149266 2.54316489]
-8.026212398485761  -  19.5109  =  -27.53711239848576
training  [2.8138, -0.5996, -1.4313]  w:  [1.42617016 1.19149266 2.54316489]
-0.34149330841277514  -  47.2879  =  -47.62939330841277
training  [-2.1202, -2.4239, 1.6265]  w:  [1.42617016 1.19149266 2.54316489]
-1.7753673448765657  -  12.3599  =  -14.135267344876565
training  [1.9253, 2.5195, -2.185]  w:  [1.42617016 1.19149266 2.54316489]
0.19095588584922218  -  65.2467  =  -65.05574411415078
training  [0.5667, -2.7133, -2.6962]  w:  [1.42617016 1.19149266 2.54316489]
-9.281547595262643  -  5.1106  =  -14.392147595262642
training  [-1.0348, -4.3581, 2.1113]  w:  [1.42617016 1.19149266 2.54316489]
-1.299061018017663  -  10.5192  =  -11.818261018017662
training  [-4.3841, 2.6733, 1.2457]  w:  [1.42617016 1.19149266 2.54316489]
0.1007652321535506  -  32.4639  =  -32.363134767846454
training  [2.8018, 1.712, 0.9061]  w:  [1.42617016 1.19149266 2.54316489]
8.340040709843326  -  90.1138  =  -81.77375929015668
training  [-1.6242, 2.1521, 1.6044]  w:  [1.42617016 1.19149266 2.54316489]
4.328079535583432  -  63.7879  =  -59.459820464416566
training  [1.0787, 1.4206, -4.5245]  w:  [1.42617016 1.19149266 2.54316489]
-8.275505328457019  -  18.0555  =  -26.331005328457017
training  [2.4125, -0.8095, -1.5122]  w:  [1.42617016 1.19149266 2.54316489]
-1.3696517444283431  -  38.8276  =  -40.19725174442834
training  [-3.9519, -1.0924, -0.4866]  w:  [1.42617016 1.19149266 2.54316489]
-8.175172487500314  -  3.6777  =  -11.852872487500314
training  [-3.7211, 3.1614, -2.591]  w:  [1.42617016 1.19149266 2.54316489]
-8.129477127214757  -  11.1518  =  -19.281277127214757
training  [0.4954, -1.8257, 2.1505]  w:  [1.42617016 1.19149266 2.54316489]
4.0002926474083065  -  47.7531  =  -43.752807352591695
training  [-0.1477, 3.1454, 3.5618]  w:  [1.42617016 1.19149266 2.54316489]
12.595320404490707  -  94.1572  =  -81.5618795955093
training  [3.9048, 2.8907, -2.1849]  w:  [1.42617016 1.19149266 2.54316489]
3.4565961156960388  -  85.8791  =  -82.42250388430395
training  [2.9896, 3.5226, 2.3105]  w:  [1.42617016 1.19149266 2.54316489]
14.3368128572796  -  98.038  =  -83.7011871427204
training  [2.3434, 0.0564, -3.6224]  w:  [1.42617016 1.19149266 2.54316489]
-5.803073163825571  -  24.7629  =  -30.565973163825568
training  [-4.4867, 1.3566, 3.3672]  w:  [1.42617016 1.19149266 2.54316489]
3.780926105627202  -  40.5785  =  -36.797573894372796
training  [-4.2711, 4.5089, -3.614]  w:  [1.42617016 1.19149266 2.54316489]
-9.909992039638823  -  10.0825  =  -19.992492039638822
training  [-4.1147, -0.5604, 0.8821]  w:  [1.42617016 1.19149266 2.54316489]
-4.292649104145606  -  8.344  =  -12.636649104145604
training  [2.9835, -4.3998, -1.3384]  w:  [1.42617016 1.19149266 2.54316489]
-4.391122629520284  -  13.2692  =  -17.660322629520284
training  [4.4301, 3.6675, 3.0676]  w:  [1.42617016 1.19149266 2.54316489]
18.489288404074365  -  99.3834  =  -80.89411159592564
training  [1.8372, 1.3119, 0.0378]  w:  [1.42617016 1.19149266 2.54316489]
4.279410679851151  -  74.9026  =  -70.62318932014885
training  [-3.6792, -1.4493, -0.1041]  w:  [1.42617016 1.19149266 2.54316489]
-7.238739043753044  -  4.2442  =  -11.482939043753044
training  [2.2272, 4.97, 3.7705]  w:  [1.42617016 1.19149266 2.54316489]
18.687087949161747  -  99.3199  =  -80.63281205083825
training  [-3.8965, -2.7583, -1.4686]  w:  [1.42617016 1.19149266 2.54316489]
-12.578458212204232  -  1.0337  =  -13.612158212204232
training  [-3.8251, 1.5245, -0.5056]  w:  [1.42617016 1.19149266 2.54316489]
-4.924637095168608  -  12.9762  =  -17.900837095168608
training  [1.4072, 1.0499, 4.6353]  w:  [1.42617016 1.19149266 2.54316489]
15.04618702889158  -  95.4618  =  -80.41561297110842
training  [-1.7119, -1.1275, -4.577]  w:  [1.42617016 1.19149266 2.54316489]
-15.424934394798719  -  1.4655  =  -16.890434394798717
training  [1.5381, -3.5781, 4.7296]  w:  [1.42617016 1.19149266 2.54316489]
9.958465110248518  -  69.9473  =  -59.98883488975148
training  [2.4913, -4.7487, -3.1079]  w:  [1.42617016 1.19149266 2.54316489]
-10.00892565211268  -  3.9825  =  -13.99142565211268
training  [0.8319, -0.7889, 1.6712]  w:  [1.42617016 1.19149266 2.54316489]
4.496599566378324  -  58.8336  =  -54.337000433621675
training  [2.4003, -3.159, 0.8644]  w:  [1.42617016 1.19149266 2.54316489]
1.8576226541107212  -  39.0041  =  -37.14647734588928
training  [-2.6517, 2.2578, 1.7511]  w:  [1.42617016 1.19149266 2.54316489]
3.361712757705516  -  54.4525  =  -51.09078724229448
training  [2.3496, -1.2964, -1.3898]  w:  [1.42617016 1.19149266 2.54316489]
-1.728212242134943  -  33.888  =  -35.61621224213494
training  [4.706, 3.4156, 1.2028]  w:  [1.42617016 1.19149266 2.54316489]
13.840137857376623  -  98.4665  =  -84.62636214262338
training  [3.6693, 2.3423, 3.1115]  w:  [1.42617016 1.19149266 2.54316489]
15.93693700668885  -  98.3069  =  -82.36996299331115
training  [-4.1377, 0.7103, -4.8074]  w:  [1.42617016 1.19149266 2.54316489]
-17.280757951541283  -  0.9782  =  -18.258957951541284
training  [-1.3356, -3.2314, -4.1613]  w:  [1.42617016 1.19149266 2.54316489]
-16.33785432925099  -  0.7659  =  -17.10375432925099
training  [-1.308, 4.5738, 4.748]  w:  [1.42617016 1.19149266 2.54316489]
15.659165480292426  -  97.0884  =  -81.42923451970756
training  [1.8503, -2.3468, 1.5135]  w:  [1.42617016 1.19149266 2.54316489]
3.6917277373682804  -  50.2125  =  -46.520772262631716
training  [0.9794, 4.2458, -2.6876]  w:  [1.42617016 1.19149266 2.54316489]
-0.37937936296409625  -  68.3262  =  -68.7055793629641
training  [2.8936, -2.7623, -0.9651]  w:  [1.42617016 1.19149266 2.54316489]
-1.6189026375490965  -  28.5596  =  -30.178502637549094
training  [-1.3235, -1.2644, -3.7798]  w:  [1.42617016 1.19149266 2.54316489]
-13.006714196246332  -  2.4511  =  -15.457814196246332
training  [-2.9397, -4.125, -2.3156]  w:  [1.42617016 1.19149266 2.54316489]
-14.996372287048981  -  0.554  =  -15.550372287048981
training  [-4.1333, 1.4012, -2.4215]  w:  [1.42617016 1.19149266 2.54316489]
-10.383543403521145  -  4.4072  =  -14.790743403521144
training  [2.7193, -3.1938, -1.6833]  w:  [1.42617016 1.19149266 2.54316489]
-4.208114207112679  -  17.0949  =  -21.30301420711268
training  [-2.9433, -4.5495, -3.4777]  w:  [1.42617016 1.19149266 2.54316489]
-18.46270705730698  -  0.2509  =  -18.71360705730698
training  [-1.1173, 2.2317, -1.5199]  w:  [1.42617016 1.19149266 2.54316489]
-2.799762068906939  -  33.1206  =  -35.92036206890694
training  [0.5178, -1.5256, -3.7834]  w:  [1.42617016 1.19149266 2.54316489]
-10.701080352794317  -  5.237  =  -15.938080352794318
training  [-2.7105, 1.6062, 3.8415]  w:  [1.42617016 1.19149266 2.54316489]
7.817709225999504  -  70.4458  =  -62.6280907740005
training  [1.4194, -1.1613, -4.0572]  w:  [1.42617016 1.19149266 2.54316489]
-9.677503104918086  -  8.3206  =  -17.998103104918087
training  [-0.1552, 1.2735, 4.3004]  w:  [1.42617016 1.19149266 2.54316489]
12.232650603341328  -  90.1085  =  -77.87584939665868
training  [-3.4815, -4.7835, -1.0098]  w:  [1.42617016 1.19149266 2.54316489]
-13.232804481919072  -  0.5839  =  -13.816704481919071
training  [2.8193, 4.1057, -4.526]  w:  [1.42617016 1.19149266 2.54316489]
-2.597651342384424  -  66.8081  =  -69.40575134238442
training  [-3.9939, 3.0056, -1.5763]  w:  [1.42617016 1.19149266 2.54316489]
-6.123621487269036  -  14.4018  =  -20.525421487269035
training  [-2.0593, 2.4585, 2.3597]  w:  [1.42617016 1.19149266 2.54316489]
5.993478693464997  -  70.6698  =  -64.676321306535
training  [-2.6263, 3.1311, 2.9468]  w:  [1.42617016 1.19149266 2.54316489]
7.479330284882829  -  77.309  =  -69.82966971511716
training  [0.3087, -1.1669, 0.4491]  w:  [1.42617016 1.19149266 2.54316489]
0.19204129481141186  -  33.0798  =  -32.88775870518859
training  [-4.085, 1.1728, 1.8622]  w:  [1.42617016 1.19149266 2.54316489]
0.3073591442955701  -  26.4056  =  -26.09824085570443
training  [-0.9468, 0.7549, 3.9363]  w:  [1.42617016 1.19149266 2.54316489]
9.559819870139233  -  79.7738  =  -70.21398012986076
training  [-3.9515, 0.3005, -4.4521]  w:  [1.42617016 1.19149266 2.54316489]
-16.59989227381075  -  1.0441  =  -17.64399227381075
training  [-3.8772, -2.2493, -1.9634]  w:  [1.42617016 1.19149266 2.54316489]
-13.20282135198288  -  1.0509  =  -14.25372135198288
training  [2.8443, -2.5137, -4.5381]  w:  [1.42617016 1.19149266 2.54316489]
-10.47973591413252  -  6.8897  =  -17.36943591413252
training  [-2.0843, -0.4836, -3.0452]  w:  [1.42617016 1.19149266 2.54316489]
-11.293218054514597  -  3.5346  =  -14.827818054514598
training  [1.0353, -2.7229, 2.2017]  w:  [1.42617016 1.19149266 2.54316489]
3.8314847439119903  -  43.9562  =  -40.12471525608801
training  [4.6442, 3.0445, 2.2175]  w:  [1.42617016 1.19149266 2.54316489]
15.8903870313954  -  98.8492  =  -82.95881296860459
training  [-0.6752, 4.861, 3.778]  w:  [1.42617016 1.19149266 2.54316489]
14.436972705497624  -  97.017  =  -82.58002729450237
training  [1.9475, -4.7001, 0.8243]  w:  [1.42617016 1.19149266 2.54316489]
-0.7263374500505106  -  18.7839  =  -19.51023745005051
training  [2.581, 0.3566, -4.2932]  w:  [1.42617016 1.19149266 2.54316489]
-6.812484046243823  -  23.5455  =  -30.357984046243825
training  [-0.6736, -4.1292, 4.2274]  w:  [1.42617016 1.19149266 2.54316489]
4.870395545746636  -  31.2667  =  -26.396304454253364
training  [1.555, 3.0209, 3.0037]  w:  [1.42617016 1.19149266 2.54316489]
13.455979177078348  -  96.4078  =  -82.95182082292165
training  [-3.9024, 4.8914, -2.1405]  w:  [1.42617016 1.19149266 2.54316489]
-5.181063687067666  -  25.4308  =  -30.611863687067668
training  [4.3376, -4.3305, 0.4366]  w:  [1.42617016 1.19149266 2.54316489]
2.136742514738841  -  43.0907  =  -40.95395748526116
training  [-3.1254, 4.394, 4.8478]  w:  [1.42617016 1.19149266 2.54316489]
13.106821302263377  -  92.8121  =  -79.70527869773662
training  [-2.3382, -4.8182, 2.1568]  w:  [1.42617016 1.19149266 2.54316489]
-3.5904229794524696  -  4.7434  =  -8.33382297945247
training  [2.9783, 1.8384, 3.3897]  w:  [1.42617016 1.19149266 2.54316489]
15.058568744907229  -  97.3486  =  -82.29003125509277
training  [-0.124, 2.8374, -0.6674]  w:  [1.42617016 1.19149266 2.54316489]
1.5065879308651886  -  62.785  =  -61.27841206913481
training  [2.6896, 0.3414, -0.2938]  w:  [1.42617016 1.19149266 2.54316489]
3.4954210188990404  -  70.4455  =  -66.95007898110096
training  [-1.0399, 3.8536, 0.6071]  w:  [1.42617016 1.19149266 2.54316489]
4.65241717898489  -  77.0369  =  -72.38448282101511
training  [-2.2706, 3.99, -2.3091]  w:  [1.42617016 1.19149266 2.54316489]
-4.356628302653627  -  31.1134  =  -35.470028302653624
training  [-4.6277, 1.2594, 2.4902]  w:  [1.42617016 1.19149266 2.54316489]
1.233667414533869  -  28.1093  =  -26.875632585466132
training  [1.7329, -3.6213, 0.0389]  w:  [1.42617016 1.19149266 2.54316489]
-1.744412989716834  -  19.3919  =  -21.136312989716835
training  [-0.7044, -2.822, 1.4681]  w:  [1.42617016 1.19149266 2.54316489]
-0.6333661766183254  -  17.8122  =  -18.445566176618325
training  [-0.4826, -3.1786, -1.9225]  w:  [1.42617016 1.19149266 2.54316489]
-9.364782804964051  -  3.5851  =  -12.949882804964052
training  [1.0986, -4.5818, -3.6128]  w:  [1.42617016 1.19149266 2.54316489]
-13.080336666872446  -  1.7158  =  -14.796136666872446
training  [-4.406, -3.9306, -0.2443]  w:  [1.42617016 1.19149266 2.54316489]
-11.588281979645249  -  0.8241  =  -12.412381979645248
training  [-1.8419, 1.1644, -1.3754]  w:  [1.42617016 1.19149266 2.54316489]
-4.737357760469199  -  17.8517  =  -22.5890577604692
training  [2.7272, 4.3966, 2.8811]  w:  [1.42617016 1.19149266 2.54316489]
16.455080281750934  -  98.904  =  -82.44891971824906
training  [1.9643, -1.4554, 2.803]  w:  [1.42617016 1.19149266 2.54316489]
8.195818825135069  -  76.0591  =  -67.86328117486494
training  [-3.7467, -0.8937, 1.6851]  w:  [1.42617016 1.19149266 2.54316489]
-2.122781579459562  -  12.1571  =  -14.279881579459563
training  [-3.6985, 4.8435, -3.665]  w:  [1.42617016 1.19149266 2.54316489]
-8.824394969150823  -  14.6793  =  -23.50369496915082
234524.56196925166
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.6218458  1.47645186 2.22903446]
11.178109648703032  -  87.3174  =  -76.13929035129698
training  [-4.1793, -4.9218, 1.7664]  w:  [1.6218458  1.47645186 2.22903446]
-10.107614410542688  -  1.5257  =  -11.633314410542688
training  [-3.9429, -0.7689, 4.883]  w:  [1.6218458  1.47645186 2.22903446]
3.354355654431216  -  39.7859  =  -36.43154434556878
training  [-3.5796, 1.5557, 2.6683]  w:  [1.6218458  1.47645186 2.22903446]
2.439089592338924  -  45.5674  =  -43.128310407661075
training  [-3.3354, 2.2292, -1.633]  w:  [1.6218458  1.47645186 2.22903446]
-5.758211273185532  -  13.3589  =  -19.117111273185532
training  [1.2096, 0.3121, 1.6238]  w:  [1.6218458  1.47645186 2.22903446]
6.042091461230665  -  74.5119  =  -68.46980853876933
training  [0.7371, -3.9118, -2.5583]  w:  [1.6218458  1.47645186 2.22903446]
-10.282660698231386  -  3.3358  =  -13.618460698231384
training  [-4.4792, 1.3177, -2.0449]  w:  [1.6218458  1.47645186 2.22903446]
-9.877203658064872  -  4.2974  =  -14.174603658064871
training  [4.312, -3.735, 1.8018]  w:  [1.6218458  1.47645186 2.22903446]
5.495125691706525  -  66.5833  =  -61.08817430829347
training  [2.2866, -3.657, 0.2785]  w:  [1.6218458  1.47645186 2.22903446]
-1.0700857386050617  -  26.0005  =  -27.07058573860506
training  [2.3784, -4.0141, -0.8841]  w:  [1.6218458  1.47645186 2.22903446]
-4.039916718397924  -  14.6809  =  -18.720816718397923
training  [-4.366, -3.5797, 1.0264]  w:  [1.6218458  1.47645186 2.22903446]
-10.078352487537803  -  1.8713  =  -11.949652487537803
training  [3.6044, -3.3175, 2.5052]  w:  [1.6218458  1.47645186 2.22903446]
6.531829096287101  -  71.0139  =  -64.48207090371291
training  [4.3441, -3.0375, 0.8353]  w:  [1.6218458  1.47645186 2.22903446]
4.422650303116414  -  63.8979  =  -59.47524969688359
training  [4.844, -1.8252, 0.5179]  w:  [1.6218458  1.47645186 2.22903446]
6.315818063662683  -  78.0461  =  -71.7302819363373
training  [3.5894, -1.8357, 0.8357]  w:  [1.6218458  1.47645186 2.22903446]
4.973934733945433  -  68.8838  =  -63.90986526605456
training  [2.8556, -2.8244, 0.1182]  w:  [1.6218458  1.47645186 2.22903446]
0.7247241109572198  -  39.5252  =  -38.80047588904278
training  [0.1338, -2.4896, -4.1741]  w:  [1.6218458  1.47645186 2.22903446]
-12.762984323167798  -  2.2644  =  -15.027384323167798
training  [-3.224, 3.9292, 2.1957]  w:  [1.6218458  1.47645186 2.22903446]
5.466734750731994  -  72.1211  =  -66.65436524926801
training  [-1.0141, 2.0322, 4.9616]  w:  [1.6218458  1.47645186 2.22903446]
12.41530902815255  -  92.3427  =  -79.92739097184744
training  [-3.6607, 0.5574, -1.4547]  w:  [1.6218458  1.47645186 2.22903446]
-8.356693079019365  -  5.8471  =  -14.203793079019366
training  [-4.6911, -3.1557, 4.7126]  w:  [1.6218458  1.47645186 2.22903446]
-1.7629321331978112  -  11.2337  =  -12.996632133197812
training  [4.3914, -2.8797, -1.5355]  w:  [1.6218458  1.47645186 2.22903446]
-0.5522471918504204  -  37.475  =  -38.02724719185042
training  [-1.9869, -4.2265, 3.8654]  w:  [1.6218458  1.47645186 2.22903446]
-0.84655937178219  -  15.7889  =  -16.63545937178219
training  [-2.0447, 4.138, -0.4531]  w:  [1.6218458  1.47645186 2.22903446]
1.7833941624925373  -  57.936  =  -56.152605837507465
training  [-1.6706, 2.0672, -0.8657]  w:  [1.6218458  1.47645186 2.22903446]
-1.5870094470799152  -  32.4185  =  -34.005509447079916
training  [-0.3293, 0.5779, -2.8227]  w:  [1.6218458  1.47645186 2.22903446]
-5.972727871304764  -  14.3434  =  -20.316127871304765
training  [1.482, -1.8657, -3.7435]  w:  [1.6218458  1.47645186 2.22903446]
-8.69543126658561  -  7.1519  =  -15.84733126658561
training  [-4.7477, -3.338, -1.9109]  w:  [1.6218458  1.47645186 2.22903446]
-16.887895541985678  -  0.4077  =  -17.295595541985676
training  [3.4221, 1.225, 2.261]  w:  [1.6218458  1.47645186 2.22903446]
12.398618946858814  -  95.0454  =  -82.64678105314118
training  [0.5903, 4.8793, 2.8287]  w:  [1.6218458  1.47645186 2.22903446]
14.466696898983006  -  97.4647  =  -82.99800310101699
training  [3.541, -3.2957, 1.9379]  w:  [1.6218458  1.47645186 2.22903446]
5.196659472528842  -  64.3732  =  -59.176540527471154
training  [-1.5212, -2.4221, -4.902]  w:  [1.6218458  1.47645186 2.22903446]
-16.969992803008655  -  0.7227  =  -17.692692803008654
training  [-0.5397, -1.032, 3.4321]  w:  [1.6218458  1.47645186 2.22903446]
5.251260687127713  -  60.5921  =  -55.34083931287229
training  [-4.4576, -4.2601, 4.2233]  w:  [1.6218458  1.47645186 2.22903446]
-4.10549113167588  -  6.0247  =  -10.130191131675879
training  [-3.2289, 1.841, 2.7095]  w:  [1.6218458  1.47645186 2.22903446]
3.5209388478351134  -  54.0111  =  -50.49016115216489
training  [1.6281, -0.9761, -4.5734]  w:  [1.6218458  1.47645186 2.22903446]
-8.994903725161256  -  7.8658  =  -16.860703725161258
training  [-1.6917, 4.8284, -1.2181]  w:  [1.6218458  1.47645186 2.22903446]
1.670036726345122  -  61.2837  =  -59.61366327365488
training  [3.9849, -0.9782, 2.0434]  w:  [1.6218458  1.47645186 2.22903446]
9.573437133762578  -  88.3402  =  -78.76676286623741
training  [-3.8184, 1.2067, 2.2951]  w:  [1.6218458  1.47645186 2.22903446]
0.7046354567592976  -  34.1122  =  -33.4075645432407
training  [4.8842, -3.4563, -2.7572]  w:  [1.6218458  1.47645186 2.22903446]
-3.327535125975179  -  23.7819  =  -27.10943512597518
training  [0.3998, -1.1865, -2.3095]  w:  [1.6218458  1.47645186 2.22903446]
-6.251351268637539  -  11.4246  =  -17.67595126863754
training  [2.0692, -3.3887, 1.7303]  w:  [1.6218458  1.47645186 2.22903446]
2.2095692508272906  -  42.6881  =  -40.478530749172705
training  [4.9949, 2.5811, -0.2251]  w:  [1.6218458  1.47645186 2.22903446]
11.41007180120416  -  95.9901  =  -84.58002819879584
training  [-2.1215, 3.7111, 1.2372]  w:  [1.6218458  1.47645186 2.22903446]
4.7962760601944066  -  71.3692  =  -66.5729239398056
training  [-0.8548, -1.4922, -2.6356]  w:  [1.6218458  1.47645186 2.22903446]
-9.464358476700484  -  4.7821  =  -14.246458476700484
training  [-0.3516, 1.8554, -3.2288]  w:  [1.6218458  1.47645186 2.22903446]
-5.027938682012885  -  20.3834  =  -25.411338682012886
training  [2.6396, -2.0585, 3.2964]  w:  [1.6218458  1.47645186 2.22903446]
8.58953722429022  -  80.826  =  -72.23646277570977
training  [3.182, 0.3063, 2.6692]  w:  [1.6218458  1.47645186 2.22903446]
11.562689318572877  -  92.9483  =  -81.38561068142712
training  [-3.9978, 3.3242, 4.3448]  w:  [1.6218458  1.47645186 2.22903446]
8.108915063556918  -  79.1768  =  -71.06788493644308
training  [-3.2188, 0.9749, -3.9211]  w:  [1.6218458  1.47645186 2.22903446]
-12.521271369982461  -  2.7053  =  -15.22657136998246
training  [-1.4037, -1.6469, -3.1777]  w:  [1.6218458  1.47645186 2.22903446]
-11.791356319212221  -  2.6234  =  -14.414756319212222
training  [-4.433, -2.0077, -4.009]  w:  [1.6218458  1.47645186 2.22903446]
-19.090113971765486  -  0.3253  =  -19.415413971765485
training  [0.2189, -0.4741, -0.1024]  w:  [1.6218458  1.47645186 2.22903446]
-0.5732169087776864  -  33.6531  =  -34.22631690877769
training  [-1.6415, -0.7735, -3.0675]  w:  [1.6218458  1.47645186 2.22903446]
-10.64185860115445  -  3.7641  =  -14.405958601154449
training  [-3.2433, -1.4039, 3.9589]  w:  [1.6218458  1.47645186 2.22903446]
1.4916012989168888  -  30.0658  =  -28.574198701083112
training  [-2.9105, 0.5832, -4.0091]  w:  [1.6218458  1.47645186 2.22903446]
-12.795737535285088  -  2.4887  =  -15.284437535285088
training  [4.0515, 2.4255, -4.5583]  w:  [1.6218458  1.47645186 2.22903446]
-0.008565566399550306  -  61.2853  =  -61.293865566399546
training  [1.7539, -0.7567, 0.573]  w:  [1.6218458  1.47645186 2.22903446]
3.0045609718879067  -  57.0797  =  -54.0751390281121
training  [-0.3153, -0.7064, 2.725]  w:  [1.6218458  1.47645186 2.22903446]
4.519785339801639  -  58.7004  =  -54.180614660198366
training  [4.1213, -3.7513, -1.8806]  w:  [1.6218458  1.47645186 2.22903446]
-3.0464229723592355  -  22.1789  =  -25.225322972359233
training  [-3.9599, -4.7557, -3.2102]  w:  [1.6218458  1.47645186 2.22903446]
-20.599555696128686  -  0.1558  =  -20.755355696128685
training  [2.4555, -2.0981, -1.6104]  w:  [1.6218458  1.47645186 2.22903446]
-2.704938381816743  -  24.4796  =  -27.184538381816743
training  [2.3627, -1.8248, -2.8985]  w:  [1.6218458  1.47645186 2.22903446]
-5.32315067094667  -  15.7052  =  -21.02835067094667
training  [0.6186, 1.5369, 0.1015]  w:  [1.6218458  1.47645186 2.22903446]
3.498679665514219  -  65.2154  =  -61.716720334485785
training  [-3.1581, 4.5694, 4.0636]  w:  [1.6218458  1.47645186 2.22903446]
10.682452339676306  -  90.3564  =  -79.67394766032369
training  [0.9721, 4.3573, 1.2892]  w:  [1.6218458  1.47645186 2.22903446]
10.883611200444216  -  94.3178  =  -83.43418879955578
training  [-2.0006, -0.4211, -3.9847]  w:  [1.6218458  1.47645186 2.22903446]
-12.748432202147523  -  2.4051  =  -15.153532202147524
training  [-3.6588, -2.5952, -1.0915]  w:  [1.6218458  1.47645186 2.22903446]
-12.198688375940225  -  1.5176  =  -13.716288375940225
training  [-2.874, 2.639, -4.4538]  w:  [1.6218458  1.47645186 2.22903446]
-10.692502063950243  -  5.497  =  -16.189502063950243
training  [3.9494, 2.5933, 0.0128]  w:  [1.6218458  1.47645186 2.22903446]
10.262732031292703  -  94.1462  =  -83.8834679687073
training  [-4.2855, 2.4065, -0.6828]  w:  [1.6218458  1.47645186 2.22903446]
-4.9193235048779975  -  14.4193  =  -19.338623504877997
training  [-2.5751, 2.4369, 4.9756]  w:  [1.6218458  1.47645186 2.22903446]
10.512334286901236  -  87.1991  =  -76.68676571309877
training  [-4.4625, -3.9408, 3.116]  w:  [1.6218458  1.47645186 2.22903446]
-6.110216958995854  -  4.1344  =  -10.244616958995854
training  [-0.5828, 1.8156, -0.1435]  w:  [1.6218458  1.47645186 2.22903446]
1.41556781335695  -  51.1166  =  -49.70103218664305
training  [-4.8672, -0.3674, 3.9445]  w:  [1.6218458  1.47645186 2.22903446]
0.3561301607971554  -  24.1396  =  -23.783469839202844
training  [3.9719, -2.8784, -3.6245]  w:  [1.6218458  1.47645186 2.22903446]
-5.887145108926864  -  14.6104  =  -20.497545108926865
training  [-3.0334, -4.0148, -1.1]  w:  [1.6218458  1.47645186 2.22903446]
-13.299303861729994  -  1.021  =  -14.320303861729993
training  [-4.0663, 3.2357, 4.2736]  w:  [1.6218458  1.47645186 2.22903446]
7.708445383449239  -  77.2328  =  -69.52435461655075
training  [-1.9263, -3.2499, 4.1749]  w:  [1.6218458  1.47645186 2.22903446]
1.3835135321590268  -  26.8814  =  -25.49788646784097
training  [-0.4394, -3.3643, 2.1357]  w:  [1.6218458  1.47645186 2.22903446]
-0.919317120173865  -  20.85  =  -21.769317120173866
training  [-3.9833, 1.6599, 1.1834]  w:  [1.6218458  1.47645186 2.22903446]
-1.3716965462865982  -  25.5397  =  -26.911396546286596
training  [4.9539, 3.9439, -1.5671]  w:  [1.6218458  1.47645186 2.22903446]
10.364320463798798  -  95.9509  =  -85.58657953620121
training  [-1.6791, 0.1656, 4.3603]  w:  [1.6218458  1.47645186 2.22903446]
7.240518116331926  -  71.5733  =  -64.33278188366808
training  [-2.0265, 2.027, -3.7523]  w:  [1.6218458  1.47645186 2.22903446]
-8.657908610863453  -  8.503  =  -17.16090861086345
training  [-4.3795, -3.4641, 2.3059]  w:  [1.6218458  1.47645186 2.22903446]
-7.077519976311711  -  3.6654  =  -10.742919976311711
training  [-2.0176, 4.5346, 1.4648]  w:  [1.6218458  1.47645186 2.22903446]
6.687972185542414  -  81.6212  =  -74.93322781445758
training  [-4.5365, 0.4088, 3.3315]  w:  [1.6218458  1.47645186 2.22903446]
0.672098370921427  -  28.9449  =  -28.27280162907857
training  [0.0543, 1.7973, -1.0172]  w:  [1.6218458  1.47645186 2.22903446]
0.47431929192620936  -  47.9317  =  -47.45738070807379
training  [2.6143, -4.6344, 2.4982]  w:  [1.6218458  1.47645186 2.22903446]
2.9660968820346207  -  43.5132  =  -40.54710311796538
training  [1.3107, 3.092, 3.3522]  w:  [1.6218458  1.47645186 2.22903446]
14.163111750678729  -  96.6993  =  -82.53618824932127
training  [-4.1011, 2.4862, -1.7754]  w:  [1.6218458  1.47645186 2.22903446]
-6.938024980805899  -  10.0187  =  -16.9567249808059
training  [-4.1914, -3.7981, 0.5226]  w:  [1.6218458  1.47645186 2.22903446]
-11.240622858905427  -  1.4295  =  -12.670122858905426
training  [2.7724, 0.2505, 4.7913]  w:  [1.6218458  1.47645186 2.22903446]
15.546229299567084  -  96.7925  =  -81.24627070043292
training  [4.0513, -1.7417, 0.4931]  w:  [1.6218458  1.47645186 2.22903446]
5.098184575327849  -  71.1234  =  -66.02521542467215
training  [0.3377, 0.4645, -1.6958]  w:  [1.6218458  1.47645186 2.22903446]
-2.546487428915998  -  27.9534  =  -30.499887428915997
training  [-3.9085, -1.0112, 1.1947]  w:  [1.6218458  1.47645186 2.22903446]
-5.168944943385232  -  8.608  =  -13.776944943385232
training  [3.2581, -0.8491, -1.3936]  w:  [1.6218458  1.47645186 2.22903446]
0.924098094667464  -  50.1924  =  -49.268301905332535
training  [-1.619, -3.1926, 2.5651]  w:  [1.6218458  1.47645186 2.22903446]
-1.6217922409156351  -  16.4754  =  -18.097192240915636
training  [-2.0603, -2.4461, -0.861]  w:  [1.6218458  1.47645186 2.22903446]
-8.872236453395868  -  3.9784  =  -12.850636453395868
training  [2.4631, -4.7946, -0.0765]  w:  [1.6218458  1.47645186 2.22903446]
-3.254748820817944  -  15.394  =  -18.648748820817943
training  [-4.8966, 4.2368, 1.9474]  w:  [1.6218458  1.47645186 2.22903446]
2.654722803731782  -  53.5883  =  -50.93357719626822
training  [-4.5155, 1.537, 4.7273]  w:  [1.6218458  1.47645186 2.22903446]
5.483176419403455  -  59.2523  =  -53.76912358059654
training  [1.6792, 4.3261, -1.7225]  w:  [1.6218458  1.47645186 2.22903446]
5.271169974757722  -  83.7729  =  -78.50173002524228
training  [1.0347, -3.3649, 3.378]  w:  [1.6218458  1.47645186 2.22903446]
4.239689411652782  -  50.5979  =  -46.35821058834722
training  [0.261, 4.211, 2.3907]  w:  [1.6218458  1.47645186 2.22903446]
11.969593207981752  -  94.9375  =  -82.96790679201825
training  [2.2971, 2.9466, 4.5417]  w:  [1.6218458  1.47645186 2.22903446]
18.19966083874182  -  98.7784  =  -80.57873916125818
training  [2.0725, 0.7739, -4.6808]  w:  [1.6218458  1.47645186 2.22903446]
-5.929763006323737  -  19.5109  =  -25.44066300632374
training  [2.8138, -0.5996, -1.4313]  w:  [1.6218458  1.47645186 2.22903446]
0.48785214566210344  -  47.2879  =  -46.8000478543379
training  [-2.1202, -2.4239, 1.6265]  w:  [1.6218458  1.47645186 2.22903446]
-3.391884559632074  -  12.3599  =  -15.751784559632075
training  [1.9253, 2.5195, -2.185]  w:  [1.6218458  1.47645186 2.22903446]
1.9720198637447606  -  65.2467  =  -63.27468013625524
training  [0.5667, -2.7133, -2.6962]  w:  [1.6218458  1.47645186 2.22903446]
-9.096879525270431  -  5.1106  =  -14.207479525270431
training  [-1.0348, -4.3581, 2.1113]  w:  [1.6218458  1.47645186 2.22903446]
-3.4066504032027938  -  10.5192  =  -13.925850403202794
training  [-4.3841, 2.6733, 1.2457]  w:  [1.6218458  1.47645186 2.22903446]
-0.3866271841514006  -  32.4639  =  -32.8505271841514
training  [2.8018, 1.712, 0.9061]  w:  [1.6218458  1.47645186 2.22903446]
9.091501259074514  -  90.1138  =  -81.02229874092548
training  [-1.6242, 2.1521, 1.6044]  w:  [1.6218458  1.47645186 2.22903446]
4.119532986663091  -  63.7879  =  -59.66836701333691
training  [1.0787, 1.4206, -4.5245]  w:  [1.6218458  1.47645186 2.22903446]
-6.238333858119709  -  18.0555  =  -24.293833858119708
training  [2.4125, -0.8095, -1.5122]  w:  [1.6218458  1.47645186 2.22903446]
-0.6532307054197375  -  38.8276  =  -39.480830705419734
training  [-3.9519, -1.0924, -0.4866]  w:  [1.6218458  1.47645186 2.22903446]
-9.106896583734708  -  3.6777  =  -12.784596583734707
training  [-3.7211, 3.1614, -2.591]  w:  [1.6218458  1.47645186 2.22903446]
-7.142823792441472  -  11.1518  =  -18.29462379244147
training  [0.4954, -1.8257, 2.1505]  w:  [1.6218458  1.47645186 2.22903446]
2.901442866732277  -  47.7531  =  -44.85165713326773
training  [-0.1477, 3.1454, 3.5618]  w:  [1.6218458  1.47645186 2.22903446]
12.34385999217556  -  94.1572  =  -81.81334000782445
training  [3.9048, 2.8907, -2.1849]  w:  [1.6218458  1.47645186 2.22903446]
5.730745452103037  -  85.8791  =  -80.14835454789696
training  [2.9896, 3.5226, 2.3105]  w:  [1.6218458  1.47645186 2.22903446]
15.199803629382625  -  98.038  =  -82.83819637061737
training  [2.3434, 0.0564, -3.6224]  w:  [1.6218458  1.47645186 2.22903446]
-4.1905491111114355  -  24.7629  =  -28.953449111111432
training  [-4.4867, 1.3566, 3.3672]  w:  [1.6218458  1.47645186 2.22903446]
2.2318238909294728  -  40.5785  =  -38.34667610907053
training  [-4.2711, 4.5089, -3.614]  w:  [1.6218458  1.47645186 2.22903446]
-8.325622360550977  -  10.0825  =  -18.408122360550976
training  [-4.1147, -0.5604, 0.8821]  w:  [1.6218458  1.47645186 2.22903446]
-5.534581223219346  -  8.344  =  -13.878581223219346
training  [2.9835, -4.3998, -1.3384]  w:  [1.6218458  1.47645186 2.22903446]
-4.640655663554263  -  13.2692  =  -17.90985566355426
training  [4.4301, 3.6675, 3.0676]  w:  [1.6218458  1.47645186 2.22903446]
19.437612366166967  -  99.3834  =  -79.94578763383302
training  [1.8372, 1.3119, 0.0378]  w:  [1.6218458  1.47645186 2.22903446]
5.0008697914281655  -  74.9026  =  -69.90173020857185
training  [-3.6792, -1.4493, -0.1041]  w:  [1.6218458  1.47645186 2.22903446]
-8.338959220167604  -  4.2442  =  -12.583159220167605
training  [2.2272, 4.97, 3.7705]  w:  [1.6218458  1.47645186 2.22903446]
19.354715125046418  -  99.3199  =  -79.9651848749536
training  [-3.8965, -2.7583, -1.4686]  w:  [1.6218458  1.47645186 2.22903446]
-13.665579315543532  -  1.0337  =  -14.699279315543532
training  [-3.8251, 1.5245, -0.5056]  w:  [1.6218458  1.47645186 2.22903446]
-5.0798713298232965  -  12.9762  =  -18.056071329823297
training  [1.4072, 1.0499, 4.6353]  w:  [1.6218458  1.47645186 2.22903446]
14.16463165430946  -  95.4618  =  -81.29716834569054
training  [-1.7119, -1.1275, -4.577]  w:  [1.6218458  1.47645186 2.22903446]
-14.64342802362943  -  1.4655  =  -16.108928023629428
training  [1.5381, -3.5781, 4.7296]  w:  [1.6218458  1.47645186 2.22903446]
7.754110030123558  -  69.9473  =  -62.19318996987644
training  [2.4913, -4.7487, -3.1079]  w:  [1.6218458  1.47645186 2.22903446]
-9.898338699209381  -  3.9825  =  -13.88083869920938
training  [0.8319, -0.7889, 1.6712]  w:  [1.6218458  1.47645186 2.22903446]
3.9096030437731635  -  58.8336  =  -54.92399695622683
training  [2.4003, -3.159, 0.8644]  w:  [1.6218458  1.47645186 2.22903446]
1.1555824444427503  -  39.0041  =  -37.84851755555725
training  [-2.6517, 2.2578, 1.7511]  w:  [1.6218458  1.47645186 2.22903446]
2.936146746634633  -  54.4525  =  -51.51635325336537
training  [2.3496, -1.2964, -1.3898]  w:  [1.6218458  1.47645186 2.22903446]
-1.2012953964663349  -  33.888  =  -35.08929539646633
training  [4.706, 3.4156, 1.2028]  w:  [1.6218458  1.47645186 2.22903446]
15.356457933247981  -  98.4665  =  -83.11004206675202
training  [3.6693, 2.3423, 3.1115]  w:  [1.6218458  1.47645186 2.22903446]
16.344972697010913  -  98.3069  =  -81.96192730298908
training  [-4.1377, 0.7103, -4.8074]  w:  [1.6218458  1.47645186 2.22903446]
-16.377847878545374  -  0.9782  =  -17.356047878545375
training  [-1.3356, -3.2314, -4.1613]  w:  [1.6218458  1.47645186 2.22903446]
-16.212824883467277  -  0.7659  =  -16.978724883467276
training  [-1.308, 4.5738, 4.748]  w:  [1.6218458  1.47645186 2.22903446]
15.215076823907252  -  97.0884  =  -81.87332317609274
training  [1.8503, -2.3468, 1.5135]  w:  [1.6218458  1.47645186 2.22903446]
2.909607722883132  -  50.2125  =  -47.30289227711687
training  [0.9794, 4.2458, -2.6876]  w:  [1.6218458  1.47645186 2.22903446]
1.8664020417900247  -  68.3262  =  -66.45979795820998
training  [2.8936, -2.7623, -0.9651]  w:  [1.6218458  1.47645186 2.22903446]
-1.5366711218753193  -  28.5596  =  -30.09627112187532
training  [-1.3235, -1.2644, -3.7798]  w:  [1.6218458  1.47645186 2.22903446]
-12.438643101352227  -  2.4511  =  -14.889743101352227
training  [-2.9397, -4.125, -2.3156]  w:  [1.6218458  1.47645186 2.22903446]
-16.019656197817312  -  0.554  =  -16.57365619781731
training  [-4.1333, 1.4012, -2.4215]  w:  [1.6218458  1.47645186 2.22903446]
-10.0323778454011  -  4.4072  =  -14.4395778454011
training  [2.7193, -3.1938, -1.6833]  w:  [1.6218458  1.47645186 2.22903446]
-4.057340371241174  -  17.0949  =  -21.152240371241174
training  [-2.9433, -4.5495, -3.4777]  w:  [1.6218458  1.47645186 2.22903446]
-19.242609604538593  -  0.2509  =  -19.493509604538595
training  [-1.1173, 2.2317, -1.5199]  w:  [1.6218458  1.47645186 2.22903446]
-1.905000182534599  -  33.1206  =  -35.0256001825346
training  [0.5178, -1.5256, -3.7834]  w:  [1.6218458  1.47645186 2.22903446]
-9.84601218335373  -  5.237  =  -15.08301218335373
training  [-2.7105, 1.6062, 3.8415]  w:  [1.6218458  1.47645186 2.22903446]
6.538299825184019  -  70.4458  =  -63.907500174815986
training  [1.4194, -1.1613, -4.0572]  w:  [1.6218458  1.47645186 2.22903446]
-8.456194237172406  -  8.3206  =  -16.776794237172407
training  [-0.1552, 1.2735, 4.3004]  w:  [1.6218458  1.47645186 2.22903446]
11.21429077382946  -  90.1085  =  -78.89420922617055
training  [-3.4815, -4.7835, -1.0098]  w:  [1.6218458  1.47645186 2.22903446]
-14.959942596624918  -  0.5839  =  -15.543842596624918
training  [2.8193, 4.1057, -4.526]  w:  [1.6218458  1.47645186 2.22903446]
0.5457282633546701  -  66.8081  =  -66.26237173664532
training  [-3.9939, 3.0056, -1.5763]  w:  [1.6218458  1.47645186 2.22903446]
-5.553493255877284  -  14.4018  =  -19.955293255877283
training  [-2.0593, 2.4585, 2.3597]  w:  [1.6218458  1.47645186 2.22903446]
5.549842458469948  -  70.6698  =  -65.11995754153004
training  [-2.6263, 3.1311, 2.9468]  w:  [1.6218458  1.47645186 2.22903446]
6.931983542592595  -  77.309  =  -70.37701645740741
training  [0.3087, -1.1669, 0.4491]  w:  [1.6218458  1.47645186 2.22903446]
-0.22114849575575324  -  33.0798  =  -33.300948495755755
training  [-4.085, 1.1728, 1.8622]  w:  [1.6218458  1.47645186 2.22903446]
-0.7427493696289522  -  26.4056  =  -27.148349369628953
training  [-0.9468, 0.7549, 3.9363]  w:  [1.6218458  1.47645186 2.22903446]
8.353158260285923  -  79.7738  =  -71.42064173971407
training  [-3.9515, 0.3005, -4.4521]  w:  [1.6218458  1.47645186 2.22903446]
-15.888934217014906  -  1.0441  =  -16.933034217014907
training  [-3.8772, -2.2493, -1.9634]  w:  [1.6218458  1.47645186 2.22903446]
-13.985689949139706  -  1.0509  =  -15.036589949139707
training  [2.8443, -2.5137, -4.5381]  w:  [1.6218458  1.47645186 2.22903446]
-9.213922323354652  -  6.8897  =  -16.103622323354653
training  [-2.0843, -0.4836, -3.0452]  w:  [1.6218458  1.47645186 2.22903446]
-10.8822810587284  -  3.5346  =  -14.4168810587284
training  [1.0353, -2.7229, 2.2017]  w:  [1.6218458  1.47645186 2.22903446]
2.566531372180606  -  43.9562  =  -41.3896686278194
training  [4.6442, 3.0445, 2.2175]  w:  [1.6218458  1.47645186 2.22903446]
16.970117848504927  -  98.8492  =  -81.87908215149507
training  [-0.6752, 4.861, 3.778]  w:  [1.6218458  1.47645186 2.22903446]
14.503254388758538  -  97.017  =  -82.51374561124146
training  [1.9475, -4.7001, 0.8243]  w:  [1.6218458  1.47645186 2.22903446]
-1.943533569645252  -  18.7839  =  -20.72743356964525
training  [2.581, 0.3566, -4.2932]  w:  [1.6218458  1.47645186 2.22903446]
-4.857204020056091  -  23.5455  =  -28.402704020056092
training  [-0.6736, -4.1292, 4.2274]  w:  [1.6218458  1.47645186 2.22903446]
2.2339799550388353  -  31.2667  =  -29.032720044961167
training  [1.555, 3.0209, 3.0037]  w:  [1.6218458  1.47645186 2.22903446]
13.677534441808444  -  96.4078  =  -82.73026555819155
training  [-3.9024, 4.8914, -2.1405]  w:  [1.6218458  1.47645186 2.22903446]
-3.878422699465096  -  25.4308  =  -29.309222699465096
training  [4.3376, -4.3305, 0.4366]  w:  [1.6218458  1.47645186 2.22903446]
1.6143400155558179  -  43.0907  =  -41.47635998444418
training  [-3.1254, 4.394, 4.8478]  w:  [1.6218458  1.47645186 2.22903446]
12.224525867341786  -  92.8121  =  -80.58757413265822
training  [-2.3382, -4.8182, 2.1568]  w:  [1.6218458  1.47645186 2.22903446]
-6.098458646405518  -  4.7434  =  -10.84185864640552
training  [2.9783, 1.8384, 3.3897]  w:  [1.6218458  1.47645186 2.22903446]
15.10041054832725  -  97.3486  =  -82.24818945167276
training  [-0.124, 2.8374, -0.6674]  w:  [1.6218458  1.47645186 2.22903446]
2.500518016552087  -  62.785  =  -60.28448198344791
training  [2.6896, 0.3414, -0.2938]  w:  [1.6218458  1.47645186 2.22903446]
4.211286795239525  -  70.4455  =  -66.23421320476047
training  [-1.0399, 3.8536, 0.6071]  w:  [1.6218458  1.47645186 2.22903446]
5.35634424924451  -  77.0369  =  -71.68055575075549
training  [-2.2706, 3.99, -2.3091]  w:  [1.6218458  1.47645186 2.22903446]
-2.9385836404837007  -  31.1134  =  -34.0519836404837
training  [-4.6277, 1.2594, 2.4902]  w:  [1.6218458  1.47645186 2.22903446]
-0.09523071063757182  -  28.1093  =  -28.204530710637574
training  [1.7329, -3.6213, 0.0389]  w:  [1.6218458  1.47645186 2.22903446]
-2.4494690826394834  -  19.3919  =  -21.84136908263948
training  [-0.7044, -2.822, 1.4681]  w:  [1.6218458  1.47645186 2.22903446]
-2.036529822325361  -  17.8122  =  -19.84872982232536
training  [-0.4826, -3.1786, -1.9225]  w:  [1.6218458  1.47645186 2.22903446]
-9.761071405297614  -  3.5851  =  -13.346171405297614
training  [1.0986, -4.5818, -3.6128]  w:  [1.6218458  1.47645186 2.22903446]
-13.036103026741678  -  1.7158  =  -14.751903026741678
training  [-4.406, -3.9306, -0.2443]  w:  [1.6218458  1.47645186 2.22903446]
-13.493747367337981  -  0.8241  =  -14.317847367337981
training  [-1.8419, 1.1644, -1.3754]  w:  [1.6218458  1.47645186 2.22903446]
-4.333911233256437  -  17.8517  =  -22.185611233256438
training  [2.7272, 4.3966, 2.8811]  w:  [1.6218458  1.47645186 2.22903446]
17.336537278538927  -  98.904  =  -81.56746272146107
training  [1.9643, -1.4554, 2.803]  w:  [1.6218458  1.47645186 2.22903446]
7.2849472676807565  -  76.0591  =  -68.77415273231924
training  [-3.7467, -0.8937, 1.6851]  w:  [1.6218458  1.47645186 2.22903446]
-3.639928699816375  -  12.1571  =  -15.797028699816375
training  [-3.6985, 4.8435, -3.665]  w:  [1.6218458  1.47645186 2.22903446]
-7.016613423566644  -  14.6793  =  -21.695913423566644
234510.79138850697
200
training  [4.4793, -4.0765, 4.4558]  w:  [1.53965666 1.37774561 2.16240562]
10.915451075250385  -  87.3174  =  -76.40194892474962
training  [-4.1793, -4.9218, 1.7664]  w:  [1.53965666 1.37774561 2.16240562]
-9.396002157873115  -  1.5257  =  -10.921702157873115
training  [-3.9429, -0.7689, 4.883]  w:  [1.53965666 1.37774561 2.16240562]
3.4289657792008157  -  39.7859  =  -36.35693422079918
training  [-3.5796, 1.5557, 2.6683]  w:  [1.53965666 1.37774561 2.16240562]
2.4019507660320545  -  45.5674  =  -43.16544923396795
training  [-3.3354, 2.2292, -1.633]  w:  [1.53965666 1.37774561 2.16240562]
-5.595308700065005  -  13.3589  =  -18.954208700065006
training  [1.2096, 0.3121, 1.6238]  w:  [1.53965666 1.37774561 2.16240562]
5.803677351808496  -  74.5119  =  -68.70822264819151
training  [0.7371, -3.9118, -2.5583]  w:  [1.53965666 1.37774561 2.16240562]
-9.78666664998357  -  3.3358  =  -13.122466649983568
training  [-4.4792, 1.3177, -2.0449]  w:  [1.53965666 1.37774561 2.16240562]
-9.502877991828406  -  4.2974  =  -13.800277991828406
training  [4.312, -3.735, 1.8018]  w:  [1.53965666 1.37774561 2.16240562]
5.3893421264511545  -  66.5833  =  -61.19395787354884
training  [2.2866, -3.657, 0.2785]  w:  [1.53965666 1.37774561 2.16240562]
-0.9156068046339475  -  26.0005  =  -26.916106804633948
training  [2.3784, -4.0141, -0.8841]  w:  [1.53965666 1.37774561 2.16240562]
-3.7802720540145716  -  14.6809  =  -18.461172054014572
training  [-4.366, -3.5797, 1.0264]  w:  [1.53965666 1.37774561 2.16240562]
-9.434563831547305  -  1.8713  =  -11.305863831547304
training  [3.6044, -3.3175, 2.5052]  w:  [1.53965666 1.37774561 2.16240562]
6.3961259761701506  -  71.0139  =  -64.61777402382985
training  [4.3441, -3.0375, 0.8353]  w:  [1.53965666 1.37774561 2.16240562]
4.309777637364967  -  63.8979  =  -59.58812236263503
training  [4.844, -1.8252, 0.5179]  w:  [1.53965666 1.37774561 2.16240562]
6.063345464120963  -  78.0461  =  -71.98275453587904
training  [3.5894, -1.8357, 0.8357]  w:  [1.53965666 1.37774561 2.16240562]
4.804438390005822  -  68.8838  =  -64.07936160999417
training  [2.8556, -2.8244, 0.1182]  w:  [1.53965666 1.37774561 2.16240562]
0.7609352120920954  -  39.5252  =  -38.764264787907905
training  [0.1338, -2.4896, -4.1741]  w:  [1.53965666 1.37774561 2.16240562]
-12.250126708440668  -  2.2644  =  -14.514526708440668
training  [-3.224, 3.9292, 2.1957]  w:  [1.53965666 1.37774561 2.16240562]
5.197578987149368  -  72.1211  =  -66.92352101285063
training  [-1.0141, 2.0322, 4.9616]  w:  [1.53965666 1.37774561 2.16240562]
11.967480529976479  -  92.3427  =  -80.37521947002351
training  [-3.6607, 0.5574, -1.4547]  w:  [1.53965666 1.37774561 2.16240562]
-8.013917203076684  -  5.8471  =  -13.861017203076685
training  [-4.6911, -3.1557, 4.7126]  w:  [1.53965666 1.37774561 2.16240562]
-1.3798824785125294  -  11.2337  =  -12.61358247851253
training  [4.3914, -2.8797, -1.5355]  w:  [1.53965666 1.37774561 2.16240562]
-0.5266195884257088  -  37.475  =  -38.00161958842571
training  [-1.9869, -4.2265, 3.8654]  w:  [1.53965666 1.37774561 2.16240562]
-0.5236229677091782  -  15.7889  =  -16.312522967709178
training  [-2.0447, 4.138, -0.4531]  w:  [1.53965666 1.37774561 2.16240562]
1.573189369320784  -  57.936  =  -56.36281063067921
training  [-1.6706, 2.0672, -0.8657]  w:  [1.53965666 1.37774561 2.16240562]
-1.5960692420324836  -  32.4185  =  -34.014569242032486
training  [-0.3293, 0.5779, -2.8227]  w:  [1.53965666 1.37774561 2.16240562]
-5.8146320941061855  -  14.3434  =  -20.158032094106186
training  [1.482, -1.8657, -3.7435]  w:  [1.53965666 1.37774561 2.16240562]
-8.383654247039155  -  7.1519  =  -15.535554247039155
training  [-4.7477, -3.338, -1.9109]  w:  [1.53965666 1.37774561 2.16240562]
-16.040883693237763  -  0.4077  =  -16.44858369323776
training  [3.4221, 1.225, 2.261]  w:  [1.53965666 1.37774561 2.16240562]
11.845796550822545  -  95.0454  =  -83.19960344917746
training  [0.5903, 4.8793, 2.8287]  w:  [1.53965666 1.37774561 2.16240562]
13.74809026433595  -  97.4647  =  -83.71660973566404
training  [3.541, -3.2957, 1.9379]  w:  [1.53965666 1.37774561 2.16240562]
5.101813889854642  -  64.3732  =  -59.27138611014536
training  [-1.5212, -2.4221, -4.902]  w:  [1.53965666 1.37774561 2.16240562]
-16.279275709960107  -  0.7227  =  -17.001975709960107
training  [-0.5397, -1.032, 3.4321]  w:  [1.53965666 1.37774561 2.16240562]
5.16880615558088  -  60.5921  =  -55.42329384441912
training  [-4.4576, -4.2601, 4.2233]  w:  [1.53965666 1.37774561 2.16240562]
-3.6000199696708712  -  6.0247  =  -9.62471996967087
training  [-3.2289, 1.841, 2.7095]  w:  [1.53965666 1.37774561 2.16240562]
3.424070292529601  -  54.0111  =  -50.5870297074704
training  [1.6281, -0.9761, -4.5734]  w:  [1.53965666 1.37774561 2.16240562]
-8.727648336890026  -  7.8658  =  -16.593448336890027
training  [-1.6917, 4.8284, -1.2181]  w:  [1.53965666 1.37774561 2.16240562]
1.4136434423954913  -  61.2837  =  -59.870056557604514
training  [3.9849, -0.9782, 2.0434]  w:  [1.53965666 1.37774561 2.16240562]
9.206326729036679  -  88.3402  =  -79.13387327096332
training  [-3.8184, 1.2067, 2.2951]  w:  [1.53965666 1.37774561 2.16240562]
0.7464377591059614  -  34.1122  =  -33.36576224089404
training  [4.8842, -3.4563, -2.7572]  w:  [1.53965666 1.37774561 2.16240562]
-3.204095849070961  -  23.7819  =  -26.98599584907096
training  [0.3998, -1.1865, -2.3095]  w:  [1.53965666 1.37774561 2.16240562]
-6.013216211651848  -  11.4246  =  -17.43781621165185
training  [2.0692, -3.3887, 1.7303]  w:  [1.53965666 1.37774561 2.16240562]
2.2587014627032107  -  42.6881  =  -40.42939853729679
training  [4.9949, 2.5811, -0.2251]  w:  [1.53965666 1.37774561 2.16240562]
10.759772764017372  -  95.9901  =  -85.23032723598263
training  [-2.1215, 3.7111, 1.2372]  w:  [1.53965666 1.37774561 2.16240562]
4.521898355386057  -  71.3692  =  -66.84730164461395
training  [-0.8548, -1.4922, -2.6356]  w:  [1.53965666 1.37774561 2.16240562]
-9.07120676864907  -  4.7821  =  -13.85330676864907
training  [-0.3516, 1.8554, -3.2288]  w:  [1.53965666 1.37774561 2.16240562]
-4.967049342159142  -  20.3834  =  -25.350449342159145
training  [2.6396, -2.0585, 3.2964]  w:  [1.53965666 1.37774561 2.16240562]
8.35614227668373  -  80.826  =  -72.46985772331627
training  [3.182, 0.3063, 2.6692]  w:  [1.53965666 1.37774561 2.16240562]
11.093084067080017  -  92.9483  =  -81.85521593291999
training  [-3.9978, 3.3242, 4.3448]  w:  [1.53965666 1.37774561 2.16240562]
7.819882483200673  -  79.1768  =  -71.35691751679933
training  [-3.2188, 0.9749, -3.9211]  w:  [1.53965666 1.37774561 2.16240562]
-12.091691351225077  -  2.7053  =  -14.796991351225076
training  [-1.4037, -1.6469, -3.1777]  w:  [1.53965666 1.37774561 2.16240562]
-11.301701644218937  -  2.6234  =  -13.925101644218937
training  [-4.433, -2.0077, -4.009]  w:  [1.53965666 1.37774561 2.16240562]
-18.260481985819094  -  0.3253  =  -18.585781985819093
training  [0.2189, -0.4741, -0.1024]  w:  [1.53965666 1.37774561 2.16240562]
-0.5375886856932182  -  33.6531  =  -34.19068868569322
training  [-1.6415, -0.7735, -3.0675]  w:  [1.53965666 1.37774561 2.16240562]
-10.226211883267881  -  3.7641  =  -13.990311883267882
training  [-3.2433, -1.4039, 3.9589]  w:  [1.53965666 1.37774561 2.16240562]
1.6329620855362794  -  30.0658  =  -28.432837914463718
training  [-2.9105, 0.5832, -4.0091]  w:  [1.53965666 1.37774561 2.16240562]
-12.346969851867373  -  2.4887  =  -14.835669851867372
training  [4.0515, 2.4255, -4.5583]  w:  [1.53965666 1.37774561 2.16240562]
-0.2772525818967768  -  61.2853  =  -61.562552581896774
training  [1.7539, -0.7567, 0.573]  w:  [1.53965666 1.37774561 2.16240562]
2.8969221401809992  -  57.0797  =  -54.182777859819005
training  [-0.3153, -0.7064, 2.725]  w:  [1.53965666 1.37774561 2.16240562]
4.433862068188769  -  58.7004  =  -54.266537931811236
training  [4.1213, -3.7513, -1.8806]  w:  [1.53965666 1.37774561 2.16240562]
-2.8895701072207354  -  22.1789  =  -25.068470107220733
training  [-3.9599, -4.7557, -3.2102]  w:  [1.53965666 1.37774561 2.16240562]
-19.59078574719667  -  0.1558  =  -19.74658574719667
training  [2.4555, -2.0981, -1.6104]  w:  [1.53965666 1.37774561 2.16240562]
-2.5923591366043084  -  24.4796  =  -27.07195913660431
training  [2.3627, -1.8248, -2.8985]  w:  [1.53965666 1.37774561 2.16240562]
-5.1440960784889125  -  15.7052  =  -20.849296078488912
training  [0.6186, 1.5369, 0.1015]  w:  [1.53965666 1.37774561 2.16240562]
3.2893730122077893  -  65.2154  =  -61.92602698779221
training  [-3.1581, 4.5694, 4.0636]  w:  [1.53965666 1.37774561 2.16240562]
10.220232558554576  -  90.3564  =  -80.13616744144542
training  [0.9721, 4.3573, 1.2892]  w:  [1.53965666 1.37774561 2.16240562]
10.287724518319962  -  94.3178  =  -84.03007548168004
training  [-2.0006, -0.4211, -3.9847]  w:  [1.53965666 1.37774561 2.16240562]
-12.276943472693448  -  2.4051  =  -14.682043472693447
training  [-3.6588, -2.5952, -1.0915]  w:  [1.53965666 1.37774561 2.16240562]
-11.569086946823413  -  1.5176  =  -13.086686946823413
training  [-2.874, 2.639, -4.4538]  w:  [1.53965666 1.37774561 2.16240562]
-10.420024736113715  -  5.497  =  -15.917024736113715
training  [3.9494, 2.5933, 0.0128]  w:  [1.53965666 1.37774561 2.16240562]
9.681306514774073  -  94.1462  =  -84.46489348522591
training  [-4.2855, 2.4065, -0.6828]  w:  [1.53965666 1.37774561 2.16240562]
-4.7591443802090305  -  14.4193  =  -19.17844438020903
training  [-2.5751, 2.4369, 4.9756]  w:  [1.53965666 1.37774561 2.16240562]
10.151923804185596  -  87.1991  =  -77.0471761958144
training  [-4.4625, -3.9408, 3.116]  w:  [1.53965666 1.37774561 2.16240562]
-5.562081856600256  -  4.1344  =  -9.696481856600256
training  [-0.5828, 1.8156, -0.1435]  w:  [1.53965666 1.37774561 2.16240562]
1.2938178204567872  -  51.1166  =  -49.82278217954321
training  [-4.8672, -0.3674, 3.9445]  w:  [1.53965666 1.37774561 2.16240562]
0.5296083128369844  -  24.1396  =  -23.609991687163017
training  [3.9719, -2.8784, -3.6245]  w:  [1.53965666 1.37774561 2.16240562]
-5.687979829592827  -  14.6104  =  -20.298379829592825
training  [-3.0334, -4.0148, -1.1]  w:  [1.53965666 1.37774561 2.16240562]
-12.580413785718944  -  1.021  =  -13.601413785718943
training  [-4.0663, 3.2357, 4.2736]  w:  [1.53965666 1.37774561 2.16240562]
7.438522235006211  -  77.2328  =  -69.79427776499378
training  [-1.9263, -3.2499, 4.1749]  w:  [1.53965666 1.37774561 2.16240562]
1.5844511289580065  -  26.8814  =  -25.29694887104199
training  [-0.4394, -3.3643, 2.1357]  w:  [1.53965666 1.37774561 2.16240562]
-0.693425014474971  -  20.85  =  -21.543425014474973
training  [-3.9833, 1.6599, 1.1834]  w:  [1.53965666 1.37774561 2.16240562]
-1.287003641574163  -  25.5397  =  -26.826703641574163
training  [4.9539, 3.9439, -1.5671]  w:  [1.53965666 1.37774561 2.16240562]
9.672290217377656  -  95.9509  =  -86.27860978262235
training  [-1.6791, 0.1656, 4.3603]  w:  [1.53965666 1.37774561 2.16240562]
7.071654391897968  -  71.5733  =  -64.50164560810204
training  [-2.0265, 2.027, -3.7523]  w:  [1.53965666 1.37774561 2.16240562]
-8.441418484534132  -  8.503  =  -16.944418484534133
training  [-4.3795, -3.4641, 2.3059]  w:  [1.53965666 1.37774561 2.16240562]
-6.529283813391032  -  3.6654  =  -10.194683813391032
training  [-2.0176, 4.5346, 1.4648]  w:  [1.53965666 1.37774561 2.16240562]
6.308605712352472  -  81.6212  =  -75.31259428764753
training  [-4.5365, 0.4088, 3.3315]  w:  [1.53965666 1.37774561 2.16240562]
0.7826242699074681  -  28.9449  =  -28.16227573009253
training  [0.0543, 1.7973, -1.0172]  w:  [1.53965666 1.37774561 2.16240562]
0.3602265466663792  -  47.9317  =  -47.57147345333362
training  [2.6143, -4.6344, 2.4982]  w:  [1.53965666 1.37774561 2.16240562]
3.0422218785730744  -  43.5132  =  -40.470978121426924
training  [1.3107, 3.092, 3.3522]  w:  [1.53965666 1.37774561 2.16240562]
13.52683353720708  -  96.6993  =  -83.17246646279291
training  [-4.1011, 2.4862, -1.7754]  w:  [1.53965666 1.37774561 2.16240562]
-6.728069746295072  -  10.0187  =  -16.746769746295072
training  [-4.1914, -3.7981, 0.5226]  w:  [1.53965666 1.37774561 2.16240562]
-10.556059370583341  -  1.4295  =  -11.985559370583342
training  [2.7724, 0.2505, 4.7913]  w:  [1.53965666 1.37774561 2.16240562]
14.974403458011249  -  96.7925  =  -81.81809654198875
training  [4.0513, -1.7417, 0.4931]  w:  [1.53965666 1.37774561 2.16240562]
4.904273725370256  -  71.1234  =  -66.21912627462974
training  [0.3377, 0.4645, -1.6958]  w:  [1.53965666 1.37774561 2.16240562]
-2.5071025582640614  -  27.9534  =  -30.46050255826406
training  [-3.9085, -1.0112, 1.1947]  w:  [1.53965666 1.37774561 2.16240562]
-4.827498440502962  -  8.608  =  -13.435498440502963
training  [3.2581, -0.8491, -1.3936]  w:  [1.53965666 1.37774561 2.16240562]
0.8329831084760313  -  50.1924  =  -49.35941689152397
training  [-1.619, -3.1926, 2.5651]  w:  [1.53965666 1.37774561 2.16240562]
-1.3445081213082304  -  16.4754  =  -17.81990812130823
training  [-2.0603, -2.4461, -0.861]  w:  [1.53965666 1.37774561 2.16240562]
-8.40408940283356  -  3.9784  =  -12.38248940283356
training  [2.4631, -4.7946, -0.0765]  w:  [1.53965666 1.37774561 2.16240562]
-2.9788348052036273  -  15.394  =  -18.372834805203627
training  [-4.8966, 4.2368, 1.9474]  w:  [1.53965666 1.37774561 2.16240562]
2.5092184847334593  -  53.5883  =  -51.07908151526654
training  [-4.5155, 1.537, 4.7273]  w:  [1.53965666 1.37774561 2.16240562]
5.387615422034194  -  59.2523  =  -53.864684577965804
training  [1.6792, 4.3261, -1.7225]  w:  [1.53965666 1.37774561 2.16240562]
4.82091307754942  -  83.7729  =  -78.95198692245059
training  [1.0347, -3.3649, 3.378]  w:  [1.53965666 1.37774561 2.16240562]
4.261712728632672  -  50.5979  =  -46.33618727136733
training  [0.261, 4.211, 2.3907]  w:  [1.53965666 1.37774561 2.16240562]
11.373200271599037  -  94.9375  =  -83.56429972840097
training  [2.2971, 2.9466, 4.5417]  w:  [1.53965666 1.37774561 2.16240562]
17.417408143916514  -  98.7784  =  -81.36099185608349
training  [2.0725, 0.7739, -4.6808]  w:  [1.53965666 1.37774561 2.16240562]
-5.864612459941518  -  19.5109  =  -25.37551245994152
training  [2.8138, -0.5996, -1.4313]  w:  [1.53965666 1.37774561 2.16240562]
0.4111384904991273  -  47.2879  =  -46.876761509500874
training  [-2.1202, -2.4239, 1.6265]  w:  [1.53965666 1.37774561 2.16240562]
-3.086744905246254  -  12.3599  =  -15.446644905246254
training  [1.9253, 2.5195, -2.185]  w:  [1.53965666 1.37774561 2.16240562]
1.7106747630896315  -  65.2467  =  -63.536025236910376
training  [0.5667, -2.7133, -2.6962]  w:  [1.53965666 1.37774561 2.16240562]
-8.695991766059283  -  5.1106  =  -13.806591766059283
training  [-1.0348, -4.3581, 2.1113]  w:  [1.53965666 1.37774561 2.16240562]
-3.032102877572899  -  10.5192  =  -13.551302877572898
training  [-4.3841, 2.6733, 1.2457]  w:  [1.53965666 1.37774561 2.16240562]
-0.3731727606022268  -  32.4639  =  -32.837072760602226
training  [2.8018, 1.712, 0.9061]  w:  [1.53965666 1.37774561 2.16240562]
8.631866260080491  -  90.1138  =  -81.48193373991951
training  [-1.6242, 2.1521, 1.6044]  w:  [1.53965666 1.37774561 2.16240562]
3.93369955099281  -  63.7879  =  -59.85420044900719
training  [1.0787, 1.4206, -4.5245]  w:  [1.53965666 1.37774561 2.16240562]
-6.165751168175342  -  18.0555  =  -24.221251168175343
training  [2.4125, -0.8095, -1.5122]  w:  [1.53965666 1.37774561 2.16240562]
-0.6708531472711714  -  38.8276  =  -39.49845314727117
training  [-3.9519, -1.0924, -0.4866]  w:  [1.53965666 1.37774561 2.16240562]
-8.641845051885184  -  3.6777  =  -12.319545051885184
training  [-3.7211, 3.1614, -2.591]  w:  [1.53965666 1.37774561 2.16240562]
-6.976404400926314  -  11.1518  =  -18.128204400926315
training  [0.4954, -1.8257, 2.1505]  w:  [1.53965666 1.37774561 2.16240562]
2.8976490353224182  -  47.7531  =  -44.85545096467759
training  [-0.1477, 3.1454, 3.5618]  w:  [1.53965666 1.37774561 2.16240562]
11.808210091351835  -  94.1572  =  -82.34898990864816
training  [3.9048, 2.8907, -2.1849]  w:  [1.53965666 1.37774561 2.16240562]
5.270060541573145  -  85.8791  =  -80.60903945842685
training  [2.9896, 3.5226, 2.3105]  w:  [1.53965666 1.37774561 2.16240562]
14.452442436951443  -  98.038  =  -83.58555756304855
training  [2.3434, 0.0564, -3.6224]  w:  [1.53965666 1.37774561 2.16240562]
-4.147361837295291  -  24.7629  =  -28.910261837295288
training  [-4.4867, 1.3566, 3.3672]  w:  [1.53965666 1.37774561 2.16240562]
2.2423243423104253  -  40.5785  =  -38.33617565768957
training  [-4.2711, 4.5089, -3.614]  w:  [1.53965666 1.37774561 2.16240562]
-8.178844304883615  -  10.0825  =  -18.261344304883615
training  [-4.1147, -0.5604, 0.8821]  w:  [1.53965666 1.37774561 2.16240562]
-5.199855920115333  -  8.344  =  -13.543855920115332
training  [2.9835, -4.3998, -1.3384]  w:  [1.53965666 1.37774561 2.16240562]
-4.362403161523697  -  13.2692  =  -17.631603161523696
training  [4.4301, 3.6675, 3.0676]  w:  [1.53965666 1.37774561 2.16240562]
18.507110495780147  -  99.3834  =  -80.87628950421984
training  [1.8372, 1.3119, 0.0378]  w:  [1.53965666 1.37774561 2.16240562]
4.717860623056052  -  74.9026  =  -70.18473937694395
training  [-3.6792, -1.4493, -0.1041]  w:  [1.53965666 1.37774561 2.16240562]
-7.886577938414736  -  4.2442  =  -12.130777938414736
training  [2.2272, 4.97, 3.7705]  w:  [1.53965666 1.37774561 2.16240562]
18.429869397926485  -  99.3199  =  -80.89003060207352
training  [-3.8965, -2.7583, -1.4686]  w:  [1.53965666 1.37774561 2.16240562]
-12.975216804293503  -  1.0337  =  -14.008916804293502
training  [-3.8251, 1.5245, -0.5056]  w:  [1.53965666 1.37774561 2.16240562]
-4.8822798047871165  -  12.9762  =  -17.858479804787116
training  [1.4072, 1.0499, 4.6353]  w:  [1.53965666 1.37774561 2.16240562]
13.636498744319308  -  95.4618  =  -81.82530125568069
training  [-1.7119, -1.1275, -4.577]  w:  [1.53965666 1.37774561 2.16240562]
-14.086476941727714  -  1.4655  =  -15.551976941727714
training  [1.5381, -3.5781, 4.7296]  w:  [1.53965666 1.37774561 2.16240562]
7.665747964988769  -  69.9473  =  -62.28155203501123
training  [2.4913, -4.7487, -3.1079]  w:  [1.53965666 1.37774561 2.16240562]
-9.427294359562811  -  3.9825  =  -13.409794359562811
training  [0.8319, -0.7889, 1.6712]  w:  [1.53965666 1.37774561 2.16240562]
3.807749138579273  -  58.8336  =  -55.02585086142072
training  [2.4003, -3.159, 0.8644]  w:  [1.53965666 1.37774561 2.16240562]
1.2125229249083325  -  39.0041  =  -37.791577075091666
training  [-2.6517, 2.2578, 1.7511]  w:  [1.53965666 1.37774561 2.16240562]
2.814554943791212  -  54.4525  =  -51.637945056208785
training  [2.3496, -1.2964, -1.3898]  w:  [1.53965666 1.37774561 2.16240562]
-1.1738434414848422  -  33.888  =  -35.06184344148484
training  [4.706, 3.4156, 1.2028]  w:  [1.53965666 1.37774561 2.16240562]
14.552393650354652  -  98.4665  =  -83.91410634964535
training  [3.6693, 2.3423, 3.1115]  w:  [1.53965666 1.37774561 2.16240562]
15.604880828810604  -  98.3069  =  -82.70201917118939
training  [-4.1377, 0.7103, -4.8074]  w:  [1.53965666 1.37774561 2.16240562]
-15.787573449582636  -  0.9782  =  -16.765773449582635
training  [-1.3356, -3.2314, -4.1613]  w:  [1.53965666 1.37774561 2.16240562]
-15.506831113264125  -  0.7659  =  -16.272731113264125
training  [-1.308, 4.5738, 4.748]  w:  [1.53965666 1.37774561 2.16240562]
14.554763840254367  -  97.0884  =  -82.53363615974563
training  [1.8503, -2.3468, 1.5135]  w:  [1.53965666 1.37774561 2.16240562]
2.888334232355387  -  50.2125  =  -47.324165767644615
training  [0.9794, 4.2458, -2.6876]  w:  [1.53965666 1.37774561 2.16240562]
1.545890707590189  -  68.3262  =  -66.78030929240981
training  [2.8936, -2.7623, -0.9651]  w:  [1.53965666 1.37774561 2.16240562]
-1.4375338401493742  -  28.5596  =  -29.997133840149374
training  [-1.3235, -1.2644, -3.7798]  w:  [1.53965666 1.37774561 2.16240562]
-11.953217907288469  -  2.4511  =  -14.404317907288469
training  [-2.9397, -4.125, -2.3156]  w:  [1.53965666 1.37774561 2.16240562]
-15.21659579398667  -  0.554  =  -15.77059579398667
training  [-4.1333, 1.4012, -2.4215]  w:  [1.53965666 1.37774561 2.16240562]
-9.669630949521691  -  4.4072  =  -14.07683094952169
training  [2.7193, -3.1938, -1.6833]  w:  [1.53965666 1.37774561 2.16240562]
-3.8534329439368973  -  17.0949  =  -20.948332943936897
training  [-2.9433, -4.5495, -3.4777]  w:  [1.53965666 1.37774561 2.16240562]
-18.31992314050826  -  0.2509  =  -18.57082314050826
training  [-1.1173, 2.2317, -1.5199]  w:  [1.53965666 1.37774561 2.16240562]
-1.9321838131078661  -  33.1206  =  -35.05278381310787
training  [0.5178, -1.5256, -3.7834]  w:  [1.53965666 1.37774561 2.16240562]
-9.485899904871484  -  5.237  =  -14.722899904871484
training  [-2.7105, 1.6062, 3.8415]  w:  [1.53965666 1.37774561 2.16240562]
6.346576799553445  -  70.4458  =  -64.09922320044656
training  [1.4194, -1.1613, -4.0572]  w:  [1.53965666 1.37774561 2.16240562]
-8.187899388932218  -  8.3206  =  -16.50849938893222
training  [-0.1552, 1.2735, 4.3004]  w:  [1.53965666 1.37774561 2.16240562]
10.814813448343052  -  90.1085  =  -79.29368655165695
training  [-3.4815, -4.7835, -1.0098]  w:  [1.53965666 1.37774561 2.16240562]
-14.134358001136569  -  0.5839  =  -14.718258001136569
training  [2.8193, 4.1057, -4.526]  w:  [1.53965666 1.37774561 2.16240562]
0.21031635295153528  -  66.8081  =  -66.59778364704846
training  [-3.9939, 3.0056, -1.5763]  w:  [1.53965666 1.37774561 2.16240562]
-5.416882522735563  -  14.4018  =  -19.818682522735564
training  [-2.0593, 2.4585, 2.3597]  w:  [1.53965666 1.37774561 2.16240562]
5.319201156074467  -  70.6698  =  -65.35059884392552
training  [-2.6263, 3.1311, 2.9468]  w:  [1.53965666 1.37774561 2.16240562]
6.642435864535935  -  77.309  =  -70.66656413546406
training  [0.3087, -1.1669, 0.4491]  w:  